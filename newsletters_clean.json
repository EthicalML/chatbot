[
    {
        "issue": "24",
        "items": [
            {
                "title": "Stanford\u2019s Deep Learning NLP Course",
                "link": "http://cs224d.stanford.edu/",
                "content": "Standford\u2019s Deep NLP Course A great time to be alive thanks to the incredible e-learning resources. Standford has made online their computer science course on Deep Learning for Natural Language Processing. All the video lectures can be found online for free - a great end-to-end introduction to the theory and practice of several cutting edge concepts. Many few alternative resources are available as well, such as Deep Mind\u2019s deep learning NLP course which can be found on Github."
            },
            {
                "title": "The data orchestration layer",
                "link": "http://www.alluxio.io/resources/whitepapers/alluxio-overview/",
                "content": "The Data Orchestration Layer Alluxio is an open source framework that provides and advocates for a data orchestration layer. This basically includes an architectural layer that is in charge of simplifying and standardising data access, making it easier for data scientists and engineers to load and interact with the right datasets. With datasets and data sources growing exponentially, this opportunity will only grow - Alluxio provides a really interesting whitepaper where they explain these challenges, and cover some of the benefits that a platform like alluxio can bring to the table."
            },
            {
                "title": "The illustrated transformer",
                "link": "http://jalammar.github.io/illustrated-transformer/",
                "content": "The Illustrated Transformer Last week we shared Jay\u2019s work on Attention in Seq2seq NLP models. This week Jay comes back with another great visual deep dive into the transformer - a model that uses attention to speed the speed in which these models can be trained."
            },
            {
                "title": "Google\u2019s people+AI guide",
                "link": "http://pair.withgoogle.com",
                "content": "People plus AI Guidebook Google released a \u201cPeople+AI\u201d guidebook where they have made available a great and extensible resource that introduces fundamental knowledge for designing human-centered AI products. The guide covers an overview of machine learning and automation, as well as more high level (and critical) topics such as data collection, explainability, trust, feedback, control, erros, feedback and more."
            },
            {
                "title": "Reproducible ML pipeliens",
                "link": "http://medium.com/comet-ml/building-a-fully-reproducible-machine-learning-pipeline-with-comet-ml-and-quilt-aa9c7bf85e72",
                "content": "Build a reproducible ML Pipeline The space on machine learning reproducibility keeps surprising us with a lot of innovative approaches - this week Cecelia Shao from CometML has put together a tutorial on how to build a reproducible machine learning pipeline using Comet.ML and Quilt. In this tutorial she shows us how we can build a Keras image classifier on a fruits dataset."
            },
            {
                "title": "GANs in action",
                "link": "http://www.manning.com/books/gans-in-action",
                "content": "GANs in Action Book This week we have seen yet another great piece of research by the Samsung AI team which has also brought a video how they are able to use this tech to bring world famous paintings (like the Mona Lisa) to life. For anyone interested to dive deeper into the world of GANs, there is a Manning book \u201cGANs in Action\u201d by Jakub Langr which has made available content for free."
            },
            {
                "title": "Industrial NLP libraries",
                "link": "http://github.com/EthicalML/awesome-machine-learning-operations",
                "content": "Industrial NLP libraries"
            }
        ]
    },
    {
        "issue": "25",
        "items": [
            {
                "title": "Google\u2019s Research Director on MLOps",
                "link": "http://www.microsoft.com/en-us/research/video/as-we-may-program/",
                "content": "Google Research on MLOps Google\u2019s current research director and former NASA chief scientist Peter Norvig dives into how machine learning will change the way we program. Peter focuses a lot on machine learning model evaluation, as well as the tools we use. You can find the hour-long video here, as well as the full slides here."
            },
            {
                "title": "A book on AutoML",
                "link": "http://www.automl.org/book/",
                "content": "The Book on AutoML AutoML provides methods and processes to make Machine Learning available for ML experts and non-experts. AutoML has achieved considerable successes in recent years and an ever-growing number of disciplines rely on it. AutoML.org provides a free e-book that covers all things around this topic, and provides extensive resources to dive into hands on use of this powerful set of tools and techniques."
            },
            {
                "title": "Deep Learning for face detection",
                "link": "http://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/",
                "content": "Deep Learning for face detection Face detection is a computer vision problem that involves finding faces in photos. In this hands-on tutorial, they provide the knowledge to understand the challenges and opportunities for face detection, as well as a hands-on example performing state-of-the-art face detection can be achieved using a Multi-task Cascade CNN via the MTCNN library."
            },
            {
                "title": "Maintainable ETL Pipelines",
                "link": "http://multithreaded.stitchfix.com/blog/2019/05/21/maintainable-etls/",
                "content": "Maintainable ETL Pipelines This great article provides a set of tips and best practices to structure your ETL data pipelines to ensure they are scalable and maintainable in the medium and longer term. The tips provided consist of 4 key themes: 1) Building a chain of simple tasks, 2) using a workflow management tool, 3) leveraging SQL where possible and 4) implementing data quality checks."
            },
            {
                "title": "Counterfactuals for XAI",
                "link": "http://docs.seldon.io/projects/alibi/en/v0.2.0/methods/CF.html",
                "content": "Counterfactuals for Explainable AI A counterfactual explanation describes a causal situation in the form: \u201cIf X had not occurred, Y would not have occurred\u201d. In interpretable machine learning, counterfactual explanations can be used to explain predictions of individual instances. Seldon\u2019s Interpretable Machine Learning Library Alibi has launched its v0.2.0 version which contains Counterfactual explanations, and provides an example of how to find counterfactual instances using the MNIST dataset."
            },
            {
                "title": "Semi-supervised machine learning",
                "link": "http://towardsdatascience.com/the-quiet-semi-supervised-revolution-edec1e9ad8c",
                "content": "The Semi-Supervised Revolution One of the most familiar settings for a machine learning engineer is having access to a lot of data, but modest resources to annotate it. Everyone in that predicament eventually goes through the logical steps of asking themselves what to do when they have limited supervised data, but lots of unlabeled data, and the literature appears to have a ready answer: semi-supervised learning. This post provides a brief introduction to the concept of semi-supervised machine learning, as well as references to papers that provide an insight on this topic."
            }
        ]
    },
    {
        "issue": "26",
        "items": [
            {
                "title": "PyTorch Hub for Reproducible ML",
                "link": "http://pytorch.org/blog/towards-reproducible-research-with-pytorch-hub/",
                "content": "PyTorch Hub + Reproducible ML Reproducibility is an essential requirement for many fields of research including those based on machine learning techniques. PyTorch has released PyTorch Hub, where the community can now share models built with PyTorch. This new great resource also has built-in support for Colab, integration with Papers With Code and currently contains a broad set of models that include Classification and Segmentation, Generative, Transformers, and beyond \ud83d\ude80."
            },
            {
                "title": "A free course on privacy preserving ML",
                "link": "http://eu.udacity.com/course/secure-and-private-ai--ud185",
                "content": "Privacy-preserving AI free course What a time to be alive for life-long learners - a brand new Free online course has been made available by Facebook AI on hands down some of the most exciting topics in this space: Federated Learning, Differential Privacy and Encrypted computation. This course teaches you how to leverage open source tools to explore these topics on an introductory level. Really awesome to see this type of content be made available freely."
            },
            {
                "title": "MLFlow for pipeline management",
                "link": "http://thenewstack.io/databricks-mlflow-aims-to-simplify-management-of-machine-learning-pipelines/",
                "content": "MLFlow for pipeline management MLflow from Databricks is an open source framework that addresses some of the biggest challenges in machine learning, including configuring environments, tracking experiments, and deploying trained models for inference. This post provides a high level overview on this framework as well as useful links to get started trying it out."
            },
            {
                "title": "E2E NLP Pipelines with Kubeflow & Seldon",
                "link": "http://github.com/SeldonIO/seldon-core/tree/master/examples/kubeflow",
                "content": "E2E NLP Pipelines with Kubeflow End to end pipelines are always a challenge in the data science space. Kubeflow is an open source framework that hells you run reproducible ML workloads in Kubernetes. This example showcases and end-to-end NLP pipeline leveraging re-usable components that utilize key frameworks such as the SpaCy NLP library to perform automation of text analysis, as well as serving the models using Seldon."
            },
            {
                "title": "The brains behind SpaCy",
                "link": "http://www.analyticsvidhya.com/blog/2019/06/datahack-radio-ines-montani-matthew-honnibal-brains-behind-spacy/",
                "content": "The Brains behind SpaCy The DataHack team has put together a great podcast where they bring the co-founders of Explosion.ai, and authors of SpaCy to talk about the story behind this popular framework. During this 40 minute episode, they dive into the idea behind developing spaCy, spaCy\u2019s evolution from the first alpha release, use cases of spaCy including a couple of surprising applicationsInes, and Matt\u2019s advice to NLP enthusiasts."
            }
        ]
    },
    {
        "issue": "27",
        "items": [
            {
                "title": "Distributed AI made easy with Ray",
                "link": "http://bair.berkeley.edu/blog/2018/01/09/ray/",
                "content": "Distributed AI made easy w Ray Last week we attended China\u2019s first Ray meetup, and had a huge pleasure to see Ion Stoica, Apache Spark founder and Databricks Chairman, presenting a technical deep dive on Ray, followed by a set of great talks from Alibaba, Didi and Ant Financial engineeering leaders on Ray usecases. Ray is a fast and simple framework for building and running distributed applications, and comes in with a broad set of tools including Tune (Rapid Hyperparam search), RLib (Scalable Reinforcement Learning), and Distributed Training, between several other features."
            },
            {
                "title": "Model interpretation with Alibi",
                "link": "http://changelog.com/practicalai/48",
                "content": "Model Interpretation with Alibi Janis Klaise, Data Scientist at Seldon, joins Daniel Whitenack and Chris Benson on their Practical AI podcast to talk about the challenges of production machine learning, and how Seldon is tackling the challenge with open source particularily in the theme of explainable machine learning with Alibi Black Box Model Explanations. Janis provides an introduction to the challenges of production machine learning, as well as the different approaches that can be used in machine learning explainability."
            },
            {
                "title": "Principled Machine Learning",
                "link": "http://dev.to/robogeek/principled-machine-learning-4eho",
                "content": "Principled Machine Learning A great blog post that summarises a set of principles presented at a talk by Patrick Ball with the Data & Society Research Institute titled Principled Data Processing. Transparency, accountability, reproducibility and scalability, which truly resonate with our 8 principles for responsible machine learning."
            },
            {
                "title": "Deep learning vs classical for time series",
                "link": "http://github.com/SeldonIO/seldon-core/tree/master/examples/kubeflow",
                "content": "Comparing Time Series Models Machine learning mastery comes back this week with a deep dive analysing results of classical and machine learning methods for time series analysis. In this post, James three key things: 1) classical methods like ETS and ARIMA out-perform ML/DL methods for one-step forecasting on univariate datasets, 2) How classical methods like Theta and ARIMA outperform DL,ML models for multi-step forecasting on univariate datasets, and how ML/DL methods do not yet deliver on their promse for univariate time series forecasting."
            },
            {
                "title": "The quest for high quality data",
                "link": "http://www.oreilly.com/ideas/the-quest-for-high-quality-data",
                "content": "The quest for high-quality data Ben Lorica and Ihab Ilyas bring us an excellent piece this week covering machine learning solutions for data integration, cleaning, and data generation, which are quickly gaining traction and popularity. This post covers fundamental topics like data integration / cleaning, data programming and https://www.oreilly.com/ideas/the-quest-for-high-quality-datamarket validation."
            },
            {
                "title": "Open source libraries for adversarial robustness",
                "link": "https://github.com/EthicalML/awesome-production-machine-learning#adversarial-robustness-libraries",
                "content": "OSS: Adversarial Robustness The theme for this week\u2019s featured ML libraries is Adversarial Robustness, which includes tools for adversarial attacks and adversarial security. These libraries are an incredibly exciting addition that fall in our Responsible ML Principle #8, and the whole section was contributed by one of the Fellows at the Institute Ilja Moisejevs from Calipso AI. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "28",
        "items": [
            {
                "title": "The state of AI in 2019",
                "link": "http://www.stateof.ai/?fbclid=IwAR0AAhweykbVQMw28mVFLc7Tl1SMQGM_IiBpk6a_jeiODm1vnTEFbg8UfUg",
                "content": "The state of AI in 2019 Nathan Benaich and Ian Hogarth bring us the report outlining the state of AI in 2019, which aims to provide an overview on the current state and advances in 5 key areas: research, talent, industry, china and politics. This annual report covers the most interesting things that they have seen in the last 12 years. You can also find last year\u2019s report here."
            },
            {
                "title": "Production machine learning in 2019",
                "link": "http://github.com/EthicalML/state-of-mlops-2019/",
                "content": "Production ML in 2019 During Kubecon Shanghai 2019 we presented a high level overview of the themes that are growingly becoming critical in the world of production machine learning. This includes over 10 themes which expand over explainability, privacy, model versioning, adversarial robustness and beyond. This repository contains a set of slides that dive into three key themes: black box explainability, model versioning and ML orchestration. For each of these themes, there is a high level explanation, together with a hands on example with a Jupyter notebook, including an end-to-end NLP pipeline, tabular explainers and a pytorchhub integration."
            },
            {
                "title": "Model governance and operations",
                "link": "http://www.oreilly.com/ideas/what-are-model-governance-and-model-operations",
                "content": "Model governance and ops Machine learning at scale introduces new challenges, as managing a large number of models that perform increasingly critical tasks becomes more complex. O\u2019Reilly Chief Scientist Ben Lorica has put together a great overview of the ecosystem and tools available in the machine learning governance and operations world."
            },
            {
                "title": "The best of modern NLP",
                "link": "http://medium.com/huggingface/the-best-and-most-current-of-modern-natural-language-processing-5055f409a1d1",
                "content": "The best of modern NLP Hugging face scientist Victor Sanh has put together an extensive list of resources related to key themes in NLP, including transfer learning, representation learning, neural dialogue, as well as other miscellaneous pieces of research that have contributed to the growth of the field in the last two years."
            },
            {
                "title": "Adversarial examples with FGSM",
                "link": "http://www.tensorflow.org/beta/tutorials/generative/adversarial_fgsm",
                "content": "Adversarial examples with FGSM Tensorflow tutorials has launched a new deep dive on adversarial examples, which covers the conceptual, theoretical and practical aspect of this topic. It provides the code for you to find an adversarial example which could trick a classifier."
            }
        ]
    },
    {
        "issue": "29",
        "items": [
            {
                "title": "The state of AI in 2019",
                "link": "http://www.stateof.ai/?fbclid=IwAR0AAhweykbVQMw28mVFLc7Tl1SMQGM_IiBpk6a_jeiODm1vnTEFbg8UfUg",
                "content": "The state of AI in 2019"
            },
            {
                "title": "Production machine learning in 2019",
                "link": "http://github.com/EthicalML/state-of-mlops-2019/",
                "content": "Production machine learning in 2019"
            },
            {
                "title": "Model governance and operations",
                "link": "http://www.oreilly.com/ideas/what-are-model-governance-and-model-operations",
                "content": "Model governance and operations"
            },
            {
                "title": "The best of modern NLP",
                "link": "http://medium.com/huggingface/the-best-and-most-current-of-modern-natural-language-processing-5055f409a1d1",
                "content": "The best of modern NLP"
            },
            {
                "title": "Adversarial examples with FGSM",
                "link": "http://www.tensorflow.org/beta/tutorials/generative/adversarial_fgsm",
                "content": "Question-answering AI in K8s Intel Software Innovator Daniel Whitenack has put together an awesome production-level framework with modular functionality to perform\u00a0question-answering ML inference on top of Kubernetes. They\u2019ve put toether a brief screencast that showcase how you can interact with it, as well as a Arxiv research paper with full details on the framework."
            }
        ]
    },
    {
        "issue": "30",
        "items": [
            {
                "title": "Production-level ML Explainers",
                "link": "http://github.com/EthicalML/explainability-and-bias/",
                "content": "Production-level ML Explainers This week we presented at PyData London and EuroPython Basel on produciton-level machine learning model explainers, which is an approach to leverage explanations end-to-end with the purpose to align with higher level frameworks like regulation or industry standards. The slides are available online and include code examples for data analysis with XAI, black box model analysis with Alibi and production explainers with Seldon."
            },
            {
                "title": "AI Explanations with Counterfactuals",
                "link": "http://arxiv.org/abs/1907.02584",
                "content": "AI Explanations w Counterfactuals An awesome research paper published in Arxiv this week by Seldon Data Scientists Arnaud Van Looveren and Janis Klaise titled \u201cInterpretable Counterfactual Explanations Guided by Prototypes\u201d. This paper dives into the concept of counterfactuals, which is an ML local model explanation technique that allows you to ask the question \u201cfor this ML prediction, what could be the smallest changes I could do to the input to change the outcome?\u201d. Being such a computationally expensive task, this paper proposas a new approach to reduce the computational resources required to use this technique."
            },
            {
                "title": "Flat light: Privacy & Cybersecurity Merging",
                "link": "http://www.lawfareblog.com/flat-light-data-protection-disoriented-policy-practice",
                "content": "Privacy & Cybersecurity Merging One of the most interesting white papers so far, written by Immuta\u2019s Chief Privacy Officer Andrew Burt. This paper covers critical topics on privacy and cybersecurity, as well as how these topics have been changing as we move into massive scale production systems. This paper also provides great historical case studies that provide an insight of how important conceptual shifts and standardisation of thses concepts will be."
            },
            {
                "title": "Hightlights of AI O\u2019Reilly Beijing",
                "link": "http://www.oreilly.com/ideas/highlights-from-ai-beijing-2019",
                "content": "Hightlights of AI O\u2019Reilly Beijing O\u2019Reilly\u2019s Ben Webb brings us a great high level overview of some of the key keynotes at the AI O\u2019Reilly Beijing. Some of these include the future of hiring in AI, RISELab innovations, breakthroughs, data orchestration, AI in retail, data structures and more."
            },
            {
                "title": "18 Impressive GAN Applications",
                "link": "http://machinelearningmastery.com/impressive-applications-of-generative-adversarial-networks/",
                "content": "18 Impressive GANs Applications Great post from Machine Learning Mastery that dives into the more practical side of GANs. This article covers use-cases of GANs across various datasets of image and text types."
            }
        ]
    },
    {
        "issue": "31",
        "items": [
            {
                "title": "End-to-end XAI in production",
                "link": "http://www.youtube.com/watch?v=vq8mDiDODhc",
                "content": "End-to-end XAI in production Our PyData London talk last week is now on youtube, where we spoke about end-to-end machine learning explainability techniques with an emphasis on production. During this talk we covered the tools and approaches you can take to tackle machine learning explainability in data and models. We also introduced the concept of production ML explainer design patterns which abstract the XAI techniques so they can use at scale across live models in production."
            },
            {
                "title": "Causal inference for UX",
                "link": "http://eng.uber.com/causal-inference-at-uber/",
                "content": "Causal inference to improve UX Excellent and comprehensible post by Uber Engineering on how they use Causal Inference techniques to improve user experience. In this post they introduce the importance of the topic, as well as a deep dive on key causal inference techniques including: compiler average cuasal effect (CACE), CUPED / Diff-in-diff propensity score matching (IPTW), Heterogeneus treatment effect Uplift modeling, quantile regression and mediation modelling. An excellent post that covers the theoretical and practical perspectives of causal inference techniques."
            },
            {
                "title": "ML in enterprise",
                "link": "http://www.oreilly.com/ideas/managing-machine-learning-in-the-enterprise-lessons-from-banking-and-health-care",
                "content": "Managing ML in enterprise Excellent post by the O\u2019Reilly team covering key lessons learned from the field from managing production machine learning systems in the financial and healthcare sectors. Historically these two sectors (and the financial sector in particular) tends to lead the way on technology adoption, so it\u2019s often great to take some of the learnings obtained introducing innovations to the sector, and abstract them to help introduce innovations into other sectors (such as transport, energy, construction, etc)."
            },
            {
                "title": "Adversarial Robustness",
                "link": "http://towardsdatascience.com/evasion-attacks-on-machine-learning-or-adversarial-examples-12f2283e06a1",
                "content": "Intro to Adversarial Examples Great high level introduction on the topic of Adversarial Robustness, which provides an introduction to this topic, as well as case studies and examples that showcase the importance of this branch of techniques. The post breaks down evasion attacks into five separate classes: gradients, confidence scores, hard labels, surrogate models and brute force."
            },
            {
                "title": "The GANs story so far",
                "link": "http://blog.floydhub.com/gans-story-so-far/",
                "content": "The GAN Story so far Great article which provides a very comprehensible overview of the recent history of Generative Adversarial Networks. GANs, DCGANs, CGANs, CycleGANs, CoGANs, ProGANs, WGANs, SAGANs, BIgGANs and StyleGANS - GANS EVERYWHERE!"
            }
        ]
    },
    {
        "issue": "32",
        "items": [
            {
                "title": "End-to-end ML Pipelines in Enterprise",
                "link": "http://www.oreilly.com/ideas/enabling-end-to-end-machine-learning-pipelines-in-real-world-applications",
                "content": "E2e ML Pipelines in Enterprise IBM Principal Engineer Nick Pentreath and Ben Lorica dive into end-to-end machine learning pipelines, and discuss the challenges and opportunities unlocking the potential of machine learning at scale. During this conversation, they cover fundamental topics not only in the training phase of machine learning but also focus on the deployment, monitoring and governance of machine learning systems at scale. An excellent overview + deep dive on an incredibly important topic."
            },
            {
                "title": "Code-free deep learning with Ludwig",
                "link": "http://eng.uber.com/introducing-ludwig/",
                "content": "Code-free deep learning Ludwig Uber engineering is making deep learning more accessible through their open source code-free deep learning framework called Ludwig. As they mention, Ludwig is unique in its ability to help make deep learning easier to understand for non-experts and enable faster model improvement iteration cycles for experienced machine learning developers and researchers alike. Of course, with great powers comes great responsibility, so we recommend any new-commers to the deep learning world to check out and follow our 8 principles for responsible Machine Learning."
            },
            {
                "title": "ML Reidentification and Privacy Issues",
                "link": "http://www.nature.com/articles/s41467-019-10933-3",
                "content": "ML Reidentification and Privacy An incredibly insightful research paper which could have a significant impact in privacy, where they propose a method that can accurately estimate the likelihood of a specific person to be correctly re-identified, even in a heavily incomplete dataset. Some of their results are impressive: \u201cUsing our model, we find that 99.98% of Americans would be correctly re-identified in any dataset using 15 demographic attributes\u201d. With the rise of privacy protection laws such as GDPR, it will be important to consider these kind of loopholes and semi-indirect (but still fully relevant) challenges."
            },
            {
                "title": "How OSS and AI will take us to the moon",
                "link": "http://venturebeat.com/2019/07/20/how-open-source-and-ai-can-take-us-to-the-moon-mars-and-beyond/",
                "content": "OSS + AI will take us to the Moon Great positive take by Venturebeat on two of the biggest changers in technology in 2019, open source and artificial intelligence. In this article they cover openess and collaboration, the spaceborne computer example, open source software+hardware and augmenting human capability with AI."
            },
            {
                "title": "Managing large-scale distributed systems",
                "link": "http://blog.pragmaticengineer.com/operating-a-high-scale-distributed-system/",
                "content": "Large Scale Distributed Systems Yet another great article by one of Uber Engineering Manager Gergely Orosz on \u201cOperating a Large, Distributed System in a Reliable Way\u201d. In this article Gergely takes us in a high level overview of the key themes he has identified managing the payments system at Uber. In this post he covers fundamental (and super interesting concepts) including Monitoring, Oncall, Anomaly Detection, Alerting, Outages, Incident Management Processes, Postmortems, Incident Reviews, a Culture of Ongoin, Improvements, Failover Drills, Capacity Planning & Blackbox Testing and more (much, much more)."
            },
            {
                "title": "Stream Processing OSS Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Stream Processing OSS Libraries"
            }
        ]
    },
    {
        "issue": "33",
        "items": [
            {
                "title": "Data streaming at scale with Brooklin",
                "link": "http://engineering.linkedin.com/blog/2019/brooklin-open-source",
                "content": "Brooklin for data streaming Linkedin open sources Brooklin, a distributed service for streaming data in near real-time at scale, currently powering over 2 trillion messages per day at Linkedin. Data streaming is truly driving the way for real-time machine learning usecases. This is also a very interesting project, primarily as it doesn\u2019t aim to replace OSS projects like Kafka, instead it sits on a higher level providing a primary solution for streaming across various stores and messaging systems (Kafka, Azure Events Hub, Kinesis, etc). In this post, they showcase how Brooklyn can be used as a streaming bridge across these heterogeneous messaging services, as well as mirroring kafka functionality, and beyond."
            },
            {
                "title": "Tensorflow AI interpretability",
                "link": "http://blog.sicara.com/tf-explain-interpretability-tensorflow-2-9438b5846e35?gi=6a3bde675a49",
                "content": "Tensorflow AI Interpretability The tensorflow team enters the ML model interpretability arena with TFExplain - a library that offers interpretability methods to understand model predictions. The library is adapted to the Tensorflow 2.0 workflow, using tf.keras API as possible, prividing: 1) heatmap visualisations & gradient analysis, 2) off-training & keras.callback usages, and 3) tensorboard integration."
            },
            {
                "title": "Smart City revolution with OSS LiDAR",
                "link": "http://v-sense.scss.tcd.ie/dublincity/",
                "content": "LIDAR and its smart applications A project that would have considered a dream for smart-city enthusiast has been fully open sourced. The Urban Modelling Group at University College Dublin has captured major area of Dublin city centre (around 5.6km^2) and made available as the densest LiDAR point cloud and imagery dataset (260m points out of 1.4b are labelled)."
            },
            {
                "title": "All hail the (AI) algorithm",
                "link": "http://interactive.aljazeera.com/aje/2019/hail-algorithms/index.html",
                "content": "All hail the (AI) algorithm A five-part video series released by Aljazeera covering high level concepts that break down some of the biggest challenges in AI through a mainstream media lens. The five parts basically break down into: 1) Trust & bias, 2) Big Tech monopolies, 3) Missinformation, 4) Surveilance, and 5) Regulation around data & privacy."
            },
            {
                "title": "Machines gone wrong",
                "link": "http://machinesgonewrong.com/#start",
                "content": "Machines (and AI) Gone Wrong An excellent project that tries to simplify one of the most popular concepts around machine learning. \u201cMachines gone wrong\u201d covers foundational topics in the challenges of AI such as an explanation of AI ethics, why AI is different when talking about these issues, as well as some key themes like algorithmic bias."
            },
            {
                "title": "Stream Processing OSS Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Stream Processing OSS Libraries"
            }
        ]
    },
    {
        "issue": "34",
        "items": [
            {
                "title": "A survey on the state of AutoML",
                "link": "http://arxiv.org/abs/1908.00709",
                "content": "A survey on the state of AutoML An extensive and interesting deep dive into the AutoML ecosystem, together with the techniques, tools and challenges that this area in machine learning will face, including end-to-end pipelines, interpretability, reproducibility and beyond."
            },
            {
                "title": "Got Speech? Voice Applications 101",
                "link": "http://www.oreilly.com/ideas/got-speech-these-guidelines-will-help-you-get-started-building-voice-applications",
                "content": "Got speech? Voice Applications O\u2019Reilly\u2019s Ben Lorica and Yishay Carmiel have put together a 101 for building voice applications. They break down the voice applications into dialogue vs monologues and human2human vs human2machine, and into some of the challenges, applications, and potential."
            },
            {
                "title": "Cloud native kubernetes semantic search",
                "link": "http://gnes.ai/",
                "content": "Cloud native semantic text search A really exciting new open source framework brings industrial NLP functionality for text search. GNES [jee-nes] is a cloud-native semantic search system based on deep neural network. It enables large-scale index and semantic search for text-to-text, image-to-image, video-to-video and any content form. Certainly an exciting space for content search at massive scale."
            },
            {
                "title": "Learning from adversaries in AI",
                "link": "http://www.oreilly.com/ideas/learning-from-adversaries",
                "content": "Learning from adversaries In machine learning adversarial attacks are becoming an increasing worry in production-level applications. This interesting article proposes that adversarial images aren\u2019t 100% a problem\u2014they\u2019re an opportunity to explore new ways of interacting with AI. This is an interesting space, as some of the work we have been doing has provided some correlations around explainability/interpretability techniques in AI, and adversarial attacks, where the ultimate objective is to reverse-engineer models (with different ultimate outcomes of course)."
            },
            {
                "title": "Python-compatible spreadsheets for data science",
                "link": "http://hackernoon.com/introducing-grid-studio-a-spreadsheet-app-with-python-to-make-data-science-easier-tdup38f7",
                "content": "Python-compatible spreadsheets An engineer approach into a data science challenge - Rick Lamers has built a python-first open source spreadsheet application. In this blog post he shows how you are able to leverage the full power of the spreadsheets, together with functionality that python makes available, such as scraping, performing pre-/post-processing, etc. Really interesting project which does seem to offer quite a lot of potential for expansion."
            },
            {
                "title": "Neural Network Search AutoML",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning#neural-architecture-search",
                "content": "OSS: NN Architecture AutoML The theme for this week\u2019s featured ML libraries is Neural Network Architecture AutoML, which you can find in our Production Machine Learning ecosystem list. These libraries are an incredibly exciting addition that fall in our Responsible ML Principle #4. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "35",
        "items": [
            {
                "title": "The future of data engineering",
                "link": "http://riccomini.name/future-data-engineering",
                "content": "The future of Data Engineering Great insight into the near future of data engineering covering the current transformations that this role has been undergoing, as well as some of the trends that will become more prominent in the immediate and medium term for data engineers. The article covers the transition from batch into realtime, the exponential increase of connectivity, automation, descentralisation and beyond."
            },
            {
                "title": "A self study journey towards machine learning",
                "link": "http://towardsdatascience.com/6-techniques-which-help-me-study-machine-learning-five-days-per-week-fb3e889fad80",
                "content": "From self study to ML Engineering Former Apple engineer shares his experience transitioning into a machine learning full time role. In this article he shares 6 techniques that helped him study machine learning 5 days a week. This includes reducing search space, fixing your environment, setting up your system, work smart, embrace being stuck and the 3-year old principle."
            },
            {
                "title": "12 NLP researchers to follow",
                "link": "http://www.kdnuggets.com/2019/08/nlp-researchers-practitioners-innovators-should-follow.html",
                "content": "12 NLP Researchers to Follow If you are interested in NLP, KDNuggets has put together an excellent list of 12 NLP researchers to follow to stay up to date with some of the latest cutting edge tools and research in this field. The list includes some really great practitioners and researchers, including Explosion (and SpaCy) cofounders Matt Honibal & Ines Montani, DeepMind Researcher Sebastian Ruder, FastAI founder Jeremy Howard and more."
            },
            {
                "title": "N-shot learning with small-data",
                "link": "http://blog.floydhub.com/n-shot-learning/",
                "content": "N-Shot Learning with Small Data N-Shot Learning is very exciting area of research which focuses on tackling challenges with \u201cSmall Data\u201d. That is, using n-data examples. These can be from zero-shot learning - zero examples - to 1-short, to few-shot, etc. This is an interesting challenge as it requires a lot of the domain expertise and in an abstract sense the concept of intuition to be embedded in the algorithms to be able to abstract insights that would otherwise be missed by vanilla deep learning (or even traditional machine learning) algorithms."
            },
            {
                "title": "Causal inference with counterfactuals",
                "link": "http://www.inference.vc/causal-inference-3-counterfactuals/",
                "content": "Causal Inference: Counterfactuals Excellent piece by Twitter\u2019s Ferenc Husz\u00e1r on Counterfactuals. Counterfactuals is an incredibly interesting technique that falls within the causal inference family. This technique has been growing in popularity especially due to its intuitive explanatory power. From a high level definition, a counterfactual asks the question around \u201cwhat would be the minimum change that I could make to change the outcome\u201d. In machine learning this has great predictive power."
            },
            {
                "title": "Neural Network Search AutoML",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning#neural-architecture-search",
                "content": "OSS: NN Architecture AutoML The theme for this week\u2019s featured ML libraries is Neural Network Architecture AutoML, which you can find in our Production Machine Learning ecosystem list. These libraries are an incredibly exciting addition that fall in our Responsible ML Principle #4. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "36",
        "items": [
            {
                "title": "The state of federated machine learning",
                "link": "http://arxiv.org/abs/1908.07873",
                "content": "The state of Federated Learning Federated learning involves training machine learning models distributed over remote devices or siloed data centers (this could be mobile phones or even hospitals, while keeping data localized). Training in heterogeneous and potentially massive networks introduces a lot of new challenges. This great article dives into the unique characteristics and challenges of federated learning, together with current approaches and future work."
            },
            {
                "title": "Data science best practices",
                "link": "http://syslog.ravelin.com/data-science-best-practices-843c9693db8",
                "content": "Data Science Best Practices It\u2019s easy and fun to ship a prototype, whether that\u2019s in software or data science. What\u2019s much, much harder is making it resilient, reliable, scalable, fast, and secure. This article brings some of the best practices identified by the team at Ravelin. Their data science guidelines include:: 1) all starters will build, train and deploy production models within a week, 2) leverage humans whilst automating manual work, 3) deploy models incrementally and often, 4) end users will never notice a model change other than improved results."
            },
            {
                "title": "Career progression of a data scientist",
                "link": "http://medium.com/sequoia-capital/progression-of-a-data-scientist-e1bebf8c8420",
                "content": "Progression of a Data Scientist Sequoia has put together a great overview of the career progression of a data scientist - specifically they examine what characteristics senior product data scientists have relative to junior ones, and why a healthy data-informed company should invest in the development of their data scientists. The article covers the key \u201cfive core skills\u201d of a data scientist, how data scientists advance, common questions in data science, and key takeaways."
            },
            {
                "title": "A 3 year retrospective on observability",
                "link": "http://thenewstack.io/observability-a-3-year-retrospective/",
                "content": "Observability 3 year retrospective Incredibly insightful deep dive into the topic of observability, which discusses terminology, challenges and key insights. It emphasises that metrics do not equal observability, and provides key terms such as cardinality for system insights, and covers some of the present and future of this very important topic."
            },
            {
                "title": "Introduction to the transformer architeture",
                "link": "http://rubikscode.net/2019/07/29/introduction-to-transformers-architecture/",
                "content": "Intro to transformer architecture Transformers are popular (and effective) sequence-to-sequence models used for language modeling, machine translation, image captioning and text generation. This article covers key concepts, including RNNs, LSTMs, attention, self-attention and then cover how these all fit togethers in the transfoerm architecture."
            },
            {
                "title": "Industry-strength NLP Frameworks",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning#industrial-strength-nlp",
                "content": "OSS: Industry-strength NLP \u00a0 The theme for this week\u2019s featured ML libraries is Industry-strength NLP, and we\u2019re happy to announce that we have added over 10 new libraries to the section. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "37",
        "items": [
            {
                "title": "Real Time NLP & ML with Spacy, Spark and Kafka",
                "link": "http://infoshare.pl/news/one,66,254,126,infoshare-alejandro-saucedo-real-time-nlp-machine-learning-with-spark-streaming-kafka-and-spacy.html",
                "content": "Real Time NLP: Spacy and Kafka The need for real time machine learning use-cases in production is increasing. This talk provides practical insight on how to build real time data streaming machine learning pipelines that are production ready, covering a case study performing automated content moderation on Reddit comments in real time. The talk dives into fundamental concepts of stream processing such as windows, watermarking and checkponting, and show how to use frameworks like Kafka, Spacy and Spark Streaming."
            },
            {
                "title": "Becoming an ML practitioner",
                "link": "http://www.oreilly.com/ideas/becoming-a-machine-learning-practitioner",
                "content": "Becoming an ML practitioner O\u2019Reilly comes with an awesome podcast, talking with Kesha Williams, technical instructor at A Cloud Guru, a training company focused on cloud computing. As a full stack web developer, Williams became intrigued by machine learning and started teaching herself the ML tools on Amazon Web Services. Fast forward to today, Williams has built some well-regarded Alexa skills, mastered ML services on AWS, and has now firmly added machine learning to her developer toolkit."
            },
            {
                "title": "Cracking the black box with interpretability techniques",
                "link": "http://opendatascience.com/cracking-the-box-interpreting-black-box-machine-learning-models/",
                "content": "Cracking the black box (XAI) Great overview on the concept, techniques and key areas in machine learning interpretability. This article covers several classes of interpretability methods such as model-specific vs model-agnostic, techniques such as partial dependency plots, permutation importance, anchors, and more,"
            },
            {
                "title": "Notebook innovation (and infrastructure) at Netflix",
                "link": "http://medium.com/netflix-techblog/notebook-innovation-591ee3221233",
                "content": "Notebook innovation at Netflix Notebooks have rapidly grown in popularity among data scientists to become the de facto standard for quick prototyping and exploratory analysis.This post provides a very interesting insight on the infrastructure and processes that Neflix has introduced internally around Notebooks and data. This article covers the processes that involve the roles of analysts, data scientists and data engineers, as well as the challenges with data access, templates and infrastructure."
            },
            {
                "title": "How AI solves scale complexities",
                "link": "https://thenewstack.io/how-ai-solves-the-kubernetes-complexity-conundrum/",
                "content": "How AI solves scale complexities How AI Solves the Kubernetes Complexity Conundrum. A really interesting article from the new stack that dives into the challenges and complexities that the introduction of kubernetes has brought to the tech world, and makes a high level case on how AI will help manage some of the key complexities that the scale of kubernates-based systems will entail."
            },
            {
                "title": "Industry-strength NLP Frameworks",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning#industrial-strength-nlp",
                "content": "OSS: Industry-strength NLP \u00a0 The theme for this week\u2019s featured ML libraries is Industry-strength NLP, and we\u2019re happy to share brand new libraries into that section. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "38",
        "items": [
            {
                "title": "Continuous delivery for machine learning",
                "link": "http://martinfowler.com/articles/cd4ml.html",
                "content": "Continuous Delivery for ML Great article from martinfowler.com tackling the challenge of Automating the end-to-end lifecycle of Machine Learning applications. As we have seen, the process for developing, deploying, and continuously improving them is more complex compared to more traditional software. This article proposes Continuous Delivery for Machine Learning (CD4ML), which is explained as the discipline of bringing Continuous Delivery principles and practices to Machine Learning applications."
            },
            {
                "title": "What is AIOps and why you should care",
                "link": "http://thenewstack.io/what-is-aiops-and-why-you-should-care/",
                "content": "AIOps and why you should care The first of a two-part series on the emerging concept of AIOps. Whilst a lot of articles that we reference focus on the productionisation techniques and hence \u201cDevOps for ML\u201d, the keyword of AIOps is growingly used to refer to applying ML to DevOps. Key examples of this would be to leverage concept drif, outlier detection, explanations and beyond. Although there is still ambiguity with these terms and concepts, here the new stack provides a deep dive on these increasingly discussed topics."
            },
            {
                "title": "Language models as knowledge bases",
                "link": "https://arxiv.org/abs/1909.01066",
                "content": "Lang models as knowledge bases Interesting perspective on how the potential of languge models can be generalised. In this paper, the authors argue that language models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as \u201cfill-in-the-blank\u201d cloze statements. They suggest that language models have advantages over structured knowledge bases, and they propose the \u201cLAMA (LAnguage Model Anal-ysis) probe\u201d to test the factual and commonsenseknowledge in language models. They have also made their code available open source."
            },
            {
                "title": "AWS Data Security best practices",
                "link": "http://datafloq.com/read/best-practices-for-data-security-in-aws/6804",
                "content": "AWS data security best practices In AI data is key, and with growing usecases it\u2019s key to ensure your security is aligned with best practices. Great article that outlines (as more of a reminder) a set of simple principles to follow as best practices when handling data in AWS (although it could also apply to other clouds)."
            },
            {
                "title": "A smooth approach to production ML",
                "link": "https://maxhalford.github.io/blog/a-smooth-approach-to-putting-machine-learning-into-production/",
                "content": "A smooth approach to prod ML Another great artcile that dives into the challenges of dealing with production machine learning system. In this article there are multiple areas discussed, including a dissection of the \u201clambda architecture\u201d, online learning, and a few other topics. The article also shares some lessons learned, and covers some hands on examples using a really interesting library called \u201ccreme\u201d."
            },
            {
                "title": "ML Explainability libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: Explainability Libraries \u00a0 The theme for this week\u2019s featured ML libraries is ML Explainability, and we\u2019re happy to share brand new libraries into that section. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "39",
        "items": [
            {
                "title": "Management insights for data science",
                "link": "http://towardsdatascience.com/everything-a-data-scientist-should-know-about-data-management-6877788c6a42",
                "content": "Management for Data Science Management in data science teams has become a big challenge in organisations looking to introduce and grow their data science teams. This article provides an excellent ground up overview of management, from a practical perspective. It first introduces high level concepts you have probably come across, but then dives into a hands on case study building end-to-end data science infrastrtructure for a recommendation app startup, detailing the stakeholders involved, together with interactions and processes."
            },
            {
                "title": "Outlier selection vs detection",
                "link": "http://koaning.io/posts/outliers-selection-vs-detection/",
                "content": "Selection vs Detection of outliers Anomaly detection algorithms have been gaining popularity due to their practical use beyond traditional areas like fraud detection. In this context, this article does a great job defining nuanced terminology involved in this area - namely the difference between selection versus detection of outliers. The blog provides code that allows you to leverage sklearn\u2019s algorithms to approach these challenges with a \u201cone size fits all\u201d approach, that encompasses a pattern that can generalise into other techniques that could be useful in similar contexts."
            },
            {
                "title": "10 rules for sharing notebooks",
                "link": "http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007007",
                "content": "Rules for sharing notebooks With a fast increase in adoption of Jupyter (and other) notebook technologies, there has also been an increase in complexity around collaborating and maintaining notebooks. Last week we showed how Netflix tackles their challenges with data and software infrastructure. This week, we see another great piece that instead proposes 10 rules you can follow as an individual to make your notebooks easier to digest, maintain and extend."
            },
            {
                "title": "AutoML and AI at Google",
                "link": "http://changelog.com/practicalai/55",
                "content": "AutoML and AI at Google Large scale use of machine learning has introduced new complexities - with that, there has been a large amount of manual work that comes when finding the best parameters for an ML algorithm (such a neural network, random forest classifier and beyond). Practical AI brings us an excellent podcast from Google\u2019s Sheron Chen diving into AutoML and AI at Google, covering some of the most popular topics in machine learning at this time."
            },
            {
                "title": "5 sampling algorithms for everyone",
                "link": "http://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c",
                "content": "5 sampling algos for everyone Data imbalance and representability of training vs production data often becomes a huge challenge, and is certianly often qutie a key point when the topic of \u201calgorithmic bias\u201d is raised. Here is a great blog post that introduces 5 common sampling techniques that every ML practitioner should be familiar with."
            },
            {
                "title": "ML Explainability libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: Explainability Libraries \u00a0 The theme for this week\u2019s featured ML libraries is ML Explainability, and we\u2019re happy to share brand new libraries into that section. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "40",
        "items": [
            {
                "title": "Tricking machine learning Malware classifiers",
                "link": "https://towardsdatascience.com/evading-machine-learning-malware-classifiers-ce52dabdb713",
                "content": "Tricking ML Classifiers The topic of cybersecurity in machine learning has seen an increase in activity in the community due to its critical nature around production systems. This blog post covers a fascinating competition that took place at DEFCON, where participants were tasked with tricking a ML classifier trained to detect malware. In this article the author provides an insight on how the challenge was applied together with the techniques used to succeed."
            },
            {
                "title": "A new paradigm for ML deployment",
                "link": "https://www.oreilly.com/radar/machine-learning-requires-a-fundamentally-different-deployment-approach/",
                "content": "ML deployment paradigm Production machine learning systems have proven that the nuanced challenges that are faced when deploying machine learning require a new paradigm. O\u2019Reilly\u2019s Mike Loukides does a fantastic job in his latest article to provide an overview to the topic of machine learning deployment, together with insights on how this challenge is currently being tackled."
            },
            {
                "title": "Five must-know graph algorithms",
                "link": "https://towardsdatascience.com/data-scientists-the-five-graph-algorithms-that-you-should-know-30f454fa5513",
                "content": "Five must-know graph algorithms Although most of the carefully curated datasets that you may come across online may be on relational or key-value store, there has been an ever-increasing interest on graph datasets, as most of the data we interact with on a regular basis will tend to have more complex, and often grap-like structures. This article provides a comprehensible and non-exhaustive list of graph algorithms to get acquaintanced with - these include an intuitive explanation, insights of where they may be relevant and an example code implementation."
            },
            {
                "title": "Survey in fairnes and bias in ML",
                "link": "https://arxiv.org/abs/1908.09635",
                "content": "Survey fairness and bias in ML As larger and more critical datasets (and decisions) become part of the machine learning end-to-end production workflow, the challenges with statistical and societal bias/fairness become more complex. This survey provides a very comprehensible deep dive on the concepts and taxonomies around the concepts of \u201ctypes of bias\u201d, \u201ctypes of discrimination\u201d, and \u201ctypes of fairness\u201d, together with how these interact with the different types of machine learning techniques."
            },
            {
                "title": "Google\u2019s OSS differential privacy library",
                "link": "https://developers.googleblog.com/2019/09/enabling-developers-and-organizations.html",
                "content": "Google\u2019s OSS differential privacy The current implications of data privacy and trust has led into reviving interest into extremely fascinating research areas that have existed for decades. This one in particular is differential privacy, a technique that allows for data to be anonymised in a way that still leaves statistical properties which allow for processing on top of the anonymised data, which can lead to improvements in privacy. Google has released a C++ library of \u03b5-differentially private algorithms, which can be used to produce aggregate statistics over numeric data sets containing private or sensitive information."
            },
            {
                "title": "Open source differential privacy libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: Privacy Preserving ML \u00a0 The theme for this week\u2019s featured ML libraries is Privacy Preserving Machine Learning libraries, and we\u2019re happy to share brand new libraries into that section. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "41",
        "items": [
            {
                "title": "One data engine to rule them all at Google",
                "link": "https://blog.acolyer.org/2019/09/11/procella/",
                "content": "One data engine to rule them all The world of data processing is full of different engines with nuanced differences. Google already has a numerous set of data processing engines including Dremel, Mesa, Photon , F1, PowerDrill and Spanner - so, why did they need yet another data processing engine? Apparently because they felt they had too many data processing systems, and wanted to unify them all. Because of this, Google released a fascinating new paper that introduces their new SQL Engine called Porcella, which aims to unify serving and analytical data at youtube. This blog post provides a great insight on the architecture, objectives and use-cases of this new engine."
            },
            {
                "title": "Tackling data processing at scale with Presto foundation",
                "link": "https://www.linuxfoundation.org/uncategorized/2019/09/facebook-uber-twitter-and-alibaba-form-presto-foundation-to-tackle-distributed-data-processing-at-scale/",
                "content": "Tackling data processing at scale The Linux Foundation is leading yet another fantastic initiative: Facebook, Uber, Twitter and Alibaba join forces to form the \u201cPresto Foundation\u201d to tackle distributed data processing at scale. This is great news as the neutral governance will enable the members to contribute to the project to tackle some of the bigger challenges dealing with massively distributed data processing."
            },
            {
                "title": "GitHub releases the ImageNet for Code",
                "link": "https://www.wandb.com/articles/codesearchnet",
                "content": "The ImageNet for Code GitHub and Weights & Biases have collaborated to put together a fantastic contribution to the machine learning ecosystem that could bring fantastic innovations to the software engineering industry itself and trigger more similar competitions. This consists of a massively large dataset containing 6 million functions, 2 million of them documented, from open source projects on GitHub in 6 languages (Go, Java, Javascript, PHP, Python and Ruby) with the objective of improving semantic code search. They are also launching the CodeSearchNet challenge, which is a benchmark that will track and compare models trained on the CodeSearchNet dataset."
            },
            {
                "title": "Six lessons learned debugging a scaling problem at Gitlab",
                "link": "https://about.gitlab.com/2019/08/27/tyranny-of-the-clock/",
                "content": "Wisdom from debugging at scale As systems grow in complexity, the approaches towards debugging issues also become more complex as the issues can be on code workflows, but also in data inconsistencies, network issues, infrastructure problems and beyond. GitLab has put together a fantastic deep dive on how they were able to resolve one of their issues at massive scale, together with a set of lessons they learned from it."
            },
            {
                "title": "Reimagining Experimentation Analysis at Netflix",
                "link": "https://medium.com/netflix-techblog/reimagining-experimentation-analysis-at-netflix-71356393af21",
                "content": "Netflix reimagining experiments As your systems and teams become larger and more complex, the need not only to experiment efficiently but to be able to track, share and reproduce experiments become more critical. Netflix has put together a great post where they outline ther approach to re-thinking the way they track and manage experiments internally. Traditionally they have been using ABlaze, which is their centralised A/B testing platform, but now with their new platform they are able to perfectly recreate analyses on notebooks."
            },
            {
                "title": "Open source differential privacy libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: Privacy Preserving ML \u00a0 The theme for this week\u2019s featured ML libraries is Privacy Preserving Machine Learning libraries, and we\u2019re happy to share brand new libraries into that section. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "42",
        "items": [
            {
                "title": "Serverless for ML in Kubernetes with Kubeflow",
                "link": "https://www.youtube.com/watch?v=hGIvlFADMhU",
                "content": "Serverless for ML in Kubernetes Serving machine learning models at scale is one of the biggest challenges. The KFServing project aims to tackle this. KFserving is a cross-industry open source collaboration (currently led by multiple technology companies including Seldon, Google, Microsoft, IBM and Bloomberg) with the objective to develop a fully fledged machine learning serving and orchestration framework in Kubernetes. This initiative is incredibly exciting, because it has several tech leaders collaborating on defining what production ML could look like, and working towards abstracting some of very complex and heterogeneous production ML terminology, into standardised protocols and interfaces."
            },
            {
                "title": "When a model is to big for production",
                "link": "http://nlathia.github.io/2019/09/29/Large-NLP-in-prod/",
                "content": "When a model is too big for prod Machine learning models that are trained with very large datasets introduce new complexities, including large memory usage, heavy compute, black box constraints and more. The team at Monzo has put together a great overview that provides an outline of the key concepts that are often taken into consideration when moving a model into production, and dive into their use-case leveraging the HuggingFace library."
            },
            {
                "title": "Optimising production machine learning at Apple",
                "link": "https://arxiv.org/abs/1909.05372",
                "content": "Optimising production machine learning at Apple"
            },
            {
                "title": "Turn your projects into visual apps with Streamlit",
                "link": "https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace",
                "content": "Turn your ML into interactive apps Historically in data science, the time it takes to convert an idea into an interactive application takes a non-trivial amount of time. A new tool called Streamlit provides a way to easily build interactive applications from complex data science tools without the need to deal with the underlying infrastructural complexities (wrapping the backend in a microservice, exposing endpoints, building a UI to consume them, etc). Really awesome tool, definitely recommend checking it out."
            },
            {
                "title": "Modern applications at Amazon",
                "link": "https://www.allthingsdistributed.com/2019/08/modern-applications-at-aws.html",
                "content": "Modern Applications at AWS As an organisation scales and teams become more distant, there is a risk for innovation to stagnate, and a lot of the challenges in the organisational structure starts to reflect in the product/service interfaces - often for the worse. Amazon provides an interesting retrospective view of how they have tackled this to be able to build modern applications at Amazon Web Services."
            },
            {
                "title": "Machine learning deployment & orchestration libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: ML Deployment Libraries \u00a0 The theme for this week\u2019s featured ML libraries is Machine learning Deployment and Orchestration Libraries, and we\u2019re happy to share brand new libraries into that section. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "43",
        "items": [
            {
                "title": "The Institute for Ethical AI & ML joins the Linux Foundation",
                "link": "https://lfai.foundation/blog/2019/10/09/the-institute-for-ethical-ai-and-machine-learning-joins-lf-ai/",
                "content": "IEML joins the Linux Foundation The Institute for Ethical AI & Machine Learning (the non-profit behind this newsletter) is thrilled to be joining the Linux Foundation\u2019s LFAI as an organisational member! Some of our core work has already made its way to LF initiatives, including large sections of our Awesome Production ML List contributing to the fast-growing LF AI Landscape. We will be involved across various workstreams within the Linux Foundation, and will be contributing across the board to their ML initiatives. Exciting times ahead, and a lot of even more exciting news in future newsletter editions!"
            },
            {
                "title": "Black holes, new cures and AI Ethics with NumFocus",
                "link": "http://numfocus.org/case-studies",
                "content": "Case studies with NumFocus We\u2019ve heard incredible achievements in the research community, ranging from creating the world\u2019s first picture of a black hole, to finding cure to diseases. NumFocus is the organisation behind the open source tools that have been enabling some of these great achievements, including NumPy, SKlearn, Jupyer, Pandas, and many more. Recently NumFocus launched an initiative where they created a set of case studies where they showcase achievements accomplished using NumFocus tools, including the black hole photograph, curing diseases and introducing transparency into AI algorithms."
            },
            {
                "title": "Machine learning for business & operational intelligence",
                "link": "http://www.oreilly.com/ideas/machine-learning-for-operational-analytics-and-business-intelligence",
                "content": "ML for business & ops intelligence O\u2019Reilly Chief Scientist Ben Lorica comes back with yet another great podcast where he speaks with Peter Bailis, Co-founder of Stanford\u2019s DAWN Lab and CEO of Sisu, a startup that is using machine learning to improve operational analytics. In this podcast they dive into the role of ML in operational analytics, ML Benchmark initiatives (such as MLPerf and DAWNBench), and trends in tools for the lifecycle of ML in the enterprise."
            },
            {
                "title": "The FairML book free resources",
                "link": "https://fairmlbook.org/about.html",
                "content": "The open FairML Book With the rise of AI, learning machine learning concepts has become critical. However the lack of resources around the social challenges which ML practitioners may face is not significant. Three researchers from Cornell, Berkeley and Princeton came together to write a non-exhaustive but comprehensible book that contains key insights to consider \u201cFairness\u201d as core throughout the development of ML-related systems, as opposed to as an afterthought. The book is still work in progress, but there are a couple of key chapters available for free."
            },
            {
                "title": "AI ethics - whose ethics?",
                "link": "http://www.meetup.com/Ethics-Lunch-Group-Rise-London/events/265585657/",
                "content": "AI Ethics - whose ethics? As AI becomes more prevalent in society, we face thougher challenges around privacy, security and trust of systems. These challenges often create scenarios that may raise ethical questions which practitioners and leaders will have to tackle. Because of this, learning and studying the underlying philosophical concepts that have been built throughout the millenia could provide incredibly positive results. We started a lunch group in London to dive into these topics once a month. Last session Dr.\u00a0Ryan Dawson provided in introducion on Aristotle\u2019s Nichomachean Ethics, which followed by a discussion around their relevance in today\u2019s connected world. Next session\u2019s topic is \u201cWhose Ethics?\u201d where we\u2019ll be diving into the\u00a0 similarities and differences of Western and Eastern philosophy and its modern relevance into AI Ethics."
            },
            {
                "title": "Machine learning deployment & orchestration libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "IEML joins the Linux Foundation The Institute for Ethical AI & Machine Learning (the non-profit behind this newsletter) is thrilled to be joining the Linux Foundation\u2019s LFAI as an organisational member! Some of our core work has already made its way to LF initiatives, including large sections of our Awesome Production ML List contributing to the fast-growing LF AI Landscape. We will be involved across various workstreams within the Linux Foundation, and will be contributing across the board to their ML initiatives. Exciting times ahead, and a lot of even more exciting news in future newsletter editions!"
            }
        ]
    },
    {
        "issue": "44",
        "items": [
            {
                "title": "Awesome Artificial Intelligence Guidelines List",
                "link": "http://github.com/ethicalml/awesome-artificial-intelligence-guidelines",
                "content": "Awesome AI Guidelines List As AI systems become more prevalent in society, we face bigger and tougher societal and ethical challenges. Recently there has been an increase in content that attempts to address these challenges in the form of \u201cPrinciples\u201d, \u201cEthics Frameworks\u201d, \u201cChecklists\u201d and beyond. Navigating through so many resources is not easy, which is why we created and now maintain \u201cThe Awesome AI Guidelines List\u201d, a repository which maps the ecosystem of guidelines, principles, codes of ethics, standards, regulation, etc related to AI \ud83d\ude80 if there is any guideline or framework which is not outlined please let us know or feel free to submit an issue / pull request!"
            },
            {
                "title": "Simplifying Model Management with MLflow",
                "link": "http://www.youtube.com/watch?v=MSUTaCBhD7A",
                "content": "MLFlow simplifying model mgmt When dealing with production machine learning systems, we may face challenges that we won\u2019t see in the experimentation stage. One of the key challenges is to manage a large number of machine learning models, potentially from various users, and being able to compare them and upgrade them into staging and production environments. Dataricks announced a new ML Management feature which tackles this issue by providing a workflow system to version and manage models across multiple stages."
            },
            {
                "title": "Choosing charts that everyone understands",
                "link": "http://sloanreview.mit.edu/article/choose-charts-everyone-understands/",
                "content": "Choosing intuitive visualisations When dealing with challenges that involve a lot of data, it\u2019s often hard to choose the best visualisations to use at different stages of the project. This post provides a set of best practices on how to approach this challenge, suggesting how to leverage complex charts for data analysis, and classic charts for communicating data. Furthermore they provide a case study / example of how this looks like in practice in their team."
            },
            {
                "title": "Machine Learning Explainability at AI O\u2019Reilly",
                "link": "http://github.com/EthicalML/explainability-and-bias/",
                "content": "ML Explainability at AI O\u2019Reilly When training complex models like neural networks, we obtain advantages in accuracy, but we face tradeoffs on explainability. Fortunately we have seen a recent increase in tools and methods that you can use to extract explanations from various types of machine learning models. Last week we gave a talk about the approaches and tools you can use to introduce interpretability techniques into your experimentation workflow. Furthermore we show how you can\u00a0 leverage explainability techniques in the production stage of your machine learning lifecycle."
            },
            {
                "title": "6-step process for building ML projects",
                "link": "http://towardsdatascience.com/a-6-step-field-guide-for-building-machine-learning-projects-6e4554f6e3a1",
                "content": "Machine learning in 6 steps There are many ways in which you can tackle building a machine learning model. This post proposes a 6-step approach towards building any machine learning model. It provides quite a reasonable breakdown that covers a reasonable amount of important pieces, from defining the problem, to identifying risks and high level, to questions around interpretability, tuning & inference time."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: ML Deployment Libraries \u00a0 The theme for this week\u2019s featured ML libraries is Machine learning Deployment and Orchestration Libraries, and we\u2019re happy to share brand new libraries into that section. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "45",
        "items": [
            {
                "title": "Deep fake detection challenge",
                "link": "http://deepfakedetectionchallenge.ai/",
                "content": "Deep fake detection challenge Lately the topic of deep fakes has been raising more concerns due to an inceasing number of high profile stories. The use of deep fakes for malicious use-cases seems to have really huge potential to cause negative damage in society. A very interesting new initiative has been launched by the Partnership in AI, Microsoft, AWS and Facebook. This initiative invites researchers and practitioners to participate in a competition to detect deep fakes. The dataset is now released, and the competition starts in December."
            },
            {
                "title": "Human knowledge to Improve AI",
                "link": "http://bair.berkeley.edu/blog/2019/10/21/coordination/",
                "content": "Human knowledge to improve AI In reinforcement learning, often agents can be trained efficiently by running them with other agents throughout a significant number of iterations. Although this may be quite efficielt, and may lead to hyper-optimised results, these may not be optimal when the agents have to interact with humans. This Berkeley project has set out to explore this topic in more detail by looking at how agents can be improved when trained with human interaction."
            },
            {
                "title": "Neural text search data flow",
                "link": "http://hanxiao.github.io/2019/10/18/GNES-Flow-a-Pythonic-Way-to-Build-Cloud-Native-Neural-Search-Pipelines/",
                "content": "Neural text search data flow A very interesting project called GNES is tackling semantic search across image, text and beyond. As its popularity and use has been increasing there has been new challenges that the open source team have to dealth with. One of these key challenges has been data flow across complex jobs. This is why the GNES team released GNES flow, a framework that brings DAG-based data flow to GNES."
            },
            {
                "title": "The causal inference book",
                "link": "http://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/",
                "content": "The Causal Inference Book An incredible resource on all things Causal inference, which aims to support researchers, practitioners from various backgrounds, including epidemiologists, statisticians, psychologists, economists, sociologists, political scientists, computer scientists and beyond. The book is divided in 3 parts of increasing difficulty: causal inference without models, causal inference with models, and causal inference from complex longitudinal data."
            },
            {
                "title": "Netflix open sources polynote",
                "link": "http://medium.com/netflix-techblog/open-sourcing-polynote-an-ide-inspired-polyglot-notebook-7f929d3f447",
                "content": "Netflix Open Sources Polynote In previous editions of the MLE Newsletter we have covered how Netflix has built advanced infrastructure and introduced processes which has allowed for production experimentation at scale. It is great to see that Netflix is now open sourcing parts of their internal infastructure, starting with Polynote - an experimental polyglot notebook environment which supports Scala and Python (with or without Spark), SQL, and Vega. If you are interested in other open source data science notebooks we have an entire section in our Production ML list which would be worth for you to check out."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: Data Science Notebooks \u00a0 The theme for this week\u2019s featured ML libraries is Data Science Notebooks, and we\u2019re happy to share brand new libraries into that section to showcase tools beyond the good old Jupyter Notebooks. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "46",
        "items": [
            {
                "title": "6 lessons learned at Booking.com",
                "link": "http://www.kdd.org/kdd2019/accepted-papers/view/150-successful-machine-learning-models-6-lessons-learned-at-booking.com",
                "content": "6 lessons learned at Booking.com Booking.com has put together 6 lessons learned from building 150 models that were successful in production inference. This has come from their currently massive user-base which consists of millions of accomodation providers and millions of guests. Most of their use-cases consits of advanced and specialised recommender systems, with a constraint of massive throughput in processing. Their main conclusion is that an iterative, hypothesis driven process, integrated with other disciplines was fundamental to build 150 successful products enabled by Machine Learning."
            },
            {
                "title": "EurNLP 2019 videos released",
                "link": "http://www.facebook.com/pg/eurnlp/videos/",
                "content": "EurNLP 2019 videos released The first annual EurNLP Summit took place in London on October 11th. This was a great opportunity to foster discussion and collaboration between NLP researchers in academia and industry. The talks from this event were recorded and are all available at their Facebook page."
            },
            {
                "title": "Consistency of AI Summarization",
                "link": "http://arxiv.org/abs/1910.12840",
                "content": "Consistency of AI Summarization A very interesting paper, which proposes that current metrics for assessing summarization algorithms do not account for whether summaries are factually consistent with source documents. The paper proposes a weakly-supervised, model-based approach for verifying factual consistency and identifying conflicts between source documents and a generated summary. This proposed approach verifies three key things: 1) identify whether sentences remain factually consistent after transformation, 2) extract a span in the source documents to support the consistency prediction, 3) extract a span in the summary sentence that is inconsistent if one exists."
            },
            {
                "title": "Linux Foundation Trusted AI",
                "link": "http://lfai.foundation/blog/2019/10/29/trusted-ai-committee-established/",
                "content": "Linux Foundation Trusted AI LF AI is an umbrella foundation of the Linux Foundation that supports open source innovation in artificial intelligence, machine learning, and deep learning. To build trust in the adoption of AI, the Trusted AI Committee has been established as part of Linux Foundation AI. We are proud to be contributing to this foundation, which has the objectives of:\u00a01) define policies, guidelines and tooling, 2) survey and contract current OSS projects to join LFAI, 3) create a badging or certification process for OSS projects, and 4) standardise taxonomy around trusted AI"
            },
            {
                "title": "AI Ethics - Whose Ethics?",
                "link": "http://www.meetup.com/Ethics-Lunch-Group-Rise-London/",
                "content": "AI Ethics - Whose Ethics? As AI becomes more prevalent in society, we face thougher challenges around privacy, security and trust of systems. These challenges often create scenarios that may raise ethical questions which practitioners and leaders will have to tackle. Because of this, learning and studying the underlying philosophical concepts that have been built throughout the millenia could provide incredibly positive results. We started a lunch group in London to dive into these topics once a month. Last session Dr.\u00a0Ryan Dawson provided in introducion on Aristotle\u2019s Nichomachean Ethics, which followed by a discussion around their relevance in today\u2019s connected world. Next session\u2019s topic is \u201cWhose Ethics?\u201d where we\u2019ll be diving into the similarities and differences of Western and Eastern philosophy and its modern relevance into AI Ethics."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: Data Science Notebooks \u00a0 The theme for this week\u2019s featured ML libraries is Data Science Notebooks, and we\u2019re happy to share brand new libraries into that section to showcase tools beyond the good old Jupyter Notebooks. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "47",
        "items": [
            {
                "title": "End-to-end ML with MLFlow and Seldon",
                "link": "http://www.youtube.com/watch?v=D6eSfd9w9eA",
                "content": "E2E ML with MLFlow and Seldon Machine Learning Engineer Adrian Gonzales has put together a fantastic hands on tutorial which covers the motivations, challenges and best practices when setting up end-to-end machine learning systems. In this talk he dives into how MLFlow can be leveraged to train models through their experimentation functionality, and leverage the Seldon-MLFlow integation to seamlessly deploy models into a production Kubernetes cluster, where he then runs real-time feedback analysis whilst A/B testing the models. You can watch the video in youtube and try it out yourself with the jupyter notebook."
            },
            {
                "title": "Reconstructing human thoughts with ML",
                "link": "http://techxplore.com/news/2019-10-neural-network-reconstructs-human-thoughts.html",
                "content": "Reconstructing thoughts with ML Neurobotics is leveraging machine learning to reverse engineer human thoughts. They have come up with quite a clever way to leverage labelled data through the expected visual appearance of an object linked to the brain waves that would be emitted when perceiving it. This startup has very interesting showcases of their technology that provide very interesting initial results. Technology applications like this can be incredibly interestibg, but also require an evaluation of its impact in society."
            },
            {
                "title": "Scalble AutoML with Ray on Spark",
                "link": "https://medium.com/riselab/scalable-automl-for-time-series-prediction-using-ray-and-analytics-zoo-b79a6fd08139",
                "content": "Scalable AutoML with Ray Machine learning experimentation can be highly time consuming, and with growing complexity of machine learning requirements make it harder to build and run experimentation at scale. The team at Intel have put together a great insight on how they are tackling it with their \u201canalytics zoo\u201d, and more specifically in this post they outline how it can be tackled leveraging AutoML using Ray on top of Spark. This is an interesting approach as it allows the technical user to leverage existing Spark infrastructure, but with the simplicity of Ray, which in this case allows for large scale automated hyperparameter search."
            },
            {
                "title": "Tensorflow world videos are now out",
                "link": "http://www.youtube.com/playlist?list=PLQY2H8rRoyvxcmHHRftsuiO1GyinVAwUg",
                "content": "Tensorflow World Videos O\u2019Reilly and TensorFlow teamed up to put together the first TensorFlow World conference, which took place recently. It brought together the growing TensorFlow community to learn from each other and explore new ideas, techniques, and approaches in deep and machine learning. The videos for the conference are now live in YouTube."
            },
            {
                "title": "14 different types of learning in ML",
                "link": "http://machinelearningmastery.com/types-of-learning-in-machine-learning/",
                "content": "14 types of learning in ML Machine learning is a very broad subject. Machine learning mastery does a fantastic job to map out some of the key different types of learning in machine learning. These include an intuitive overview of what these consist of, and include learning problems, hybrid learning problems, statistical inference and learning techniques."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: Data Science Notebooks \u00a0 The theme for this week\u2019s featured ML libraries is Data Science Notebooks, and we\u2019re happy to share brand new libraries into that section to showcase tools beyond the good old Jupyter Notebooks. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "48",
        "items": [
            {
                "title": "ONNX Joins the Linux Foundation",
                "link": "http://lfai.foundation/press-release/2019/11/14/lf-ai-welcomes-onnx/",
                "content": "ONNX Joins the Linux Foundation ONNX has joined the Linux Foundation! This is an incredibly exciting announcement given the potential this presents towards standardisation of protocols in the machine learning ecosystem. ONNX stands for Open Neural Network eXchange, and it is an open format used to represent machine learning and deep learning models, which provides for advanced and standardised functionalities for model creation and export, visualization, optimization, and acceleration capabilities."
            },
            {
                "title": "The Nuances in DevOps for ML",
                "link": "http://hackernoon.com/why-is-devops-for-machine-learning-so-different-384z32f1",
                "content": "The Nuances in DevOps for ML MLOps is a concept that is used to define the challenges and methodologies to continuously integrate, deploy and monitor machine learning in production. Open Source Engineer Ryan Dawston has put togher a great article that provides a high level overview of what MLOps is, and how machine learning is different to traditional software."
            },
            {
                "title": "Continuous Delivery for ML",
                "link": "http://martinfowler.com/articles/cd4ml.html",
                "content": "Continuous Delivery for ML When managing hundreds or even thousands of models in production it is necessary to introduce automation across the deployment and integration process. This great article provides a thorough overview of the nuanced challenges that machine learning introduces when deploying at scale, and provides some of the core concepts that need to be taken into consideration when introducing automation for continuous deployment of ML."
            },
            {
                "title": "Learnings reaching 2% in Kaggle",
                "link": "http://towardsdatascience.com/my-secret-sauce-to-be-in-top-2-of-a-kaggle-competition-57cff0677d3c",
                "content": "Learnings reaching 2% in Kaggle Instacart machine learning engineer Abhay Pawar has put together a very comprehensible article on lessons learned reaching top 2% in a Kaggle competition. In the article he covers best practices to learn more from the data to be able to build feature understanding, and iteratively improve the solution to ensure reliable results."
            },
            {
                "title": "The New Data Exchange",
                "link": "http://thedataexchange.media/taking-stock-of-foundational-tools-for-analytics-and-machine-learning",
                "content": "The New Data Exchange O\u2019Reilly Chief Scientist Ben Lorica has announced a brand new podcast that focuses in Machine Learning called \u201cThe Data Exchange\u201d. The first episode dives right in with a conversation with Paco Nathan exploring core trends in ML including data governance, autoML, notebooks and deep learning libraries."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "OSS: Data Science Notebooks \u00a0 The theme for this week\u2019s featured ML libraries is Industry Strength NLP. The four featured libraries this week are:"
            }
        ]
    },
    {
        "issue": "49",
        "items": [
            {
                "title": "New Outlier & Aversarial Detector OSS Library",
                "link": "http://docs.seldon.io/projects/alibi-detect/en/stable/overview/getting_started.html",
                "content": "Outlier & Adversarial Detector Often machine learning models, and just systems in general, are monitored with very basic rules - e.g.\u00a0send an alert if a metric drops under a certain threshold. However this can lead to a lot of false positives being flagged, creating too much noise, which could lead into ignoring these alerts (And real issues not being caught). The Seldon team has released a new open source machine learning library that focuses on outlier, adversarial and concept drift detection, which allows for smarter monitoring techniques. The package aims to cover both online and offline detectors for tabular data, text, images and time series. This package is built with production machine learning use-cases in mind, and has continuously updated integrations with the ML deployment framework Seldon Core."
            },
            {
                "title": "The AI Governance Dilemma",
                "link": "https://hackernoon.com/move-fast-and-break-things-the-ai-governance-dilemma-dsq32ix",
                "content": "The AI Governance Dilemma As machine learning is adopted in more critical use-cases, the common phrase that tech startups have used \u201cmove fast and break things\u201d becomes less desired. In this great article by Seldon Open Source Engineer Ryan Dawston, breaks down this AI Governance Dilemma. Ryan provides an introduction to the challenges of ML being deployed in critical use-cases, together with the different areas that should be taken into account, including outliers, concept drift, bias, privacy and other risks."
            },
            {
                "title": "Mening-aware word vectors with sense2vec",
                "link": "http://explosion.ai/blog/sense2vec-reloaded",
                "content": "Contextually Keyed Word Vectors Neural word representations have proven useful in Natural Language Processing (NLP) tasks due to their ability to efficiently model complex semantic and syntactic word relationships. However, most techniques model only one representation per word, despite the fact that a single word can have multiple meanings or \u201csenses\u201d. The ExplosionAI team, which is also behind SpaCy created a technique which they called sense2vec, which builds word embeddings in a similar way to word2vec, but also takes into account part-of-speech attributes for word tokens, which allow for meaning-aware vectors."
            },
            {
                "title": "Time series anomaly detection at Microsoft",
                "link": "http://arxiv.org/abs/1906.03821",
                "content": "Time Series Anomaly Detection Large companies need to monitor various metrics of their applications and services in realtime. Microsoft has released a fascinating paper where they share some of their knowledge developing and maintaining a time-series anomaly detection service which helps customers to monitor the time-series continuously and alert for potential incidents on time. In this paper, they introduce the pipeline and algorithm of their anomaly detection service,which is designed to be accurate, efficient and general. The pipeline consists of three major modules, including data ingestion, exper-imentation platform and online compute. In this paper, the team also proposes a novel algorithmbased on Spectral Residual (SR) and Convolutional Neural Network(CNN)."
            },
            {
                "title": "Pyro 1.0 Released with LFAI",
                "link": "http://lfai.foundation/blog/2019/11/18/pyro-1-0-has-arrived/",
                "content": "Pyro 1.0 Released Another great announcement from the LFAI this week - Pyro has released it\u2019s 1.0 version! Pyro is a universal probabilistic programming language (PPL) written in Python and supported by PyTorch on the backend. Pyro enables flexible and expressive deep probabilistic modeling, unifying the best of modern deep learning and Bayesian modeling. It is developed and maintained by Uber AI and community contributors."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "50",
        "items": [
            {
                "title": "Data Science Best Practices",
                "link": "http://syslog.ravelin.com/data-science-best-practices-843c9693db8",
                "content": "Data Science Best Practices It\u2019s easy and fun to ship a prototype, whether that\u2019s in software or data science. What\u2019s much, much harder is making it resilient, reliable, scalable, fast, and secure. Ravelin co-founder and CTO Leonard Austin has written an excellent blog post where he outlines some best practices that are brought from the software engineering best practices."
            },
            {
                "title": "A Contract for the Web",
                "link": "http://contractfortheweb.org/",
                "content": "A Contract for the Web Sir Tim Berners-Lee has launched what he has called a \u2018Contract for the Web\u2019, intended to govern the behaviour of both internet giants, such as Google and Facebook, and governments. The Contract describes itself as \u201ca global plan of action to make our online world safe and empowering for everyone\u201d."
            },
            {
                "title": "Deep Learning Indaba 2019",
                "link": "http://www.youtube.com/playlist?list=PLICxY_yQeGYng7mbMmuZjt3S1sDb6YpBJ",
                "content": "Deep Learning Indaba 2019 The videos for Deep Learning Indaba 2019 are out! The mission of the Deep Learning Indaba is to Strengthen African Machine Learning. The Deep Learning Indaba is the annual meeting of the African machine learning community. In 2019, the Indaba aims to see 700 members of Africa\u2019s artificial intelligence community for a week-long event of teaching, research, exchange, and debate around the state of the art in machine learning and artificial intelligence."
            },
            {
                "title": "Uncertainty Quantification in Deep Learning",
                "link": "http://www.inovex.de/blog/uncertainty-quantification-deep-learning/",
                "content": "Uncertainty Quantification in DL While we usually cannot guarantee our models to be absolutely perfect, we could use information about how certain they are with their predictions. That way, in case of high uncertainty, we can perform more extensive tests or pass the case to a human in order to avoid potentially wrong results. This, however, requires our models to be aware of their prediction accuracy for a given input. This article aims to break down just that."
            },
            {
                "title": "Google XAI Whitepaper",
                "link": "http://storage.googleapis.com/cloud-ai-whitepapers/AI%20Explainability%20Whitepaper.pdf",
                "content": "Google XAI Whitepaper Google entered the XAI ecosystem with a new Google Cloud AI Explanations product, which is targetted at model developers and data scientists. Together with their new system, they have released a whitepaper that outlines their approach towards XAI, togeter with a high level overview of the motivations and features."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "51",
        "items": [
            {
                "title": "Play Endless Game Built by AI",
                "link": "http://aiweirdness.com/post/189511103367/play-ai-dungeon-2-become-a-dragon-eat-the-moon",
                "content": "Play Endless Game Built by AI \u201cAI Dungeon 2\u201d, a new dungeon-crawling game was built using the GPT-2 model, and has been very well received by the community. This \u201copen-world\u201d game allows you to interact with the storyline by providing actions that are followed by results that expand on a story that is generated on the go. This is a very creative use of pre-trained language models, and certainly quite an exciting one that could be interesting to explore in many different industry applications."
            },
            {
                "title": "Gentle Intro to Model Selection",
                "link": "http://machinelearningmastery.com/a-gentle-introduction-to-model-selection-for-machine-learning/",
                "content": "Gentle Intro to Model Selection Given easy-to-use machine learning libraries like scikit-learn and Keras, it is straightforward to fit many different machine learning models on a given predictive modeling dataset. The challenge of applied machine learning, therefore, becomes how to choose among a range of different models that you can use for your problem. Machine learning mastery has put together a great article containing insights on what is model selection, considerations for model selection and techniques available."
            },
            {
                "title": "Code Reviews for Jupyter Notebooks",
                "link": "http://towardsdatascience.com/introducing-reviewnb-visual-diff-for-jupyter-notebooks-6797e6dfa20c",
                "content": "Code Reviews for Jupyter NBs Code-review methodologies have brought robust development practice into software development. A new exciting project is now extending existing frameworks to provide further code-review functionality into Jupyter notebooks specifically. This project has been named ReviewNB, and it is a visual diff for Jupyter notebooks presented as a GitHub app that communicates to GitHub APIs directly, and processes changes which are then displayed as side-by-side diff formats. Very exciting project, and certainly a space to keep an eye on."
            },
            {
                "title": "Netflix Releases Metaflow",
                "link": "http://www.zdnet.com/article/netflix-our-metaflow-python-library-for-faster-data-science-is-now-open-source/",
                "content": "Netflix Releases Metaflow Netflix\u2019s data-science team has open-sourced its Metaflow Python library, a key part of the \u2018human-centered\u2019 machine-learning infrastructure it uses for building and deploying data-science workflows. It\u2019s great to see tech giants contributing to open source, especially in areas that are currently progressing at breakneck speed, namely the intersection between data science, devops and software engineering."
            },
            {
                "title": "Adversarial Detection Hands On Example",
                "link": "http://docs.seldon.io/projects/alibi-detect/en/stable/examples/ad_advvae_mnist.html",
                "content": "Adversarial Detection Hands On Adversarial detection algorithms are growing in popularity due to growing concern in exploitation of production machine learning models. A great tutorial was put together by the data science team at Seldon outlining how to use Adversarial Variational Autoencoder Detection algorithms specifically on the MNIST dataset (and more generally on image datasets)."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "52",
        "items": [
            {
                "title": "Top Python ML Libraries in 2019",
                "link": "http://tryolabs.com/blog/2019/12/10/top-10-python-libraries-of-2019/",
                "content": "Top Python ML Libraries in 2019 This last year we have seen a large number of open source libraries coming out. This article highlights 10 python machine learning libraries that came out in 2019 which are must watch, many of the libraries in the list which are machine learning related. This list includes HTTX, Starlette, FastAPI, Immutables, Pyodide, Modin, Streamlit, Transformers, Detectron2 and Metaflow."
            },
            {
                "title": "NeurIPS 2019 Videos are Out",
                "link": "http://slideslive.com/neurips/",
                "content": "NeurIPS 2019 Videos are Out Neural Information Processing Systems (NeurIPS) is a multi-track machine learning and computational neuroscience conference that includes invited talks, demonstrations, symposia and oral and poster presentations of refereed papers. The videos for this year\u2019s conference are now online and available at https://slideslive.com/neurips/"
            },
            {
                "title": "Modern NLP with SpaCy Podcast",
                "link": "http://changelog.com/practicalai/68",
                "content": "Modern NLP with SpaCy Podcast SpaCy is an awesome NLP open source library! It\u2019s easy to use, has widespread adoption, is open source, and integrates the latest language models. Ines Montani and Matthew Honnibal (core developers of spaCy and co-founders of Explosion) join the PracticalAI podcast to discuss the history of the project, its capabilities, and the latest trends in NLP. They also dive into the practicalities of taking NLP workflows to production."
            },
            {
                "title": "Testing Guide for Software",
                "link": "http://martinfowler.com/testing/",
                "content": "Testing Guide for Software As software approaches production scale, it requires the relevant amount of testing on a component and system level. The approaches involve when testing systems, especially in machine learning become more ambiguous, and benefit from the best practices that have been gathered. The testing guide in martin fowler\u2019s blog is an excellent and comprehensible source of information about testing, which can be adopted not only for traditional software projects but also for machine learning / data science projects."
            },
            {
                "title": "Spotify on Better ML Infrastructure",
                "link": "http://labs.spotify.com/2019/12/13/the-winding-road-to-better-machine-learning-infrastructure-through-tensorflow-extended-and-kubeflow/",
                "content": "Spotify on Better ML Infrastructure When Spotify launched people were amazed that they could access almost the world\u2019s entire music catalog instantaneously. More users and more features led to more systems that relied on Machine Learning to scale inferences across a growing user base. As these ML systems were buildt, they started to hit a point where engineers spent more of their time maintaining data and backend systems in support of the ML-specific code than iterating on the model itself. They realized we needed to standardize best practices and build tooling to bridge the gaps between data, backend, and ML. This blog post outlines their experience building just that, and how they leverage Tensorflow Extended (TFX) and Kubeflow in their Paved Road for ML systems."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "53",
        "items": [
            {
                "title": "Real time computer vision at scale",
                "link": "http://thedataexchange.media/building-large-scale-real-time-computer-vision-applications/",
                "content": "Real time computer vision at scale Chief Data Scientist Ben Lorica comes back with another fantastic podcast with the Data Exchange - this time with a conversation with Reza Zadeh on large scale & real time computer vision use cases, adversarial attacks, deepfakes, fairness, privacy, and security. In this edition they dive into 1) Challenges in building large-scale, real-time computer vision applications. 2) Robustness of computer vision applications (adversarial attacks, deepfakes). 3) Impact of computer vision technologies on society: security, privacy and surveillance."
            },
            {
                "title": "Ray for the curious",
                "link": "http://medium.com/distributed-computing-with-ray/ray-for-the-curious-fa0e019e17d3",
                "content": "Ray for the curious Ray is an open-source system for scaling Python applications from single machines to large clusters. Dean Wampler from the newly announced company (founded by some of the core Ray team) has put together a great article that provides an intuitive understanding on Ray for distributed data processing."
            },
            {
                "title": "Evolution of Zulily\u2019s Airflow",
                "link": "http://zulily-tech.com/2019/11/19/evolution-of-zulilys-airflow-infrastructure/",
                "content": "Evolution of Zulily\u2019s Airflow In production data science use-cases, the challenge of enabling and managing scheduling of data processing tasks at scale becomes growingly complex. Apache Airflow has skyrocketed since its debut as a key tool to perform workflow management, and with the grow of cloud native / Kubernetes technologies, Airflow has been able to ride the wave by providing more integrated Kubernetes support. Zulily has put together a great overview of how they have been able to extend their Airflow production infrastructure in Kubernetes, together with lessons learned on the way."
            },
            {
                "title": "Key trends in ML for 2020",
                "link": "http://www.kdnuggets.com/2019/12/predictions-ai-machine-learning-data-science-research.html",
                "content": "Key trends in ML for 2020 It\u2019s year end again, and that means it\u2019s time for KDnuggets annual year end expert analysis and predictions. This year they posed the question: What were the main developments in AI, Data Science, Deep Learning, and Machine Learning in 2019, and what key trends do you expect in 2020? They brought together insights from renowned various experts in the field which has been made available in this article."
            },
            {
                "title": "A gentle intro to imbalanced ML",
                "link": "http://www.meetup.com/Ethics-Lunch-Group-Rise-London/events/267303953/",
                "content": "A gentle intro to imbalanced ML Machine learning mastery has put together a very comprehensible introduction to \u201cimbalanced classification\u201d. This tutorial covers three key areas: 1) Imbalanced classification is the problem of classification when there is an unequal distribution of classes in the training dataset. 2) The imbalance in the class distribution may vary, but a severe imbalance is more challenging to model and may require specialized techniques. 3) Many real-world classification problems have an imbalanced class distribution, such as fraud detection, spam detection, and churn prediction."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "54",
        "items": [
            {
                "title": "From system 1 to system 2 by Yoshua Bengio",
                "link": "http://slideslive.com/38921750/from-system-1-deep-learning-to-system-2-deep-learning",
                "content": "Yoshua Bengio; Towards system 2 Past progress in deep learning has concentrated mostly on learning from a static dataset, mostly for perception tasks and other System 1 tasks which are done intuitively and unconsciously by humans. However, in recent years, a shift in research direction and new tools such as soft-attention and progress in deep reinforcement learning are opening the door to the development of novel deep architectures and training frameworks for addressing System 2 tasks (which are done consciously), such as reasoning, planning, capturing causality and obtaining systematic generalization in natural language processing and other applications. Yoshua Bengio shared very interesting insights on this NeurIPS talk which covered the key concepts that will enable expansion from System 1 tasks to System 2 tasks."
            },
            {
                "title": "The Artificial Intelligence Index 2019 Report",
                "link": "http://hai.stanford.edu/sites/g/files/sbiybj10986/f/ai_index_2019_report.pdf",
                "content": "AI Index 2019 Report The AI Index, a Stanford-backed initiative to assess the progress and impact of AI, has launched its 2019 report. The new report contains a vast amount of data relating to AI, covering areas ranging from bibliometrics, to technical progress, to analysis of diversity within the field of AI. Jack Clark from OpenAI, who is part of the steering committee outlined some key statistics that include: 300% growth in volume of peer-reviewed AI papers, 800% growth in NeurIPS attendance since 2012, $70b invested worldwide in AI, and more."
            },
            {
                "title": "Microsoft\u2019s NLP Best Practices",
                "link": "http://github.com/microsoft/nlp-recipes/",
                "content": "Microsoft\u2019s NLP Best Practices In recent years, natural language processing (NLP) has seen quick growth in quality and usability, and this has helped to drive business adoption of artificial intelligence (AI) solutions. Microsoft has put together a great repository with examples and best practices for building NLP systems, provided as Jupyter notebooks and utility functions. The focus of the repository is on state-of-the-art methods and common scenarios that are popular among researchers and practitioners working on problems involving text and language."
            },
            {
                "title": "The day that changed Netflix tech",
                "link": "http://www.linkedin.com/pulse/date-changed-netflixs-attitude-towards-availability-jaspreet-bakshi/",
                "content": "The day that changed Netflix tech On Christmas Eve 2012, Netflix streaming service experienced an outage. This particular incident got a lot of media coverage for obvious reasons, and was caused due to an AWS region becoming fully unavailable. To mitigate region-based outages, Netflix invested heavily in Resiliency Engineering and Cloud Platform teams to create a discipline to break things on purpose. This post provides really interesting insight on some of the approaches taken to address these issues."
            },
            {
                "title": "Attention and Augmented RNNs",
                "link": "http://distill.pub/2016/augmented-rnns/",
                "content": "Attention and Augmented RNNs Recurrent neural networks are one of the staples of deep learning, allowing neural networks to work with sequences of data like text, audio and video. Such models have been found to be very powerful, achieving remarkable results in many tasks including translation, voice recognition, and image captioning. As a result, recurrent neural networks have become very widespread in the last few years. This post provides a great overview on RNNs, together with intuition on some of the core concepts around these."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "55",
        "items": [
            {
                "title": "Machine Learning System Design",
                "link": "http://github.com/chiphuyen/machine-learning-systems-design",
                "content": "Machine Learning System Design With the rise of large scale machine learning applications, it is becoming increasingly critical for practitioners to learn the best practices in machine learning system design. This great booklet covers four may steps of desingin machine learning systems, including 1) project setup, 2) data pipeline, 3) modeling, and 4) serving. The booklet itself also contains 27 open-minded machine learning system design questions that might come up in machine learning interviews."
            },
            {
                "title": "Machine Learning Interviews",
                "link": "http://docs.google.com/presentation/d/1MX2V6fTp71j1aztvY5HLYM44iLG4HYMrYd4Dxn6Cxnw/edit#slide=id.g6152350dbb_0_63",
                "content": "Machine Learning Interviews As the role of machine learning engineer becomes more prominent in industry, more useful content is contributed by the community to define the role, together with the best practices, and even advise on job interviews. This presentation by Machine Learning Engineer Chip Huyen provides great insight on the role of the MLE, together with advice on how to best approach machine learning interviews."
            },
            {
                "title": "A Deep Dive into Online Learning",
                "link": "http://parameterfree.com/2019/09/02/introduction-to-online-learning/",
                "content": "A Deep Dive into Online Learning A fantastic resource that provides a very comprehensible introduction to online learning, which comes together with a set of lecture notes from Boston University\u2019s \u201cIntroduction to Online Learning\u201d course. This first lecture provides an initial insight on the topic, with a strong technical foundation as well as an exercise to put the learnings into practice."
            },
            {
                "title": "Unsupervised NLU via GPT-2",
                "link": "http://rakeshchada.github.io/Zero-Shot-GPT-2.html",
                "content": "Unsupervised NLU via GPT-2 Amazon Applied Scientist Rakesh Chada has put together a great post that showcases the power of GPT-2. The language model GPT-2 from OpenAI is one of the most coherent generative models for text out there. While its generation capabilities are impressive, it\u2019s ability to zero-shot perform some of the Natural Language Understanding (NLU) tasks seems even more fascinating to Rakesh. In this blog post, some of those capabilities are highlighted as well as a deep dive on one such fun use-case of converting singular nouns in english to their plural counterparts (and vice-versa)."
            },
            {
                "title": "Open Source Business Models",
                "link": "http://a16z.com/2019/10/04/commercializing-open-source/",
                "content": "Open Source Business Models The open source software (OSS) movement has created some of our most important and widely used technologies, including operating systems, web browsers, databases and (of course) machine learning. Our world would not function, or at least not function as well, without open source software. In this podcast, Peter Levene shares some of his experience working with open source as a developer, entrepreneur and investor around business models for open source projects."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "56",
        "items": [
            {
                "title": "The Evolution of Tensorflow and ML Infrastructure",
                "link": "http://thedataexchange.media/the-evolution-of-machine-learning-infrastructure",
                "content": "Evolution of ML Infrastructure Chief Data Scientist Ben Lorica comes back with another great podcast on The Data Exchange Podcast in conversation with Rajat Monga, one of the founding members of the TensorFlow Engineering team. Up until recently Rajat was the engineering manager for TensorFlow at Google. In this podcast they dive into TFX, a production scale ML platform based on Tensorflow, they talk about Multi-Level Intermediate Representation (MLIR), Deep Learning and the state of machine learning infrastructure."
            },
            {
                "title": "30 Woman Advancing AI",
                "link": "http://blog.re-work.co/top-women-in-ai-2019/",
                "content": "30 Woman Advancing AI Re-work has put together a Women in AI list of the year, which focuses on individuals that have spearheaded or taken part in great research in 2019, and therefore deserve recognition."
            },
            {
                "title": "Calculating the Value of Data",
                "link": "http://bair.berkeley.edu/blog/2019/12/16/data-worth/",
                "content": "Calculating the Value of Data People give massive amounts of their personal data to companies every day and these data are used to generate tremendous business values. Some economists and politicians argue that based on value of data people there are situations where paid transactions should take place. Furthermore in the context of organisations holding data, this data has both a value and a risk that is currently ambiguous to quantify. This artcle discusses methods proposed in Bekeley papers that attempt to answer this question in the ML context."
            },
            {
                "title": "Intro to Ethics in Artificial Intelligence",
                "link": "http://www.meetup.com/Ethics-Lunch-Group-Rise-London/events/267303953/",
                "content": "Intro to Ethics in AI The discussion of ethics in AI has become more critical as more applications make their way into production environments that affect the real world. We\u2019re organising a London meetup on January 24th covering an introduction to AI, where HATLAB Deputy Director James Kingston will help us get our bearings by taking us on a survey of an AI Ethics Landscape, followed by an open discussion. Come join us!"
            },
            {
                "title": "A Guide to File Formats in ML",
                "link": "http://towardsdatascience.com/guide-to-file-formats-for-machine-learning-columnar-training-inferencing-and-the-feature-store-2e0c3d18d4f9",
                "content": "A Guide to File Formats in ML Most machine learning models are trained using data from files. Logical Clocks Co-Founder James Dowling has put toghether this guide to the popular file formats used in open source frameworks for machine learning in Python, including TensorFlow/Keras, PyTorch, Scikit-Learn, and PySpark. This post also describes how a Feature Store can make the Data Scientist\u2019s life easier by generating training/test data in a file format of choice on a file system of choice."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "57",
        "items": [
            {
                "title": "Google Research in 2019 and beyond",
                "link": "http://ai.googleblog.com/2020/01/google-research-looking-back-at-2019.html",
                "content": "Google Research 2019 + Beyond Google reaserch has put together a very comprehensible overview of their key highlights and results from 2019 as well as their focus for 2020 and beyond. In this post they touch upon ethical use of AI, AI for social good, Applications of AI in Other Fields, Assistive Technology, Use of AI in Mobile Devices, Quantum Computing, AutoML and more."
            },
            {
                "title": "Facebook Open Source Year in Review",
                "link": "http://engineering.fb.com/open-source/open-source-2019/",
                "content": "Facebook OSS Year in Review Facebook dives into their open source year in review list, where they cover high level overview of their open source projects and the achievements/updates in 2019, including their ~2500 contributors and 32000 contributions. In this article they cover their open source frameworks PyTorch, Hydra, Calibra as well as other Open Source partnerships."
            },
            {
                "title": "AI Lessons Learned with Rakuten",
                "link": "http://thedataexchange.media/business-at-the-speed-of-ai-lessons-from-rakuten",
                "content": "AI Lessons Learned with Rakuten Chief Scientist Ben Lorica comes back with another Data Exchange podcast. This time he dives into lessons learned with Rakuten Data Science VP Bahman Bahmani. In this podcast they cover the impact that machine learning in Rakuten, best practices in attracting/retaining ML talent, the trio of strategic options and culture within the organisation."
            },
            {
                "title": "Rethinking moving fast and breaking things with AI",
                "link": "http://practical-ai-ethics.org/move-fast-and-break-things-the-ai-governance-dilemma/",
                "content": "Move fast and break things w AI The AI Governance Dilemma: As machine learning is adopted in more critical use-cases, the common phrase that tech startups have used \u201cmove fast and break things\u201d becomes less desired. In this great article by Seldon Open Source Engineer Ryan Dawston, this AI Governance Dilemma is broken down. Ryan provides an introduction to the challenges of ML being deployed in critical use-cases, together with the different areas that should be taken into account, including outliers, concept drift, bias, privacy and other risks."
            },
            {
                "title": "Intro to Ethics in Artificial Intelligence Meetup",
                "link": "http://www.meetup.com/Ethics-Lunch-Group-Rise-London/",
                "content": "Intro to Ethics in AI Intro to Ethics in AI: The discussion of ethics in AI has become more critical as more applications make their way into production environments that affect the real world. We\u2019re organising a London meetup on January 24th covering an introduction to AI, where HATLAB Deputy Director James Kingston will help us get our bearings by taking us on a survey of an AI Ethics Landscape, followed by an open discussion. Come join us!"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "58",
        "items": [
            {
                "title": "Feature Stores for Machine Learning",
                "link": "http://featurestore.org/",
                "content": "Feature Stores for ML Duplicated work in data science scales as the projects and teams scale. Feature stores are now seen as core part of the solution for re-usability, however there is still a lot of ambiguity on its definition, architecture and best practices. This site contains an excellent list of resources that map large part of the ecosystem to drive the conversation forward, including videos, articles and beyond."
            },
            {
                "title": "Key AI & Data Trends for 2020",
                "link": "http://thedataexchange.media/key-ai-and-data-trends-for-2020",
                "content": "Key AI & Data Trends for 2020 The Data Exchange podcast comes back this week with an excellent deep dive into the key AI, Machine Learning and data trends for 2020. In this episode they dive into types of machine learning, real life applications, infrastructure/tools, and other topics such as managing risks and trends to watch."
            },
            {
                "title": "LF AI 2019 Year in Review",
                "link": "https://lfai.foundation/blog/2020/01/22/lf-ai-2019-year-in-review/",
                "content": "LF AI 2019 Year in Review It has been an incredible journey at the LF AI since we became an organisational member, and we could not be more excited for the great leaps it has achieved, and more importantly what it has yet to achieve. This great post provides an insight on some of the achievements and updates from 2019. Massive shoutout especially to the core team for their great work driving this forward, here is to yet another great 2020."
            },
            {
                "title": "From local interpretability to global understanding",
                "link": "http://www.nature.com/articles/s42256-019-0138-9",
                "content": "From local to global XAI Tree-based models have seen a steady increase in adoption in produciton use-cases, and with that adoption has also come demand for compliance and reduction of operational risks. This paper proposes a solution that improves the interpretability of tree-based models through three main contributions. Contributions like this are what furthers the area of interpretaibility in machine learning."
            },
            {
                "title": "Sampling methods for imbalanced classes",
                "link": "http://machinelearningmastery.com/data-sampling-methods-for-imbalanced-classification/",
                "content": "Sampling methods for imbalances Machine learning techniques often fail or give misleadingly optimistic performance on classification datasets with an imbalanced class distribution. The reason is that many machine learning algorithms are designed to operate on classification data with an equal number of observations for each class. When this is not the case, algorithms can learn that very few examples are not important and can be ignored in order to achieve good performance. In this article, machine learning mastery dives into a set of practical sampling methods that can be used when facing imbalanced datasets."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "59",
        "items": [
            {
                "title": "Table Detection, Information Extraction with Deep Learning",
                "link": "http://nanonets.com/blog/table-extraction-deep-learning/",
                "content": "Table Detection & NLP with DL The amount of data being collected is drastically increasing day-by-day with lots of applications, tools, and online platforms booming in the present technological era. To handle and access this humongous data productively, it\u2019s necessary to develop valuable information extraction tools. One of the sub-areas that\u2019s demanding attention in the Information Extraction field is the fetching and accessing of data from tabular forms.Table Extraction (TE) is the task of detecting and decomposing table information in a document. In this article they cover the motivations, techniques and solutions on how this can be achieved."
            },
            {
                "title": "Google\u2019s general AI conversational agent",
                "link": "http://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html?m=1",
                "content": "Towards general conv. agent The current open-domain chatbots have a critical flaw \u2014 they often don\u2019t make sense; somtimes they say inconsistencies, lack common sense and basic knowledge of the world. In this research, they present Mena, a 2.5 billion parameter end-to-end trained neural conversation model which can conduct conversations that are more sensible and specific than existing state of the art chatbots. New improvements are reflected through a human evaluation metrics proposed for open domain chatbots called sensibleness and specificity averave (SSA)."
            },
            {
                "title": "TF-Encrypt and the state of privacy-preserving ML",
                "link": "http://thedataexchange.media/the-state-of-privacy-preserving-machine-learning",
                "content": "State of privacy preserving ML Ben Lorica comes back this week with yet another great episode of the data exchange podcast, where he dives into conversation with Morten Dahl, research scientist at Dropout Labs, a startup building a platform and tools for privacy-preserving machine learning (and the person behind TF-Encrypt). In this conversation they dive into the current state of TF Encrypted, Federated learning (FL) and secure aggregation for FL, Privacy-preserving ML solutions,\u00a0 differential privacy, homomorphic encryption, and RISELab\u2019s stack for coopetitive learning (MC2)."
            },
            {
                "title": "Airflow\u2019s new Distributed Job Queueing System",
                "link": "http://medium.com/airbnb-engineering/dynein-building-a-distributed-delayed-job-queueing-system-93ab10f05f99",
                "content": "Distributed Delayed Job Queueing Asynchronous background jobs can often dramatically improve the scalability of web applications by moving time-consuming, resource-intensive tasks to the background. These tasks are often prone to failures, and retrying mechanisms often make it even more expensive to operate applications with such jobs. Having a background queue helps the web servers handle incoming web requests promptly, and reduces the likelihood of performance issues that occur when requests become backlogged. At Airbnb, they built a job scheduling system called Dynein for very critical use cases. In this article, they walk through the history of job queuing systems at Airbnb, explain why they built Dynein, and describe how they were able to achieve its high scalability."
            },
            {
                "title": "Confidence models in financial research & practice",
                "link": "http://www.oreilly.com/ideas/the-trinity-of-errors-in-applying-confidence-intervals-an-exploration-using-statsmodels",
                "content": "Applying confidence models Financial models are at the mercy in model specifications, errors in model parameter estimates and errors resulting from the failure of a model to adapt to structural changes of an environment. Because of this trifecta of errors, it\u2019s important for dynamic models to quanitfy the uncertainty inherent in the financial estimates and predictions. This post they explore three types of errors in applying confidence intervals that are common in financial research and practice."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "60",
        "items": [
            {
                "title": "An MLOps Framework for Machine Learning at Scale",
                "link": "https://www.youtube.com/watch?v=68_Phxwaj-k&feature=youtu.be",
                "content": "Hands on MLOps for AI at Scale Production machine learning systems bring fundamentally different challenges to those in traditional software engineering. Last week in our talk at FOSDEM 2020 we provided a practical CI/CD framework to scale production machine learning at massive scale. In this talk we define the concept of MLOps, cover some of the challenges that production machine learning brings to the table, as well as a hands on example using Seldon Core and Jenkins X to build machine learning pipelines that can scale to hundreds of models."
            },
            {
                "title": "Why ML Degrades in Production",
                "link": "http://towardsdatascience.com/why-machine-learning-models-degrade-in-production-d0f2108e9214",
                "content": "Why ML Degrades in Production The lifecycle of a machine learning model only begins when it\u2019s deployed. Degrading performance is a big challenge that requires the right processes and infrastructure to ensure it\u2019s monitored so that any business impact that would arise from skewed predictions due to drift in performance is avoided."
            },
            {
                "title": "Kaggle Kernel on Interpretability",
                "link": "http://www.kaggle.com/parulpandey/intrepreting-machine-learning-models",
                "content": "Kaggle Kernel on Interpretability Machine learning interpretability is key in high risk use-cases - there are large number of techniques available, each with their own tradeoffs, and it\u2019s important to make sure the tradeoffs of these are understood. This Kaggle Kernel,\u00a0 covers a high level overview of the importance of machine learning interpretability, together with hands on examples around permutation importance, partial dependence plots and SHAP."
            },
            {
                "title": "Building Domain Specific NLP",
                "link": "http://thedataexchange.media/building-domain-specific-natural-language-applications",
                "content": "Building Domain Specific NLP In this episode of the Data Exchange, Chief Scientist Ben Lorica speaks with David Talby, co-creator of Spark NLP, an open source, highly scalable, production grade natural language processing (NLP) library. Spark NLP has become one of the more popular NLP libraries and is available on PyPI, Conda, Maven, and Spark Packages. With recent advances in research in large-scale natural language models, there is strong interest in domain specific natural language applications - in this podcast they dive into some of these."
            },
            {
                "title": "Bayesian Product Raking at Wayfair",
                "link": "http://tech.wayfair.com/data-science/2020/01/bayesian-product-ranking-at-wayfair/",
                "content": "Bayesian Product Raking Wayfair Wayfair has a huge catalog with over 14 million items with very broad categories. However, the large size of our product catalog also makes it hard for customers to find the perfect item among all of the possible options. In this post wayfair introduces their new Bayesian system which was developed to (1) identify these products and (2) present them to their customers."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "61",
        "items": [
            {
                "title": "Microsoft\u2019s NLP Recipes",
                "link": "http://github.com/microsoft/nlp-recipes/",
                "content": "Microsoft\u2019s NLP Recipes In recent years, the field of natural language processing (NLP) has seen quick growth in quality and usability, and this has helped to drive business adoption of artificial intelligence solutions. Microsoft has put together a great resource with best practices for NLP through Jupyter notebooks and utility functions."
            },
            {
                "title": "Messaging & Data Ingestion with Pulsar",
                "link": "http://thedataexchange.media/taking-messaging-and-data-ingestion-systems-to-the-next-level",
                "content": "Messaging & Data Ingestion++ The Data Exchange Podcast dives into conversation with Sijie Guo on how Apache Pulsar is able to handle both queuing and streaming, and both online and offline applications. In this episode they cover the role of messaging in modern data applications/platforms, queuing implementations, streaming applications, and a status update on apache pulsar."
            },
            {
                "title": "Why Imbalanced ML is so hard",
                "link": "http://machinelearningmastery.com/imbalanced-classification-is-hard/",
                "content": "Why Imbalanced ML is so hard Machine learning mastery sheds light into the topic of imbalanced classification in machine learning, specifically around why this challenge is so difficutl to tackle. In this tutorial they cover the challenges of severly skewed class distributions, costs of missclassification, proprieties that can be imbalanced, and a framework to develop an intuition to compoind the effects on the modelling difficulty posed by different dataset properties."
            },
            {
                "title": "AI for Data Cleaning at Scale",
                "link": "http://towardsdatascience.com/ai-should-not-leave-structured-data-behind-33474f9cd07a",
                "content": "AI for Data Cleaning at Scale An interesting article that proposes using ML to clean data at scale (for training more ML). This article breaks down the challenge of data cleaning, and covers a fascinating academic opens ource project called HoloClean, which aims to tackle this, together with a breakdon of the techniques and next steps."
            },
            {
                "title": "Training Models with 1b+ Params",
                "link": "http://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/",
                "content": "Training Models with 1b+ Params Larger models are difficult to train because of cost, time, and ease of code integration. Microsoft is releasing an open-source library called DeepSpeed, which suggests to provide scale, speed, cost, and usability, unlocking the ability to train models at massive scale."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "62",
        "items": [
            {
                "title": "Jurgen\u2019s Retrospective AI 2010s",
                "link": "http://people.idsia.ch/~juergen/2010s-our-decade-of-deep-learning.html",
                "content": "Jurgen\u2019s Retrospective AI 2010s J\u00fcrgen Schmidhuber has put together a fantasic post focusing on the recent decade\u2019s most important developments and applications based on their work, as well as developments from related work, addressing privacy and data markets. The post includes LSTMs, Feed Forward NNs, Network Comparisons, Trends and the Future."
            },
            {
                "title": "Missinformation in a Hyperconnected World",
                "link": "http://www.meetup.com/Ethics-Lunch-Group-Rise-London/events/268774414/",
                "content": "Hyperconnected Missinformation This Friday we are organising an open event in London to dive into the topic of missinformation and bias in a hyperconnected world. Head of Machine Learning at Factmata Dr.\u00a0Magdalena Lis will be presenting a brief overview of the topic of fake news and bias, which will follow by a discourse on this topic to explore key themes, such as \u201cIs social media fuelling the spread of misinformation?\u201d, \u201cwhat can be done to address it?\u201d. Come join us!"
            },
            {
                "title": "MLOps: The End of End-to-End",
                "link": "http://www.mosaicventures.com/mosaicblog/2020/2/20/mlops-the-end-of-end-to-end",
                "content": "MLOps: The End of End-to-End Mosaic has put together an overview of the concept of MLOps in the context of the full lifecycle of machine learning. This post provides a conceptual understanding of the different stages in end-to-end ML including data exploration, modelling and production inference."
            },
            {
                "title": "Empirical Quality Metrics for Deep Learning",
                "link": "http://calculatedcontent.com/2020/02/16/weightwatcher-empirical-quality-metrics-for-deep-neural-networks/",
                "content": "Empirical Quality Metrics for DL A blog post that dives into the release of a tool called \u201cWeightwatcher\u201d which provides a set of tools for computing quality metrics of trained and pre-trained deep neural networks. The post provides insihgt on some of the metrics that are computed, as well as ways in which models can be benchmarked against each other."
            },
            {
                "title": "How to Interpret an ML Model",
                "link": "http://francescopochetti.com/whitening-a-black-box-how-to-interpret-a-ml-model/",
                "content": "How to Interpret an ML Model A practical jupyter notebook that dives into some high level techniques for explaining machine learning models. Some of the methods explored include partial dependency plots, individual conditional expectation, tree ensambles feature contribution, permutation feature importance and the good old LIME & SHAP."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "63",
        "items": [
            {
                "title": "The Building Blocks of ML Interpretability",
                "link": "http://distill.pub/2018/building-blocks/",
                "content": "Building Blocks of Interpretability Often machine learning interpretability techniques are studied and analysed in isolation. This post explores the powerful interfaces that arise when you combine interpretability techniques, as well as the the rich structure of the combinatorial space that results when combining them. The post provides an intuitive explanation, together with visual representations of these building blocks for machine learning interpretability techniques."
            },
            {
                "title": "Scalable ML for Everyone with Ray",
                "link": "http://thedataexchange.media/scalable-machine-learning-scalable-python-for-everyone",
                "content": "Scalable ML for Everyone with Ray"
            },
            {
                "title": "Linux Foundation\u2019s Ethics in AI and Big Data Course",
                "link": "http://www.edx.org/course/ethics-in-ai-and-big-data",
                "content": "Ethics in AI and Big Data Course The Linux Foundation has put together an excellent resource that covers key topics that form the foundations of Ethics in AI and Big Data. In this course they cover a brief overview on AI, as well as principles for building responsible AI, together with several initiatives and open source drivers that suround this topic. The course starts this week, so perfect timing to join in."
            },
            {
                "title": "Re-assessing Emotional Expressions",
                "link": "http://francescopochetti.com/whitening-a-black-box-how-to-interpret-a-ml-model/",
                "content": "Re-assessing Emotional Expressions"
            },
            {
                "title": "Microsoft\u2019s Agile Data Science Process",
                "link": "http://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview",
                "content": "Microsoft\u2019s Data Science Process Microsoft has put together a post that dives into the Team Data Science Process, which is an agile and iterative data science methodology to delivery predictive analytics solutions and intelligent applications efficiently. This article provides an overview of TDSP and its main components."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "64",
        "items": [
            {
                "title": "Kubeflow 1.0: Kubernetes ML for Everyone",
                "link": "http://medium.com/kubeflow/kubeflow-1-0-cloud-native-ml-for-everyone-a3950202751",
                "content": "Kubernetes ML for Everyone The Kubeflow Project has made their official release of the v1.0, a great milestone to bring Kubernetes Machine Learning for everyone.\u00a0The Kubeflow project brings end to end machine learning capabilities, including Development with Jupyter Notebook Management, Building with Kubeflow Fairing, Training leveraging multiple ML frameworks and Deployment with KFServing and Seldon Core."
            },
            {
                "title": "Production-Ready ML Systems",
                "link": "http://medium.com/cracking-the-data-science-interview/the-5-components-towards-building-production-ready-machine-learning-system-a4d5237ec04e",
                "content": "Production-Ready ML Systems One of the biggest issues that we face in machine learning is how to deploy and scale models in production. This article breaks down the core concepts that make machine learning deployment and productionionisation different to that of traditional software, as well as the core components that are part of the machine learning lifecycle. These include the Training, Validation, Testing, Serving and Monitoring."
            },
            {
                "title": "Explaining Long Term ML Impact",
                "link": "http://ai.googleblog.com/2020/02/ml-fairness-gym-tool-for-exploring-long.html",
                "content": "Explaining Long Term ML Impact Machine learning systems have been increasingly deployed to aid in high-impact decision-making, such as determining criminal sentencing, child welfare assessments, who receives medical attention and many other settings. Understanding whether such systems are fair is crucial, and requires an understanding of models\u2019 short- and long-term effects.Google released a research paper which outlines a set of components for building simple simulations that explore potential long-run impacts of deploying machine learning-based decision systems in social environments."
            },
            {
                "title": "Quantifying Reproducibility of ML",
                "link": "http://thegradient.pub/independently-reproducible-machine-learning/",
                "content": "Quantifying Reproducibility of ML Peer review has been an integral part of scientific research for more than 300 years. But even before peer review was introduced, reproducibility was a primary component of the scientific method. Now, we hear warnings that Artificial Intelligence (AI) and Machine Learning (ML) face their own reproducibility crises. This article dives into insights obtained whilst attempting to reproduce ML algorithms from papers continuously, leading into a framework to assess and quantify how reproducible a specific resource is."
            },
            {
                "title": "Adversarial Examples Resource",
                "link": "http://nicholas.carlini.com/writing/2019/all-adversarial-example-papers.html",
                "content": "Adversarial Examples Resource It can be hard to stay up-to-date on the published papers in the field of adversarial examples, where we have seen massive growth in the number of papers written each year. This resource attempts to address just that by putting together a huge list of papers from Arxiv related to adversarial examples."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "65",
        "items": [
            {
                "title": "Explainability, Security & MLOps in Podcast",
                "link": "http://thedataexchange.media/the-responsible-development-deployment-and-operation-of-machine-learning-systems",
                "content": "Explainability, Security & MLOps The Data Exchange Podcast comes back this week with a conversation on machine learning explainability, MLOps, adversarial robustness and privacy preserving ML, with Institute for Ethical AI Chief Scientist & Seldon Engineering Director Alejandro Saucedo. In this podcast Ben Lorica and Alejandro dive into some of the key trends in machine learning, as well as some of the core best practices for developing, deploying and monitoring production machine learning at massive scale."
            },
            {
                "title": "Python Machine Learning Books",
                "link": "http://pythonbooks.org/topical-books/machine-learning-and-artifical-intelligence/",
                "content": "Python Machine Learning Books A fantastic resource that has been compiled together from some of the best books found through conversations across developers and researchers. Specifically this sub-page has carefully curated Python Books that focus specifically on machine learning. The books referenced in this section are not only great for beginners, but also for intermediate-level ML learners."
            },
            {
                "title": "DevOps in Machine Learning",
                "link": "http://www.theregister.co.uk/2020/03/07/devops_machine_learning_mlops/",
                "content": "DevOps in Machine Learning What would machine learning look like if you mixed in DevOps? Wonder no more, Seldon Open Source Developer Dr.\u00a0Ryan Dawson has put together a great piece that outlines the concept of MLOps, together with some of the existing biggest challenges, solutions and best practices, together with some of the initiatives that are advancing these discussions forward."
            },
            {
                "title": "A Tour on E2E ML Platforms",
                "link": "http://databaseline.tech/a-tour-of-end-to-end-ml-platforms/",
                "content": "A Tour on E2E ML Platforms A fantastic article by Spotify Senior Data Engineer Ian Hellstr\u00f6m which aims to provide a high level overview of some of the end-to-end platforms available in the MLOps space. This post dives into Google TFX, Uber Michelangelo, Airbnb Bighead, Netflix Metaflow and more."
            },
            {
                "title": "Adversarial ML Reading List",
                "link": "http://nicholas.carlini.com/writing/2018/adversarial-machine-learning-reading-list.html",
                "content": "Adversarial ML Reading List Another fantastic resource that dives into the broad world of Adversarial Robustness, which has curated and carefully selected pieces that are recommended as reading list for anyone interested to learn more on the topic. This resource also provides a high level overview that covers the basics, a quick introduction, a complete background and papers broken down by various categories."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "66",
        "items": [
            {
                "title": "PyTorch ML from Scratch",
                "link": "http://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/",
                "content": "PyTorch ML from Scratch Machine Learning Mastery has put together a great resource providing a step by step guide on how to train a PyTorch machine learning model. The article covers every step including installation, ML lifecycle (data prep, training, evaluation), and even going further into developing a MLP for multiclass & regression and a CNN for image classification."
            },
            {
                "title": "The MLOps References List",
                "link": "http://github.com/visenger/mlops-references",
                "content": "The MLOps References List A fantastic resource that has put together a very comprehensive list of resources related to MLOps, or the topic surounding the components required to productionise machine learning. This resource contains multiple different themes including references, papers, talks, existing ML systems, and more."
            },
            {
                "title": "Deep Learning in Information Retrieval",
                "link": "http://thedataexchange.media/how-deep-learning-is-being-used-in-search-and-information-retrieval",
                "content": "Deep Learning & Info Retrieval The Data Exchange Podcast comes back this week in conversation with Hypercube Founder Edo Liberty, focusing primarily on how deep learning can be used in search & information retrieval. This podcast includes Edo\u2019s experience, deep learning & IR, challenges when building information retrieval tools at scale, and deep learning based search including enterprise e2e deep search paltforms"
            },
            {
                "title": "Integrating SHAP Explainability",
                "link": "http://docs.seldon.io/projects/alibi/en/latest/methods/KernelSHAP.html",
                "content": "Integrating SHAP Explainability SHAP (SHapley Additive exPlanations) is an algorithm which provides model-agnostic (black box), human interpretable explanations suitable for regression and classification models applied to tabular data. This method is a member of the additive feature attribution methods class; feature attribution refers to the fact that the change of an outcome to be explained (e.g., a class probability in a classification problem) with respect to a baseline (e.g., average prediction probability for that class in the training set) can be attributed in different proportions to the model input features. The Alibi Explain OSS project has implemented this technique and has put together several jupyter notebook examples to implement this algorithm across various models."
            },
            {
                "title": "AI meets operations with OReilly",
                "link": "http://www.oreilly.com/radar/ai-meets-operations/",
                "content": "AI meets operations with OReilly One of the biggest challenges operations groups will face over the coming year will be learning how to support AI- and ML-based applications. The OReilly team has put together a comprehensive high level overview of the probelm of managing machine learning at scale. In this article Mike Loukides provides a high level overview of this challenge, together with some of the components that may comprise the solutions, as well as examples."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "67",
        "items": [
            {
                "title": "Deploying COVID-19 AI solutions at scale",
                "link": "http://github.com/axsaucedo/seldon-core/blob/corona_research_exploration/examples/models/research_paper_classification/README.md",
                "content": "COVID-19 AI solutions at scale There has been great momentum from the machine learning community to extract insights from the increasingly growing COVID-19 Datasets, such as the Allen Institute for AI Open Research Dataset as well as the data repository by Johns Hopkins CSSE - the best insights have come out of cross-functional collaborations across ML practitioners and relevant domain experts such as infectious disease experts. Chief Scientist at the Institute for Ethical AI Alejandro Saucedo has put together a brief hands on tutorial to showcase how to deploy COVID-19 AI Solutions at scale, encouraging cross functional collaboration across domain experts such as data scientists, software engineers and even epidemiologists & healthcare professionals."
            },
            {
                "title": "Democratising Deep Fakes \ud83d\ude2c",
                "link": "http://colab.research.google.com/github/AliaksandrSiarohin/first-order-model/blob/master/demo.ipynb#scrollTo=d8kQ3U7MHqh-",
                "content": "Democratising Deep Fakes \ud83d\ude2c An incredibly fascinating tutorial that showcases yet further improvement and simplification into the creation of deep fakes, making it even easier for researchers and practitioners to create deep fakes. The rate of improvement of the quality and simplicity around creation of deep fakes is improving with break-neck speed, and with that a lot of very interesting questions arise around the ethical, privacy- and security-related concerns, across others. Try out the hands on collab notebook to try it yourself. You can also check out the video that covers the paper and implementation into further detail."
            },
            {
                "title": "Shopify on Scaling AI",
                "link": "http://thedataexchange.media/business-at-the-speed-of-ai-lessons-from-shopify",
                "content": "Shopify on Scaling AI The Data Exchange comes back this week with a fantastic podcast in converastion with Shopify VP and Head of Data Science and Data Platform Engineering Solmaz Shahalizadeh. In this podcast they dive into building and scaling machine learning data products, building and scaling data teams, and data informed product building."
            },
            {
                "title": "Industry Reinforcement Learning",
                "link": "http://anyscale.com/blog/enterprise-applications-of-reinforcement-learning-recommenders-and-simulation-modeling/",
                "content": "Industry Reinforcement Learning Chief Scientist Ben Lorica has put together a great article that covers a high level overview of enterprise applications of reinforcement learning. The post covers applications of reinforcement learning in recommenders systems, simulation modelling & opimisation, and dives into some of the tools that power some of those solutions, together with an insight on some of the biggest challenges currently in this space."
            },
            {
                "title": "Transfer Learning in NLP",
                "link": "http://docs.google.com/presentation/d/1LsUAhR_qIVbq6xH6Aw4ag8MGB_-UWfd0KoVhtTgye6o/edit#slide=id.g6e76c30798_0_0",
                "content": "Transfer Learning in NLP A fantastic presentation that covers a very comprehensive overview and deep dive on all-things-transfer-learning in NLP. The presentation covers the motivations, open problems, definitions/terminology, as well as some of the current work in the research and practitioner communities. The slides are available, as well as a version of that presentation in video format."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "68",
        "items": [
            {
                "title": "GitLab Data Lessons Learned",
                "link": "http://about.gitlab.com/blog/2020/02/10/lessons-learned-as-data-team-manager/",
                "content": "GitLab Data Lessons Learned A fantastic article by GitLab Staff Data Engineer Taylor Murphy on his key lessons learned leading the GitLab Data Team. In this article Taylor covers the importance of management skills in data engineering, together with key areas to focus including growth, hiring, process, tools, performance, meetings and beyond. The article also provides a significant amount of links and resources to expand in these very useful areas."
            },
            {
                "title": "Data Discovery at Spotify",
                "link": "http://labs.spotify.com/2020/02/27/how-we-improved-data-discovery-for-data-scientists-at-spotify/",
                "content": "Data Discovery at Spotify Spotify has released a high level overview of their journey to improve data discovery across the firm. In this article they provide a set of high level steps (or themes) that they follow to achieve these; including diagnosing the problem, understanding intent, enabling knowledge, mapping expertise and more."
            },
            {
                "title": "Exploratory Data Analysis Deep Dive",
                "link": "http://towardsdatascience.com/an-extensive-guide-to-exploratory-data-analysis-ddd99a03199e",
                "content": "Exploratory Data Analysis Dive A very comprehensive article that outlines the best practices on Exploratory Data Analysis, a step which is foundational to the data science process. This article covers a high level definition to EDA, it\u2019s components, and a deep dive into how to dive into understanding features, cleaning datasets and analysing feature relationships."
            },
            {
                "title": "Tokenisers & How Machines Read",
                "link": "http://blog.floydhub.com/tokenization-nlp/",
                "content": "Tokenisers & How Machines Read NLP applications are only growing in industry, and hence best practices and understanding of its fundamentals is increasingly crucial. This article provides a very comprehensive deep dive in one of the core components of NLP; tokenization. This article provides a deep dive on the topic of tokenization, together with the challenges that present in this space, and common types of text tokenization."
            },
            {
                "title": "Intel Demystifying the AI Stack",
                "link": "http://www.intel.com/content/www/us/en/intel-capital/news/story.html?id=730#/type=QWxs/page=0/term=/tags=",
                "content": "Intel Demystifying the AI Stack Intel Capital has created an overview of the end-to-end AI infrastructure stack, together with a mapping of how existing projects fall into their respective categories. In this article they cover an overview of the different layers of their Stack, including Hardware, Software Accelerators, Libraries, Data Science Frameworks, Orchestration, Automation, and Autonomous."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "69",
        "items": [
            {
                "title": "AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/69.html",
                "content": "This week in Issue #69:"
            },
            {
                "title": "Insights for Remote ML Teams",
                "link": "http://www.comet.ml/site/how-to-make-remote-work-effective-for-data-science-teams/",
                "content": "Insights for Remote ML Teams CometML has put together a great article that outlines best practices for managing remote data science teams. The article includes key considerations, including ortanisational structures, biggest challenges that remote workers face, and best practices; these include productive workspaces, communication, habits, trust and more."
            },
            {
                "title": "Human-in-the-loop in Prod ML",
                "link": "http://thedataexchange.media/human-in-the-loop-machine-learning/",
                "content": "Human-in-the-loop in Prod ML A great Data Exchange Podcast with Machine Learning Consulting CEO Rob Munro, where they dive into \u201cHuman in the loop Machine Learning\u201d, and cover Rob\u2019s experience at various tech giants, writing his book on the topic, several NLP areas where it\u2019s relevant, and how this fits in real life."
            },
            {
                "title": "Netflix & Druid for Real Time Data",
                "link": "http://netflixtechblog.com/how-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06",
                "content": "Netflix & Druid for Real Time Data Netflix brings us a high level overview of how they use Druid for real time insights. Apache Druid is a high performance real-time analytics database, which is designed primarily for workflows where fast queries and ingest really matter. In this post they highlight how Druid\u2019s capabilities shine around instant data visibility, ad-hoc queries, operational analytics and handling high concurrency. They cover a high level architecture of their data processing lifecycle, as well as insights they have gathered to ensure scale."
            },
            {
                "title": "The Importance of Data Prep",
                "link": "http://www.oreilly.com/radar/the-unreasonable-importance-of-data-preparation/",
                "content": "The Importance of Data Prep The O\u2019Reilly team published a great post that highlights the importance of data preparation. In this article they present a \u201cData Science Hierarchy of Needs\u201d, where they outline how key data processing is to ensure accurate and reliable insights when tackling any data-related challenge. In the post they cover the importance of automatic data prep, some key tools aiding in this area, and they dive into the future of tooling."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "70",
        "items": [
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/70.html",
                "content": "This week in Issue #70:"
            },
            {
                "title": "Privacy Preserving AI Lecture",
                "link": "http://www.youtube.com/watch?v=4zrU54VIK6k",
                "content": "Privacy Preserving AI Lecture Andrew Trask joins Lex Fridman to deliver a full-length lecture on privacy preserving AI. This excellent resource covers a broad set of areas within the space of privacy preserving AI, including the premise of the problem it aims to solve, the different tools available at our disposal, terminoogy and other key concepts in this area."
            },
            {
                "title": "Backpropagation 101 from Thinc",
                "link": "http://thinc.ai/docs/backprop101",
                "content": "Backpropagation 101 from Thinc SpaCy Cofounder Matt Honibal has put together a fantastic resource that dives into a step by step intuitive overview of the backpropagation algorithm and it\u2019s implementation in deep learning, and breaks in down in its constituent terms with hands on practical examples."
            },
            {
                "title": "Harvard Offering Free Courses",
                "link": "http://online-learning.harvard.edu/catalog?keywords=&subject%5B%5D=3&paid%5B1%5D=1&max_price=&start_date_range%5Bmin%5D%5Bdate%5D=&start_date_range%5Bmax%5D%5Bdate%5D=",
                "content": "Harvard Offering Free Courses Harvard is offering free online courses for anyone that wants to expand their knowledge boundaries, which is fantastic as they are accessible for free. These courses cover a broad range of topics in computer science, including their AI with Python course. For anyone interested, they also have made available over 50 courses across various other academic fields that are also available for free."
            },
            {
                "title": "GPT2 AI Dungeon Game Update",
                "link": "http://medium.com/@aidungeon/ai-dungeon-multiplayer-is-out-84177419bf7a",
                "content": "GPT2 AI Dungeon Game Update AI Dungeons is a narrative based game built on top of the natural language generation model GPT-2, which allows for a fully unique and pseudo-personalised gaming experience. They have released new functionality which allows players to try it out without any code, and even being able to play in multi-player model"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "71",
        "items": [
            {
                "title": "A Practical Intro to Responsible AI",
                "link": "http://www.youtube.com/watch?v=TPoEs-HJE6U",
                "content": "A Practical Intro to Responsible AI The next generation of young innovators took the virtual channels this weekend to build solutions to tackle the challenge of our generation at the YouthVsCOVID TeensInAI Hackathon. During this event we presented a talk that covered a practical introduction to responsible AI, where we covered some of the key motivations for following best practices to ensure responsible development, deployment and operation of AI systems. Please also check out the other fantastic talks presented at the event at the TeensInAI Youtube Channel."
            },
            {
                "title": "Simulating the Real World in Python",
                "link": "http://realpython.com/simpy-simulating-with-python/",
                "content": "Simulating Real World in Python A simulation is a representation of a real-world system. One can use mathematical or computational models of this system to study how it works - this article showcases how you can leverage Python\u2019s SimPy library to get started."
            },
            {
                "title": "Advanced NLP with SpaCy",
                "link": "http://course.spacy.io/en/",
                "content": "Advanced NLP with SpaCy SpaCy Co-founder Ines Montani has put together an official advanced NLP course which introduces core Natural Language Processing concepts using SpaCy. This course is broken down into four chapters which cover foundational pieces such as finding workds / phrases, scaling analysis, building processing pipelines and training your own neural network model."
            },
            {
                "title": "500 Free CompSci Courses",
                "link": "http://www.freecodecamp.org/news/free-courses-top-cs-universities/",
                "content": "500 Free CompSci Courses Every year, Class Central publishes rankings of the world\u2019s highest rated and most popular online courses. This year they decided to showing all the free online courses from some of the top courses at universities (with a section focusing on computer science). This article provides the methodology (and jupyter notebook) used to rank the universities using the central class database."
            },
            {
                "title": "Modelling & Simulating Epidemics",
                "link": "https://thedataexchange.media/computational-models-and-simulations-of-epidemic-infectious-diseases/",
                "content": "Modelling & Simulating Epidemics The Data Exchange comes back with an excellent podcast where it dives into the trending topic of computational modelling and simulations of epidemic infectionus diseases. During this podcast Chief Scientist Ben Lorica speaks with Data Scientist Bruno Goncalves, and covers some key techniques used for epidemic modelling, as well as their impact in decision making."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/70.html",
                "content": "AI Conferences Gone Virtual 2020 [Updated List 26/04/2020] Due to the current global situation, a large number of conferences have had to face hard choices, several which decided going fully virtual. This hard choice has now open the doors to people from around the world to gain access to the great online content generated by expert speakers and contributors. We wanted to highlight some of these key conferences so they are not missed - these include:"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "72",
        "items": [
            {
                "title": "Monitoring Machine Learning Models in Prod",
                "link": "http://christophergs.com/machine%20learning/2020/03/14/how-to-monitor-machine-learning-models/",
                "content": "Monitoring ML Models in Prod The lifecycel of a machine learning model only begins when it\u2019s deployed to production. It\u2019s key to be able to understand the performance, and especially the degrades that the models experience as time passes. Whether it is due to data distribution changing, or other external factors, it\u2019s key to ensure the right infrastructure is in place. This article provides an excellent picture of this challenge and various tools and solutions available."
            },
            {
                "title": "65 Free Springer ML Books",
                "link": "http://towardsdatascience.com/springer-has-released-65-machine-learning-and-data-books-for-free-961f8181f189",
                "content": "65 Free Springer ML Books Springer has released hundreds of free books on a wide range of topics to the general public. The list, which includes 408 books in total, covers a wide range of scientific and technological topics. In order to save you some time, this article has created a single list of all the books (65 in number) that are relevant to the data and Machine Learning field."
            },
            {
                "title": "Neural Network Music Generator",
                "link": "http://openai.com/blog/jukebox/",
                "content": "Neural Network Music Generator OpenAI has released a very interesting announcement, the launch of Jukebox, a neural network based model that can be used to generate music of different genres with lyrics. In this post they cover in depth the approach as well as various examples that were generated with this model."
            },
            {
                "title": "Open Source Deep Learning",
                "link": "http://thedataexchange.media/an-open-source-platform-for-training-deep-learning-models/",
                "content": "Open Source Deep Learning The Data Exchange podcast comes back this week with a deep dive with DeterminedAI CEO Evan Sparks, where they dive into their brand new open sourced Deep Learning Training platform, together with some key enterprise use-cases of deep learning, the challenges and opportunities of distributed training & hyperparameter tuning, as well as some examples of how teams have been using their open source platform."
            },
            {
                "title": "AI, COVID19, Ethics & Contact Tracing",
                "link": "http://www.meetup.com/Ethics-Lunch-Group-Rise-London/events/270379397/",
                "content": "AI, COVID19 & Contact Tracing As we face one of the biggest challenges of our generation, several ethical implications arise which often appear to clash with urgency of proposed solutions - one of the ongoing key technological discussions in this space is the use and approach towards contact tracing techology. We are organising a meetup on the 15th of March where HATLAB Deputy Director wil dive into the ethical implications of responses to COVID in the context of contact tracing in particular."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/70.html",
                "content": "[Updated] AI Conferences Gone Virtual in 2020"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "73",
        "items": [
            {
                "title": "Real Time ML Stream Processing",
                "link": "http://pycon.hk/sessions-2020-spring/real-time-stream-processing-with-python-at-scale/",
                "content": "Real Time ML Stream Processing This weekend we have a talk at PyConHK 2020 about real time machine learning using Python, Faust, Kafka and Seldon. During this talk we dive into the core concepts of stream processing, as well as the ecosystem of tools available and a hands on example building a streaming pipeline with multiple workers processing real time comments from Reddit\u2019s /r/science subreddit using 200k comments the \u201ccomments removed by mods\u201d dataset."
            },
            {
                "title": "ACM Position Statement on Contact Tracing",
                "link": "http://www.acm.org/binaries/content/assets/public-policy/europe-tpc-contact-tracing-statement.pdf",
                "content": "Statement on Contact Tracing We have been contributing to a position statement on Contact Tracing applications through our role at the Association for Computer Machinery (ACM)\u2019s European Policy Committee. This statement provides a set of principles and recommendations to countries that are looking to use contact tracing to tackle the challenges COVID has been posing in our societies. This Friday we\u2019re also organising a virtual meetup where the Hatlab Deputy Director will be sharing insights on contact tracing apps."
            },
            {
                "title": "ICLR 2020 Videos Released",
                "link": "http://iclr.cc/virtual_2020/calendar.html",
                "content": "ICLR 2020 Videos Released The Eighth Conference on Learning Representations took place virtually in 2020, and has recently released the videos for the all the talks, which are now available at their website. This is a fantastic resource that provides access to state of the art research in a digestible format, and provides for an open resource from which other researchers and practitioners will be able to build upon."
            },
            {
                "title": "Why TinyML will be Huge",
                "link": "http://thedataexchange.media/why-tinyml-will-be-huge/",
                "content": "Why TinyML will be Huge The Data Exchange Podcast comes back this week with a fantastic session with Staff Research Engineer Pete Warden. This episode covers the early days of deep learning for computer vision, core early days of the tensorflow project, insights on TinyML and why it\u2019s such an important topic, privacy in the context of tinyML, and Pete\u2019s new book."
            },
            {
                "title": "PapersWithCode: A home for ML",
                "link": "http://medium.com/paperswithcode/a-home-for-results-in-ml-e25681c598dc",
                "content": "PapersWithCode: A home for ML The PapersWithCode project has released a new update, where they share some insights on the challenge of reproducibility that they have been tackling with this project. They are introducing new exciting features, including new results interface, an ML Extraction Algorithm that automatically extracts results from papers, and a Big Database update with 800+ new leaderboards, 550+ new results and more."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/73.html",
                "content": "This week in Issue #73:"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "74",
        "items": [
            {
                "title": "Coding Habits for Data Scientists",
                "link": "http://www.thoughtworks.com/insights/blog/coding-habits-data-scientists",
                "content": "Coding Habits for Data Scientists Often ML code is written in Jupyter notebooks with the main purpose of experimentation instead of scalability, which may come with undesired side-effects and may have deterimental impacts on the stability and robustness of the model beyond it\u2019s deployment. This article has put toghether a great overview of some of the motivations as well as best practices around coding habits for data science."
            },
            {
                "title": "Enterprise AI Adoption 2020",
                "link": "http://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2020/",
                "content": "Enterprise AI Adoption 2020 O\u2019Reilly has put together and compiled the results of a survey they carried out which provides insights on AI Adoption in the Enterprise in 2020. In this article they dive into how the efforts are maturing from prototype to production on AI, and how companies are able to fill the skills gap across a broad range of industries."
            },
            {
                "title": "Natural Language Processing 101",
                "link": "http://realpython.com/natural-language-processing-spacy-python/",
                "content": "Natural Language Processing 101 A fantastic tutorial that goes into the depths of Natural Language Processing. This article dives into the foundational terms and concepts in NLP, how to use the SpaCy framework for NLP, building end to end pipelines and diving into more advanced NLP concepts."
            },
            {
                "title": "AI Scalability & Performance",
                "link": "http://thedataexchange.media/improving-performance-and-scalability-of-data-science-libraries/",
                "content": "AI Scalability & Performance The data exchange podcast goes into conversation with Wes McKinney, Director of Ursa Labs and Apache Arrow PMC member. Wes is the creator of Pandas, and author of the best selling book \u201cPython for Data Analysis\u201d. In this post they cover these open source projects, they dive into the need for shared infrastructure for data science, and some of the critical work at Ursa Labs."
            },
            {
                "title": "MLOps is Not Enough",
                "link": "http://techcommunity.microsoft.com/t5/azure-ai/mlops-is-not-enough/ba-p/1386789#",
                "content": "MLOps is Not Enough MLOps is defined as the operational complexities involved in operating production machine learning at scale. This article from microsoft provides deeper thoughts on the concept of MLOps and argues that a broader approach is required to tackle the challenge at scale - namely the Data Science Lifecycle process."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/74.html",
                "content": "This week in Issue #74:"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "75",
        "items": [
            {
                "title": "Microsoft Code Autocomplete AI",
                "link": "http://www.youtube.com/watch?v=fZSFNUT6iY8",
                "content": "Microsoft Programming AI Microsoft and OpenAI shared yet another interesting use-case of GPT-2 text generation - this time its function is to generate Python code. They showcased it during the Microsoft Build 2020 last week, which although was only a prepared demonstration, does seem to have some really interesting insights showing how to generate suggested code based on an initial input."
            },
            {
                "title": "ML Infra for Model Building",
                "link": "http://towardsdatascience.com/ml-infrastructure-tools-for-model-building-464770ac4fec",
                "content": "ML Infra for Model Building Arize AI Co-Founder Aparna Dhinakaran has put togher an overview on the tools available to address the challenges present in the end to end machine learning lifecycle. This article proposes over a dozen different t hemes to classify the various different technologies available, which shows the complexity that the end to end ML challenge encompasses, and provides a brief intuitive overview of each"
            },
            {
                "title": "Virtual Discourse on Rethinking Public Data",
                "link": "http://www.meetup.com/Tech-Ethics-London/events/270315999/",
                "content": "Discourse Rethinking Public Data Thanks to advances in the development of data-driven technologies, we now have unprecedented opportunities to unlock the social value of data. Data could now truly function as a common resource and a public good with transformative power for communities and society. This Friday we are organising an online session where Head of Public Engagement at the UK Ada Lovelace Institute, Reema Patel, will be share insights on the ethical challenges about data use and we will dive into how we can best ensure data is used in the interests of society."
            },
            {
                "title": "Advanced NLP Video Course",
                "link": "http://www.youtube.com/watch?v=THduWAnG97k",
                "content": "Advanced NLP Video Course Last week we shared the Advanced NLP Course that dives into how to use SpaCy to tackle intermediate and advanced NLP real-life challenges. This week the SpaCy team has shared a video series they have created which covers the NLP Course end to end. This is a fantastic resource which has now (and still is) been translated into a large range of different languages (with Humans help not NLP in this case, we\u2019re fully not there just yet)."
            },
            {
                "title": "What to Do When AI Fails",
                "link": "http://www.oreilly.com/radar/what-to-do-when-ai-fails/",
                "content": "What to Do When AI Fails O\u2019Reilly has put together a great piece that emphasises the implications AI use-cases have when they go wrong, namely it introduces the motivation of such reflection quoting several relatively recent high profile incidents that showcase their impact. In this post they outline how these AI cases are different, as well as terminology around \u201cAI incidents\u201d, and some of the best practices and approaches available to mitigate these scenarios."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/75.html",
                "content": "This week in Issue #75:"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "76",
        "items": [
            {
                "title": "Highlights on EuroPython & ACM",
                "link": "http://www.acm.org/articles/membernet/2020/membernet-05282020#ACM-officers",
                "content": "Highlights on EuroPython & ACM"
            },
            {
                "title": "ML in Production Deployment Guide",
                "link": "http://mlinproduction.com/what-does-it-mean-to-deploy-a-machine-learning-model-deployment-series-01/",
                "content": "ML in Prod Deployment Guide \u201cML in Production\u201d is a website that curates content focused around best practices for building real world machine learning systems. They have put together a fantastic five-part series that dives into the concepts and challenges of production machine learning, including the definitions, the software interfaces, batch processing, online inference and ml deployment."
            },
            {
                "title": "Frameworks used by ML Startups",
                "link": "http://neptune.ai/blog/tools-libraries-frameworks-methodologies-ml-startups-roundup?utm_source=reddit&utm_medium=post&utm_campaign=blog-tools-libraries-frameworks-methodologies-ml-startups-roundup",
                "content": "Frameworks used by ML Startups Navigating the wide and deep range of machine learning tools can be hard, especially for fast-moving requirements that startups face. In this article 41 machine learning startups were surveyed across the world to gain understanding on the tools, libraries and frameworks used on a day to day basis. The insights obtained are grouped into Methodology, Software Development setup, ML Frameworks, MLOps and \u201cthe unexpected\u201d."
            },
            {
                "title": "GPT-3 Deep Dive Explanation",
                "link": "http://www.youtube.com/watch?v=SY5PvZrJhLE",
                "content": "GPT-3 Deep Dive Explanation A paper was released last week covering initial achievements in the experimental results the GPT Language Model, trained on almost 500 Billion tokens and 175 Billion parameters. This 60 minute video dives into the paper and breaks it down in an intuitive and comprehensible perspective, covering the terminology & foundations, details on the model size & dataset, methodology, fine tuning, experimental results and much more."
            },
            {
                "title": "Scaling Data with Outliers for ML",
                "link": "http://machinelearningmastery.com/robust-scaler-transforms-for-machine-learning/",
                "content": "Scaling Data with Outliers for ML Machine Learning Mastery has put together a comprehensive article which dives into how to use robust scaler transforms to standardise numerical input variables for classification and regression. In this tutorial they cover the algorithms that benefit from these techniques, some of the approches that enable it, and how to use the RobustScaler to scale numerical input variables using the median and interquartile range."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/75.html",
                "content": "AI Conferences Gone Virtual 2020 [Updated List 31/05/2020] Due to the current global situation, a large number of conferences have had to face hard choices, several which decided going fully virtual. This hard choice has now open the doors to people from around the world to gain access to the great online content generated by expert speakers and contributors. We wanted to highlight some of these key conferences so they are not missed - these include:"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "77",
        "items": [
            {
                "title": "Made with Machine Learning Platform",
                "link": "http://madewithml.com/",
                "content": "Made with ML Platform \u201cMade with ML (MWML)\u201d is a fantastic free platform that focuses on enabling the ML community to learn, explore and built, through a set of curated resources, ML related lessons, a continuously updated set of ML projects, and more. Check it out and do make sure to add any projects / resources that are not listed already."
            },
            {
                "title": "Identifying & Mitigating AI Risks",
                "link": "http://thedataexchange.media/identifying-and-mitigating-liabilities-and-risks-associated-with-ai/",
                "content": "Identifying & Mitigating AI Risks The Data Exchange podcast comes back with a fantastic conversation with Immuta Chief Legal Officer and BNH AI Managing Partner Andrew Burt. This podcast dives into core components of machine learning model governance, specifically from a legal professional perspective, diving into the intersection between these two fields, covering best practices and challenges of identifying and mitigating risks, as well as incident response and recovery in ML."
            },
            {
                "title": "ACM ByteCast with Donald Knuth",
                "link": "http://learning.acm.org/bytecast",
                "content": "ACM ByteCast with Donald Knuth The Association for Computing Machinery has released their first ByteCast podcast, kicking off with a fantastic conversation with Computer Science Legend Donald Knuth, largely known for his book, \u201cThe Art of Computer Programming\u201d. In this podcast they discuss what led him to discover his love for computer science, as well as his outlook on how people learn technical skills, and how his mentorship has helped him write \u201chuman oriented\u201d programs."
            },
            {
                "title": "Microsoft NLP Bias Research",
                "link": "http://venturebeat.com/2020/06/01/microsoft-researchers-say-nlp-bias-studies-must-consider-role-of-social-hierarchies-like-racism/",
                "content": "Microsoft NLP Bias Research Following our post last week covering GPT-3, this week Microsoft comes with a very important topic, publishing a paper that covers the analysis of 146 NLP bias research papers. In this paper they dive into the issues and impact in some of this bias, as well as best practices required in the research field to ensure some of these undesired biases are identified and mitigated."
            },
            {
                "title": "Feature Selection with Continuous Data",
                "link": "http://machinelearningmastery.com/feature-selection-with-numerical-input-data/",
                "content": "Feature Selection with Cont. Data Machine Learning mastery has put together a great overview of an important sub-topic in feature selection. Namely this is feature selection with numerical or continuous input data. In this post they cover a hands on example using a diabetes prediction dataset, showcasing the challenges found in conitnuous inputs in the context of binary classification, and they teach how to evaluate the importance of numerical features using the ANOVA f-test and mutual information statistics."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/75.html",
                "content": "[Updated] AI Conferences Gone Virtual in 2020"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "78",
        "items": [
            {
                "title": "Outlier & Anomaly Detection ML",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning/#outlier-and-anomaly-detection",
                "content": "Outlier & Anomaly Detection ML"
            },
            {
                "title": "The State of ML in Python 2020",
                "link": "http://arxiv.org/abs/2002.04803",
                "content": "The State of ML in Python 2020 Python continues to be the fastest growing language for scientific computing, data science and machine learning. Sebastian Raschka has put together together with Joshua Patterson and Corey Nolet an overview of the current state of machine learning in python, diving into some of the main developments and technology trends in data science, machine learning and broader artificial intelligence."
            },
            {
                "title": "Applied Homomorphic Encryption",
                "link": "http://simons.berkeley.edu/talks/practical-applications-homomorphic-encryption",
                "content": "Applied Homomorphic Encryption Homomorphic Encryption is a fascinating privacy preserving machine learning technique that allows for processing to take place on encrypted data, which provides the same results as if the computation was processed on the plaintext. This of course comes at a computational cost, however the developments in these techniques are making them more accessible. In this talk Hao Chen from Microsoft Research dives into some of the practical applications of this techqnique, together with an overview of the technique itself."
            },
            {
                "title": "OpenAI NLP API Beta Launch",
                "link": "http://beta.openai.com/",
                "content": "OpenAI NLP API Beta Launch We covered last week the launch of the new OpenAPI GPT3 release, a model that requires an unprecedented amount of computational power to even process an inference, let alone train. This week OpenAPI has released a new commercial API for NLP tasks including semantic search, summarization, sentiment analysis, content generation, translation, and more."
            },
            {
                "title": "Continuous Delivery Podcast",
                "link": "http://cd.foundation/podcast/",
                "content": "Continuous Delivery Podcast With the demands for large scale production machine learning systems, the skills required to build, maintain and operate these systems require a set of cross-functional skills which range from data science to devops. In the context of the devops requirements, the trend of continuous delivery has become growingly important with the emergence and adoption of frameworks like Kubernetes. The Continuous Delivery foundation has released an exciting initiative to dive into some of the topics that are critical in MLOps in their new CI/CD & DevOps Podcasts. Check it out."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/75.html",
                "content": "[Updated] AI Conferences Gone Virtual in 2020"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "79",
        "items": [
            {
                "title": "ML Model Serving Ecosystem",
                "link": "http://github.com/EthicalML/awesome-production-machine-learning#model-serving-and-monitoring",
                "content": "Model Serving Ecosystem Demands for large scale production machine learning capabilities are growing at breakneck speeds, and the ecosystem of tools are growing at equally fast pace. DKB ML Lead Engineer Lina Weichbrodt has made a fantastic contribution to our OSS Production ML Tools list, adding a new section with tools that specialise on large-scale frameworks for ML serving and monitoring. This is a great new addition which we\u2019re quite excited about as it will allow the community to stay up to date with innovation in this field."
            },
            {
                "title": "GitHub Actions for MLOps",
                "link": "http://github.blog/2020-06-17-using-github-actions-for-mlops-data-science/",
                "content": "GitHub Actions for MLOps Machine Learning Operations (or MLOps) enables Data Scientists to work in a more collaborative fashion, by providing testing, lineage, versioning, and historical information in an automated way. GitHub has put together an article that outlines how it\u2019s possible to leverage the GitHub Actions feature that integrates parts of the data science and machine learning workflow with a software development workflow."
            },
            {
                "title": "Building OSS Tools for NLP Devs",
                "link": "http://thedataexchange.media/building-open-source-developer-tools-for-language-applications/",
                "content": "Building OSS Tools for NLP Devs The Data Exchange podcast dives into conversation with SpaCy and ExplosionAI Cofounder Matt Honnibal. In this great episode Matt shares insights related to the most popular NLP library SpaCy, together with some of the other fantastic projects the ExplosionAI team is working on including the ML framework Thinc, their commercial data labelling tool Prodi.gy and beyond."
            },
            {
                "title": "Reinforcement Learning Applications",
                "link": "http://anyscale.com/blog/enterprise-applications-of-reinforcement-learning-recommenders-and-simulation-modeling/",
                "content": "Reinforcement Learning Apps In recent years machine learning research \u2013 particularly research in deep learning \u2013 has had a profound impact on enterprise applications. We\u2019re now also seeing more researchers studying RL and some of these investments will begin to show up in applications. In this post Chief Data Scientist Ben Lorica dives into enterprise applications of reinforcement learning, together with insightful metrics and facts of adoption in industry."
            },
            {
                "title": "NLP Search Transfer Learning at Scale",
                "link": "http://aidemos.cs.toronto.edu/nds/paper.html",
                "content": "NLP Transfer Learning at Scale Transfer learning has proven to be a successful technique to train deep learning models in the domains where little training data is available. The dominant approach is to pretrain a model on a large generic dataset such as ImageNet and finetune its weights on the target domain. This fascinating paper proposes an architecture for a large scale neural transfer search framework, together with a SaaS implementation of the service which can be tested."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/75.html",
                "content": "[Updated] AI Conferences Gone Virtual in 2020"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "80",
        "items": [
            {
                "title": "[XAI] Explainable AI in Retail",
                "link": "http://ai.science/e/xai-explainable-ai-in-retail--P5GX9My5lrZufnFvL9h6",
                "content": "[XAI] Explainable AI in Retail Great deep dive into Explainability in AI, which is a key component in production machine learning systems. In this article they dive into how Machine learning algorithms are increasingly being used in high stakes decisions, steps to mitigate the risk of these black-box algorithms, a number of explainability techniques, a great collection of resources representing the application of explainability methods in a practical setting, and key insights on challenges applying these methods in the field."
            },
            {
                "title": "MLflow Joins Linux Foundation",
                "link": "http://databricks.com/blog/2020/06/25/mlflow-joins-the-linux-foundation-to-become-the-open-standard-for-machine-learning-platforms.html",
                "content": "MLflow Joins Linux Foundation Last week at the Spark + AI Summit 2020 Databricks announced that their flagship open source AI framework MLFlow is becoming a Linux Foundation project! This is absolutely fantastic news for the open souce and enterprise machine learning ecosystem as it will further the current topic of experiment management and deployment lifecycle. During this conference they also announced some core roadmap features that will be added into the MLFlow library, together with some of the plans and stats behind this great decision."
            },
            {
                "title": "DVC 1.0 features for MLOps",
                "link": "http://dvc.org/blog/dvc-1-0-release",
                "content": "DVC 1.0 features for MLOps The Data Version Control (DVC) framework has released their 1.0 version! This is a great announcement for the MLOps ecosystem as this is one of the core tools providing full provenance and version control to machine learning assets, introducing sophisticated versioning capabilities for the machine learning constitutens of each pipeline component, consisting of data, config and code."
            },
            {
                "title": "Designing Industrial Scale ML",
                "link": "http://thedataexchange.media/designing-machine-learning-models-for-both-consumer-and-industrial-applications/",
                "content": "Designing Industrial Scale ML The Data Exchange Podcast comes back this week with a conversation with Christopher Nguyen, CEO of Arimo (a Panasonic company). Christopher is a former Engineering Director at Google, and was an early proponent of deep learning for enterprise applications. In this podcast they dive into the difference between working at an AI vendor company vs working at a AI buying company. They also dive into ML usecases for IoT and Industrial internet apps, and also cover key concepts in MLOps."
            },
            {
                "title": "Machine Learning Operations",
                "link": "http://ml-ops.org/",
                "content": "Machine Learning Operations ML-ops.org is new resource in the MLOps space covering some of the core principles on the topic of productionisation of machine learning across its full lifecycle. This resource includes a concise definition of MLOps, together with several deep dives into sub-topics of MLOps, including underlying motivations, design processes, workflows, principles and more."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/75.html",
                "content": "[Updated] AI Conferences Gone Virtual in 2020"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "81",
        "items": [
            {
                "title": "Getting ML into Production",
                "link": "http://veekaybee.github.io/2020/06/09/ml-in-prod/",
                "content": "Getting ML into Production A fantastic and comprehensible post by Automaticc Machine Learning Engineer Vicki Boykis covering an end to end journey towards productionising an AI powered application. This great post provides a sneak-peek into some of the challenges and pain-points involved when developing some of the underlying components required to produce production ready machine learning services, which are able to power an AI application."
            },
            {
                "title": "Top Books on ML Feature Engineering",
                "link": "http://machinelearningmastery.com/books-on-data-cleaning-data-preparation-and-feature-engineering/",
                "content": "Top Books on ML Feature Eng Machine Learning Mastery\u2019s Jason Brownlee has put together a great post featuring 8 of the top books on data cleaning and feature engineering as recommended reads. Feature engineering is key in the machine learning lifecycle, as it enables for better performance, more robust moedls, more explainable models (through domain knowledge abstraction), between other improvements."
            },
            {
                "title": "Adversarial ML in Industry",
                "link": "http://arxiv.org/abs/2002.05646",
                "content": "MSFT Adversarial ML in Industry Micosoft Researches have published a research survey that provides insights on the state of adversarial ML in industry, through 28 interviews which outlines key insighs on the gaps in securing machine learning systems when viewed from the context of traditional software security development. This paper provides a deep dive from the perspective of both ML engineers and security incident responders, making it quite an interesting piece for practitioners involved in the development and design of production machine learning systems."
            },
            {
                "title": "Google on Neural Nets for Tables",
                "link": "http://ai.googleblog.com/2020/04/using-neural-networks-to-find-answers.html",
                "content": "Google on Neural Nets for Tables Table information extraction in natural language processing is a well known and still not fully resolved challenge across both research and industry. Google has released an article that aims to showcase their achievements tacking this challenge by leveraging state-of-the-art NLP deep learning frameworks. This article provides both theoretical and practical insights on \u201cTAPAS\u201d, a weakly supervised table parsing approach that extends the BERT architecture to tackle this challenge via question answering techniques on (seemlingly structured) text-based tables."
            },
            {
                "title": "Getting into a Causal Flow",
                "link": "http://www.causalflows.com/introduction/",
                "content": "Getting into a Causal Flow Why should you care about Causal Inference? Most, if not all, business analytics questions, are inquiries of cause and effect. This fantastic article provides an introductory insight into causal inference with practical and intuitive examples. It also aims to provide an intuition on when this branch of techniques are \u201cgood enough\u201d as well as more importantly \u201cwhen they are not\u201d."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/81.html",
                "content": "This week in Issue #81:"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "82",
        "items": [
            {
                "title": "Full Stack Deep Learning Course",
                "link": "http://course.fullstackdeeplearning.com/",
                "content": "Full Stack Deep Learning Course A fantastic resource which covers end to end concepts in productionisation of machine learning systems, taught by experts in the field. They have compiled insights focused around formulating the problem, estimating costs, finding & cleaning datasets, picking the right frameworks, assessing compute infrastructure, ensuring reproducibility, troubleshooting training and deploying models at scale."
            },
            {
                "title": "Software Engineers in ML",
                "link": "http://towardsdatascience.com/what-software-engineers-can-bring-to-machine-learning-25f458c80e5",
                "content": "Software Engineers in ML Many production machine learning challenges are analogous to that of software engineering; this article puts together a high level overview of key insights that software engineers can bring to machine learning. This article dives into reproducibility as version control, model serving as devops and model drift as performance monitoring."
            },
            {
                "title": "Web Services vs Streaming for Inference",
                "link": "http://towardsdatascience.com/web-services-vs-streaming-for-real-time-machine-learning-endpoints-c08054e2b18e",
                "content": "Web Services vs Streaming in ML A very interesting evaluation of machine learning performance comparing rest vs kafka APIs for the usecase of streaming data. In this article we can see Playtica\u2019s journey assessing a benchmarking of the ETL systems (such as Airflow) vs streaming systems (such as Kafka), and how they compare in service exhaustion, client starvation, handling failures, retries and performance."
            },
            {
                "title": "Continuous ML (CML) CI/CD",
                "link": "http://dvc.org/blog/cml-release",
                "content": "Continuous ML (CML) CI/CD Iterative.ai has announced a new OSS project in their data version control family, called continuous machine learning (CML). This CML framework dives into CI/CD for machine learning, introducing best practices for continuous delivery for model training, model evaluation, comparing ML experiments, and monitoring dataset changes."
            },
            {
                "title": "Papers With Code Methods",
                "link": "http://paperswithcode.com/methods",
                "content": "Papers With Code Methods The great ML resource PapersWithCode has released a new feature called \u201cMethods\u201d. Here they are now tracking 730+ building blocks of machine learning: optimizers, activations, attention layers, convolutions and much more. This allows the community to track usage over time and explore papers from a new perspective."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/82.html",
                "content": "This week in Issue #82:"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "83",
        "items": [
            {
                "title": "Building an Enterprise Deep Learning Stack",
                "link": "http://medium.com/@Determined_AI/building-a-deep-learning-platform-21a4a9dd90fe",
                "content": "Building an Enterprise DL Stack Determined AI has put together a fantastic article outlining how they leveraged open source and enterprise tools to build an end to end deep learning platform. They cover some of the motivations that lead to require end to end capabilities, dive into some of the key challenges, and provide a solution for each phase of the model lifecycle."
            },
            {
                "title": "5 Key Features for ML Platforms",
                "link": "http://anyscale.com/blog/five-key-features-for-a-machine-learning-platform/",
                "content": "5 Key Features for ML Platforms ML Platform Designers need to meet current challenges and plan for future workloads. In this post by Anyscale Ben Lorica and Ion Stoica cover some of the key components in the machine learning lifecycle, as well as how the different components of Ray tackle each of these pieces, including model training, model tuning, model serving and model monitoring."
            },
            {
                "title": "AI Dungeon Open World w GPT3",
                "link": "http://medium.com/@aidungeon/ai-dungeon-dragon-model-upgrade-7e8ea579abfe",
                "content": "AI Dungeon Open World w GPT3 This week there has been a large surge of GPT3 case-studies showcasing the astonishing capabilities of this massive-scale new model. AI Dungeon has been an early adopted for the GPT-x algorithms, and has included a release to their open world, proceduraly generated, smart AI text-based adventure game."
            },
            {
                "title": "The State of Apache Airflow",
                "link": "http://softwareengineeringdaily.com/2020/06/10/apache-airflow-with-maxime-beauchemin-vikram-koka-and-ash-berlin-taylor/",
                "content": "The State of Apache Airflow Apache Airflow creator Maxime Beuchemin joins the Software Engineering Daily podcast to dive into the state of Airflow in 2020. Since Airflow\u2019s creation, it has powered the data infrastructure at companies like AirBnb, Netflix, Lyft and beyond. It has had a huge, and growing impact in the data pipeline space, and there\u2019s a lot yet to come."
            },
            {
                "title": "D2IQ KUDO for Kubeflow",
                "link": "http://d2iq.com/blog/kudo-for-kubeflow-the-enterprise-machine-learning-platform",
                "content": "D2IQ KUDO for Kubeflow D2IQ (formerly known as Mesosphere) has announced their new machine learning platform KUDO, which builds on top of the Kubeflow project at scale. This end-to-end platform allows showcases the power of open source, largely through the adoption of the Kubeflow framework, which has continued to grow in features and impact, bringing machine learning into the Cloud Native / Kubernetes ecosystem at massive scale."
            },
            {
                "title": "[Updated] AI Conferences Gone Virtual in 2020",
                "link": "http://ethical.institute/mle/83.html",
                "content": "This week in Issue #83:"
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "84",
        "items": [
            {
                "title": "Netflix On Cutting Data Costs",
                "link": "http://netflixtechblog.com/byte-down-making-netflixs-data-infrastructure-cost-effective-fee7b3235032",
                "content": "Netflix On Cutting Data Costs Netflix has put together an article that outlines their approach to making their data infrastructure cost effective, whilst providing transparency and efficiency across the organiastion. They cover their motivations, dataflow, tools, learnings and future focus."
            },
            {
                "title": "Awesome Github GPT-3 List",
                "link": "http://github.com/elyase/awesome-gpt3",
                "content": "Awesome Github GPT-3 List Recently there has been a surge of mind blowing AI prototypes built on top of the GPT-3 API, this awesome github repo has a compiled list of some of the available prototypes, categorised across apps, search, codegen, general reasoning and other interesting areas."
            },
            {
                "title": "Lessons from ML Prod Monitoring",
                "link": "http://mlinproduction.com/lessons-learned-from-15-years-of-monitoring-machine-learning-in-production/",
                "content": "Lessons from ML Prod Monitoring ML in Production has released a multi-part series sharing insights obtained around monitoring of machine learning systems in production. In this article they dive into 3 key lessons together with key takeaways."
            },
            {
                "title": "Uber on Editing Massive GeoData",
                "link": "https://eng.uber.com/nebulagl/",
                "content": "Uber on Editing Massive GeoData Uber is known for dealing with geospatial data, and recently they have released an article outlining their approach towards editing massive geospatial datasets with their open source project Nebula.GL, a toolset designed for performant geometry editing in a web browser with massive geospatial datasets."
            },
            {
                "title": "Airflow Summit Videos are Out",
                "link": "http://www.youtube.com/playlist?list=PLGudixcDaxY3RGLSlWoN_cEEXhIT1OPmj&app=desktop",
                "content": "Airflow Summit Videos are Out The Apache Airflow Summit took place recently, and the videos for the conference have just been released. These include a broad set of deep dives, keynotes, case studies and specialised use-cases - over 35 talks available for free streaming."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "85",
        "items": [
            {
                "title": "Experts Recommend ML Books",
                "link": "http://mentorcruise.com/books/ml/",
                "content": "Experts Recommend ML Books The team at MentorCruise asked dozens of experts and professionals in Machine Learning about their favourite books, and they have compiled a list of their top recommendations. In this list they further categorised the books by topic, including fundamentals, coding, practical ML, specializations, and theory."
            },
            {
                "title": "Why NLP Beyond English",
                "link": "http://ruder.io/nlp-beyond-english/",
                "content": "Why NLP Beyond English Over 7000 languages are spoken around the world, but NLP research has mostly focused on English. Sebastian Ruder has put together an article that outlines why you should work on languages other than English, including motivations, potential and action points."
            },
            {
                "title": "Kubeflow ML Prod Workflow",
                "link": "http://blog.kubeflow.org/release/official/2020/07/31/kubeflow-1.1-blog-post.html",
                "content": "Kubeflow ML Prod Workflow The Kubeflow team has launched version 1.1 of their end-to-end cloud native machine learning ecosystem. They have put together a post that outlines the key focuses, which improve the ML Workflow Productivity, Isolation, Security, GitOps and beyond."
            },
            {
                "title": "Configuring K-Fold Cross-Validation",
                "link": "http://machinelearningmastery.com/how-to-configure-k-fold-cross-validation/",
                "content": "Configuring Cross-Validation Machine Learning Mastery has put together a hands on tutorial that showcases how to leverage k-fold cross validation, which is a foundational and important concept in machine learning model evaluation. In this tutorial they cover how to evaluate ML models, how to perform sensitivity analysis for k-fold cross validation, and how to calculate correlations between cross-validation tests and ideal test conditions."
            },
            {
                "title": "Philosophers on GPT-3 (feat. AI)",
                "link": "http://dailynous.com/2020/07/30/philosophers-gpt-3/",
                "content": "Philosophers on GPT-3 (feat. AI) Nine philosophers explore the various issues and questions raised by the newly released language model, GPT-3. The content contributed from these philosophers is broken down into further 9 topics, including consciousness, justice and creativity."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "86",
        "items": [
            {
                "title": "Innovation, Regulation and AI",
                "link": "http://www.openaccessgovernment.org/ensuring-artificial-intelligence-is-humane-and-regulated/91866/",
                "content": "Innovation, Regulation and AI As AI technology is adopted across broader areas in our society, it becomes increasingly important to ensure these systems are aligned with best practices. Individuals often find that economies tend to optimize for metrics that are sometimes not aligned with ethical or societal interests, and hence there is a role for standardisation and regulation of AI. In this article IEML Chief Scientist Alejandro Saucedo provides an insight on the motivations and drivers for \u201cappropriate\u201d regulation in around AI systems as a catalyst for long-term longevity of positive impacts in AI systems in society."
            },
            {
                "title": "The Role of AI Product Managers",
                "link": "http://www.oreilly.com/radar/bringing-an-ai-product-to-market/",
                "content": "The Role of AI Product Managers Machine learning delivery teams require a broad set of cross functional skillsets in order to achieve success. The role of AI specialised Product Managers becomes more important in the machine learning productisation lifecycle. In this article, the O\u2019Reilly team breaks down the role of the AI product manager, together with core motivations, responsibilities and recommendations."
            },
            {
                "title": "Data Observability in Production",
                "link": "http://towardsdatascience.com/what-is-data-observability-40b337971e3e",
                "content": "Data Observability in Production Data observability is a common concept in production software systems, however recently there has been an increase in use of this term in the machine learning space. WIth the rise of data availabilty requirements and the increasing complexity of the AI stack, observability has emerged as a critical concern for data teams. This article provides a high level overview of observability in data systems."
            },
            {
                "title": "Graph Algorithms in Industry",
                "link": "http://thedataexchange.media/how-graph-technologies-are-being-used-to-solve-complex-business-problems/",
                "content": "Graph Algorithms in Industry The data exchange podcast delves into conversation with Chief Data Officer at DataStax specifically in regards to how graph technologies are being used to solve complex business problems. They also delve into Denise\u2019s new book, the practitioner\u2019s guide to graph data, and dive into tools and techniques needed to utilise graph technologies in production applications."
            },
            {
                "title": "Open RL Benchmark 0.3.0",
                "link": "http://app.wandb.ai/cleanrl/cleanrl.benchmark/reports/Open-RL-Benchmark-0-3-0---Vmlldzo0MDcxOA",
                "content": "Open RL Benchmark 0.3.0 The team behind the CleanRL framework have put together a post outlining the benchmark they have proposed and used to evaluate their different reinforcement learning algorithms. This is a great contribution as it falls under the general momentum towards reproducibility and transparency for new methods and libraries deployed, which can give users more granular and accurate insights on where each different algorithm can excel on."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "87",
        "items": [
            {
                "title": "Production ML Model Server Features",
                "link": "http://anyscale.com/blog/heres-what-you-need-to-look-for-in-a-model-server-to-build-ml-powered-services/",
                "content": "Prod Model Server Features Anyscale\u2019s Advisor Ben Lorica and Chairman Ion Stoica have put together a comprehensive overview of the state of machine learning model servers in production, as well as the core components that constitute full-featured systems. In this article they delve into toolkit support, user interfaces, ability to scale, deployment strategies, monitoring and more."
            },
            {
                "title": "New Jupyter Book Launch",
                "link": "http://blog.jupyter.org/announcing-the-new-jupyter-book-cbf7aa8bc72e",
                "content": "New Jupyter Book Launch The Jupyter Book has been re-written from the ground up, making it easier to install, faster to use, and able to create more complex publishing content in everyone\u2019s books. The new jupyter book comes with a broad set of new features that will help both researchers and practitioners."
            },
            {
                "title": "Computational Causal Inference",
                "link": "http://netflixtechblog.com/computational-causal-inference-at-netflix-293591691c62",
                "content": "Computational Causal Inference Causal effects methods can provide rich information for decision making, such as in experimentation platforms (\u201cXP\u201d) or in algorithmic policy engines. Every Netflix data scientist, whether their background is from biology, psychology, physics, economics, math, statistics, or biostatistics, has made meaningful contributions to the way Netflix analyzes causal effects - this article provides a high level insight to some of these."
            },
            {
                "title": "Practical AI\u2019s 100th Episode",
                "link": "http://changelog.com/posts/practical-ai-100th-episode-giveaway",
                "content": "Practical AI\u2019s 100th Episode The Practical AI podcast has reached their 100th episode. In this edition the Practical AI team has released the podcast together with a giveaway for prizes. In this edition they delve into conversation with the Pachyderm team, together with some big announcements from their data science and machine learning provenance platform."
            },
            {
                "title": "Realistic Tennis AI with Vid2Player",
                "link": "http://cs.stanford.edu/~haotianz/research/vid2player/",
                "content": "Realistic Tennis AI w Vid2Player Stanford University researchers have published a fascinating paper together with a showcase of their algorithm simulating a realistic video of a tennis game. In their work they are able to convert annotated broadcast videos of tennis matches into interactively controllable video sprites that behave and appear like professional tennis players. This is quite an impressive demonstration which provides an intuition of the potential AI technology can have."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "88",
        "items": [
            {
                "title": "FastAI New Course, Libs & Book",
                "link": "http://www.fast.ai/2020/08/21/fastai2-launch/",
                "content": "FastAI New Course, Libs & Book FastAI has announced a massive release - they have just made available their FastAI V2 framework, they released multiple new libraries (fastcore, fastscript and fastgpu), they have released an online course on deep learning for coders, and a brand new book from O\u2019Reilly that delves deeper into these concepts."
            },
            {
                "title": "Massive Scaling Google Meets",
                "link": "http://cloudblog.withgoogle.com/products/g-suite/keeping-google-meet-ahead-of-usage-demand-during-covid-19/amp/",
                "content": "Massive Scaling Google Meets The Google Meets team provides an overview of how they tackled the massive spikes in use on the Google Meets platform. In this post they cover how they dealt with the massive spikes in traffic and usage since the increase of remote working increased due to the COVID pandemic. They delve into the key strategies they took to ensure operational sustainability, as well as the results achieved."
            },
            {
                "title": "DeepFakes Threat Report",
                "link": "http://cset.georgetown.edu/research/deepfakes-a-grounded-threat-assessment/",
                "content": "DeepFakes Threat Report The rise of deepfakes could enhance the effectiveness of disinformation efforts by states, political parties and adversarial actors. This report offers a comprehensive deepfake threat assessment grounded in the latest machine learning research on generative models, and delves into how rapidly is this technology advancing, as well as who in reality might adopt it for malicious ends."
            },
            {
                "title": "AI Developer Tools Landscape",
                "link": "http://towardsdatascience.com/the-problem-with-ai-developer-tools-for-enterprises-and-what-ikea-has-to-do-with-it-b26277841661",
                "content": "AI Developer Tools Landscape Databricks Director of Product Clemens Mewald has put together an overview of the AI Developer Tools landscape for enterprises. In this post he covers the dominant design in ML APIs & Platforms, together with some of the key challenges in the ecosystem."
            },
            {
                "title": "Beginner to Professional Dev with Python",
                "link": "http://thedataexchange.media/from-python-beginner-to-seasoned-software-engineer/",
                "content": "Beginner to Prof.\u00a0Dev with Python Capital Group Principal Engineer Joel Grus joins this week\u2019s Data Exchange podcast. In this session Joel talks about his new book \u201cTen Essays on Fizz Buzz\u201d, key concepts in hiring software engineers, as well as key data science & ML tools for engineers."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "89",
        "items": [
            {
                "title": "FastAI Practical Data Ethics",
                "link": "http://ethics.fast.ai/",
                "content": "FastAI Practical Data Ethics The FastAI team has been creating a lot of fantastic content that covers all areas of machine learning. A great resource is their Practical Data Ethics course, they cover several very important topics around the practical implications and applications in this field, as well as it\u2019s critical importance in our day to day professional lives."
            },
            {
                "title": "Building Conversational AI Apps",
                "link": "http://thedataexchange.media/best-practices-for-building-conversational-ai-applications/",
                "content": "Building Conversational AI Apps The data exchange podcast comes back this week with a great podcast with Rasa CTO Alan Nichol. In this podcast, Alan delves into the state of developer tools in the AI conversational space, as well as best practices for building conversational AI applications."
            },
            {
                "title": "Computational Learning Intro",
                "link": "http://machinelearningmastery.com/introduction-to-computational-learning-theory/",
                "content": "Computational Learning Intro Machine learning mastery comes back with a great tutorial on computational learning theory, which refers to the mathematical frameworks for quantifying learning tasks and algorithms. In this tutorial, Jason covers how computational learning methods use formal methods to study learning tasks and algorithms, as well as a couple of hands on algorithms to dive into this field."
            },
            {
                "title": "Topic Modelling with Gensim",
                "link": "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/",
                "content": "Topic Modelling with Gensim Topic modelling is a technique to extract the hidden topics from large volumes of text. Latent dirichlet allocation is a popular algorithm for topic modelling, and the Python Gensim package is a great framework to implement these techniques. This very comprehensible resource provides a full end to end introduction into the theoretical and practical applications of topic modelling."
            },
            {
                "title": "Optical Character Recognition for All",
                "link": "http://www.jaided.ai/easyocr/tutorial",
                "content": "Optical Character Recog for All Optimal character recognition has been a big challenge in industry and research, as well as a big pre-requisite in a lot of NLP real-world applications. A really interesting project called EasyOCR is bringing together an open source solution on top of Pytorch that provides deep learning based optical character recognition capabilities."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "90",
        "items": [
            {
                "title": "AI, Data & Ethics Research Event",
                "link": "http://www.meetup.com/Tech-Ethics-London/events/272651566/",
                "content": "AI, Data & Ethics Research Join us the following week at our online AI, Data & Ethics event, where Prof.\u00a0Joanna Bryson will share her insights on AI, Data & Ethics in 2020, as well as on her research around accountability for and transparency in AI, technological impact on human cooperation, and beyond."
            },
            {
                "title": "AI Summarize Human Feedback",
                "link": "http://openai.com/blog/learning-to-summarize-with-human-feedback/",
                "content": "AI Summarize Human Feedback OpenAI has published new research showing how they\u2019ve applied reinforcement learning from human feedback to train language models that are better at summarization. They mention how their models generate summaries that are better than summaries from 10x larger models trained only with supervised learning."
            },
            {
                "title": "LipSync DeepFake AI Improved",
                "link": "https://medium.com/deepgamingai/deepfakes-ai-improved-lip-sync-animations-with-wav2lip-b5d4f590dcf",
                "content": "LipSync DeepFake AI Improved Recently new research showcased how you can transform the face of a video to look as if it was saying dynamically provided text, with only a sample of audio required. This is a great post that provides a brief overview of the recent paper (and surprising video) \u201cA lip sync expert is all you need for speech to lip generation in the wild\u201d."
            },
            {
                "title": "Getting started with ML resource",
                "link": "http://gettingstarted.ml/?s=r",
                "content": "Getting started with ML resource Often getting started with ML can be quite challenging due to the sheer amount of resources available. The resource GettingStartedWithML is a community-driven effort to curate a set of tools for individuals to dive into the ML world."
            },
            {
                "title": "AI Monitoring & Assurance",
                "link": "http://thedataexchange.media/what-is-ai-assurance/",
                "content": "AI Monitoring & Assurance AI Operations is a topic that has been more widely discussed recently due to the importance of automated monitoring and observability of (and with) machine learning. Superwise.AI CEO Ofer Razon joins this week\u2019s Data Exchange podcast to discuss key insights in this space, such as solutions to evaluate models, receive alerts, validate insights, etc."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "91",
        "items": [
            {
                "title": "ML in Mobile & Cross Vendor GPUs made simple",
                "link": "http://medium.com/@AxSaucedo/machine-learning-and-data-processing-in-the-gpu-with-vulkan-kompute-c9350e5e5d3a",
                "content": "Machine learning in cross-vendor & mobile GPUs made simple Machine learning fits incredibly well to the parallel-processing architecture that GPU computing offers. Projects like the Vulkan OSS initiative have enabled for cross-platform, cross-vendor, mobile-enabled advanced data-processing GPU applications. This article provides an intuitive hands on tutorial that teaches you to build your own machine learning algorithm from scratch in only a handful lines of code using the Vulkan Kompute framework."
            },
            {
                "title": "AI, Data & Ethics Research Event",
                "link": "http://www.meetup.com/Tech-Ethics-London/events/272651566/",
                "content": "AI, Data & Ethics Research Join us this coming week at our online AI, Data & Ethics event, where Prof.\u00a0Joanna Bryson will share her insights on AI, Data & Ethics in 2020, as well as on her research around accountability for and transparency in AI, technological impact on human cooperation, and beyond."
            },
            {
                "title": "Detecting Shifts in Policy with ML",
                "link": "http://thedataexchange.media/using-machine-learning-to-detect-shifts-in-government-policy/",
                "content": "Detecting Shifts in Policy with ML The Data Exchange podcast comes back this week with a fascinating conversation with Weifeng Zhong, Senior Research Fellow at George mason University. He is the core maintainer of the OSS Policy Change Index, a framework that uses ML and NLP to process government priorities and policies."
            },
            {
                "title": "AI Enabled Code Compilers",
                "link": "http://thenewstack.io/swifts-chris-lattner-on-the-possibility-of-machine-learning-enabled-compilers/",
                "content": "AI Enabled Code Compilers LLVM co-creator and Swift Language designer, Chris Lattner, joins TheNewStack editor David Cassel on a very interesting conversation around his current/future work, together with his thoughts on the future of programming itself. This article covers some key highlights, including some learnings and retrospective thoughts on Swift, as well as his thoughts on machine learning in code compilers. The full video is also available in the article."
            },
            {
                "title": "AI O\u2019Reilly 2020 Trends to Watch",
                "link": "http://www.oreilly.com/radar/radar-trends-to-watch-september-2020/",
                "content": "AI O\u2019Reilly 2020 Trends to Watch O\u2019Reilly\u2019s Mike Loukides has put together an overview of an AI O\u2019Reilly Radar on trends to watch in 2020. This covers some key highlights across AI, General Programming, Cloud & Microservices, innovations in infrastructure and beyond."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "92",
        "items": [
            {
                "title": "Data Version Control with Dmitry",
                "link": "http://softwareengineeringdaily.com/2020/08/24/data-version-control-with-dmitry-petrov/",
                "content": "Data Version Control with Dmitry Iterative.ai CEO & DVC Author Dmitry Petrov joins the software engineering daily podcast to talk about the importance of version control in data science as well as trends, challenges and solutions."
            },
            {
                "title": "Differential Privacy Series",
                "link": "http://medium.com/pytorch/differential-privacy-series-part-1-dp-sgd-algorithm-explained-12512c3959a3",
                "content": "Differential Privacy Series Applied Researchers at Facebook have put together an interesting and comprehensible series on Differential Privacy. In this article they dive into some of the core concepts in privacy preserving ML."
            },
            {
                "title": "Reinforcement Learning Pathmind",
                "link": "http://thedataexchange.media/connecting-reinforcement-learning-to-simulation-software/",
                "content": "Reinforcement Learning Pathmind Pathmind Deep Learning Engineer joins the Data Exchange podcast to discuss some key applications of reinforcement learning to tackle simulations. In this session Max provides an insight on how they use Reinforcement Learning at Pathmind."
            },
            {
                "title": "Which GPUs for Deep Learning",
                "link": "http://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/",
                "content": "Which GPUs for Deep Learning Deep learning can benefit massively from GPU computing. Similar to the requirements when choosing a new CPU or RAM, it\u2019s important to understand the tradeoffs across different GPU choices, especially when it comes to specialised processing. This comprehensive post covers a deep dive on core concepts and best practices when considering GPU hardware for deep learning."
            },
            {
                "title": "Explainable AI Monitoring",
                "link": "http://medium.com/@fiddlerlabs/explainable-monitoring-stop-flying-blind-and-monitor-your-ai-48ad33b9928d",
                "content": "Explainable AI Monitoring Machine Learning systems introduce new complexities where traditional monitoring approaches may fall short. This article provides some insight on the gaps in these tools when used for machine learning, as well as some of the key areas where \u201cexplainable\u201d monitoring solutions can bring value."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "93",
        "items": [
            {
                "title": "GPU Accelerated ML in Game Development",
                "link": "http://towardsdatascience.com/supercharging-game-development-with-gpu-accelerated-ml-using-vulkan-kompute-the-godot-game-engine-4e75a84ea9f0",
                "content": "GPU Accelerated ML in GameDev Recently, the world has seen various defining milestones in both, the gaming industry and the AI sector. This article provides an insight into the intersection of these two fast growing fields, and delves into a hands on tutorial showing how to leverage GPU optimized ML code in game development workflows using the Godot Game Engine and the Vulkan Kompute framework."
            },
            {
                "title": "Modular vs E2E ML Platforms",
                "link": "http://www.oreilly.com/radar/why-best-of-breed-is-a-better-choice-than-all-in-one-platforms-for-data-science/",
                "content": "Modular vs E2E ML Platforms All-in-one platforms built from open source software make it easy to perform certain workflows, but make it hard to explore and grow beyond those boundaries. This article from O\u2019Reilly provides great insights on the topic of end-to-end platforms vs modular integrated platforms."
            },
            {
                "title": "Dagster Data Orchestration",
                "link": "http://medium.com/dagster-io/dagster-the-data-orchestrator-5fe5cadb0dfb",
                "content": "Dagster Data Orchestration A great and in-depth article on data orchestration, including some of the biggest challenges in this space, and how the open source project Dagster is aiming to tackle them."
            },
            {
                "title": "ML for MedTech Monitoring",
                "link": "http://thedataexchange.media/using-machine-learning-to-modernize-medical-triage-and-monitoring-systems/",
                "content": "ML for MedTech Monitoring The data exchange podcast dives into conversation with Diagnostic Robotics CTO Kira Radinsky. In this edition they covertheir work on prediction for disease outbreaks, as well as the need for medical data analysis."
            },
            {
                "title": "Whose Ethics? Eastern & Western Philosophies",
                "link": "http://www.meetup.com/Tech-Ethics-London/events/273159372/",
                "content": "Whose Ethics? Eastern + Western This October we\u2019ll be hosting a meetup titled, \u201cAI Ethics - Whose Ethics? An Analysis Across Eastern & Western Philosophy\u201d. During this session, we will dive into the similarities and differences in foundational philosophical concepts such as the meaning of good, continuity & the self, and we\u2019ll analyse published resources in the space of AI Ethics & Principles across the globe."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "94",
        "items": [
            {
                "title": "Distributed Training of ML Models",
                "link": "http://blog.twitter.com/engineering/en_us/topics/insights/2020/distributed-training-of-sparse-machine-learning-models-1.html",
                "content": "Distributed Training of ML Models Twitter Machine Learning Engineer Andrew Bean has written a series of posts outlining their journey enabling distributed training for sparse machine learning models. In this first part they cover how at twitter they increased performance by 100x over the standard tensorflow distribution strategies allowing for faster iterations on model training."
            },
            {
                "title": "State of AI Report 2020",
                "link": "http://www.stateof.ai/",
                "content": "State of AI Report 2020 The state of AI report 2020 has come out, covering top highlights on AI in 2020. The report includes key developments around research, talent, industry and politics, together with predictions for next year."
            },
            {
                "title": "Embracing Logging in ML",
                "link": "http://medium.com/whylabs/whylogs-embrace-data-logging-a9449cd121d",
                "content": "Embracing Logging in ML This post covers some of the key concepts that cover the area of data monitoring, and the challenges and motivations for logging in machine learning. This is an important component due to growing requirements of auditability and reproducibility."
            },
            {
                "title": "A Brief History of ML Platforms",
                "link": "http://databaseline.tech/a-brief-history-of-ml-platforms/",
                "content": "A Brief History of ML Platforms D2IQ Senior ML Engineer Ian Hellstrom has put together an archeological overview of machine learning platforms through the decades. This includes some high level tools provided that show some highlight on ML libraries and frameworks that have been released from the early 2000s to date."
            },
            {
                "title": "Whose Ethics? Eastern + Western",
                "link": "http://www.meetup.com/Tech-Ethics-London/events/273159372/",
                "content": "Whose Ethics? Eastern + Western Later this month we\u2019ll be hosting a meetup titled, \u201cAI Ethics - Whose Ethics? An Analysis Across Eastern & Western Philosophy\u201d. During this session, we will dive into the similarities and differences in foundational philosophical concepts such as the meaning of good, continuity & the self, and we\u2019ll analyse published resources in the space of AI Ethics & Principles across the globe."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "95",
        "items": [
            {
                "title": "Real Time Machine Learning at Scale",
                "link": "http://towardsdatascience.com/real-time-stream-processing-for-machine-learning-at-scale-with-spacy-kafka-seldon-core-6360f2fedbe",
                "content": "Real Time ML at Scale A hands on tutorial that covers how to train a machine learning model using the Reddit comment moderation dataset, and deploy it in a scalable infrastructure using Kafka and Seldon Core. It includes the accompanying code, together with the video format of the content that also covers core concepts in stream processing."
            },
            {
                "title": "Awful AI Listing Scary Usecases",
                "link": "http://github.com/daviddao/awful-ai",
                "content": "Awful AI Listing Scary Usecases Awful AI is a curated list to track current scary usages of AI. The authors put together this open source list, hoping to raise awareness to its misuses in society, as well as encourage best practices."
            },
            {
                "title": "Scientific Computing with Python",
                "link": "http://sebastianraschka.com/blog/2020/numpy-intro.html",
                "content": "Scientific Computing with Python Sebsatian Raschka has put together a comprehensible article that outlines core founcations when using NumPy and Matplotlib. This content is from the course he delivers on \u201cintroduction to ML and statistical pattern classification\u201d."
            },
            {
                "title": "Deep Learning Models Repo",
                "link": "http://github.com/rasbt/deeplearning-models",
                "content": "Deep Learning Models Repo A great repository that provides a broad range of jupyter notebooks to build and deep learning models that can be used across a broad range of applications. The models range across a lot of categories including Foundational Algorithms, GANs, Autoencoders, CNNs, and more."
            },
            {
                "title": "AI for Software Development",
                "link": "https://arxiv.org/abs/2009.06520",
                "content": "AI for Software Development There has been a lot of applications of AI into the software development space itself - this paper has put together a comprehensive overview of the current state of the ecosystem around the use of deep learning in software engineering research."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "96",
        "items": [
            {
                "title": "Supercharge Mobile Apps with ML",
                "link": "http://towardsdatascience.com/gpu-accelerated-machine-learning-in-your-mobile-applications-using-the-android-ndk-vulkan-kompute-1e9da37b7617",
                "content": "Android Apps with ML on GPU A hands on tutorial that teaches you how to leverage your on-device smartphone GPU for accelerated data processing and machine learning edge use-cases. This article covers how to build a simple Android App using the Native Development Kit (NDK) and run on-device GPU accelerated processing using the Vulkan Kompute framework."
            },
            {
                "title": "The Canonical DL & ML Stack",
                "link": "http://towardsdatascience.com/rise-of-the-canonical-stack-in-machine-learning-724e7d2faa75",
                "content": "The Canonical ML Stack Pachyderm Chief Evangelist Dan Jeffries writes about the canonical stack in machine learning, proposed to be analogous to the LAMP/MEAN stack in web development. This includes data processing, experimentation, productisation and compliance capabilities - as well as the open source and enterprise tools that could be involved throughout the ML & data lifecycle."
            },
            {
                "title": "Modern Data Infra Architectures",
                "link": "http://a16z.com/2020/10/15/the-emerging-architectures-for-modern-data-infrastructure/",
                "content": "Modern Data Infra Architectures A16z has put together a comprehensible report on emerging architectures for modern data infrastucture. In this report they cover the underlying patterns arising for analytics and operational systems around data-powered products."
            },
            {
                "title": "Facebook Eng Lead discusses Fairness",
                "link": "http://www.wandb.com/podcast/joaquin-candela",
                "content": "FB Eng Lead discusses Fairness Facebook Engineering Director Joaquin Candela joins the weights & biases podcast to discuss his thoughts around fairness, as well as his work scaling and democratising AI at facebook."
            },
            {
                "title": "AI Ethics - Whose Ethics? Event",
                "link": "http://www.meetup.com/Tech-Ethics-London/events/273159372/",
                "content": "AI Ethics - Whose Ethics? Event This week we\u2019ll be hosting the meetup, \u201cAI Ethics - Whose Ethics? An Analysis Across Eastern & Western Philosophy\u201d. During this session, we will dive into the similarities and differences in foundational philosophical concepts such as the meaning of good, continuity & the self, and we\u2019ll analyse published resources in the space of AI Ethics & Principles across the globe."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "http://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "97",
        "items": [
            {
                "title": "Accelerating GPU Workloads",
                "link": "http://towardsdatascience.com/parallelizing-heavy-gpu-workloads-via-multi-queue-operations-50a38b15a1dc",
                "content": "Accelerating GPU Workloads GPUs have proven extremely useful for highly parallelizable data processing use-cases. The computational paradigms found in machine learning & deep learning for example fit extremely well to the processing architecture graphics cards provide. This tutorial shows how it\u2019s possible to achieve 2x+ performance improvements when submitting independent GPU-intensive workloads by leveraging multi-queue operation parallelism using Vulkan and Kompute."
            },
            {
                "title": "Software Engineering for Deep Learning",
                "link": "https://event.on24.com/eventRegistration/EventLobbyServlet?target=reg20.jsp&partnerref=bull1&eventid=2709113&sessionid=1&key=A797526F9AA558F0B778491FB85C23AF",
                "content": "Software Eng for Deep Learning Jeremy Howard, FastAI Author delves into how bringing software engineering best practices, such as layered API design and decoupling, have allowed him to provide a deep learning library that is both easier to use for beginners, at the same time as being more deeply hackable for experts, and also increasing performance. He will be drawing from research discussed in the peer reviewed paper describing the principles of software engineering applied to deep learning."
            },
            {
                "title": "The Rise of MLOps",
                "link": "http://twosigmaventures.com/blog/article/the-rise-of-ml-ops-why-model-performance-monitoring-could-be-the-next-billion-dollar-industry/",
                "content": "The Rise of MLOps Data-driven software is the future. This shift is bringing about a new category of tools\u2014what we call model performance monitoring (MPM). This article provides an introduction to the topic of MLOps as well as the core pillars that contribute to its potential to become \u201cthe next billion dollar industry\u201d."
            },
            {
                "title": "200 Best ML & Python Tutorials",
                "link": "https://medium.com/machine-learning-in-practice/over-200-of-the-best-machine-learning-nlp-and-python-tutorials-2018-edition-dd8cf53cb7dc",
                "content": "200 Best ML & Python Tutorials A fantastic article containing 200 resources for machine learning and Python, ranging across introductions, mathematical foundations, best practices, and a broad range of machine learning algorithms and use-cases across multiple data types."
            },
            {
                "title": "Running 1M+ Batch Jobs in Kubernetes",
                "link": "http://www.gresearch.co.uk/article/armada-how-to-run-millions-of-batch-jobs-over-thousands-of-compute-nodes-using-kubernetes/",
                "content": "Running 1M+ Batch Jobs in K8s G-Research published an article covering how they were able to leverage Kubernetes, together with cloud native framework tools to enable processing of millions of batch jobs with heterogenious data dependencies and computational DAG processing requirements."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "98",
        "items": [
            {
                "title": "Andrew Ng on Production AI",
                "link": "http://crossminds.ai/video/5f9a11f026cd723d6a05efa4/?timecode=396.4620130972748",
                "content": "Andrew Ng on Production AI Andrew Ng discusses key challenges facing AI deployments and possible solutions, ranging from techniques for working with small data to improving algorithms\u2019 robustness and generalizability to systematically planning out the full cycle of machine learning projects."
            },
            {
                "title": "Netflix\u2019s Distributed Tracing Infra",
                "link": "http://netflixtechblog.com/building-netflixs-distributed-tracing-infrastructure-bb856c319304",
                "content": "Netflix\u2019s Distributed Tracing Infra Production machine learning models introduce complex infrastructure complexities, which require more advanced approaches for monitoring and observability. Netflix provides insights into the knowledge obtained throughout building their distributed tracing infrastructure. Distributed tracing is the ability to measure performance and other metrics across microservice hops of requests as they travel through the system."
            },
            {
                "title": "Importance of Data in MLOps",
                "link": "http://greatexpectations.io/blog/ml-ops-data-quality/",
                "content": "Importance of Data in MLOps Machine Learning Operations continues to growing in importance. This post discusses the importance of data quality in MLOps workflows, as well as the flow of data involved across the diffeent components of the stack."
            },
            {
                "title": "Image Outlier Detection in ML",
                "link": "http://towardsdatascience.com/simplifing-image-outlier-detection-with-alibi-detect-6aea686bf7ba",
                "content": "Image Outlier Detection in ML Outlier detection is the identification of data set elements that vary significantly from the majority. When it comes to production systems this is a key tool to ensure sound performance of production models. This post introduces a practical use-case for image outlier detection."
            },
            {
                "title": "The State of AI Ethics Report",
                "link": "http://montrealethics.ai/oct2020/",
                "content": "The State of AI Ethics Report Montreal AI Ethics Institute released a report which captures the most relevant developments in Q3 2020 in the domain of AI ethics across academia, civil society, government, and industry. It covers key areas such as AI & society, bias, disinformation, labour impacts, privacy, risk, and the future of AI ethics."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "99",
        "items": [
            {
                "title": "Definitive AI Monitoring Guide",
                "link": "http://towardsdatascience.com/the-definitive-guide-to-ai-monitoring-2427812cc1b",
                "content": "Definitive AI Monitoring Guide Deployed production models require domain specific monitoring capabilities. This article provides an insight on the topic of ML monitoring, including performance metrics, behavioural metrics, feature behaviour, metadata and inference data."
            },
            {
                "title": "Safely Rolling out ML to Prod",
                "link": "http://towardsdatascience.com/safely-rolling-out-ml-models-to-production-13e0b8211a2f",
                "content": "Safely Rolling out ML to Prod Safely rolling out ML models to production is key in production. This article provides an overview of the lifecycle of a model, together with the key components that can improve the stability and robustness of production models at scale."
            },
            {
                "title": "Audio ML Infrastructure at Spotify",
                "link": "http://engineering.atspotify.com/2020/11/04/its-all-just-wiggly-air-building-infrastructure-to-support-audio-research/",
                "content": "Audio ML Infrastructure at Spotify Spotify has open sourced Kilo, their framework for building data pipelines for audio and media processing based on Python and Apache Beam. In this article they dive into the core architectural and domain-specific principles."
            },
            {
                "title": "Computational Limits of DL",
                "link": "http://thedataexchange.media/the-computational-limits-of-deep-learning/",
                "content": "Computational Limits of DL The Data Exchange Podcast comes back this week with a conversation with CSAIL Lab Research Scientist Neil Thompson, where they discuss his recent paper \u201cThe Computational Limits of Deep Learning\u201d."
            },
            {
                "title": "Stop using k8s for ML (instead use k8s)",
                "link": "http://allegro.ai/blog/stop-using-kubernetes-for-ml-ops/",
                "content": "Stop using k8s for ML (use k8s) Great article that discusses how to set up an efficient environment for machine learning on Kubernetes. The article covers some of the common architectural bottlenecks to avoid, as well as best practices in machine learning using kubernetes terminology (and vice-versa)."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "100",
        "items": [
            {
                "title": "Beyond CUDA: Cross-vendor GPU Python ML",
                "link": "http://towardsdatascience.com/beyond-cuda-gpu-accelerated-python-for-machine-learning-in-cross-vendor-graphics-cards-made-simple-6cc828a45cc3",
                "content": "Cross-vendor GPU Python ML Machine learning algorithms \u2014 together with many other advanced data processing paradigms \u2014 fit incredibly well to the parallel-architecture that GPU computing offers. In this article you\u2019ll learn how to write your own GPU accelerated algorithms in Python, which you will be able to run on virtually any GPU hardware, including non-NVIDIA GPUs."
            },
            {
                "title": "ML Metadata Management Tools",
                "link": "https://github.com/EthicalML/awesome-production-machine-learning/blob/master/README.md#metadata-management",
                "content": "ML Metadata Management Tools Machine learning metadata management is becoming a key challenge in production AI systems. We have started mapping the ecosystem of Open Source metadata management frameworks - check out the tools and like always contribution are greatly appreciated."
            },
            {
                "title": "Practical Guide To Responsible AI",
                "link": "https://www.youtube.com/watch?v=Hnrp-qjv-sE&feature=youtu.be",
                "content": "Practical Guide To Responsible AI Our talk at the PyData Global has now been published, where we cover the principles, standards, tools and practical frameworks towards responsible development and operation of AI systems."
            },
            {
                "title": "Navigating ML Deployment",
                "link": "http://towardsdatascience.com/navigating-ml-deployment-34e35a18d514",
                "content": "Navigating ML Deployment Seldon MLOps Developer Ryan Dawson has put together a fantastic article covering the concepts, challenges and solutions around machine learning model deployment and orchestration."
            },
            {
                "title": "Stanford MLSys Seminars",
                "link": "https://www.youtube.com/channel/UCzz6ructab1U44QPI3HpZEQ",
                "content": "Stanford MLSys Seminars Stanford has published their seminar videos on the frontier of machine learning systems, covering key concepts around challenges and solutions in AI research and industry in conversation with thought leaders in the space."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "101",
        "items": [
            {
                "title": "E2E Production ML Monitoring",
                "link": "https://www.youtube.com/watch?v=QcevzK9ZuDg&feature=youtu.be",
                "content": "E2E Production ML Monitoring The lifecycle of a machine learning model only begins once it\u2019s in production. Our keynote at Pycon HK 2020 is now available online, where we delve into the end to end principles, patterns and techniques around production machine learning monitoring. We cover AI monitoring through explainability, outlier detection, concept drift and statistical performance from a theoretical and practical hands-on standpoint."
            },
            {
                "title": "Feature Stores Demystified",
                "link": "http://www.tecton.ai/blog/what-is-a-feature-store/",
                "content": "Feature Stores Demystified TectonAI has published a high level overview that breaks down the concepts and components of feature stores from an architectural standpoint. They mention the nuances of serving, storage, data transformations, monitoring and registries."
            },
            {
                "title": "ML in Compiler Optimization",
                "link": "https://www.youtube.com/watch?v=6P1ldaiX20g&feature=youtu.be",
                "content": "ML in Compiler Optimization The research area around automated optimizations on low level intermediate code representation is incredibly fascinating. This talk provides an introduction and an overview of how this is being achieved through advanced reinforcement learning techniques."
            },
            {
                "title": "Explainable AI in Drug Discovery",
                "link": "https://www.nature.com/articles/s42256-020-00236-4",
                "content": "Explainable AI in Drug Discovery Explainability techniques in machine learning have seen applicability in a broad range of highly regulated sectors. ETH Zurich researchers have published an interesting paper in Nature covering how these techniques can be used in the drug discovery space. In this resource they\u00a0 provide an overview as well as a deep dive around the tools available in the ecosystem."
            },
            {
                "title": "Challenges in Deploying ML",
                "link": "https://arxiv.org/abs/2011.09926",
                "content": "Challenges in Deploying ML Cambridge researchers have published a survey that explores the challenges of deploying machine learning in production. In this paper they delve into findings gathered from a broad range of practitioners deploying machine learning in industry, and cover the nuanced issues across the various phases of the end to end machine learning lifecycle."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "102",
        "items": [
            {
                "title": "AI Diversity of Development & Applications",
                "link": "https://blogs.microsoft.com/ai/shrinking-the-data-desert/",
                "content": "AI Diversity of Dev & Apps Microsoft Principal Software Engineer Saquib Shakh is leading a fantastic initiative to increase the number of AI use-cases currently in place to empower individuals with impaired vision. This is part of a broader initiative to create further AI use-cases that can impact people\u2019s lives positively by making usability key component in developing any type of AI applications."
            },
            {
                "title": "High Performance NLP",
                "link": "http://www.aclweb.org/anthology/2020.emnlp-tutorials.4/",
                "content": "High Performance NLP Scale has played a central role in the rapid progress natural language processing has enjoyed in recent years. While benchmarks are dominated by ever larger models, efficient hardware use is critical for their widespread adoption and further progress in the field. In tutorial, Google Engineers and University of Washington Researchers cover a wide range of techniques to improve efficiency in NLP models."
            },
            {
                "title": "Facebook on Data Discovery",
                "link": "http://engineering.fb.com/2020/10/09/data-infrastructure/nemo/",
                "content": "Facebook on Data Discovery Following the announcements of Airbnb, Lyft, Netflix and Uber on their custom-built internal metadata management and discovery platforms, Facebook presents their approach to metadata discovery infrastructure. In this article they cover a high level overview of their \u201cNemo\u201d metadata system, including the architecture, and brief lessons learned."
            },
            {
                "title": "Netflix on Real Time Batch",
                "link": "http://netflixtechblog.com/bulldozer-batch-data-moving-from-data-warehouse-to-online-key-value-stores-41bac13863f8",
                "content": "Netflix on Real Time Batch Netflix showcases their real time processing framework \u201cBulldozer\u201d. In this article they present how they are experimenting as they explore introducing more interoperability between offline batch use-cases and online key value store-based processing architectures."
            },
            {
                "title": "ML Street Talk Podcast",
                "link": "https://www.youtube.com/watch?v=iccd86vOz3w",
                "content": "ML Street Talk Podcast \u201cML Street Talk\u201d has published a great content-dense podcast. In this edition they speak with Professor Gary Marcus, Dr.\u00a0Walid Saba and Connor Leahy about GPT-3. They also invite the audience into their in-depth experimentation with the GPT-3 APIs, where they delve into demos and use-cases."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "103",
        "items": [
            {
                "title": "UK Data Strategy Consultation",
                "link": "https://www.acm.org/binaries/content/assets/public-policy/europe-tpc-comments-uknds.pdf",
                "content": "UK Data Strategy Consultation The UK\u2019s Department for Digital, Culture, Media & Sport launched a consultation to gather expert insights on the National Data Strategy. We contributed to this consultation through the Association for Computing Machinery\u2019s European Technology Policy Committee, which is included in the full document outlining comments collected from the committee."
            },
            {
                "title": "Applying the MLOps Lifecycle",
                "link": "http://towardsdatascience.com/applying-the-mlops-lifecycle-3b60033b7cbf",
                "content": "Applying the MLOps Lifecycle A great overview of the MLOps lifecycle, covering a simplified architecture of how all the constituent components interact as a machine learning model evolves. This includes the training, deployment, monitoring, and other more specific needs including scoping considerations and further terminology."
            },
            {
                "title": "Break into NLP with Andrew NG",
                "link": "https://www.youtube.com/watch?v=SzAmGg2TVBg",
                "content": "Break into NLP with Andrew NG NLP is an essential part of the practical application of AI. Andrew NG and the Deeplearning.ai team have put together a panel of experts in the NLP field where they dive into their current projects, and the future of NLP, as well as career advice for ML practitioners or non-MLEs hoping to break into NLP."
            },
            {
                "title": "NLP Applications Podcast",
                "link": "http://thedataexchange.media/increasing-the-robustness-of-natural-language-applications/",
                "content": "NLP Applications Podcast The data exchange podcast presents a conversation with Google AI Resident Jack Morris on Adversarial Attacks, Data Augmenttation and Adversarial Training in the field of NLP."
            },
            {
                "title": "Uber on Scale Data Queries",
                "link": "http://eng.uber.com/operating-apache-pinot/",
                "content": "Uber on Scale Data Queries Uber deals with complex and large-scale challenges that require real time data queries across a broad range of distributed and varied datasets and datastores. In this blog post they cover how they leverage Apache Pinot to achieve low latency analytical queries across the Uber marketplace ecosystem in multi-cluster, multi-data-store contexts."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "104",
        "items": [
            {
                "title": "End-to-end Production ML Monitoring",
                "link": "http://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158",
                "content": "End-to-end Prod ML Monitoring The lifecycle of a machine learning model only begins once it\u2019s in production. This article presents an end-to-end example showcasing best practices, principles, patterns and techniques around monitoring of machine learning models. It covers standard microservice monitoring techniques adapted towards deployed machine learning models, as well as more advanced paradigms including concept drift, outlier detection and AI explainability."
            },
            {
                "title": "Metadata Architectures Explained",
                "link": "https://engineering.linkedin.com/blog/2020/datahub-popular-metadata-architectures-explained",
                "content": "Metadata Architectures Explained Metadata lineage and discovery is critical in large scale machine learning and data systems. Linkedin Principle Engineer Shirshanka Das has put together a comprehensive overview of the key architectural, conceptual and infrastructural components in metadata management systems. This covers search, access control, lineage, compliance, etc, as well as common architecture patterns."
            },
            {
                "title": "Applied ML In Production",
                "link": "http://madewithml.com/courses/applied-ml-in-production/",
                "content": "Applied ML In Production A hands-on course on MLOps for software engineers, data scientists and product managers. This course covers end to end examples building from the very basics to the advanced knowledge required to train, improve and productionise machine learning."
            },
            {
                "title": "State of AI Ethics Panel",
                "link": "http://montrealethics.ai/state-of-ai-ethics/",
                "content": "State of AI Ethics Panel The Montral AI Ethics Institute has put together a fantstic panel with several thought leaders in the AI Ethics space following the release of their AI Ethics report. In this panel they cover a broad range of topics, and dive into a lot of interesting resources which they have linked in their transcript."
            },
            {
                "title": "FOSDEM 2021 CFP Opens",
                "link": "https://hpc-bigdata-fosdem21.github.io/",
                "content": "FOSDEM 2021 CFP HPC & ML The Free & Open Source Developers European Meeting is an annual software conference which for the first time will take place online in 2021. This fantastic conference has a broad range of tracks, and one of them will be focusing on HPC, Big Data and Data Science, which is currently looking for proposals - do feel free to submit a proposal or share with anyone relevant that would be keen to showcase best practices, learning, case studies, etc. on ML related topics."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "105",
        "items": [
            {
                "title": "The NLP Pytorch Tutorial",
                "link": "https://github.com/graykode/nlp-tutorial",
                "content": "The NLP Pytorch Tutorial The nlp-tutorial repository is one of the most highly starred tutorials relevant for individuals currently studying NLP (Natural Language Processing) using Pytorch. The repo provides coverage for a broad range of models, and most are implemented with less than 100 lines of code."
            },
            {
                "title": "Navigating Resposible AI",
                "link": "http://gradientflow.com/navigate-the-road-to-responsible-ai/",
                "content": "Navigating Resposible AI Deploying AI ethically and responsibly will involve cross-functional team collaboration, new tools and processes, and proper support from key stakeholders. The Gradient Flow team has put together a great overview of the ecosystem of tools and resources around \u201cResponsible AI\u201d."
            },
            {
                "title": "Research at Microsoft in 2020",
                "link": "https://www.microsoft.com/en-us/research/blog/research-at-microsoft-2020-addressing-the-present-while-looking-to-the-future/",
                "content": "Research at Microsoft in 2020 Microsoft has published a blog post outlining some of the highlights in the area of research, showcasing some of their work across the areas of AI, graphics, language and domain specific applications, between many others."
            },
            {
                "title": "Gentle Intro to Concept Drift",
                "link": "http://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/",
                "content": "Gentle Intro to Concept Drift Machine learning mastery has put together a comprehensive deep dive into the topic of concept drift in machine learning. In this post they cover the challenge of data changing over time, how concept drift is defined, and how to handle concept drift in predictive modelling pipelines."
            },
            {
                "title": "Uber on Data Workflows at Scale",
                "link": "http://eng.uber.com/managing-data-workflows-at-scale/",
                "content": "Uber on Data Workflows at Scale Uber serves millions of rides and deliveries a day, generating hundreds of petabytes of raw data - this introduces demands for innovative approaches in order to service all the analytics teams across the organisation. In this post the Uber engineering team covers how they approached the road towards a unified workflow management system."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "106",
        "items": [
            {
                "title": "Top 10 Python Libraries of 2020",
                "link": "http://tryolabs.com/blog/2020/12/21/top-10-python-libraries-of-2020/",
                "content": "Top 10 Python Libraries of 2020 TryoLabs release their 6th annual Python libraries list. This year\u2019s list highlights general and data science related libraries that are growing in popularity in 2020, as well as currently well maintained and generally worth checking out."
            },
            {
                "title": "2020 Curated List of AI Research",
                "link": "https://medium.com/towards-artificial-intelligence/2020-a-year-full-of-amazing-ai-papers-a-review-c42fa07aff4b",
                "content": "2020 Curated List of AI Research A comprehensive article containing a curated list of the latest breakthroughs in AI by release date with a clear video explanation, link to a more in-depth article, and access to source code."
            },
            {
                "title": "NumPy Deep Dive Illustrated",
                "link": "https://medium.com/better-programming/numpy-illustrated-the-visual-guide-to-numpy-3b1d4976de1d",
                "content": "NumPy Deep Dive Illustrated NumPy is a fundamental library for data processing. Understanding how NumPy works can give a boost to your skills. This article provides an intuitive overview of the concepts and features around the NumPy library leveraging a broad range of visual resources."
            },
            {
                "title": "Metadata Journey at PayPal",
                "link": "https://medium.com/paypal-engineering/the-journey-of-metadata-at-paypal-c374ac66e2e6",
                "content": "Metadata Journey at PayPal Insightful article from the Paypal Engineering team showcasing the journey at Paypal. They outline the evolution of their team\u00a0 /infrastructure, their priorities across quarters, and the high level architecture behind their Enterprise Data Catalogue."
            },
            {
                "title": "Interactive C++ for Data Science",
                "link": "http://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/",
                "content": "Interactive C++ for Data Science The LLVM team showcases how practitioners can leverage dynamic eval-style programming capabilities of the Cling C++ interpreter, which enable for interactive jupyter notebooks with C++ as the core language. This allows for practitioners to leverage the efficiency and speed of C++ whilst getting access to the dynamic experimentation properties that jupyter notebooks provide, and which are important in iterative/experiment-heavy contexts, such as in the data science examples showcased."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "107",
        "items": [
            {
                "title": "2020 Year Review Papers with Code",
                "link": "https://medium.com/paperswithcode/papers-with-code-2020-review-938146ab9658",
                "content": "Year Review Papers with Code Papers with Code indexes various machine learning artifacts (papers, code and results) to facilitate discovery and comparison. Using this data they can get a sense of what the ML community found useful and interesting this year. In this article they summarize the top trending papers, libraries and benchmarks for 2020 on Papers with Code."
            },
            {
                "title": "Machine Learning going Realtime",
                "link": "http://huyenchip.com/2020/12/27/real-time-machine-learning.html",
                "content": "Machine Learning going Realtime This article covers the topic of real time machine learning in a comprehensive overview. It breaks it down into two levels of real-time machine learning, namely: 1) ML system makes predictions in real-time (online predictions), and 2) system can incorporate new data and update your model in real-time (online learning)."
            },
            {
                "title": "An eXplainability toolbox for ML",
                "link": "https://www.kaggle.com/kritidoneria/xai-an-explainability-toolbox-for-ml/",
                "content": "An eXplainability toolbox for ML AI explainability techniques continue to become adopted throughout the multiple stages of the machine learning lifecycle. This Kaggle notebook provides a set of techniques that can be used to uncover\u00a0 potential undesired biases, and delves into concepts surounding demographic parity, disparate impact, equal opportunity, and equalized odds."
            },
            {
                "title": "Simplifying Outlier Detection",
                "link": "http://towardsdatascience.com/simplifing-image-outlier-detection-with-alibi-detect-6aea686bf7ba",
                "content": "Simplifying Outlier Detection Outlier detection is the identification of data set elements that vary significantly from the majority. Those elements are known as outliers, and there are various incentives for detecting them, depending on the context and domain of each case. This article provides a practical example on how outlier detection can be used in image classification use-cases."
            },
            {
                "title": "Public Engineering Career Ladders",
                "link": "http://www.swyx.io/career-ladders/",
                "content": "Public Engineering Career Ladder Career progression in the engineering world can be quite complex and ambiguous, however there are growing number of resources available online to provide guidance. This great resource has compiled the public engineering career ladders published by tech companies."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "108",
        "items": [
            {
                "title": "Harvard Introduction to CompSci",
                "link": "http://online-learning.harvard.edu/course/cs50-introduction-computer-science?delta=0",
                "content": "Harvard Introduction to CompSci Harvard\u2019s computer science course is available for free for anyone looking to brush up or strengthen their software engineering foundations. This course includes algorithms, data structures, security and has several practical webapp development examples."
            },
            {
                "title": "ML & DL Compendium 2017-2020",
                "link": "https://docs.google.com/document/d/1wvtcwc8LOb3PZI9huQOD7UjqUoY98N5r3aQsWKNAlzk/edit",
                "content": "ML & DL Compendium 2017-2020 AXA Global Head of Tech Innovation Ori Cohen has put together a fantastic 390-page document containing chunk-sized referenceable information ranging across a broad range of topics in machine / deep learning."
            },
            {
                "title": "NYU Deep Learning with PyTorch",
                "link": "https://atcold.github.io/pytorch-Deep-Learning/",
                "content": "NYU Deep Learning with PyTorch Fantastic online course consisting of the latest techniques in deep learning and representation learning, focusing on supervised and unsupervised deep learning, embedding methods, metric learning, convolutional and recurrent nets, with applications to computer vision, natural language understanding, and speech recognition."
            },
            {
                "title": "Python & Jupyter in Excel (Yep)",
                "link": "http://towardsdatascience.com/python-jupyter-notebooks-in-excel-5ab34fc6439",
                "content": "Python & Jupyter in Excel (Yep) Software Developer Tony Roberts is bridging the gap between data science and traditional Excel analysis providing access to the flexibility of Jupyter notebooks (and Python). Innovations like this can only open the doors to greater innovations - I do look forward to the robust productionisation process for these Jupyter Notebooks (or Excel sheets) required to ensure scalable end-to-end advanced analytics capabilites, aka MLOps\u2026 or more specifically AIExcelOps?"
            },
            {
                "title": "Learning NLP the Practical Way",
                "link": "http://towardsdatascience.com/learn-nlp-the-practical-way-b854ce1035c4",
                "content": "Learning NLP the Practical Way FinText Founder Vered Zimmerman has put together a comprehensive guide to dive into NLP in a practical way. This article covers the journey through the NLP ecosystem covering the foundational must-have-s, key datasets to play with, shallow reading resources, deep reading resources, libraries, projects and beyond."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "109",
        "items": [
            {
                "title": "Production ML Monitoring at SF",
                "link": "https://www.meetup.com/SF-Big-Analytics/events/275779757/",
                "content": "Production ML Monitoring at SF We\u2019ll be speaking at the SF Big Analytics meetup on \u201cProduction ML Monitoring: Outliers, Drift, Explainers & Statistical Performance\u201d in February. It will be happening online so feel free to join even if you\u2019re not in the area - we will be joining from across the pond!"
            },
            {
                "title": "100+ Free (& OSS) Dev Books",
                "link": "http://www.theinsaneapp.com/2021/01/free-programming-books.html",
                "content": "100+ Free (& OSS) Dev Books Following the DS & ML books list, the team at \u201cInsaneApp\u201d has put together a fantastic 100+ free programming books ranging across a broad set of programming languages (Python, C++, C, Java and beyond)."
            },
            {
                "title": "The geopolitics of AI & ML",
                "link": "https://tib.buzzsprout.com/1597213/7217326-ian-hogarth-the-geopolitics-of-ai",
                "content": "The geopolitics of AI & ML Entrepreneur First CEO Matt Clifford released a podcast conversation with State-of-AI report author Co-author Ian Hogarth to discuss the geopolitics of AI, where they explore how technology collides with politics, culture and society."
            },
            {
                "title": "Ignoring Advice & Building a Decent Software Startup",
                "link": "https://www.youtube.com/watch?v=74AsJ7RET20",
                "content": "Building Decent Software Startup \u201cHow to Ignore Most Startup Advice and Build a Decent Software Business\u201d by SpaCy and Explosion.ai Co-founder Ines Montani. In this talk Ines shares some of the things she has learned from building a successful software company around commercial developer tools and their open-source library spaCy."
            },
            {
                "title": "Uber\u2019s Real-Time Push Platform",
                "link": "http://eng.uber.com/real-time-push-platform/",
                "content": "Uber\u2019s Real-Time Push Platform Uber builds multi-sided marketplaces handling millions of trips every day across the globe. This has presented challenges that have required innovative thinking around the interaction between the multiple heterogeneous types of applications that require data flow. In this post they discuss the challenges with polling, and showcase how they introduced a push infrastructure through their framework RAMEN."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "110",
        "items": [
            {
                "title": "Entire CompSci Curriculum in Youtube",
                "link": "http://laconicml.com/computer-science-curriculum-youtube-videos/",
                "content": "Entire CS Curriculum in Youtube Great initiative which has attempted to create an entirer Compute Science curriculum using only Youtube videos. The scope of this course aims to cover every skill essential for a Software Engineer, and provides further specialisations in subfields like ML, Discrete Maths, etc."
            },
            {
                "title": "From MLOps to MLOops",
                "link": "https://github.com/daviddao/awful-ai",
                "content": "From MLOps to MLOops Awful AI is a curated list to track current scary usages of AI. The authors put together this open source list, hoping to raise awareness to its misuses in society, as well as encourage best practices."
            },
            {
                "title": "2020\u2019s Top ML Papers",
                "link": "http://www.topbots.com/ai-machine-learning-research-papers-2020/",
                "content": "2020\u2019s Top ML Papers Metamaven CTO Mariya Yao has shared their list of top 2020\u2019s AI research papers. This article includes a very comprehensible brief of each of the 10 papers provided."
            },
            {
                "title": "Python Data Science Startups",
                "link": "http://talkpython.fm/episodes/show/300/building-a-data-science-startup-panel?s=09",
                "content": "Python Data Science Startups The TalkPython podcast brings together a group of Python data science startup founders to share insights aound their journey. This podcast includes Ines Montani from Explosion AI, Matthew Rocklin from Coiled, Jonathon Morgan from Yonder AI and William Stein from Cocalc"
            },
            {
                "title": "The \u201cSimplest\u201d NumPy Course",
                "link": "http://www.gormanalysis.com/blog/python-numpy-for-your-grandma-1-1-introduction/",
                "content": "The \u201cSimplest\u201d NumPy Course Data Scientist Ben Gorman has released a very comprehensive free course that introduces NumPy from scratch. This course\u2019s core principle is that it was designed to be \u201cso easy one\u2019s grandma could learn it\u201d."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "111",
        "items": [
            {
                "title": "Top 2020 ML Notebooks",
                "link": "https://medium.com/deepnote/data-science-notebooks-2020-review-15a3c95cfc09",
                "content": "Top 2020 ML Notebooks An interesting analysis of key stats and trends of jupyter notebooks on Github, together with statistics on the popularity of python libraries for ML used, and relevant linked trends from youtube/google/data sources."
            },
            {
                "title": "Massive Scale Kubernetes for AI",
                "link": "https://openai.com/blog/scaling-kubernetes-to-7500-nodes/",
                "content": "Massive Scale Kubernetes for AI OpenAI shares insights on how they\u2019ve pushed their Kubernetes cluster towards massive scale for their large models like GPT-3, CLIP and DALL-E, but also for rapid smaller-scale iterative research initiatives such as scaling laws for neural language models."
            },
            {
                "title": "Tech in 2020 Data Science",
                "link": "http://mark.douthwaite.io/data-science-2020-technology/",
                "content": "Tech in 2020 Data Science An analysis of 30,000 unique data science blog posts from 2020 to identify the most discussed topics and technologies. This blog post provides deeper insights on software tools, programming languages, cloud platforms and data science platforms."
            },
            {
                "title": "Architecture of ML Systems",
                "link": "https://www.youtube.com/watch?v=_39H53RN1O4&list=PLx8omXiw3n9y26FKZLV5ScyS52D_c29QN&index=1",
                "content": "Architecture of ML Systems This short video series aims to introduce core concepts in software architecture and software requirements planning into production machine learning systems. It covers the motivations, approaches towards requirements gathering, methodologies to take technical decisions, software architecture diagram approaches, communication, documentation, skills and personal development"
            },
            {
                "title": "State of AI Ethics Report 2021",
                "link": "http://montrealethics.ai/jan2021/",
                "content": "State of AI Ethics Report 2021 The Montreal AI Ethics Institute has published \u201cThe State of AI Ethics Report (January 2021)\u201d which captures the most relevant developments in AI Ethics since October of 2020. In this report they cover 8 key themes including: 1) Algorithmic Injustice, 2) Discrimination, 3) Ethical AI, 4) Labor Impacts, 5) Misinformation, 6) Privacy, 7) Risk & Security, and 8) Social Media."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "112",
        "items": [
            {
                "title": "Misinformation: Tech & Solutions",
                "link": "https://www.meetup.com/Tech-Ethics-London/events/275765322/",
                "content": "Misinformation: Tech & Solutions This week we are organising an online meetup on \u201cMisinformation and Bias\u201d, where Dr.\u00a0Magdalena Liz will cover how are governments and companies tackling issues related to this topic. Dr.\u00a0Magdalena is an advisor for the Centre for Data Ethics & Innovation, a body established by the government to advise on challenges & opportunities of AI."
            },
            {
                "title": "Metadata Management Systems",
                "link": "http://gradientflow.com/the-growing-importance-of-metadata-management-systems/",
                "content": "Metadata Management Systems As companies embrace digital technologies to transform their operations and products, many are using best-of-breed software, open source tools, and software as a service (SaaS) platforms to rapidly and efficiently integrate new technologies which results in growing metadata sources - this blog post provides an overview of the ecosystem of metadata management systems."
            },
            {
                "title": "Papers With Code Datasets",
                "link": "http://paperswithcode.com/datasets",
                "content": "Papers With Code Datasets PapersWithCode has launched their datasets component; they are now indexing 3000+ research datasets from machine learning. This enables users to find datasets by task and modality, compare usage over time, browse benchmarks, and more. You can now explore the live dataset in their new section."
            },
            {
                "title": "AI & ML Platforms in 2021",
                "link": "http://databaseline.tech/ml-platforms-in-2021/",
                "content": "AI & ML Platforms in 2021 A comprehensive analysis of machine learning platforms in 2021. This article dives into machine learning frameworks and plaforms across a broad range of quadrants, covering from cloud / onprem, to specialised / end-to-end."
            },
            {
                "title": "AI Regulatory Proposals",
                "link": "http://syncedreview.com/2020/12/31/2020-in-review-8-new-ai-regulatory-proposals-from-governments/",
                "content": "AI Regulatory Proposals Synced has compiled a global list of proposals, rules and regulatory frameworks for AI introduced in 2020, covering Ai governance frameworks, whitepapers, executive orders and beyond."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "113",
        "items": [
            {
                "title": "Linux Foundation AI Principles",
                "link": "http://lfaidata.foundation/blog/2021/02/08/lf-ai-data-announces-principles-for-trusted-ai/",
                "content": "Linux Foundation AI Principles Announcing the Linux Foundation principles for Trusted AI, a fantastic and exciting initiative we have been contributing to for the last couple of months is finally live. These principles provide a strong foundation for open source and AI practitioners and researchers through the renowned Linux Foundation ecosystem."
            },
            {
                "title": "Beyond CUDA Python in GPU",
                "link": "https://www.youtube.com/watch?v=AJRyZ09IUdg",
                "content": "Beyond CUDA Python in GPU A deep dive into GPU processing in Python using the Vulkan Kompute framework. This talk covers the motivations and trends in GPU processing, as well as the high level concepts and architecture of the Vulkan SDK, as well as how the Kompute framework extends it to provide a Python interface by implementing a simple logistic regression algorithm from scratch that can run in cross-vendor GPUs (AMD, Qualcomm, NVIDIA & Friends)."
            },
            {
                "title": "ML Reliability Engineering",
                "link": "http://testdriven.io/blog/machine-learning-reliability-engineering/",
                "content": "ML Reliability Engineering An interesting article that delves into the intersection between SREs and production machine learning systems at scale by proposing the resposibilities that would encompass a \u201cMachine Learning Reliability Engineering\u201d role."
            },
            {
                "title": "Building a Chess AI Engine",
                "link": "http://sebastian.itch.io/chess-ai",
                "content": "Building a Chess AI Engine A fantastic in-depth hands on introduction into developing a Chess AI engine from scratch, covering the intuition, methodology and code required to get up and running. A full demo is also available for anyone looking to test their Chess skills."
            },
            {
                "title": "Data in Healthcare & Life Science",
                "link": "http://thedataexchange.media/data-exchanges-and-their-applications-in-healthcare-and-the-life-sciences/",
                "content": "Data in Healthcare & Life Science The Data Exchange Podcast brings a conversation with LynxMD CEO Omer Dror, a startup that enables data exchanges and markets in the health and life sciences. In this podcast they delve into insights around datasets, privacy preserving tools, NLP, trends in the field and more."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "114",
        "items": [
            {
                "title": "Gen Z and Artificial Intelligence",
                "link": "https://www.meetup.com/Tech-Ethics-London/events/275967589/",
                "content": "Gen Z and Artificial Intelligence This week in our Tech Ethics Online meetup we are hosting an event on Generation Z and Artificial Intelligence, where TeensInAI Founder Elena Sinel will share her journey building a global initiative to empower teenagers to develop and further AI, and will dive into several case studies that showcase the importance and impact this generation is having in the future of artificial intelligence."
            },
            {
                "title": "Security in Prod ML Systems",
                "link": "http://sahbichaieb.com/mlsystems-security/",
                "content": "Security in Prod ML Systems Security is a highly critical topic in production machine learning systems, this post outlines key insights around this topic, including the motivations for security in ML systems, the vulnerabilities of ML systems and intuition on how to explore securing these systems."
            },
            {
                "title": "How To Do All in Computer Vision",
                "link": "http://towardsdatascience.com/how-to-do-everything-in-computer-vision-2b442c469928",
                "content": "How To Do All in Computer Vision Very comprehensible blog post that provides a brief and concise overview on all-things-computer-vision, including: Classification, object detection, segmentation, pose estimation, action recognition, enhancement and restoration."
            },
            {
                "title": "Medicine\u2019s ML Problem",
                "link": "https://bostonreview.net/science-nature/rachel-thomas-medicines-machine-learning-problem",
                "content": "Medicine\u2019s ML Problem Machine learning\u2019s growing presence in production use-cases, particularly in medicine, raises a broad range of concerns. This article provides a comprehensive overview on some of the key challenges, risks and considerations for machine learning in medicine."
            },
            {
                "title": "Top 50 Matplotlib Visualisations",
                "link": "http://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/",
                "content": "Top 50 Matplotlib Visualisations A compilation of the Top 50 matplotlib plots most useful in data analysis and visualization. This list lets you choose what visualization to show for what situation using python\u2019s matplotlib and seaborn library."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "115",
        "items": [
            {
                "title": "Towards Simple Trustworthy AI",
                "link": "http://thedataexchange.media/towards-simple-interpretable-and-trustworthy-ai/",
                "content": "Towards Simple Trustworthy AI The Data Exchange podcast presents an interesting conversation with DarwinAI CoFounders Sheldon Fernandez and Alex Wong, where they dive into the topic of simple, interpretable and trustworthy AI."
            },
            {
                "title": "Python Developers Survey 2020",
                "link": "http://www.jetbrains.com/lp/python-developers-survey-2020/",
                "content": "Python Developers Survey 2020 JetBrains has published the results for their 4th official Python Developer Survey in collaboration with the Python Software Foundation. In this interesting edition they showcase results from more than 28k Python devs from almost 200 countries."
            },
            {
                "title": "SpaCy 3.0 Launch Highlights",
                "link": "http://explosion.ai/blog/spacy-v3",
                "content": "SpaCy 3.0 Launch Highlights The SpaCy team has published an interesting overview of the release of the 3.0 version of one of the mos popular NLP libraries. They provide an overview of features as well as hands on guides going from prototype to production for NLP usecases."
            },
            {
                "title": "Neural Massive Online Multiplayer",
                "link": "https://jsuarez5341.github.io/neural-mmo/build/html/rst/userguide.html",
                "content": "Neural Massive Online Multiplayer Neural MMO is a really interesting initiative that provides a platform for agent-based intelligence research featuring hundreds of concurrent agents, multi-thousand-step time horizons, and procedurally-generated, million-tile maps. The documentation provides an intutivie and practical deep dive into the project."
            },
            {
                "title": "Teaching Cars to See at Scale",
                "link": "https://www.meetup.com/2d3d-ai/events/276541235/",
                "content": "Teaching Cars to See at Scale An intereting set of lectures that dive into practical insights on applied research around perception algorithms for driverless cars. This has been created through an online meetup and although most of the lectures have been published there are still a couple of events coming up."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "116",
        "items": [
            {
                "title": "Scaling Linkedin Experiments",
                "link": "https://engineering.linkedin.com/blog/2020/making-the-linkedin-experimentation-engine-20x-faster",
                "content": "Scaling Linkedin Experiments The LinkedIn data infrastructure teams share interesting insights around how they have scaled \u201cexperimentation serving\u201d to almost 1M queries per second, with thousands of concurrent A/B tests and over 23 trillion experiments a day."
            },
            {
                "title": "The Rise of Metadata Systems",
                "link": "http://thedataexchange.media/the-rise-of-metadata-management-systems/",
                "content": "The Rise of Metadata Systems The data exchange podcast dives into the rise of metadata management systems with Intel Capital investment manager Assaf Araki and Chief Scientist Ben Lorica, where they discuss how metadata systems will impact organisations and industries."
            },
            {
                "title": "Data Version Control 2.0 Release",
                "link": "http://dvc.org/blog/dvc-2-0-release",
                "content": "Data Version Control 2.0 Release The Data Version Control (DVC) team has released a new open source version bringing interesting features like metrics logging, CI/CD integration, ML model checkpoints and lightweight model experiments."
            },
            {
                "title": "The Python SpeedSheet Docs",
                "link": "http://speedsheet.io/s/python",
                "content": "The Python SpeedSheet Docs An interesting project that brings together common snippets of python documentation and tips, together with an intuitive interface that allows for faster serach to answer queries related to the Python programming language."
            },
            {
                "title": "The Graph Neural Net Repository",
                "link": "https://github.com/thunlp/GNNPapers",
                "content": "The Graph Neural Net Repository GNNPapers is an extremely comprehensible compendium of must-read papers on the fascinating topic of graph neural networks. It provides organised sections across different types of models, and applications (physics, recommenders, cv, few-shot, etc)."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "117",
        "items": [
            {
                "title": "Starcraft AI Programming Tutorial",
                "link": "https://www.youtube.com/watch?v=FEEkO6__GKw",
                "content": "Starcraft AI Programming Tutorial An interesting excerpt of a lecture series on applied AI in games, which delves into a practical tutorial that teaches how to program your own Starcraft AI client. This resource provides a very comprehensive overview and intuition on how AI systems can be built against games, and although a full reinforcement-AI-based system is not developed within this lesson specifically, it will provide with the tools and directions to develop towards that milestone for anyone interested."
            },
            {
                "title": "The Netflix Cosmos Platform",
                "link": "https://netflixtechblog.com/the-netflix-cosmos-platform-35c14d9351ad",
                "content": "The Netflix Cosmos Platform The Netflix infra engineering team shares learnings and best practices from their Cosmos platform, a system that leverages serverless \u201clambdas\u201d to enable for the processing of resource-intensive algorithms coordinated via complex hierarchical workflows that can last from minutes to \u201cyears\u201d."
            },
            {
                "title": "Scaling ETL Workers with K8s",
                "link": "https://learnk8s.io/scaling-celery-rabbitmq-kubernetes",
                "content": "Scaling ETL Workers with K8s An excellent tutorial that covers a popular trend in the Kubernetes space, applied towards the intuition behind scaling ETL pipelines. It shows how to use the KEDA (Kubernetes Event-Driven Autoscaler) to scale a celery/rabbit-mq based ETL system."
            },
            {
                "title": "Production ML at Booking.com",
                "link": "https://booking.ai/https-booking-ai-machine-learning-production-3ee8fe943c70",
                "content": "Production ML at Booking.com A broad overview of concepts, techniques and results from Booking.com\u2019s production machine learning infrastructure and data science capabilities. It dives into the main \u201cpillars\u201d of mechanisms used to productionise models, as well as tradeoffs, architectures, and lessons learned."
            },
            {
                "title": "Kaggle Tricks & Best Practices",
                "link": "https://towardsdev.com/tricks-and-best-practices-from-kaggle-794a5914480f",
                "content": "Kaggle Tricks & Best Practices A brief and consise overview of a set of tips, tricks and best practices that can be followed to tackle Kaggle (and general ML) challenges, including correlation matrices, missing values, dataframe styler, and more."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "118",
        "items": [
            {
                "title": "Visualizing Timeliness at Airbnb",
                "link": "https://medium.com/airbnb-engineering/visualizing-data-timeliness-at-airbnb-ee638fdf4710",
                "content": "Visualizing Timeliness at Airbnb An interesting post from Airbnb Engineering that delves into the concept of \u201cDataset Creation/Updating SLAs\u201d, including approaches to identify and manage the dependencies across datasets, as well as the best practices and approaches to ensure bottlenecks and risks are identified and addressed to minimise out-of-date/unavailable datasets when they are required."
            },
            {
                "title": "Video Calls on Steroids with NVIDIA",
                "link": "https://www.youtube.com/watch?v=dVa1xRaHTA0",
                "content": "Video Calls on Steroids w NVIDIA A fascinating piece of research by Nvidia where they showcase an approach to achieve higher quality video transfer with significantly lower data transfer rates. This method takes an innovative approach transferring only an initial picture and streaming information about the head position and metadata of expressions, achieving impressive results - and also opening a new frontier in privacy considerations given the metadata that will be extracted from individuals."
            },
            {
                "title": "Break a Prod Model in 20 Days",
                "link": "http://evidentlyai.com/blog/tutorial-1-model-analytics-in-production",
                "content": "Break a Prod Model in 20 Days A tutorial that provides a practical example of performance divergence for production models, using a case study with a simple random forest model trained on the Kaggle bike sharing demand dataset."
            },
            {
                "title": "The Annual 2021 AI Index",
                "link": "http://hai.stanford.edu/news/2021-ai-index-major-growth-despite-pandemic",
                "content": "The Annual 2021 AI Index The AI Index this year showcases interesting insights about the state of AI in research and industry, and showcases major growth despite the pandemic, including a maturing industry, significant private investment, and rising competition between China and the US."
            },
            {
                "title": "The Next Generation of AI",
                "link": "https://www.oreilly.com/radar/the-next-generation-of-ai/",
                "content": "The Next Generation of AI The O\u2019Reilly team explores the interesting trends in the intersection of emerging areas in artificial intelligence to identify the next big trends, and also delves into some of the key challenges both technical and ethical in the current state of AI."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "119",
        "items": [
            {
                "title": "Andrew Ng deep dive on MLOps",
                "link": "https://www.youtube.com/watch?v=06-AZXmwHjo",
                "content": "Andrew Ng deep dive on MLOps A great overview of MLOps by Andrew Ng. This talk provides a foundational intuition coming from the core machine learning principles, and introduces the challenges around deployed models such as re-training, bias/variance, and general DevOps / ML Engineering challenges."
            },
            {
                "title": "ML & DL Online Courses",
                "link": "http://elvissaravia.substack.com/p/machine-learning-and-deep-learning",
                "content": "ML & DL Online Courses Facebook AI PM Elivs has put together a list of machine learning and deep learning courses which contain extensive content spanning across a broad range of ML areas."
            },
            {
                "title": "Playbook for Model Monitoring",
                "link": "http://towardsdatascience.com/the-playbook-to-monitor-your-models-performance-in-production-ec06c1cc3245",
                "content": "Playbook for Model Monitoring Arize AI Co-founder Aparna Dhinakaran has put together a playbook that outlines the challenges in prod ML connected to availability of ground truth with deployed models, as well as the metrics available that can be used for each scenario."
            },
            {
                "title": "Continuous Retraining Strategy",
                "link": "http://towardsdatascience.com/framework-for-a-successful-continuous-training-strategy-8c83d17bb9dc",
                "content": "Continuous Retraining Strategy Data Scientist Or Itzary shares a conceptual framework that enable practitioners to assess when models should be retrained, as well as the data that should be used in the context of production deployments."
            },
            {
                "title": "Building a Database from Scratch",
                "link": "https://cstack.github.io/db_tutorial/",
                "content": "Building a Database from Scratch A fascinating resource that provides a hands on intuition of the internals of databases by guiding us through the development of a simple database from scratch using the C language. It covers foundational concepts such as data saving formats, moving memory, primary keys, transaction rollbacks and more."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "120",
        "items": [
            {
                "title": "Machine Learning in Healthcare",
                "link": "http://thedataexchange.media/machine-learning-in-healthcare/",
                "content": "Machine Learning in Healthcare The data exchange podcast dives into a fascinating conversation with University of Florida Biomedical Engineering Associate Professor Parisa Rashidi, who specialises in applications of ML to healthcare and biomedical domains. In this podcast they dive into her reseach around applying deep learning into electronic health records and severity assessment models, as well as the requirements to ensure the use of AI is fit-for-purpose, ethically-aligned and compliant to regulation - between other very interesting topics."
            },
            {
                "title": "CPU Architecture Golden Age",
                "link": "https://dl.acm.org/doi/10.1145/3282307",
                "content": "CPU Architecture Golden Age As AI practitioners it\u2019s often easy to overlook the underlying revolution that is driving the break-neck speed of advancement in specialised processing units like GPUs, TPUs, FPGAs, etc. ACM Turing Award Recipients and Computer Architecture legends John Hennessy and David Patterson provide a deep dive on the core foundations that are driving the current \u201cnew golden age of computer architecture\u201d."
            },
            {
                "title": "Growing Importance of Metadata",
                "link": "https://gradientflow.com/the-growing-importance-of-metadata-management-systems",
                "content": "Growing Importance of Metadata A fantastic resource from Gradient Flow which provides an intuition on the growing importance of metadata management systems across industries, and how they are the foundation for data governance solutions, data catalogues, and other enterprise data systems."
            },
            {
                "title": "Data Quality at Airbnb",
                "link": "https://medium.com/airbnb-engineering/data-quality-at-airbnb-e582465f3ef7",
                "content": "Data Quality at Airbnb Airbnb provides a lens into their data driven culture, specifically around the importance they put on data quality across their transition from scaleup into mature thousands-employee organisation - specifically in the context of the data quality initiative internal to Airbnb."
            },
            {
                "title": "Featured OSS Production ML Libraries",
                "link": "https://github.com/ethicalml/awesome-production-machine-learning",
                "content": "Featured OSS Production ML Libraries"
            }
        ]
    },
    {
        "issue": "121",
        "items": [
            {
                "title": "MIT Deep Learning Life Sciences",
                "link": "https://www.youtube.com/watch?v=0jWOZoTsYzI",
                "content": "MIT Deep Learning Life Sciences MIT has released as part of their OpenCourseware a fascinating course that dives into deep learning in the life sciences / computational systems biology, and contains practical knowledge on applicable and cutting edge concepts in this sub-field."
            },
            {
                "title": "Build Your Voice Cloning App",
                "link": "https://www.youtube.com/playlist?list=PLk5I7EvFL13GjBIDorh5yE1SaPGRG-i2l",
                "content": "Build Your Voice Cloning App An interesting project that contains an intuitive overview and practical repo that enables anyone to get started with Pytorch-based voice synthesis. This also provides a glimpse around the ease of access to similar state-of-the-art emerging technologies, including opportunities and challenges."
            },
            {
                "title": "Data Quality in AI Products",
                "link": "http://thedataexchange.media/data-quality-is-key-to-great-ai-products-and-services/",
                "content": "Data Quality in AI Products The data exchange podcast dives into conversation with Superconductive CEO Abe Gong, where they dive into tools aimed at improving data quality through tools for validation and testing."
            },
            {
                "title": "Deep Learning for Cancer Dataset",
                "link": "http://machinelearningmastery.com/neural-network-for-cancer-survival-dataset/",
                "content": "Deep Learning for Cancer Dataset Machine Learning Mastery has put together a tutorial that walks through one of the hello-worlds of machine learning, using robust best practices for building and training a neural network on the cancer dataset."
            },
            {
                "title": "New Sklearn Features Overview",
                "link": "http://towardsdatascience.com/new-features-of-scikit-learn-fbbfe7652bfb",
                "content": "New Sklearn Features Overview A comprehensive blog post overview of the new features available in the latest minor 0.24 version of Sklearn, including upgrading gotchas, sequential feature selectors, individual conditional expectation plots and other new features."
            }
        ]
    },
    {
        "issue": "122",
        "items": [
            {
                "title": "Free AutoML Online Course",
                "link": "http://ki-campus.org/courses/automl2020?locale=en",
                "content": "Free AutoML Online Course Free online course that covers the challenge of designing well-performing machine learning pipelines, including their hyperparameters, architectures of deep neural networks and pre-processing."
            },
            {
                "title": "Exploiting Security ML Pickles",
                "link": "https://blog.trailofbits.com/2021/03/15/never-a-dill-moment-exploiting-machine-learning-pickle-files/",
                "content": "Exploiting Security ML Pickles Fascinating article outlining the security risks of pickles in the context of machine learning artifacts, as well as proposing approaches to tackle these by scanning for malicious code in these ML artifact pickles before loading them."
            },
            {
                "title": "Neural Networks in Minecraft",
                "link": "https://www.youtube.com/watch?v=7OdhtAiPfWY",
                "content": "Neural Networks in Minecraft It had to happen eventually (if it hadn\u2019t already). Yannic Kilcher has brought a scientific-meme to life, implementing a neural network purely on minecraft. In his deep dive video he basically does what it says on the can."
            },
            {
                "title": "ML Deployment Online Course",
                "link": "https://www.linkedin.com/learning/deploying-scalable-machine-learning-for-data-science/introduction-to-kubernetes",
                "content": "ML Deployment Online Course An interesting resource in Linkedin Learning portal focused specifically on the concept of deploying machine learning models, covering the core challenges in the orchestration and serving of machine learning models as services at scale."
            },
            {
                "title": "Defining DataOps and MLOps",
                "link": "http://gradientflow.com/what-is-dataops/",
                "content": "Defining DataOps and MLOps Ben Lorica and Assaf Araki provide some thoughts on terminology in the machine learning and data ecosystem, specifically focusing on defining the trending concept of DataOps and MLOps in industry."
            }
        ]
    },
    {
        "issue": "123",
        "items": [
            {
                "title": "CERN on Scaling 600 Clusters",
                "link": "http://www.oicheryl.com/2021/03/25/managing-600-clusters-with-cern-cloud-native-end-user-lounge/",
                "content": "CERN on Scaling 600 Clusters CNCF\u2019s VP Ecosystem Cheryl Hung interviews CERN computing engineer Ricardo Rocha and delves into the scale of CERN\u2019s infrastructure managing 600 clusters."
            },
            {
                "title": "Real time Data Infra at Uber",
                "link": "https://arxiv.org/pdf/2104.00087.pdf",
                "content": "Real time Data Infra at Uber Uber Engineers Yupeng Fu and Chinmay Soman share key insights on Uber\u2019s data infrastructure in a recent whitepaper - they cover the overall architecture of the real time infrastructure and identify scaling challenges that they need to continuously address for each component in the architecture."
            },
            {
                "title": "OpenAI Powered Linux Shell",
                "link": "http://riveducha.onfabrica.com/openai-powered-linux-shell",
                "content": "OpenAI Powered Linux Shell A fascinating application of OpenAPI\u2019s GPT3 API showcasing how to leverage these models specifically for automatic text to bash-scripts applications. This provides an intuition of the potential of these emerging technologies, but also the importance of human in the loop, in this case to avoid an accidental \u201csudo rm -rf /\u201d."
            },
            {
                "title": "DevSecOps for Machine Learning",
                "link": "http://databaseline.tech/devsecops-for-ml/",
                "content": "DevSecOps for Machine Learning Security in the MLOps lifecycle is key - Ian Hellstrom shares in a latest blog post some key principles for Development Security Operations for Machine Learning, or DevSecOps for ML. This article dives into vulnerability scalling and benefits of distroless images."
            },
            {
                "title": "Python 3.10 Feature Highlights",
                "link": "https://martinheinz.dev/blog/46",
                "content": "Python 3.10 Feature Highlights A great overview of key features coming in with Python 3.10, including type checking improvements, type aliases syntax, population count, context manager syntax, and more."
            }
        ]
    },
    {
        "issue": "124",
        "items": [
            {
                "title": "Automated ML Evaluation at Scale",
                "link": "https://www.youtube.com/watch?v=8ORl8lu1Eeo",
                "content": "Automated ML Eval at Scale Machine Learning models come in different sizes, shapes and flavours - each with varying hardware (and software) requirements. This talk provides a deep dive into the motivations and best practices for benchmarking specifically applied to machine learning, as well as the practical steps and frameworks we can leverage to introduce automation to performance evaluation."
            },
            {
                "title": "Tech Capabilities for MLOps",
                "link": "https://medium.com/prosus-ai-tech-blog/towards-mlops-technical-capabilities-of-a-machine-learning-platform-61f504e3e281#6941",
                "content": "Tech Capabilities for MLOps Data Science Architect Theofilos Papapanagiotou has put together a very comprehensive overview of the MLOps ecosystem, and covers the full spectrum including the workflows, the ML pipeline, and each of the sub-sections such as fefature stores, training pipelines, serving, etc."
            },
            {
                "title": "Selecting ML Feature Eng Method",
                "link": "http://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/",
                "content": "Selecting ML Feature Eng Method A popular post from machine learning mastery covering the different approaches to choose a feature selection method for machine learning. It also introduces some key concepts and tips when performing feature engineering."
            },
            {
                "title": "Best Practices in Data Governance",
                "link": "http://thedataexchange.media/injecting-software-engineering-practices-and-rigor-into-data-governance/",
                "content": "Eng Best Practices in Data Gov The Data Exchange podcast dives into conversation with Immuta Cofounder and CTO Steve Touw to discuss the importance of data governance across organisations. In this podcast they dive into data discovery, privacy, securty and governance."
            },
            {
                "title": "The NLP Index with 3000+ Repos",
                "link": "http://index.quantumstat.com/",
                "content": "The NLP Index with 3000+ Repos A great resource published this week with over 3000 code repositories for practitioners and researchers. In provides features to search across the arxiv index and includes further resources such as link to the paper and github repo."
            }
        ]
    },
    {
        "issue": "125",
        "items": [
            {
                "title": "AI Adoption in Enterprise 2021",
                "link": "https://www.oreilly.com/radar/ai-adoption-in-the-enterprise-2021/",
                "content": "AI Adoption in Enterprise 2021 O\u2019Reilly VP Mike Loukides shares a snapshot of the current state of AI adoption in industry. In this report they cover some key highlights including the challenges on skills, data quality, maturity of systems and sub-sector specific insight - between others."
            },
            {
                "title": "State of Data Engineering in 2021",
                "link": "http://lakefs.io/the-state-of-data-engineering-in-2021/",
                "content": "State of Data Engineering in 2021 The LakeFS team presents a comprehensive overview of the different areas relevant to data engineering, as well as key trends and tools. In this post they cover data ingestion, storage, processing and metadata management."
            },
            {
                "title": "Choosing Best E2E MLOps Tools",
                "link": "http://www.ambiata.com/blog/2020-12-07-mlops-tools/",
                "content": "Choosing Best E2E MLOps Tools A high level overview of the MLOps ecosystem and the approaches that can be taken to select a best-of-class integration that fits organisational requirements, as well as the requirements that have to be taken into consideration when stitching together solutions from multiple suppliers."
            },
            {
                "title": "Python Beginner to Advanced Resources",
                "link": "http://devwriteups.com/beginner-to-pro-in-python-with-these-free-resources",
                "content": "Python Beg. to Adv. Resources As practitioners there is a great incentive to continuously improve our skills and knowledge, and this article provides resources for beginner, intermediate and advanced Python developers, and spans across a broad range of tutorials, blogs, courses and books."
            },
            {
                "title": "Importance of Reliable Metadata",
                "link": "http://towardsdatascience.com/why-reliable-metadata-is-becoming-important-f29e01b01d4d",
                "content": "Importance of Reliable Metadata As the requirements for DataOps and MLOps increases, there is also an increasing importance in the systems to manage the metadata of these resources. This post provides insights on the motivations, concepts, challenges, and solutions around metadata systems."
            }
        ]
    },
    {
        "issue": "126",
        "items": [
            {
                "title": "Kubernetes AI & ML Day Talks",
                "link": "https://www.youtube.com/watch?v=mPGOZqJTjns&list=PLj6h78yzYM2PvESltZXZEVbkIN4DCq96i",
                "content": "Kubernetes AI & ML Day Talks The Kubernetes AI day took place at this year\u2019s KubeCon Conference, and all the videos are now available for free streaming. This great resource includes content that ranges across productionisation of ML in the context of experimentation, deployment, inference, monitoring and beyond."
            },
            {
                "title": "ML Cards for MLOps Governance",
                "link": "http://databaseline.tech/ml-cards/",
                "content": "ML Cards for MLOps Governance An interesting initiative that extends Google\u2019s research paper on ML Cards defining metadata of models, into the MLOps space. This blog post proposes a schema for production models that outlines attributes of deployed models that could be standardised for better interoperability across broader systems."
            },
            {
                "title": "MLOps & Differences to DevOps",
                "link": "http://www.ambiata.com/blog/2020-12-07-mlops-tools/",
                "content": "MLOps & Differences to DevOps This blog post provides a practitioner perspective into MLOps, namely providing an intuition on the nuanced differences between traditional DevOps and MLOps. It dives into the end to end stages of the ML lifecycle including training, deployment, monitoring and further resources."
            },
            {
                "title": "AI Usecases Beyond Automation",
                "link": "http://thedataexchange.media/ai-beyond-automation/",
                "content": "AI Usecases Beyond Automation The Data Exchange podcast delves into conversation with DXC Technology Head of AI Jerry Overton, where they discuss centres of excellence for AI, automation in the workforce, human-centered AI and responsible ML."
            },
            {
                "title": "Andrew Ng Course on MLOps",
                "link": "https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops",
                "content": "Andrew Ng Courses on MLOps Andrew Ng has released a new fantastic resource that aims to demystify the field of MLOps with a theoretical and practical coursera specialisation on the field, where they cover the different areas of MLOps across four courses."
            }
        ]
    },
    {
        "issue": "127",
        "items": [
            {
                "title": "Get started with MLOps",
                "link": "http://towardsdatascience.com/get-started-with-mlops-fd7062cab018",
                "content": "Get started with MLOps A very comprehensive overview of the MLOps journey covering every phase of the ML lifecycle including development, testing, versioning, registries, governance, deployment, monitoring feedback, A/B testing and beyond."
            },
            {
                "title": "Building Drift Monitoring System",
                "link": "http://devblogs.microsoft.com/cse/2020/10/29/building-a-clinical-data-drift-monitoring-system-with-azure-devops-azure-databricks-and-mlflow/",
                "content": "Building Drift Monitoring System An interesting end to end deep dive on a practical industry-specific usecase building a clinical data drift monitoring system in Azure with Databricks and MLOps, covering the objectives, concepts, architecture, and solution."
            },
            {
                "title": "Better Abstractions in Prod ML",
                "link": "http://thedataexchange.media/the-future-of-machine-learning-lies-in-better-abstractions/",
                "content": "Better Abstractions in Prod ML The data exchange podcast brings together a conversation with former Uber DL Leader Travis Addair, where they cover the need for better abstractions in ML. In this podcast they dive into the his work in the Horovod deep learning framework, as well as Ludwig which is the toolbox that allows users to train and test deep learning models without the need to write code."
            },
            {
                "title": "Start Guide to Anomaly Detection",
                "link": "http://towardsdatascience.com/a-comprehensive-beginners-guide-to-the-diverse-field-of-anomaly-detection-8c818d153995",
                "content": "Start Guide to Anomaly Detection A deep dive into the diverse world of anomaly detection. In this blog post they cover a tour of techniques including Isolation Forest, Local Outlier Factor, One-Class SVM, Autoencoders, Robust Covariance Estimator and Time Series Analysis"
            },
            {
                "title": "Revisiting Dev Design Patterns",
                "link": "https://www.youtube.com/watch?v=u5EAJTHPJN8",
                "content": "Revisiting Dev Design Patterns The design patterns book is a classic in computer science. The author Klaus Iglberger has put together a great video where he shares his thoughts on facts and missconceptions about some of the key architecture patterns from the book, a great resource for MLOps and ML Engineering practitioners."
            }
        ]
    },
    {
        "issue": "128",
        "items": [
            {
                "title": "Key AI Research Labs In Europe",
                "link": "https://medium.com/@ODSC/top-10-machine-learning-and-ai-research-labs-in-europe-bc5ce0579010",
                "content": "Key AI Research Labs In Europe The Open Data Science Conference (ODSC) team have put together a great overview of \u201cEurope Research Labs to Watch\u201d, and we are thrilled that they have featured The Institute for Ethical AI & ML, together with other great academic and industry research labs."
            },
            {
                "title": "Responsible AI at Linkedin",
                "link": "https://engineering.linkedin.com/blog/2021/responsible-ai-update",
                "content": "Responsible AI at Linkedin An interesting introspective post from Linkedin analysing and reviewing what Responsible AI means internally. In this post they cover the areas of Fairness and Privacy as well as the road ahead."
            },
            {
                "title": "Lessons from Netflix, Spotify, etc",
                "link": "http://towardsdatascience.com/lessons-on-ml-platforms-from-netflix-doordash-spotify-and-more-f455400115c7",
                "content": "Lessons from Netflix, Spotify, etc. This article analyses the end to end lifecycle of ML and Data, as well as the approach & tools used by leading tech organisations including Netflix, Intuit, Intel, etc. covering the areas of model registries, feature stores, workflow orchestration, serving and monitoring, also showcasing that most of the tools used include a combination of in-house systems with open source frameworks."
            },
            {
                "title": "Twitter on Elastic + Neural Nets",
                "link": "https://blog.twitter.com/engineering/en_us/topics/insights/2021/fusing-elasticsearch-with-neural-networks-to-identify-data.html",
                "content": "Twitter on Elastic + Neural Nets A fascinating post from Twitter Engineering around how they developed a recommendation engine to annotate legacy datasets to a new standardized taxonomy. This is very relevant as the importance of metadata grows across organisations, which often comes with manual labor required to annotate the required metadata retrospectively."
            },
            {
                "title": "Three ML Roles in Organisations",
                "link": "http://laszlo.substack.com/p/you-only-need-these-3-data-roles",
                "content": "Three ML Roles in Organisations An interesting conceptual review of the roles and their responsibilities in organisations building ML & Data systems. In this post it is proposed that the three key roles involve the Data Warehouse Engineers, Data Science Analysis and Data Scientists (which encompasses DS and MLOps / DevOps)."
            }
        ]
    },
    {
        "issue": "129",
        "items": [
            {
                "title": "GitOps Demystified in Practice",
                "link": "https://testingclouds.wordpress.com/2021/06/02/gitops-demystified/",
                "content": "GitOps Demystified in Practice Despite the trend of GitOps becoming the preferred method for continuous deployment in cloud native applications, there is still ambiguity around what it entails. Given that GitOps is also entering the MLOps space, this is a great resources for production ML practitioners to dive into scalable architectural patterns that can enable for CI/CD of ML at scale."
            },
            {
                "title": "DeepCheapFakes and Impact",
                "link": "https://www.oreilly.com/radar/deepcheapfakes/",
                "content": "DeepCheapFakes and Impact As the awareness of DeepFakes increases and the barrier to entry to access its underlying technology lowers, there is a big risk of its use becomes more mainstream. This article discusses the impact of DeepFakes as the trend grows towards them becoming more present in daily online interactions."
            },
            {
                "title": "Biases in AI Systems Taxonomy",
                "link": "http://queue.acm.org/detail.cfm?id=3466134",
                "content": "Biases in AI Systems Taxonomy Algorithmic bias as a challenge is now being tackled in industry, but there are still terms that often are used interchangeably. This resource proposes a taxonomy on algorithmic bias terms as well as references to the meaning behind each."
            },
            {
                "title": "Robust ML Monitoring Overview",
                "link": "http://gradientflow.com/machine-learning-model-monitoring/",
                "content": "Robust ML Monitoring Overview This article dives into key features of machine learning monitoring solutions, why companies need a holistic MLOps platform that includes model monitoring, and challenges companies face in making that happen"
            },
            {
                "title": "Detecting & Mitigating Ethical Risk",
                "link": "https://www.coursera.org/learn/detect-mitigate-ethical-risks",
                "content": "Detecting & Mitigating Ethical Risk Coursera has put together what seems to be like a scarce resource in the AI Ethics space, namely a course that covers the key principles, tools an techniques of the detection and mitigation of ethical risks."
            }
        ]
    },
    {
        "issue": "130",
        "items": [
            {
                "title": "All-Things-Python at Netflix",
                "link": "http://netflixtechblog.com/python-at-netflix-bba45dae649e",
                "content": "All-Things-Python at Netflix A great high level overview of how Python has been adopted and is being used at Netflix. The use of Python ranges across various systems and teams, including their CDN services, demand engineering teams, core engineering teams, monitoring (alerting & remediation), information security, machine learning, ML infrastructure, experimentation notebooks and more."
            },
            {
                "title": "Monitoring ML Systems Course",
                "link": "http://madewithml.com/courses/mlops/monitoring/",
                "content": "Monitoring ML Systems Course A fantastic resource that covers real life and cutting edge techniques for advanced machine learning monitoring. In this hands on course, they cover the theory and practical examples on systems monitoring, drift, outliers, alerting, and more."
            },
            {
                "title": "AI Risk and Liability in Industry",
                "link": "http://thedataexchange.media/how-companies-are-investing-in-ai-risk-and-liability-minimization/",
                "content": "AI Risk and Liability in Industry The data exchange podcast dives into conversation with BHN.ai Co-founder Andrew Burt. In this podcast they dive into a broad range of topics including Andrew\u2019s work at BHN.ai which focuses on legal services around AI compliance and risk mitigation. They also cover practical insights on how companies are tackling these issues in critical and production environments."
            },
            {
                "title": "Kubernetes Learning from Scratch",
                "link": "http://techblost.com/kubernetes-learning-path/",
                "content": "Kubernetes Learning from Scratch Kubernetes is becoming ubiquitous in production systems - this resource provides a comprehensive learning path for interested practitioners that want to learn how to develop and operate systems in kubernetes clusters. It covers the basics for application deployment and then dives into the internals for operations, as well as for extension of the Kubernetes APIs."
            },
            {
                "title": "What is Your ML Model Hiding",
                "link": "http://What%20is%20Your%20ML%20Model%20Hiding",
                "content": "What is Your ML Model Hiding"
            }
        ]
    },
    {
        "issue": "131",
        "items": [
            {
                "title": "HuggingFace Online Course \ud83e\udd17",
                "link": "http://huggingface.co/course/chapter1?s=09",
                "content": "HuggingFace Online Course \ud83e\udd17 A brand new course from HuggingFace which dives into Natural Language Processing with the libraries and frameworks in their ecosystem, and covers the full spectrum of transformers, datasets, tokenizers and more."
            },
            {
                "title": "TWIML\u2019s AI Solutions Guide",
                "link": "http://twimlai.com/solutions/introducing-twiml-ml-ai-solutions-guide/",
                "content": "TWIML\u2019s AI Solutions Guide A great resources that maps the ML tooling ecosystem and provides a visualisation and overview of the top tools in the end to end machine learning lifecycle, as well as their \u201ccoverage\u201d of features compared side-by-side."
            },
            {
                "title": "The Top Trends in Tech Report",
                "link": "http://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/the-top-trends-in-tech",
                "content": "The Top Trends in Tech Report McKinsey digital has produced a report that explores the technologies they identify having the most momentum in the fast-growing tech world, and provides a taxonomy and intuition for these technologies."
            },
            {
                "title": "Going Full Circle with Kafka",
                "link": "http://dok.community/schedule/recP8b5mRFZ3r0yXJ/",
                "content": "Going Full Circle with Kafka An interesting talk from Feature Engineering Company Tecton which covers lessons learned adopting and then moving away from Apache Kafka, reminding us how popular frameworks have their time, place and context."
            },
            {
                "title": "Introduction to Vector Databases",
                "link": "http://www.pinecone.io/learn/vector-database/",
                "content": "Introduction to Vector Databases This article proposes the need for specialisation on database architectures to support optimal interoperability with vector embeddings. This post provides a great overview on the growing popularity of embeddings in machine learning, as well as their generalisation across a broad range of applications, and the need for specialised architectures to get the most out of them at scale."
            }
        ]
    },
    {
        "issue": "132",
        "items": [
            {
                "title": "Machine Learning Interview Prep",
                "link": "http://huyenchip.com/ml-interviews-book/?s=09",
                "content": "Machine Learning Interview Prep A fantastic new resource that aims to provide comprehensive knowledge for individuals preparing for machine learning interviews. It contains a broad range of topics including the different type of jobs, the ML lifecycle, the types of companies, the types of questions, suggested timelines and much more."
            },
            {
                "title": "ML Data Structures with Pydantic",
                "link": "http://datascience.statnett.no/2020/05/11/how-we-validate-data-using-pydantic/",
                "content": "ML Data Structures with Pydantic As the intersection between software engineering and data science grows, the robustness of the tools and techniquest for interoperability becomes of growing importance. This article covers an interesting approach handling data structures and robust validation across production-ready data use-cases."
            },
            {
                "title": "Applied NLP Thinking Solutions",
                "link": "http://explosion.ai/blog/applied-nlp-thinking",
                "content": "Applied NLP Thinking Solutions An important part of any technical role is to master the ability to translate problems into digestible conceptual and tangible solutions. Explosion AI has shared a resource that covers how to adopt an \u201cApplied NLP Thinking\u201d methodology."
            },
            {
                "title": "Disasters in a Microservice World",
                "link": "http://world.hey.com/joaoqalves/disasters-i-ve-seen-in-a-microservices-world-a9137a51",
                "content": "Disasters in a Microservice World A fantastic resource relevant to MLOps practitioners, covering some \u201chorror stories\u201d from production microservice environments. It addresses issues such as \u201chype-driven development\u201d, and covers a set of practical situations which hopefully will help other practitioners learn from and avoid."
            },
            {
                "title": "A Day in the Life of a Senior Dev",
                "link": "http://www.darkcoding.net/software/a-day-in-the-life-of-a-professional-software-engineer/",
                "content": "A Day in the Life of a Senior Dev An extremely amusing blog post covering \u201cthe life of a professional software engineer\u201d. Although comedic, this article does emphasize the gap between expectation and reality, and is very relevant to the first resource above - specifically around addressing the gap of what one is tested on vs what one expected to do on the job."
            }
        ]
    },
    {
        "issue": "133",
        "items": [
            {
                "title": "Pitfalls of Causal Inference in XAI",
                "link": "http://towardsdatascience.com/be-careful-when-interpreting-predictive-models-in-search-of-causal-insights-e68626e664b6",
                "content": "Pitfalls of Causal Inference in XAI SHAP Author Scott Lundberg shares an insightful perspective in an article that advocates for best practices in explainable AI and raises awareness of the pitfalls of trying to extract causal insights from modern predictive machine learning models."
            },
            {
                "title": "7 Layers of MLOps Security",
                "link": "https://denyslinkov.medium.com/7-layers-of-mlops-security-5bfd87eea928",
                "content": "7 Layers of MLOps Security A comprehensive article that covers 7 high level themes in security related to MLOps systems. This first article covers the first one which is protecting data, and provides an intuition across multiple phases of the ML lifecycle."
            },
            {
                "title": "Growing Large Language Models",
                "link": "http://thedataexchange.media/training-and-sharing-large-language-models/",
                "content": "Growing Large Language Models The data exchange podcast dives into conversation with AI Researcher Connor Leathy, and discusses large language models, open datasets for language models, the state of natural language research, and more."
            },
            {
                "title": "Automated Data Wrangling",
                "link": "http://catalyst.coop/2021/05/23/automated-data-wrangling/",
                "content": "Automated Data Wrangling An interesting article that presents the motivations and tools available to introduce automation on data pre-processing, cleaning, curation, and labelling across open and closed datasets of all types and sizes."
            },
            {
                "title": "Clever vs Insightful Code",
                "link": "http://www.hillelwayne.com/post/cleverness/",
                "content": "Clever vs Insightful Code A proposed conceptual framework advocating for best practices on programming, differentiating clever vs insightful code, showing snippets that provide an intuition on what can be both a practical and philosophical concept."
            }
        ]
    },
    {
        "issue": "134",
        "items": [
            {
                "title": "From ML Model to Microservice",
                "link": "http://cloudblogs.microsoft.com/opensource/2021/07/09/simple-steps-to-create-scalable-processes-to-deploy-ml-models-as-microservices/",
                "content": "From ML Model to Microservice An exciting collaboration blog post between Seldon and Microsoft that outlines best practices and practical steps to deploy a GPT-2 Model with Triton ONNX Runtime using Seldon Core in Azure Kubernetes."
            },
            {
                "title": "HuggingFace Founder on MLOps",
                "link": "https://www.youtube.com/watch?v=NKw_fPMRe4o",
                "content": "HuggingFace Founder on MLOps HuggingFace CEO joins the MLOps podcast to dive into conversation around the challenges and best practices of deploying large language / transformer-based models in production."
            },
            {
                "title": "How to NOT Measure Latency",
                "link": "http://www.infoq.com/presentations/latency-response-time/",
                "content": "How to NOT Measure Latency A classic in the performance space which outlines some of the biggest pitfalls of performance evaluation - although this talk was presented a while ago, it is as relevant today in the MLOps space as it is in the general microservice performance evaluation context."
            },
            {
                "title": "MIT Deep Learning Intro Course",
                "link": "https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI",
                "content": "MIT Deep Learning Intro Course A fantastic and comprehensive online course from MIT that covers an introduction to the different areas of deep learning, and provides quite a breadth on all the sub-topics it spans across."
            },
            {
                "title": "Data Mesh Design & Architecture",
                "link": "http://martinfowler.com/articles/data-mesh-principles.html",
                "content": "Data Mesh Design & Architecture An extensive analysis on the core principles and logical architecture of data meshes. It covers the premise and motivations, and proposes concepts such as data as product, self serve data platform, federated computational governance, and the principles that surround these."
            }
        ]
    },
    {
        "issue": "135",
        "items": [
            {
                "title": "Drift Detection: An Introduction",
                "link": "http://www.seldon.io/drift-detection-an-introduction/",
                "content": "Drift Detection: An Introduction Seldon Applied ML Researcher Oliver Cobb has put together a comprehensive introduction to drift detection that provides intuition on a key area of research that is being used to develop robust production machine learning monitoring capabilities at scale."
            },
            {
                "title": "The HashiCorp OpenCore Story",
                "link": "https://www.hashicorp.com/resources/the-story-of-hashicorp-terraform-with-mitchell-hashimoto",
                "content": "The HashiCorp OpenCore Story A fantastic overview of the Open Core history of HashiCorp which is covered as part of their announcement of Terraform 1.0. Terraform is a core technology that has now become critical for production systems, and has been widely adopted and is becoming the standard for infrastructure as code."
            },
            {
                "title": "Guide to Onboarding Developers",
                "link": "http://codesubmit.io/blog/guide-to-onboarding-developers/",
                "content": "Guide to Onboarding Developers Onboarding newhires is a critical process for any technical team, this guide provides a great set of principles and frameworks for onboarding, which can be adopted for not only software engineering, but also machine learning engineering, MLOps and data science roles, between others."
            },
            {
                "title": "Neural Net in Julia from Scratch",
                "link": "http://fluxml.ai/tutorials/2021/01/26/mlp.html",
                "content": "Neural Net in Julia from Scratch The Julia programming languages is making strides in the data science community. This post showcases how to use the popular framework Flux to write a GPU accelerated multi-layer perceptron from scratch."
            },
            {
                "title": "Exploiting Security in ML Binaries",
                "link": "https://blog.trailofbits.com/2021/03/15/never-a-dill-moment-exploiting-machine-learning-pickle-files/",
                "content": "Exploiting Security in ML Binaries Fascinating article outlining the security risks of pickles in the context of machine learning artifacts, as well as proposing approaches to tackle these by scanning for malicious code in these ML artifact pickles before loading them."
            }
        ]
    },
    {
        "issue": "136",
        "items": [
            {
                "title": "A Time Series DB from Scratch",
                "link": "https://nakabonne.dev/posts/write-tsdb-from-scratch/",
                "content": "A Time Series DB from Scratch An interesting article that showcases how to implement a time series database from scratch - the tutorial uses golang but proposes a generic architecture that can be implemented in any language."
            },
            {
                "title": "Best of Speed & Simplicity w Julia",
                "link": "http://www.matecdev.com/posts/numpy-julia-fortran.html",
                "content": "Best of Speed & Simpl. w Julia This overview contains a showcase that shows the speeds that Julia can achieve, which are compared to FORTRAN equivallent, emphasising on the speed benefits whilst having a high level programming interface."
            },
            {
                "title": "Towards Next Gen Dataflow",
                "link": "http://thedataexchange.media/building-a-next-generation-data-and-workflow-orchestrator/",
                "content": "Towards Next Gen Dataflow The Data Exchange podcast brings a conversation with Prefect CTO Chris White, where they talk about all-things-data-pipelines. They dive into the challenges, components, architectures and use-cases of ETL pipelines in production."
            },
            {
                "title": "The Future of Deep Learning",
                "link": "http://bdtechtalks.com/2021/07/01/deep-learning-future-bengio-hinton-lecun/",
                "content": "The Future of Deep Learning A comprehensive compilation of perspectives from thought leaders in the deep learning space including Yoshua Bengio, Geoffrey Hinton and Yann LeCun, covering trends and insights on the future of deep learning."
            },
            {
                "title": "Privacy & Cybersecurity Merging",
                "link": "https://www.lawfareblog.com/flat-light-data-protection-disoriented-policy-practice",
                "content": "Privacy & Cybersecurity Merging One of the most interesting white papers so far, written by Immuta\u2019s Chief Privacy Officer Andrew Burt. This paper covers critical topics on privacy and cybersecurity, as well as how these topics have been changing as we move into massive scale production systems. This paper also provides great historical case studies that provide an insight of how important conceptual shifts and standardisation of thses concepts will be."
            }
        ]
    },
    {
        "issue": "137",
        "items": [
            {
                "title": "Uber Distributed Computing AI",
                "link": "http://eng.uber.com/fiberdistributed/",
                "content": "Uber Distributed Computing AI Uber engineering shares in this blog post a framework called Fiber which enables for simple distributed processing, specifically focused on AI frameworks, covering some specialised algorithm implementations."
            },
            {
                "title": "Building Robust ML Workflows",
                "link": "http://winderresearch.com/how-to-build-a-robust-ml-workflow-with-pachyderm-and-seldon/",
                "content": "Building Robust ML Workflows A collaboration between Pachyderm and Seldon showcasing how to build robust ML workflows that can cover the end to end ML lifecycle spectrum."
            },
            {
                "title": "Bjarne on Future of Programming",
                "link": "https://www.youtube.com/watch?v=ae6nFZn3auQ",
                "content": "Bjarne on Future of Programming C++ Creator Bjarne Stroustrup dives into a conversation where he shares his thoughts on the future of programming, including the impact of AI in programming language particularly in the context of compiler optimization."
            },
            {
                "title": "Papers with Code Highlights",
                "link": "http://paperswithcode.com/top-social",
                "content": "Papers with Code Highlights Papers with Code releases a new feature to allow researchers to keep track of trending papers discussed by the community through \u201chot\u201d category sorting."
            },
            {
                "title": "A Base ML Project Starter",
                "link": "http://www.mihaileric.com/posts/setting-up-a-machine-learning-project/",
                "content": "A Base ML Project Starter A great set of resources for kickstarting ML projects, including a foundation codebase to accelerate getting started, as well as an overview of the key concepts to take into consieration, followed by 5 more extension blog posts."
            }
        ]
    },
    {
        "issue": "138",
        "items": [
            {
                "title": "EU AI Regulation Consultation",
                "link": "https://www.linkedin.com/feed/update/urn:li:activity:6829368746381996032/",
                "content": "EU AI Regulation Consultation Our consultation submission for the European Commission\u2019s AI Regulation Proposal has now been published! We are thrilled to have worked with such a fantastic team of thought leaders with the Association for Computing Machinery to contribute to such an important topic \ud83d\ude80 In the submission we outline the need to better protect public health, safety, & privacy + leverage universal Informatics education to close \u201cskills gap\u201d with a diverse, AI-literate workforce."
            },
            {
                "title": "Declarative ML Systems",
                "link": "http://queue.acm.org/detail.cfm?id=3479315",
                "content": "Declarative ML Systems Insightful article written by contributors from Ludwig and Overton, where they share their insights on motivations, concepts and learnings on the higher level topic they define as declarative machine learning systems."
            },
            {
                "title": "MLOps Event with Andrew Ng",
                "link": "https://www.eventbrite.com/e/data-centric-ai-real-world-approaches-tickets-163151092309",
                "content": "MLOps Event with Andrew Ng Andrew Ng started creating resources around MLOps including the online Coursera course. This week they are hosting a panel event where they will be diving deeper into what they refer as the area of data centric MLOps."
            },
            {
                "title": "Feature Stores Review",
                "link": "http://datatonic.com/insights/bigquery-memorystore-feast-feature-store/",
                "content": "MLOps Feature Stores Review An insightful article which is part of a longer MLOps series, which dives into feature distribution stores, and compares popular solutions such as Google Cloud services and open source frameworks like FEAST."
            },
            {
                "title": "An Intro to Statistical Learning",
                "link": "http://www.statlearning.com/",
                "content": "An Intro to Statistical Learning Practitioners that are looking to enhance their core knowledge will be able to leverage the recently released book \u201cAn introduction to statistical learning\u201d, which is available for free online as PDF version."
            }
        ]
    },
    {
        "issue": "139",
        "items": [
            {
                "title": "StackOverflow 2021 Dev Survey",
                "link": "http://insights.stackoverflow.com/survey/2021",
                "content": "StackOverflow 2021 Dev Survey The annual StackOverflow survey has been released, collecting key insights from over 80,000 developers, presenting interesting insights around general trednds, including insights specific to the Data Science & ML space."
            },
            {
                "title": "Alibi for ML Explainability",
                "link": "http://jmlr.org/papers/v22/21-0017.html",
                "content": "Alibi for ML Explainability A recent paper published in JMLR outlining Alibi Explain, an Open Source Python library for explaining predictions of machine learning models, offering a broad range of techniques for various data formats and explainability types."
            },
            {
                "title": "Data Science Role Evolution",
                "link": "http://thedataexchange.media/the-evolution-of-the-data-science-role-and-of-data-science-tools/",
                "content": "Data Science Role Evolution The Data Exchange dives into conversation with Lyft Data Science Manager Sean Taylor, where he shares insights on how the data science role has evolved during the years, including management duties, recruiting, mentoring, tooling and higher level challenges."
            },
            {
                "title": "CPU Transformer Optimization",
                "link": "http://huggingface.co/blog/bert-cpu-scaling-part-1",
                "content": "CPU Transformer Optimization A comprehensive overview of optimization techniques for transformer-like models in CPU, particularly relevance for inference performance in models. It covers the motivations, tooling, approaches and hands on steps carried out, together with the reslts achieved."
            },
            {
                "title": "Open\u00a0End-to-end MLOps Platform",
                "link": "http://towardsdatascience.com/open-mlops-open-source-production-machine-learning-f4080f02e9f0",
                "content": "Open End-to-end MLOps Platform An interesting blog post showcasing a recent open source project that aims to provide an end to end MLOps platform that puts together best-in-class open source tools to cover the end to end lifecycle of ML models."
            }
        ]
    },
    {
        "issue": "140",
        "items": [
            {
                "title": "CompSci Favourite Papers",
                "link": "https://ordep.dev/posts/my-favorite-papers",
                "content": "CompSci Favourite Papers Fantastic compilation of research papers that are worth reading at least once - this list covers a broad range of topics, from computer science foundations, to algorithms, to databases, and more."
            },
            {
                "title": "AI & Data Trends to Watch",
                "link": "https://www.oreilly.com/radar/radar-trends-to-watch-august-2021/",
                "content": "AI & Data Trends to Watch O\u2019Reilly\u2019s Mike Loukides has put together a comprehensive overview of trends to watch in 2021, extending to AI, Data, Programming, Robotics, Materials, Hardware, Security, Operations, Web, Mobile and VR."
            },
            {
                "title": "Language Model Learnings",
                "link": "https://pair.withgoogle.com/explorables/fill-in-the-blank/",
                "content": "Language Model Learnings Really interesting interactive resource that explains and provides an intuition on language models and their internals, encompassing the underlying learnings, as well as what the models have not captured."
            },
            {
                "title": "Trending Open Source MLOps",
                "link": "https://techninjahere.medium.com/top-11-open-source-mlops-tools-2021-d1b6530e512e",
                "content": "Trending Open Source MLOps Tech Ninja has put together a list of Top Open Source MLOps tools and frameworks that machine learning practitioners can add to their stack to take their production machine learning to the next level."
            },
            {
                "title": "TorchServe Model Optimization",
                "link": "http://opendatascience.com/model-performance-optimization-with-torchserve/",
                "content": "TorchServe Model Optimization An interesting case study from a real life customer application, where various configurations of TorchServe are explored to identify performance differences across multiple platforms."
            }
        ]
    },
    {
        "issue": "141",
        "items": [
            {
                "title": "Kompute Joins the Linux Foundation",
                "link": "http://lfaidata.foundation/blog/2021/08/26/kompute-joins-lf-ai-data-as-new-sandbox-project/",
                "content": "Kompute Joins Linux Foundation The Kompute Project joins the Linux foundation to further the cross-vendor GPU Computing ecosystem for AI, Machine Learning and Advanced Data Processing use-cases, enabling practitioners to accelerate their applications across AMD, NVIDIA, Qualcomm & Friends over 1000s of graphics cards \ud83d\ude80"
            },
            {
                "title": "MLOps London Meetup Kickoff",
                "link": "https://www.meetup.com/mlopslondon/events/280295841/",
                "content": "MLOps London Meetup Kickoff MLOps London is a new meetup that is looking to bring together practitioners that work with production machine learning, and will be doing their first kick-off event this coming month which can be joined both online and in-person."
            },
            {
                "title": "Feature Stores Demystified",
                "link": "https://medium.com/riselab/feature-stores-the-data-side-of-ml-pipelines-7083d69bff1c",
                "content": "Feature Stores Demystified The concept of feature stores has been growing in popularity in recent years, and the concepts it encompasses tend to be relatively ambiguous. This post provides a comprehensive overview of the concept, motivations, architectures and use-cases for feature stores."
            },
            {
                "title": "Data Science Efficient Python",
                "link": "http://towardsdatascience.com/data-scientists-guide-to-efficient-coding-in-python-670c78a7bf79",
                "content": "Data Science Efficient Python A great short article that provides practical tips and tricks when using python for data science through useful libraries, frameworks and code snippets."
            },
            {
                "title": "Auditing ML for Compliance Risk",
                "link": "http://thedataexchange.media/auditing-machine-learning-models-for-discrimination-bias-and-other-risks/",
                "content": "Auditing ML for Compliance Risk Distinguished CMU ML Professor Rayid Ghani dives into conversation together with BNH.ai cofounder Andrew Burt in the Data Exchange podcast where they discuss how organisations are developing ways to audit ML models for discrimination, bias and other risks."
            }
        ]
    },
    {
        "issue": "142",
        "items": [
            {
                "title": "Principles for Digital Citizenship",
                "link": "https://www.linkedin.com/posts/axsaucedo_acm-europe-tpc-european-commission-digital-activity-6839481536169955328-R2cV/",
                "content": "Principles for Digital Citizenship Our submission for the European Commission consultation on the Foundational Principles for Digital Citizenship has now been published \ud83d\ude80 This contribution includes comments that emphasise the importance of universal access to internet & services, ethical principles for human-centric algorithms and a broad range of other critical topics."
            },
            {
                "title": "Stories from ML Practitioners",
                "link": "http://applyingml.com/mentors/",
                "content": "Stories from ML Practitioners ApplyingML has put together a set of compiled interviews with seasoned practitioners in the machine learning space, including senior, staff and director level experiences across tech companies like Amazon, Databricks, Spotify and more."
            },
            {
                "title": "Drift Without Labelled Data",
                "link": "http://concept-drift.fastforwardlabs.com/",
                "content": "Drift Without Labelled Data A comprehensive article that provides a deep dive into concept drift techniques, as well as best practices on how to combat the divergence between static models and dynamic environments."
            },
            {
                "title": "Software Design for Data Scientists",
                "link": "http://third-bit.com/talks/sd4ds/#1",
                "content": "Software Design & Data Scientists A great resource that provides best practices around software design for data scientists, and outlines the motivations, principles and hands on examples for the various concepts it introduces."
            },
            {
                "title": "Data Quality Unpacked",
                "link": "http://gradientflow.com/data-quality-unpacked/",
                "content": "Data Quality Unpacked The rise of DataOps has emphasised the importance of data quality as opposed to just quantity. This article provides an overview of some core concepts of data quality, but also the reasoning for the growing ecosystem of solutions to address these challenges."
            }
        ]
    },
    {
        "issue": "143",
        "items": [
            {
                "title": "Machine Learning EngSci Book",
                "link": "http://smlbook.org",
                "content": "Machine Learning EngSci Book A new online machine learning text book targetted for engineers and scientists being created from a recent online course, and which is covers a wide variety of resources including the underlying foundations, techniques, user aspects and matters related to ethics an responsibility in AI. Until the book is out the online course is available for free, which is yet another great resource that practitioners can benefit from."
            },
            {
                "title": "Graph Deep Learning Overview",
                "link": "https://ericmjl.github.io/essays-on-data-science/machine-learning/graph-nets/",
                "content": "Graph Deep Learning Overview This article aims to provide an intuitive introduction and overview of graph deep learning, and covering the concepts for implementing the internals as well as how it all integrates together."
            },
            {
                "title": "Massively Scaling ML Training",
                "link": "https://arxiv.org/abs/2011.09208",
                "content": "Massively Scaling ML Training Very interesting paper that discusses the motivations, challenges and solutions for massive-scale model training, and proposes a distributed training framework for giant models with the codename Whale."
            },
            {
                "title": "FAANG Interview Prep Repository",
                "link": "https://github.com/AkashSingh3031/The-Complete-FAANG-Preparation",
                "content": "FAANG Interview Prep Repository For practitioners looking to brush up their data structures and algorithms, here is a github repo that contains a very comprehensive list of resources and material for typical algorithmic interview questions."
            },
            {
                "title": "Awesome Kubernetes Lists",
                "link": "https://github.com/ramitsurana/awesome-kubernetes",
                "content": "Awesome Kubernetes Lists Similar to other \u201cawesome\u201d github lists, this \u201cawesome kubernetes\u201d list provides a set of useful resources for practitioners to dive into the world of kubernetes, and for intermediate practitioners to brush up their foundational skills."
            }
        ]
    },
    {
        "issue": "144",
        "items": [
            {
                "title": "The MLE Newsletter has reached 6000+ subcribers \ud83e\udd73",
                "link": "https://ethical.institute/mle.html",
                "content": "The MLE Newsletter has reached 6000+ subcribers \ud83e\udd73"
            },
            {
                "title": "The Production ML List reached 10,000+ Stars \ud83c\udf1f",
                "link": "https://github.com/EthicalML/awesome-production-machine-learning/",
                "content": "The Production ML List reached 10,000+ Stars \ud83c\udf1f"
            },
            {
                "title": "The Kompute Framework reached 500+ Stars \ud83c\udf81",
                "link": "https://github.com/KomputeProject/kompute",
                "content": "The Kompute Framework reached 500+ Stars \ud83c\udf81"
            },
            {
                "title": "The AI Guidelines List reached 600+ Stars \ud83c\udf88",
                "link": "https://github.com/EthicalML/awesome-artificial-intelligence-guidelines",
                "content": "Awesome AI Guidelines to check out this week"
            }
        ]
    },
    {
        "issue": "145",
        "items": [
            {
                "title": "MLOps LDN Online & In-Person",
                "link": "https://www.meetup.com/mlopslondon/events/280295841/",
                "content": "MLOps LDN Online & In-Person This coming week the MLOps London meetup is kicking off with their first event aimed at bringing together practitioners that work with production machine learning, and will be taking place both online and in-person."
            },
            {
                "title": "First GPU Acceleration Kompute",
                "link": "http://kompute.cc/overview/community.html",
                "content": "First GPU Acceleration Kompute The monthly GPU Acceleration Kompute sessions will kick off with its first one this week. This week\u2019s session will cover GPU acceleration across edge device, convolutional neural network (CNN) implementations, features from v0.8.0 release, optimizations and more."
            },
            {
                "title": "ICML 2021 Videos & Slides",
                "link": "http://icml.cc/virtual/2021/calendar",
                "content": "ICML 2021 Videos & Slides The Thirty-eighth International Conference on Machine Learning has now made available the slides, videos and resources for the tutorials that took place at the conference, covering a broad range of interesting topics in the machine learning research ecosystem."
            },
            {
                "title": "Graph Database Ecosystem",
                "link": "http://thedataexchange.media/why-interest-in-graph-databases-and-graph-analytics-are-growing/",
                "content": "Graph Database Ecosystem The Data Exchange Podcast delves into conversation with O\u2019Reilly\u2019s Paco Nathan on recent trends in large-scale graph technologies, novel applications of graph databases, and general trends that are causing the rise in interest for graph-based data systems."
            },
            {
                "title": "Kubernetes Operators Made Easy",
                "link": "http://developers.redhat.com/articles/2021/09/07/build-kubernetes-operator-six-steps#",
                "content": "Kubernetes Operators Made Easy Kubernetes Custom Resource Definitions were introduced as a cloud-native architectural pattern that has seen growing adoption to enable for reliable distributed systems applications. This article will provide MLOps practitioners with the required intuition to get started."
            }
        ]
    },
    {
        "issue": "146",
        "items": [
            {
                "title": "GPT2 with ONNX, Triton & Tempo",
                "link": "http://pycon.hk/2021/bridging-the-data-science-gap-in-production-ml-with-tempo/",
                "content": "GPT2 with ONNX, Triton & Tempo Join us this week at both PyCon HK and/or\u00a0NLP Summit 2021 where we\u2019ll be giving keynote talks where we\u2019ll cover how to accelerate NLP at scale with a GPT2 model using ONNX, Triton, Seldon Core & Tempo."
            },
            {
                "title": "2021 Data/AI Salary Survey",
                "link": "https://www.oreilly.com/radar/2021-data-ai-salary-survey/",
                "content": "2021 Data/AI Salary Survey AI O\u2019Reilly\u2019s Mike Loukides shares the results of a survey on salaries in the Data & AI space, providing some perspective on the job market for this growing field, and although it is currently geographically limited provides some insights on the sub-trends of challenges, gaps, opportunities and trends."
            },
            {
                "title": "An Intuitive Deep Dive on Drift",
                "link": "https://docs.seldon.io/projects/alibi-detect/en/latest/cd/background.html",
                "content": "An Intuitive Deep Dive on Drift The OSS Alibi Detect project has published a comprehensive introduction and overview of the drift detection which covers the high level concepts required to understand some of the key components, as well as relevant references to dive into more detail for any practitioners interested."
            },
            {
                "title": "A Gentle Introduction to MLOps",
                "link": "https://medium.com/@yashaswi_nayak/a-gentle-introduction-to-mlops-7d64a3e890ff",
                "content": "A Gentle Introduction to MLOps A high level article that provides an introduction to the fast-growing and broad field of MLOps, including a lot of images and diagrams to introduce new practitioners to the field and common concepts."
            },
            {
                "title": "Julia Multi-Dispatch Effectiveness",
                "link": "http://thedataexchange.media/julia-multiple-dispatch/",
                "content": "Julia Multi-Dispatch Effectiveness Julia Computing Co-Founder and CEO Viral Shah dives into conversation on the data exchange podcast where he covers interesting insights on the Julia language and community, as well as some updates on the goals and objectives with their recent Series A investment."
            }
        ]
    },
    {
        "issue": "147",
        "items": [
            {
                "title": "Real Time Fraud Detection at ING",
                "link": "http://www.ververica.com/blog/real-time-fraud-detection-ing-bank-apache-flink",
                "content": "Real Time Fraud Detection at ING A practical case study of ING bank showcasing adoption of production ready real time machine learning capabilities through a risk engine that supports a broad range of ML models, support across multiple environments and higher level interfaces for extensibility."
            },
            {
                "title": "Practical AI Ethics from MLOps",
                "link": "https://www.meetup.com/Tech-Ethics-London/events/281139652/",
                "content": "Practical AI Ethics from MLOps The London Tech Ethics online meetups is coming back again with an upcoming event covering practical AI ethics from an MLOps perspective by Pacyderm Chief Evangelist Dan Jeffries."
            },
            {
                "title": "Federated Learning Research",
                "link": "http://analyticsindiamag.com/top-10-research-papers-on-federated-learning/",
                "content": "Federated Learning Research A fantastic list of popular research papers on federated learning covering a broad range of key topics relevant to edge, mobile, privacy-preserving ML and more."
            },
            {
                "title": "Technical Debt Opinion Survey",
                "link": "https://dzone.com/articles/what-do-engineers-really-think-about-technical-debt",
                "content": "Technical Debt Opinion Survey The Gradient Flow team has released an interesting overview of trends on robotic process automation across leading global organisations."
            },
            {
                "title": "The Road to Intelligent RPA",
                "link": "http://gradientflow.com/the-road-to-intelligent-process-automation/",
                "content": "The Road to Intelligent RPA Technical debt is a challenge that goes beyond software very relevant to machine learning systems, this survey provides an interesting perspective from over 200 engineers on technical debt in projects and their impact in teams."
            }
        ]
    },
    {
        "issue": "148",
        "items": [
            {
                "title": "Linkedin\u2019s Approach to XAI",
                "link": "https://engineering.linkedin.com/blog/2021/transparent-and-explainable-AI-systems",
                "content": "Linkedin\u2019s Approach to XAI An overview from Linkedin Engineering on their Responsible AI program. They dive into high level principles, architectural blueprints, techniques used, processes, and brief insights on their future work."
            },
            {
                "title": "Prod ML Resources Curated List",
                "link": "https://github.com/eugeneyan/applied-ml",
                "content": "Prod ML Resources Curated List A comprehensive github list containing an extensive set of curated papers, articles and blogs on data science and machine learning in production, ranging across a broad range of different areas."
            },
            {
                "title": "Top Places to Work for ML",
                "link": "http://gradientflow.com/top-places-to-work-for-data-scientists/",
                "content": "Top Places to Work for ML A great resource that explores top organisations for data scientists of different levels of seniority, covering also the methodology they used to approach this question."
            },
            {
                "title": "ML, AI & Data Landscape (MAD)",
                "link": "http://mattturck.com/data2021/",
                "content": "ML, AI & Data Landscape (MAD) This latest landscape maps an extensive list of technologies across a broad set of different areas and themes involving the full end to end machine learning lifecycle, focusing primarily on \u201cMAD\u201d suppliers."
            },
            {
                "title": "Training System for Industry Scale",
                "link": "https://arxiv.org/pdf/2108.09373.pdf",
                "content": "Training System for Industry Scale The Facebook team has put together a great overview of a large effort to identify scalable approaches and systems to achieve the data ingestion for large-scale training of recommender system models."
            }
        ]
    },
    {
        "issue": "149",
        "items": [
            {
                "title": "NeurIPS Practical Responsible AI",
                "link": "https://twitter.com/_LXAI/status/1451941540964802565",
                "content": "NeurIPS Practical Responsible AI We are thrilled to announce that Chief Scientist Alejandro Saucedo will be giving a keynote at NeurIPS 2021 at the LXAI workshop this coming December 7th \ud83d\ude80 The virtual tickets are free so come join us at this fantastic event to hear about a broad range of topics in state of the art machine learning research & applications. Until then, you can also join upcoming talks this week at CppCon 2021 and PyData Global 2021 \ud83e\udd16"
            },
            {
                "title": "Github on Deploying ML Safely",
                "link": "http://thedataexchange.media/deploying-machine-learning-models-safely-and-systematically/",
                "content": "Github on Deploying ML Safely Github Staff Machine Learning Engineer Hamel Husain joins the Data Exchange podcast and provides great insights on the areas of CI/CD for ML, MLOps tools and processes, and how much software engineering should data scientists know."
            },
            {
                "title": "The State of AI Report 2021",
                "link": "http://www.stateof.ai/",
                "content": "The State of AI Report 2021 The Annual State of AI report has come out, providing an outline of very interesting development of AI, and covers the areas of research, talent, industry, politics and predictions."
            },
            {
                "title": "Shopify on Building ML Models",
                "link": "http://shopify.engineering/building-business-machine-learning-models",
                "content": "Shopify on Building ML Models A great practical perspective from Shopify Engineering on their perspective around building machine learning models in industry, which covers practical advise to question the relevance, requirements, measurements, plans, and stability when considering ML in practical contexts."
            },
            {
                "title": "20 Lessons Across 20 Years",
                "link": "https://www.simplethread.com/20-things-ive-learned-in-my-20-years-as-a-software-engineer/",
                "content": "20 Lessons Across 20 Years A great high level article providing 20 points of advise from a long career in software engineer, aiming to outline a set of principles that are important to consider for a meaningful and consciencious approach to software as a applicable and useful craft."
            }
        ]
    },
    {
        "issue": "150",
        "items": [
            {
                "title": "MLOps and Devops around Data",
                "link": "https://www.oreilly.com/radar/mlops-and-devops-why-data-makes-it-different/",
                "content": "MLOps and Devops around Data This article attempts to identify the key principles that distinguish MLOps from DevOps, particularly covering data, compute, orchestration and the software development layers."
            },
            {
                "title": "The Guide to GitOps Architecture",
                "link": "http://www.weave.works/technologies/gitops/",
                "content": "The Guide to GitOps Architecture Weaveworks has released a resource that would be very relevant for MLOps practitioners which provides practical insights around the concept of GitOps, including comparisons with similar concepts, as well as principles, processes and tools."
            },
            {
                "title": "Case Study for Ethics in AI/ML",
                "link": "http://numfocus.org/case-studies/ethics-in-ai-ml",
                "content": "Case Study for Ethics in AI/ML The Institute for Ethical AI published a collaboration with NumFocus on how they use foundation tools to enable accountability and ethics in AI and machine learning, which is one of several fantastic case studies including the story of the first photograph of the black hole https://numfocus.org/case-studies."
            },
            {
                "title": "Large Scale ML Multi-Modal Data",
                "link": "http://thedataexchange.media/large-scale-machine-learning-and-ai-on-multi-modal-data/",
                "content": "Large Scale ML Multi-Modal Data The data exchange podcast dives into conversation with Mist Systems CTO Bob Friday, where they delve into large scale machine learning on multi-modal data."
            },
            {
                "title": "ML Monitoring at EuroPython",
                "link": "https://www.youtube.com/watch?v=n0bR0IArJDo",
                "content": "ML Monitoring at EuroPython The Production Machine Learning Montioring EuroPython talk is now out, covering standard microservice monitoring techniques applied into deployed machine learning models, as well as more advanced paradigms to monitor machine learning models with Python leveraging advanced monitoring concepts such as concept drift, outlier detector and explainability."
            }
        ]
    },
    {
        "issue": "151",
        "items": [
            {
                "title": "NeurIPS LX Workshop Keynotes",
                "link": "http://www.latinxinai.org/neurips-2021-about#block-d57fecdfc85c08184315",
                "content": "NeurIPS LX Workshop Keynotes The keynotes for the NeurIPS 2021 LXAI Workshop have been published \ud83c\udf89 We will be delivering a keynote on Responsible AI, together with two other Keynotes by Data Science Leader Ana Paula Appel on intersecting themes of industry & research, and Professor Joaquin Salas on the role of AI in challenging times."
            },
            {
                "title": "HuggingFace Online NLP Course",
                "link": "http://huggingface.co/course/chapter1",
                "content": "HuggingFace Online NLP Course The HuggingFace team has published an online course that ill teach you about natural language processing (NLP) using libraries from the Hugging Face ecosystem \u2014 \ud83e\udd17 Transformers, \ud83e\udd17 Datasets, \ud83e\udd17 Tokenizers, and \ud83e\udd17 Accelerate \u2014 as well as the Hugging Face Hub. It\u2019s completely free and without ads."
            },
            {
                "title": "Neural Network for Chess Engine",
                "link": "https://medium.com/@bellerb/building-a-chess-engine-part2-db4784e843d5",
                "content": "Neural Network for Chess Engine A great and comprehensive tutorial that shows how to first create a chess engine from scratch and then how to create and train an AI model that is able to run against the engine itself. It includes the underlying theory, code snippets and references."
            },
            {
                "title": "SpaCy vs NLTK. Normalization",
                "link": "http://newscatcherapi.com/blog/spacy-vs-nltk-text-normalization-comparison-with-code-examples",
                "content": "SpaCy vs NLTK. Normalization A comprehensive overview that takes two of the most popular python NLP libraries and evaluates them side by side to perform text normalization, sharing code snippets, comparisons and high level benchmarks including tradeoffs."
            },
            {
                "title": "The State of AI-Generated Code",
                "link": "https://www.oreilly.com/radar/the-quality-of-auto-generated-code/",
                "content": "The State of AI-Generated Code The AI O\u2019Reilly team dives into the Github Copilot programme sharing their high level thoughts on practical and theoretical questions on the potential opportunities and challenges it presents."
            }
        ]
    },
    {
        "issue": "152",
        "items": [
            {
                "title": "MLOps London November Meetup",
                "link": "https://www.meetup.com/mlopslondon/events/281090209/",
                "content": "MLOps LDN November Meetup The MLOps London meetup comes back with its 2nd online & on-prem session looking to bring together practitioners that work with production machine learning, and will be doing their first kick-off event this coming month."
            },
            {
                "title": "Scalable Explainable NLP Search",
                "link": "http://ai.stanford.edu/blog/retrieval-based-NLP/",
                "content": "Scalable Explainable NLP Search Insightful piece from Standford AI Lab blog covering retrieval-based NLP systems that provide state-of-the-art capabilities for tasks like answering open-domain questions and verifying complex claims."
            },
            {
                "title": "KubeCon North America 2021",
                "link": "https://www.youtube.com/playlist?list=PLj6h78yzYM2Nd1U4RMhv7v88fdiFqeYAP",
                "content": "KubeCon North America 2021 The KubeCon 2021 North America conference videos have now been published. These are a fantastic resource for MLOps practitioners to gain insights around key trends in the Kubernetes world including observability, security, real world applications, best practices and more."
            },
            {
                "title": "AI begins with Data Quality",
                "link": "http://thedataexchange.media/ai-begins-with-data-quality/",
                "content": "AI begins with Data Quality The Data Exchange podcast dives into conversation with Anomalo CTO to cover key insigths in the area of data quality, and provide some insights on data engineering, most important chalelnges, end-to-end dataops and more."
            },
            {
                "title": "Reflections 10k hrs Programming",
                "link": "http://matt-rickard.com/reflections-on-10-000-hours-of-programming/",
                "content": "Reflections 10k hrs Programming An interesting and succint overview that aims to extract key lessons from a career of software development, providing 31 different high level ideas that aim to capture best practices and lessons."
            }
        ]
    },
    {
        "issue": "153",
        "items": [
            {
                "title": "O\u2019Reilly Radar Trends to Watch",
                "link": "https://www.oreilly.com/radar/radar-trends-to-watch-november-2021/",
                "content": "O\u2019Reilly Radar Trends to Watch The O\u2019Reilly team has released an overview of key highlights identified in the areas of artificial intelligence, ethcis in technology, general programming, security, infrastructure, IOT, web and quantum computing."
            },
            {
                "title": "Thoughtworks MLOps Platforms",
                "link": "https://github.com/thoughtworks/mlops-platforms#mlops-platforms",
                "content": "Thoughtworks MLOps Platforms EIML Institute Contributor & Thoughtworks Principal Data Engineer Ryan Dawson has published an analysis of MLOps platforms across various different categories and capabilities."
            },
            {
                "title": "Best AI Papers of 2021 [WIP]",
                "link": "https://github.com/louisfb01/best_AI_papers_2021#2021-a-year-full-of-amazing-ai-papers--a-review--work-in-progress",
                "content": "Best AI Papers of 2021 [WIP] A great resource bringing together a urated list of the latest breakthroughs in AI by release date with a clear video explanation, link to a more in-depth article, and code."
            },
            {
                "title": "MLOps Anti-Paterns & Lessons",
                "link": "http://thedataexchange.media/mlops-anti-patterns/",
                "content": "MLOps Anti-Paterns & Lessons The Data Exchange podcast dives into conversation with Virginia College Researcher Nikhil Muralidhar into his paper \u201cUsing AntiPatterns to avoid MLOps Mistakes\u201d and covers insights from learnings obtained in the financial services industry."
            },
            {
                "title": "Containers from the Bottom Up",
                "link": "http://iximiuz.com/en/posts/container-learning-path/",
                "content": "Containers from the Bottom Up A fantastic refresher for MLOps practitioners from booking.com SRE Ivan Velichko on the core concepts & intuition of container fundamentals."
            }
        ]
    },
    {
        "issue": "154",
        "items": [
            {
                "title": "NeurIPS LXAI Opening Keynote",
                "link": "https://neurips.cc/Conferences/2021/ScheduleMultitrack?event=22884",
                "content": "NeurIPS LXAI Opening Keynote The final schedule for the NeurIPS 2021 LXAI Workshop has been published on the website \ud83c\udf89 join us on December 7th where we will be delivering the opening keynote on \u201cMeditations on First Deployment: A Practical Guide to Responsible AI\u201d \ud83d\ude80"
            },
            {
                "title": "Reddit Production ML Architecture",
                "link": "https://www.reddit.com/r/RedditEng/comments/q14tsw/evolving_reddits_ml_model_deployment_and_serving/",
                "content": "Reddit Production ML Architecture Reddit Staff Engineer Garrett Hoffman provides an overview on Reddit\u2019s re-architecture journey for their internal machine learning model deployment and serving systems, covering perfromance, scalability, maintainability, reliability, observability and more."
            },
            {
                "title": "State of Privacy Preserving ML",
                "link": "http://gradientflow.com/get-ready-for-confidential-computing/",
                "content": "State of Privacy Preserving ML An interesting overview of the different areas of confidential computing as well as their challenges and opportunities, including homomorophic encryption, differential privacy, federated learning, etc."
            },
            {
                "title": "Organisational Data Challenges",
                "link": "http://locallyoptimistic.com/post/the-next-big-challenge-for-data-is-organizational/",
                "content": "Organisational Data Challenges An overview of the challenges organisationas are currently and will be increasingly facing around data, including the areas of modularity, specialisation, clarity, and buy-in."
            },
            {
                "title": "Dynamic AI Learning Mind Map",
                "link": "http://app.learney.me/#",
                "content": "Dynamic AI Learning Mind Map An interesting project that aims to provide intuitive ways of creating mind maps and showing an application showing the learning path for machine learning covering foundational concepts such as statistics, calculus, optimization, and more."
            }
        ]
    },
    {
        "issue": "155",
        "items": [
            {
                "title": "NeurIPS LXAI Opening Keynote",
                "link": "http://neurips.cc/Conferences/2021/ScheduleMultitrack?event=22884",
                "content": "NeurIPS LXAI Opening Keynote The NeurIPS 2021 Conference is kicking off this week \ud83c\udf89 Join us this Tuesday at the NeurIPS LXAI Workshop where we will be giving the opening keynote on \u201cMeditations on First Deployment: A Practical Guide to Responsible AI\u201d \ud83d\ude80"
            },
            {
                "title": "Machine Learning Advent of Code",
                "link": "http://data-puzzles.com/",
                "content": "Machine Learning Advent of Code As the year end approaches we have the chance to jump into the many advent-of-code-like challenges. This is a fantastic resource for ML practitioners to brush up their data science & engineering skills by taking a range of very well (and creatively) prepared set of data challenges."
            },
            {
                "title": "Open MLOps End to End Tech",
                "link": "https://github.com/datarevenue-berlin/OpenMLOps#open-mlops---a-production-focused-open-source-machine-learning-framework",
                "content": "Open MLOps End to End Tech"
            },
            {
                "title": "Kubernetes Introduction Course",
                "link": "https://www.edx.org/course/introduction-to-kubernetes",
                "content": "Kubernetes Introduction Course A fantastic resource for MLOps practitioners looking to adopt Kubernetes. This free resource provides essential Kubernetes knowledge, and provides the foundation for practitioners to get started with the important and growing cloud native ecosystem."
            },
            {
                "title": "O\u2019Reilly Radar Trends December",
                "link": "https://www.oreilly.com/radar/radar-trends-to-watch-december-2021/",
                "content": "O\u2019Reilly Radar Trends December The O\u2019Reilly team comes back with a fantastic compilation of resources that highlight key trends in the areas of Machine Learning, Programming, Web, VR, Quantum and much more."
            }
        ]
    },
    {
        "issue": "156",
        "items": [
            {
                "title": "Video for NeurIPS 2021 is Out!",
                "link": "https://www.youtube.com/watch?v=57YpXjcj0Ho",
                "content": "Video for NeurIPS 2021 is Out! NeurIPS 2021 wrapped up last week and was an absolutely fantastic conference! Our opening keynote at the LXAI Workshop on \u201cMeditations on First Deployment: A Practical Guide to Responsible AI\u201d is now available for streaming online \ud83d\ude80"
            },
            {
                "title": "Twitter Processing Billion Events",
                "link": "https://blog.twitter.com/engineering/en_us/topics/infrastructure/2021/processing-billions-of-events-in-real-time-at-twitter-",
                "content": "Twitter Processing Billion Events Twitter shares an insightful insight into a recent architectural migration to one of their core data systems that process ~400 billion events in real time generating petabyte scale data every day. They provide an overview of the old and new architecture, as well as the performance resutls when evaluating the new kafka dataflow system."
            },
            {
                "title": "Avoiding Data Disasters Example",
                "link": "http://www.fast.ai/2021/11/04/data-disasters/",
                "content": "Avoiding Data Disasters Example FastAI Co-founder Rachael Thomas shares in a new blog post a case study that covers the importance of data in real-world challenges, covering in particularly a national covid tracking application."
            },
            {
                "title": "NLP and AI in Financial Services",
                "link": "http://thedataexchange.media/nlp-and-ai-in-financial-services/",
                "content": "NLP and AI in Financial Services The Data Exchange podcast comes back this week with an insightful conversation with Accern CTO Anshul Pandey, where they dive into specific challenges of building AI and NLP applications within the financial services."
            },
            {
                "title": "26-Week Data Science Course",
                "link": "http://towardsdatascience.com/a-complete-26-week-course-to-learn-python-for-data-science-in-2022-e95b67551df4",
                "content": "26-Week Data Science Course An interesting resource that aims to provide a comprehensive amount of content serving as a learning path for data science covering 26 weeks of broad educational content."
            }
        ]
    },
    {
        "issue": "157",
        "items": [
            {
                "title": "Call to Build Models like OSS",
                "link": "https://colinraffel.com/blog/a-call-to-build-models-like-we-build-open-source-software.html",
                "content": "Call to Build Models like OSS An interesting article posing a call to action to encourage similar principles and philosophies present in open source software development in the AI model training world, namely outlining the benefits on communication, cooperation, ineroperability, contributions, backwards compatibility and more."
            },
            {
                "title": "Cross-Vendor GPGPU at CppCon",
                "link": "https://www.youtube.com/watch?v=UfWvM9u8ISo",
                "content": "Cross-Vendor GPGPU at CppCon Our CppCon 2021 talk is now out \ud83d\ude80 In this session we provide a hands on introduction to cross-vendor GPU acceleration for general compute using C++ as well as machine learning use-cases using the Vulkan & Kompute open source projects."
            },
            {
                "title": "The 18 Highest Paying Dev Roles",
                "link": "http://www.infoworld.com/article/3638775/the-18-highest-paying-developer-roles-in-2021.html",
                "content": "The 18 Highest Paying Dev Roles An overview of some key software development roles and specialisations that have currently grown to become some of the highest paid roles, ranging across architecture, cloud, web, mobile and data."
            },
            {
                "title": "Making Language Models Smart",
                "link": "http://thedataexchange.media/making-large-language-models-smarter/",
                "content": "Making Language Models Smart The data exchange podcast comes back this week in conversation with AI21 Labs Co-founder and Stanford Professor Yoav Shoham where they dive into the power of NLP and language models as well as key opportunities and the future in the field."
            },
            {
                "title": "Scaling Teams Parallel Systems",
                "link": "http://getsturdy.com/blog/2021-11-29-scaling-teams",
                "content": "Scaling Teams Parallel Systems This article provides an interesting set of concepts analogous to the philosophy behind the \u201cmythical man-month\u201d through parallel computing systems concepts, showing the relationship between increased stakeholders and output."
            }
        ]
    },
    {
        "issue": "158",
        "items": [
            {
                "title": "Prod ML Monitoring Deep Dive",
                "link": "http://towardsdatascience.com/production-machine-learning-monitoring-outliers-drift-explainers-statistical-performance-d9b1d02ac158?source=friends_link&sk=15c7b4d977e2470f9709621a56318903",
                "content": "Prod ML Monitoring Deep Dive The lifecycle of a machine learning model only begins once it\u2019s in production. Our hands on article covers end to end principles, patterns and techniques around production machine learning monitoring, including the code to deploy and monitor an ML model using explainability, outlier detection, concept drift and statistical performance techniques."
            },
            {
                "title": "Data & AI Platforms at Shopify",
                "link": "http://thedataexchange.media/data-and-machine-learning-platforms-at-shopify/",
                "content": "Data & AI Platforms at Shopify The data exchange podcast dives into conversation with Shopify Director of Engineering Azeem Ahmed, and covers key insights from the team he leads developing the APIs used by all internal data scientists."
            },
            {
                "title": "Evolution of the Canonical Stack",
                "link": "http://opendatascience.com/the-rapid-evolution-of-the-canonical-stack-for-machine-learning/",
                "content": "Evolution of the Canonical Stack As organisations develop their internal capabilities for end to end machine learning, the concept of the canonical stack for machine learning has been growing providing best practices and unified infrastructure architectures leveraging the best available tools for each specialised phase of the ML lifecycle."
            },
            {
                "title": "Must Read Books in MLOps 2022",
                "link": "http://www.seldon.io/machine-learning-books-you-must-read-in-2022/",
                "content": "Must Read Books in MLOps 2022 As MLOps practitioners the ecosystem keeps changing, and it is often hard to navigate the best resources to use - this article has found five key books for MLOps and Machine Learning practitioners to develop their skills further for 2022."
            },
            {
                "title": "2022 AI Predictions from Experts",
                "link": "http://thenextweb.com/news/neurals-ai-predictions-2022",
                "content": "2022 AI Predictions from Experts TheNextWeb has put together for the 5th concecutive year an annual set of predictions for the AI ecosystem, gathering views for several experts in the industry."
            }
        ]
    },
    {
        "issue": "159",
        "items": [
            {
                "title": "A Year Full of Amazing AI Papers",
                "link": "http://www.louisbouchard.ai/2021-ai-papers-review/",
                "content": "A Year Full of Amazing AI Papers A fantastic effort bringing together key highlights from the world of AI research in 2021, providing an overview from top research highlights including intuitive summaries, videos and relevant links to learn more."
            },
            {
                "title": "Model Monitoring Areas Overview",
                "link": "https://medium.com/prosus-ai-tech-blog/model-monitoring-1849fb3afc1e",
                "content": "Model Monitoring Areas Overview An overview of key metrics, attributes and concepts in the topic of monitoring in regards to machine learning models deployed in production."
            },
            {
                "title": "Data Science for Infrastructure",
                "link": "https://www.youtube.com/watch?v=Wi8gR43x-6Q",
                "content": "Data Science for Infrastructure An interesting Stanford MLSys Episode showcasing insights from applying data science into operational software infrastructure by Pixie CEO Zain Asgar."
            },
            {
                "title": "Master Dataclasses in Python",
                "link": "https://www.youtube.com/watch?v=OdBF3W1MIWw",
                "content": "Master Dataclasses in Python This video series covers an in-depth overview of python dataclasses, showcasing the varying features and capabilities, best practices and applications."
            },
            {
                "title": "Graph Neural Networks Overview",
                "link": "https://distill.pub/2021/gnn-intro/",
                "content": "Graph Neural Networks Overview Graph Neural Networks are neural networks that operate on graph data. This article provides an in-depth introduction and overview on the intuition and concepts behind graph neural networks."
            }
        ]
    },
    {
        "issue": "160",
        "items": [
            {
                "title": "MLOps Free University Course",
                "link": "https://skaftenicki.github.io/dtu_mlops/",
                "content": "MLOps Free University Course The Technical University of Denmark has released the complete resources for their recently released course in Machine Learning Operations. This fantastic resource covers key topics including Reproducibiliy, Cloud, Scalable Apps, Deployment, Monitoring and more."
            },
            {
                "title": "AI & Data Trends for 2022",
                "link": "http://thedataexchange.media/key-ai-and-data-trends-for-2022/",
                "content": "AI & Data Trends for 2022 The Data Exchange team has released a conversation discussing key AI and Data trends for 2022, gathering insights from Chief Scientist Ben Lorica and Applied AI Expert Mikio Braun."
            },
            {
                "title": "How to Evaluate MLOps Tools",
                "link": "https://medium.com/mlops-community/how-to-evaluate-mlops-platforms-c98cf7874cca",
                "content": "How to Evaluate MLOps Tools Thoughtworks Principal Data Consultant Ryan Dawson has put together a conceptual framework for practitioners to navigate the MLOps ecosystem and evaluate key platforms for each of the different phases of the end to end MLOps lifecycle."
            },
            {
                "title": "The State of Graph ML in 2022",
                "link": "http://towardsdatascience.com/graph-ml-in-2022-where-are-we-now-f7f8242599e0",
                "content": "The State of Graph ML in 2022 Last year was quite a year for Graph ML with thousands of papers, numerous conferences and workshops, and to navigate the great range of content produced, this article provides a great overview of the state of graph ML in 2022 covering a range of key topics as well as tips to stay updated."
            },
            {
                "title": "Deep Learning Interview Prep",
                "link": "https://arxiv.org/abs/2201.00650",
                "content": "Deep Learning Interview Prep An absolutely fantastic effort that has brought together hundreds of fully solved job interview questions from a wide range of key topics in AI. This is one of the best resources out there for AI practitioners to lean on for interview prep."
            }
        ]
    },
    {
        "issue": "161",
        "items": [
            {
                "title": "Principles for Responsible AI",
                "link": "http://venturebeat.com/2022/01/14/4-principles-for-responsible-ai/",
                "content": "Principles for Responsible AI Our VentureBeat article on Responsible AI is now live \ud83d\ude80 AI will become ubiquitous over the next decade and like any technology, it poses personal, societal, and economic risks. In this article we dive into some of the principles from The Institute for Ethical AI & Machine Learning that ensure the responsible development, design and operation of AI systems."
            },
            {
                "title": "Google Research ML Themes",
                "link": "http://ai.googleblog.com/2022/01/google-research-themes-from-2021-and.html?m=1",
                "content": "Google Research ML Themes The Google Research team has published an overview of the key research themes at Google from 2021 and beyond, covering general-purpose ML models, efficiency improvements, growing benefits, and deeper understanding."
            },
            {
                "title": "Introduction to Explainable ML",
                "link": "http://docs.seldon.io/projects/alibi/en/latest/overview/high_level.html",
                "content": "Introduction to Explainable ML The team behind the Alibi Explain project has put together a comprehensive introducion and deep dive into the key concepts of explainability in machine learning, including intuition, background, examples and relevant references."
            },
            {
                "title": "ML Architectures from Industry",
                "link": "http://towardsdatascience.com/serve-hundreds-to-thousands-of-ml-models-architectures-from-industry-bf3d9474d427",
                "content": "ML Architectures from Industry An interesting exploration across the growing number of architectures from leading tech giants on production machine learning systems, diving into common patterns, components across the ML lifecycle, requirements for massive scale and more."
            },
            {
                "title": "Validation & Testing of ML Models",
                "link": "https://medium.com/@ptannor/new-open-source-for-validating-and-testing-machine-learning-86bb9c575e71",
                "content": "Validation & Testing of ML Models As part of the continued trend of software engienering best practices making it to the machine learning lifecycle, this interesting article provides a practical overview on how to introduce robust validation and testing to the machine learning lifecycle leveraging the Deepchecks tooling."
            }
        ]
    },
    {
        "issue": "162",
        "items": [
            {
                "title": "MLOps Meetup Online this Week",
                "link": "https://www.meetup.com/mlopslondon/events/282604634/",
                "content": "MLOps Meetup Online this Week The MLOps London meetup comes back this week with a fully online edition bringing together insights from FuzzyLabs Cofounder Matt Squire and Trainline Principal Data Scientist Jan Teichmann to share knowledge on various practical production MLOps topics."
            },
            {
                "title": "Architecture Series for MLOps",
                "link": "https://fractaldle.medium.com/mlops-series-ai-engineering-with-opensource-tools-aks-part1-cb6914ee7688",
                "content": "Architecture Series for MLOps An interesting practical tutorial series that provides hands on insights on production architectures for MLOps, specifically focusing on the feature extraction, process management, serving infrastructure and monitoring phases of the ML lifecycle with a practical use-case."
            },
            {
                "title": "Testing Approach in Data Science",
                "link": "http://www.peterbaumgartner.com/blog/testing-for-data-science/",
                "content": "Testing Approach in Data Science A hands on article convering an interesting perspective into the software engineering best practices of unit testing applied into data science, covering a set of practical examples."
            },
            {
                "title": "A Gentle Intro to Shapley Values",
                "link": "http://www.h2o.ai/blog/shapley-values-a-gentle-introduction/",
                "content": "A Gentle Intro to Shapley Values The H2O team has put together a comprehensive overview into one of the more popular methods in the machine learning explainability space, namely shapley values, together with a set of examples into how these values can be calculated for a feature."
            },
            {
                "title": "Kubernetes the Documentary",
                "link": "https://www.youtube.com/watch?v=BE77h7dmoQU",
                "content": "Kubernetes the Documentary A recently released documentary which covers the history of Kubernetes and container applications - this is the first part of an upcoming series of episodes."
            }
        ]
    },
    {
        "issue": "163",
        "items": [
            {
                "title": "CI/CD for Prod ML at Scale Event",
                "link": "https://www.linkedin.com/events/aci-cdframeworkforproductionmac6886695103981727744/about/",
                "content": "CI/CD for Prod ML at Scale Event IEML Chief Scientist & Seldon Engineering Director Alejandro Saucedo is covering best practices, architectural patterns and practical examples of continuous integration/delivery for production machine larning at massive scale, enabling for thousands of models in Kubernetes."
            },
            {
                "title": "Machine Learning at Discord",
                "link": "http://thedataexchange.media/machine-learning-at-discord/",
                "content": "Machine Learning at Discord The Data Exchange podcast comes back this week to dive into conversation with Discord Senior Machine Learning Engineering Manager Gaurav Chakravorty to share insights on building industrial grade machine learning systems for search, recommenders, and personalization systems at Discord."
            },
            {
                "title": "Kubernetes the Documentary Pt.2",
                "link": "https://www.youtube.com/watch?v=318elIq37PE",
                "content": "Kubernetes the Documentary Pt.2 The second part of the positively received Kubernetes documentary is out. A fantastic overview of the history and principles behind this successful open source orchestration framework which is increasingly adopted in the MLOps space, diving into fascinating insights on relationships and tensions with Mesos, Docker, CentOS and beyond."
            },
            {
                "title": "Open Source MLOps E2e Stacks",
                "link": "http://fuzzylabs.ai/blog/open-source-mlops-is-awesome/",
                "content": "Open Source MLOps E2e Stacks Fuzzylabs Cofounder Matt Squire joined the MLOps London Meetup last week to cover their version of their canonical stack for MLOps, covering key OSS projects including DVC, Sacred, ZenML, Seldon Core and Evidently."
            },
            {
                "title": "ML Algorithms Cheat Sheet",
                "link": "https://medium.com/accel-ai/machine-learning-algorithms-cheat-sheet-990104aaaabc",
                "content": "ML Algorithms Cheat Sheet A great resource that aims to provide a high level cheatsheet for a broad range of machine learning algorithms, together with a visual grouping that allows for fast lookup for refrence."
            }
        ]
    },
    {
        "issue": "164",
        "items": [
            {
                "title": "DeepMind AI Developer AlphaCode",
                "link": "http://deepmind.com/blog/article/Competitive-programming-with-AlphaCode",
                "content": "DeepMind AI Dev AlphaCode Absolutely fascinating project from DeepMind that shows promising results for an AI based system that is able to tackle programming/algorithmic challenges. The article provides fascinating insights together with even attention visualisation of the algorithm itself as it tackles a specific challenge description."
            },
            {
                "title": "Databases 2022 Year in Review",
                "link": "http://ottertune.com/blog/2021-databases-retrospective/",
                "content": "Databases 2022 Year in Review A great resource that provides a comprehensive overview of the state of databses in 2021, showing key insights including the dominance of Postgres, benchmarking competition, increasing revenues, failings and more."
            },
            {
                "title": "Evolving Notebook Infra at Twitter",
                "link": "https://blog.twitter.com/engineering/en_us/topics/infrastructure/2021/advancing-jupyter-notebooks-at-twitter---part-1--a-first-class-d",
                "content": "Evolving Notebook Infra at Twitter A great article from Twitter Engineering providing an insight into the evolution of Jupyter Notebook infrastructure at scale, including some of their challenges, tooling, features, infrastructure, security, data sources, and what\u2019s next."
            },
            {
                "title": "Doordash Feature Eng System",
                "link": "http://doordash.engineering/2022/01/11/introducing-fabricator-a-declarative-feature-engineering-framework/",
                "content": "Doordash Feature Eng System Feature engineering is a growingly critical requirements in the MLOps lifecycle - Doordash engineering presents their internal system \u201cFabricator\u201d. In this article they provide an architectural and conceptual overview of their system, together with their requirements, data & control planes, features, examples, limitations, and future developments."
            },
            {
                "title": "O\u2019Reilly on Causal Inference",
                "link": "https://www.oreilly.com/radar/what-is-causal-inference/",
                "content": "O\u2019Reilly on Causal Inference The AI O\u2019Reilly team has put together a great introduction into Causal Inference, where they provide a high level overview, together with useful resources, as well as insights across a broad range of sub-fields."
            }
        ]
    },
    {
        "issue": "165",
        "items": [
            {
                "title": "Evolution of AI Ethics Meetup",
                "link": "https://www.meetup.com/Tech-Ethics-London/events/282563396",
                "content": "Evolution of AI Ethics Meetup The AI Ethics Meetup comes back with an online event where \u201cMachine Ethics Podcast\u201d founder shares his thoughts reflecting on 6 years of running the podcast, providing insights around how the conversation and ecosystem has evolved throughout."
            },
            {
                "title": "Distribution Shifts and Monitoring",
                "link": "http://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html",
                "content": "Distribution Shifts and Monitoring ML Streaming Platform founder Chip Huyen has put together a fantastic resource which is part of the new Stanford course on Machine Learning Systems Design focusing on data distribution shifts and relevant monitoring themes."
            },
            {
                "title": "O\u2019Reilly Radar Trends Feb 2022",
                "link": "https://www.oreilly.com/radar/radar-trends-to-watch-february-2022/",
                "content": "O\u2019Reilly Radar Trends Feb 2022 The O\u2019Reilly team has put together a fantastic summary of key trends and developments for the start of the year, covering Machine Learning, general development, security, automation, infrastructure and more."
            },
            {
                "title": "Overview of MLOps Definition",
                "link": "http://learn.layer.ai/what-is-mlops/",
                "content": "Overview of MLOps Definition As the field of MLOps continues to mature, so does its definition. This article provides a great revisit to the term of MLOps including the sub-themes it encompasses, as well as a definition and examples of each of these."
            },
            {
                "title": "Millions of Messages with Kafka",
                "link": "https://medium.com/yotpoengineering/scheduling-millions-of-messages-with-kafka-debezium-6d1a105160c",
                "content": "Millions of Messages with Kafka Yotpo Tech Leader Elia Rohana has put together an interesting piece summarising lessons learned building scalable real time infrastructure for large scale data and events processing, including the architectural details and some of the frameworks that were explored and then used."
            }
        ]
    },
    {
        "issue": "166",
        "items": [
            {
                "title": "Data Scientists and Kubernetes",
                "link": "http://outerbounds.com/blog/kubernetes-to-metaflow/",
                "content": "Data Scientists and Kubernetes The relatively new startup behind the Metaflow Open Source project has put together a fantastic introduction as well as hands on examples that reflect the principle \u201cData Scientists Don\u2019t Need to Know Kubernetes with Metaflow\u201d."
            },
            {
                "title": "Cross Vendor GPU Acceleration",
                "link": "https://www.youtube.com/watch?v=DBcXrJtJaIQ",
                "content": "Cross Vendor GPU Acceleration Our CppCon2021 talk is out and has been gathering momentum in the C++ community, covering best practices for GPU acceleration across cross-vendor GPUs using Vulkan and the Kompute project, as well as hands on examples for ML and low-level optimizations."
            },
            {
                "title": "Open Python ML Inference Server",
                "link": "http://www.seldon.io/introducing-mlserver/",
                "content": "Open Python ML Inference Server The team at Seldon has announced the 1.0 release of an ML inference server that focuses on Python based models, providing extendable runtimes to create reusable runtimes, and key features such as MLFlow integration, multiprocessing, adaptive batching + more."
            },
            {
                "title": "Building ML Infra at Netflix",
                "link": "http://thedataexchange.media/building-machine-learning-infrastructure-at-netflix-and-beyond/",
                "content": "Building ML Infra at Netflix The Data Exchange podcast dives into conversation with Outerbounds Co-founder Savin Goyal to discuss about his previous work at Netflix led into the open sourcing of Metaflow, a framework to adddress challenges of data science around version control and scalability."
            },
            {
                "title": "Interpretable Machine Learning",
                "link": "http://queue.acm.org/detail.cfm?id=3511299",
                "content": "Interpretable Machine Learning A fantsatic resource on interpretable machine learning which dives into a robust taxonomy for explainability related terms, as well as a deep dive into the current state of the ecosystem."
            }
        ]
    },
    {
        "issue": "167",
        "items": [
            {
                "title": "ML Monitoring with Outliers & Drift",
                "link": "https://www.linkedin.com/events/6890258691988545536/about/",
                "content": "ML Monitoring with Outliers & Drift The lifecycle of a machine learning model only begins once it\u2019s in production. This week Seldon Engineering Director & IEML Chief Scientist Alejandro Saucedo will be giving a live webinar on production machine learning monitoring covering how to introduce operational and data science monitoring (outliers & drift) at scale."
            },
            {
                "title": "Netflix Infra Systems Design",
                "link": "http://highscalability.com/blog/2021/12/13/designing-netflix.html",
                "content": "Netflix Infra Systems Design Systems Design skills are key for ML & MLOps engineers; in this article Amazon Senior ML Engineer covers in detail a systems design interview type question covering an approach to explore the question of designing the infrastructure behind Netflix from scratch, covering the requirements gathering, design, technical considerations, APIs, etc."
            },
            {
                "title": "Building Infrastructure Platforms",
                "link": "http://martinfowler.com/articles/building-infrastructure-platform.html",
                "content": "Building Infrastructure Platforms Thoughtworks Engineering has put together a comprehensive overview that explores the challenge of developing infrastructure platforms through 7 key principles that identify key important areas that allow for teams to focus on building on functionality that will bring value to the ultimate users."
            },
            {
                "title": "Uber Orbit Bayesian ML Platform",
                "link": "http://eng.uber.com/the-new-version-of-orbit-v1-1-is-released/",
                "content": "Uber Orbit Bayesian ML Platform Uber Engineering has put together an overview of Orbit, their Bayesian time-series analysis and forecasting library. In this article they cover some of the key features as well as provide insights on how Uber built an internal platform to productise their user-base workflows across their organisation."
            },
            {
                "title": "The State of ML in JuliaLang",
                "link": "http://discourse.julialang.org/t/state-of-machine-learning-in-julia/74385",
                "content": "The State of ML in JuliaLang A very interesting discussion in the Julia community forum providing insights on the state of machine learning in the Julia language, diving into various key questions that highlight some of the key achievements, opportunities and gaps."
            }
        ]
    },
    {
        "issue": "168",
        "items": [
            {
                "title": "Kompute Promoted to Incubation",
                "link": "http://lfaidata.foundation/blog/2022/03/01/lf-ai-data-foundation-announces-the-promotion-of-kompute-project-into-incubation/",
                "content": "Kompute Promoted to Incubation Kompute is promoted to Incubation level at the Linux Foundation \ud83d\ude80 Kompute is an open source project that enables developers to introduce GPU acceleration to their projects across 1000s of cross-vendor GPUs (NVIDIA, AMD, Qualcomm & Friends) for machine learning and advanced data processing use-cases. This reflects the matury and adoption of Kompute across the OSS community."
            },
            {
                "title": "Modern C++ Computer Vision",
                "link": "http://www.ipb.uni-bonn.de/teaching/cpp-2020/",
                "content": "Modern C++ Computer Vision The University of Bonn has released a fantstic resource for practitioners to learn\u00a0Modern C++ for Computer Vision covering key foundational and advanced concepts through 10 video lectures, including build tools, core libraries, programming concepts, memory management and hands on projects."
            },
            {
                "title": "Another Road to MLOps Mastery",
                "link": "http://suhas.org/posts/mlops-2022/",
                "content": "Another Road to MLOps Mastery Another useful resource from the MLOps community that provides a suggested set of resources that can be used for progressive learning to build a deeper understanding on core MLOps concepts and best practices."
            },
            {
                "title": "Extending Kubernetes for MLOps",
                "link": "http://www.information-age.com/how-kubernetes-extends-machine-learning-ml-123492360/",
                "content": "Extending Kubernetes for MLOps This article provides insights from various practitioners and technology leaders in the machine learning space on how Kubernetes is currently being used and extended to support the key funcionalities required for production-grade machine learning at scale."
            },
            {
                "title": "Airflow Unbundling ETL at Scale",
                "link": "https://blog.fal.ai/the-unbundling-of-airflow-2/",
                "content": "Airflow Unbundling ETL at Scale An interesting article that explores the architectural and practical challenges that rise when adopting ETL at scale, and covers the way they introduced some solution such as delegating processing into 3rd party systems for relevant processing."
            }
        ]
    },
    {
        "issue": "169",
        "items": [
            {
                "title": "The Future of AI Infrastructure",
                "link": "http://sapphireventures.com/blog/the-future-of-ai-infrastructure-is-becoming-modular/",
                "content": "The Future of AI Infrastructure An interesting strategic market analysis of the MLOps ecosystem from a VC firm that proposes that the current trend for technologies is from the e2e platforms towards the best-of-breed open core and SaaS products."
            },
            {
                "title": "Radar Trends to Watch March",
                "link": "https://www.oreilly.com/radar/radar-trends-to-watch-march-2022/",
                "content": "Radar Trends to Watch March The O\u2019Reilly team has once again put together a fantastic compilation of key trends across various areas of the technology space, including AI, programming, security, web and much more."
            },
            {
                "title": "Cloud Resources for DL Training",
                "link": "https://www.cncf.io/blog/2022/02/15/managing-public-cloud-resources-for-deep-learning-training-experiments-and-lessons-learned/",
                "content": "Cloud Resources for DL Training An interesting article outlining key insights and lessons learned from applying kubernetes architectural patterns into the domain of declarative and distrbuted deep learning model training, enabling for elastic infrastructure scaling for AutoML in an automated manner."
            },
            {
                "title": "Google NLP Model for Everything",
                "link": "http://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html",
                "content": "Google NLP Model for Everything An interesting paper from Google showcasing their most recent multi-domain language model which aims to provide for a variety of tasks including translation, summarisation, question answering and more, whilst aiming to abide by higher level Responsible AI principles."
            },
            {
                "title": "Cloud Security Themes for 2022",
                "link": "http://www.battery.com/blog/from-code-to-cloud/",
                "content": "Cloud Security Themes for 2022 This article provides a high level overview as well as a set of key trends for the cloud security ecosystem in 2022, ranging across the development stack, remediation processes, pipelines, security resources and even machine learning."
            }
        ]
    },
    {
        "issue": "170",
        "items": [
            {
                "title": "MLOps Virtual & Online Talks",
                "link": "https://www.meetup.com/mlopslondon/events/283523195/",
                "content": "MLOps Virtual & Online Talks The London MLOps meetup comes back this week with two fantastic talks from TolokaAI and MeshAI, and will be delivered by experienced practitioners in the production machine learning operations space. Join us this Tuesday in-person in London or virtually through he livestream."
            },
            {
                "title": "Karpathy\u2019s Deep Learning Retro",
                "link": "https://karpathy.github.io/2022/03/14/lecun1989/",
                "content": "Karpathy\u2019s Deep Learning Retro Fascinating article from Andrej Karpathy where he attempts to reproduce Yann LeCun\u2019s 1989 paper on backprop, achieving a 90 second training on a modern laptop compared to the many days it took back then, sharing a lot of interesting retrospective insights on machine learning then and now."
            },
            {
                "title": "Stanford 2022 AI Index Report",
                "link": "http://hai.stanford.edu/research/ai-index-2022",
                "content": "Stanford 2022 AI Index Report The annual AI Index Report from Stanford University\u2019s Human Centered Artificial Intelligence lab has come out. A lot of fantastic insights, including investments in the AI space doubling to $93b+ and counting, as well as interesting geopolitical, technological and societal trends."
            },
            {
                "title": "Microsoft ML Microservices at Scale",
                "link": "https://www.microsoft.com/en-us/research/publication/large-scale-services/",
                "content": "Microsoft ML Microservice Scale An interesting effort from Microsoft Research showcasing how they have tackled the chalenge of varied computational footprints of modern ML algorithms when reaching large scale for data processing, namely through a microservice-based service architecture running in spark-based infrastructure, shocasing benchmarks and practical applications."
            },
            {
                "title": "Kubernetes the Hard Way Course",
                "link": "https://github.com/kelseyhightower/kubernetes-the-hard-way",
                "content": "Kubernetes the Hard Way Course A fantastic and growingly popular resource for practitioners to learn the foundations and best practices of all-things-kubernetes with a hands on tutorial, which is recommended for anyone intrested to learn about the internals of kubernetes beyond the application and use of this powerful framework."
            }
        ]
    },
    {
        "issue": "171",
        "items": [
            {
                "title": "Machine Learning Youtube List",
                "link": "https://github.com/dair-ai/ML-YouTube-Courses",
                "content": "Machine Learning Youtube List A fantastic resource providing an extensive list of freely available educational courses and videos in youtube related to various applied and theorietical topics in the machine learning space."
            },
            {
                "title": "Data Management Trends 2022",
                "link": "http://gradientflow.com/data-management-trends-you-need-to-know",
                "content": "Data Management Trends 2022 This article provides great insights on key trends in the data management space, including growing trends on open source, cloud, SaaS, serverless, and more."
            },
            {
                "title": "Ultimate Guide to Text Similarity",
                "link": "http://newscatcherapi.com/blog/ultimate-guide-to-text-similarity-with-python",
                "content": "Ultimate Guide to Text Similarity An extensive and comprehensive overview of different similarity metrics and texte embedding techniques with both practical and intuitive examples in python that can be implemented in real world NLP projects."
            },
            {
                "title": "OpenTelemetry and Python",
                "link": "http://www.timescale.com/blog/opentelemetry-and-python-a-complete-instrumentation-guide/",
                "content": "OpenTelemetry and Python OpenTelemetry has been growing with the potential to become the future of instrumentation, which is growingly important in the MLOps space to ensure robust observability infrastructure and techniques can be used in production machine learning at scale."
            },
            {
                "title": "Lessons Learned from 10y OSS",
                "link": "https://medium.com/@micallst/lessons-learned-from-my-10-year-open-source-project-4a4c8c2b4f64",
                "content": "Lessons Learned from 10y OSS An insightful article sharing lessons learned and insights from building, extending and maintaining a successful and popular open sourcee project through various phases of the project lifecycle."
            }
        ]
    },
    {
        "issue": "172",
        "items": [
            {
                "title": "Secure ML with MLSecOps",
                "link": "https://www.linkedin.com/events/securemachinelearningatscalewit6915232278545612800/",
                "content": "Secure ML with MLSecOps The operation and maintenance of large scale production machine learning systems has uncovered new challenges in the intersection of machine learning and security. This session will cover practical and conceptual insights related to challenges and solutions to ensure secure machine learning systems at scale."
            },
            {
                "title": "The State of Data Engineering",
                "link": "https://gradientflow.com/the-data-integration-market/",
                "content": "The State of Data Engineering As exciting as the MLOps space is, a lot of key challenges in scaling ML systems still lie at the Data Engineering systems and operations; this article covers great insights and trends on the state of data engineering."
            },
            {
                "title": "Doordash Declarative Fabricator",
                "link": "https://doordash.engineering/2022/01/11/introducing-fabricator-a-declarative-feature-engineering-framework/",
                "content": "Doordash Declarative Fabricator DoorDash shares how they tackled some of their machine learning challenges at scale through a declarative ML framework, in this article they cover the motivations, challenges, concepts and lessons learned."
            },
            {
                "title": "Google Brain Distributed Flow ML",
                "link": "https://arxiv.org/abs/2203.12533",
                "content": "Google Brain Distributed Flow ML Interesting research from Google Brain on dataflow architectures for distributed training in machine learning, showcasing the advantages optimizing for hardware utilization compared to the more traditional push (MPI) architectures."
            },
            {
                "title": "Hashicorp from CEO to Tech IC",
                "link": "https://stackoverflow.blog/2022/02/04/moving-from-ceo-back-to-ic-a-chat-with-mitchell-hashimoto-on-his-love-for-code-ep-412/",
                "content": "Hashicorp from CEO to Tech IC Hashicorp CEO Mitchell Hashimoto joins the Stackoverflow podcast to share insights on how he has been making the shift back to technical roots as technical contributor to once again support on spearheading innovations."
            }
        ]
    },
    {
        "issue": "173",
        "items": [
            {
                "title": "Linkedin\u2019s Explainable AI RecSys",
                "link": "https://engineering.linkedin.com/blog/2022/the-journey-to-build-an-explainable-ai-driven-recommendation-sys",
                "content": "Linkedin\u2019s Explainable AI RecSys A really insightful article showcasing how they approached the design, development and productionisation of an explainable AI recommendation system to help them scale sales efficiency across the Linkedin organisation."
            },
            {
                "title": "Google\u2019s AI Autogen Summary",
                "link": "http://ai.googleblog.com/2022/03/auto-generated-summaries-in-google-docs.html",
                "content": "Google\u2019s AI Autogen Summary The Google AI team explains how they tackled text summarisation for Google docs using machine learning, discussing key insights from the data, model training and even MLOps infrastructure for serving to productionise these machine learning capabilities."
            },
            {
                "title": "OpenAI\u2019s Text to Image Model",
                "link": "https://openai.com/dall-e-2/",
                "content": "OpenAI\u2019s Text to Image Model The team at OpenAI launches the updated version of their DALL-E model which generates realistic images from text - this has sparked fascinated examples with creative portraits of animals, dinosaurs and more random creative images."
            },
            {
                "title": "Wisdom from 50+ Years of Code",
                "link": "http://changelog.com/podcast/484",
                "content": "Wisdom from 50+ Years of Code An interesting with software development pioneer Brian Kerninghan, who shares great insights learned throughout his 50+ years of programming since the early days of Unix in Bell Labs, covering programming languages like C, Rust, Go and beyond."
            },
            {
                "title": "Continuous Intelligence at Scale",
                "link": "http://thedataexchange.media/delivering-continuous-intelligence-at-scale/",
                "content": "Continuous Intelligence at Scale The Data Exchange podcast comes back with another great conversation on distributed data infrastructure for analysis, learning and predictions in real time."
            }
        ]
    },
    {
        "issue": "174",
        "items": [
            {
                "title": "Spotify Semantic AI for Podcasts",
                "link": "http://www.pinecone.io/learn/spotify-podcast-search/",
                "content": "Spotify Semantic AI for Podcasts A very comprehensive and intuitive explanation of how spotify uses semantic search for podcasts, providing visual and conceptual overviews, as well as hands on code to showcase some of the interesting and practical aspects."
            },
            {
                "title": "Microsoft on Data Drift at Scale",
                "link": "https://www.microsoft.com/en-us/research/publication/matchmaker-data-drift-mitigation-in-machine-learning-for-large-scale-systemsmatchmaker-data-drift-mitigation-in-machine-learning-for-large-scale-systems/",
                "content": "Microsoft on Data Drift at Scale The team at Microsoft has put together an interesting research paper that explores the challenges for data drift in production ML systems at scale. They propose a new solution that suggests to tackle the challenges with flexibility and scale by design."
            },
            {
                "title": "ZenML E2E Deployment Seldon",
                "link": "https://github.com/zenml-io/zenml/tree/main/examples/seldon_deployment",
                "content": "ZenML E2E Deployment Seldon The ZenML team has put together a fantastic overview deploying machine learning models end to end through their new integration with Seldon Core. They showcase the hands on steps to deploy a FashionMNIST model into an EKS kubernetes cluster through a programmatic Kubeflow pipeline."
            },
            {
                "title": "Borg, Omega and Kubernetes",
                "link": "http://queue.acm.org/detail.cfm?id=2898444",
                "content": "Borg, Omega and Kubernetes A really insightful article by various thought leaders in the container orchestration space, where they discuss some lessons learned from three widely known container scheduling systems including Borg, Omega and the now widely adopted and fast growing Kubernetes."
            },
            {
                "title": "The Annual 2022 AI Index",
                "link": "http://thedataexchange.media/the-2022-ai-index/",
                "content": "The Annual 2022 AI Index The Data Exchange podcast dives into conversation with Jack Clark on their recent published annual AI Index report. In this episode they cover recent progress in Deep Learning, the raise of AI ethics, and what lies ahead of language models."
            }
        ]
    },
    {
        "issue": "175",
        "items": [
            {
                "title": "Prod ML + Security = MLSecOps",
                "link": "https://www.linkedin.com/events/securemachinelearningatscalewit6915232278545612800/",
                "content": "Prod ML + Security = MLSecOps Join us for this hands on online session where we\u2019ll dive into the top security vulnerabilities present at every stage of the ML lifecycle throught practical \u201cFlawed ML Security\u201d examples, as well as cover hands on MLSecOps best practices to address them at scale."
            },
            {
                "title": "MLOps in Food Delivery at Wolt",
                "link": "http://blog.wolt.com/engineering/2022/04/20/machine-learning-at-wolt-our-journey-towards-mlops/",
                "content": "MLOps in Food Delivery at Wolt An interesting article from food delivery service Wolt showcasing their journey developing and scaling MLOps across their organisation, including concepts, lessons learned, challenges, and interesting insights throughout the various lifecycle phases of production ML."
            },
            {
                "title": "OpenAI Davinci Building Games",
                "link": "https://andrewmayneblog.wordpress.com/2022/03/17/building-games-and-apps-entirely-through-natural-language-using-openais-davinci-code-model/",
                "content": "OpenAI Davinci Building Games A mind blowing overview of applications of OpenAI\u2019s code generation model. This post provides some examples of how this model has been used to generate games from text counterparts, which are quite astonishing as they can also be tested interactively thorugh the codepen examples."
            },
            {
                "title": "AI in 2021 GitLab Devops Survey",
                "link": "https://about.gitlab.com/developer-survey/",
                "content": "AI in 2021 GitLab Devops Survey The developer survey from GitLab has been released with very interesting insights on the Devops ecosystem. This year\u2019s edition provides particularly interesting insights on the rise of AI/ML in devops as well as vice-versa, including relevant trends and metrics."
            },
            {
                "title": "C is Not a Language Anymore",
                "link": "https://gankra.github.io/blah/c-isnt-a-language/",
                "content": "C is Not a Language Anymore As we celebrate the 50th anniversary of the C programming language, this post covers very insightful perspectives on how C has evolved from a programming language into a cross-industry standardised protocol adopted globally, covering resources, examples and concepts that outline its shortcomings and impact."
            }
        ]
    },
    {
        "issue": "176",
        "items": [
            {
                "title": "Monzo\u2019s Machine Learning Stack",
                "link": "https://monzo.com/blog/2022/04/26/monzos-machine-learning-stack",
                "content": "Monzo\u2019s Machine Learning Stack A fantastic overview of Monzo\u2019s machine learning stack, covering some of their initial principles, architectural overviews, and deep dives on each major component that covers different areas of the ML lifecycle, which allow them to power the ML systems behind their financial products."
            },
            {
                "title": "Real World RecSys that Scales",
                "link": "http://blog.fennel.ai/p/real-world-recommendation-system",
                "content": "Real World RecSys that Scales A very insighftul and practical series that cover key architecture considerations for recommender systems at scale, including paradigms, ML algorithms, libraries, data management, features, serving systems, deployment systems, hardware and beyond."
            },
            {
                "title": "MLOps London Meetup May",
                "link": "https://www.meetup.com/mlopslondon/events/285056845/",
                "content": "MLOps London Meetup May The MLOps meetup comes back this month with key insights in the MLOps space, this time the sessions will dive into production grade feature-stores, as well as best practices for machine learning security at scale."
            },
            {
                "title": "Human-Centric MLOps in K8s",
                "link": "http://outerbounds.com/blog/human-centric-data-science-on-kubernetes-with-metaflow/",
                "content": "Human-Centric MLOps in K8s The team behind the Metaflow project has put together an overview of their most recent development expanding this intuitive MLOps library to work with Kubernetes at scale. In this article they provide insights on the motivations, historical context, and intuition on underlying infrastructure."
            },
            {
                "title": "Rethink interviews for Great Devs",
                "link": "http://freakingrectangle.com/2022/04/15/how-to-freaking-hire-great-developers/",
                "content": "Rethink interviews for Great Devs An insightful opinion that advocates for a growingly adopted method to find good senior software practitioners that goes beyond the algorithmic tests, namely understanding their capabilities in the areas that are relevant to the day-to-day such as reading and understanding code."
            }
        ]
    },
    {
        "issue": "177",
        "items": [
            {
                "title": "MLOps London Meetup May",
                "link": "https://www.meetup.com/mlopslondon/events/285056845/",
                "content": "MLOps London Meetup May The MLOps meetup comes back this week with key insights in the MLOps space, this time the sessions will dive into production grade feature-stores, as well as best practices for machine learning security at scale."
            },
            {
                "title": "End-to-end Open Source MLOps",
                "link": "https://medium.com/@omolade/an-end-to-end-mlops-platform-implementation-using-open-source-tooling-110948bb49b4",
                "content": "End-to-end Open Source MLOps A fantastic practical deep dive into building an end to end MLOps pipeline, covering the various phases of the machine learning lifecycle using a broad range of machine learning libraries. This article covers the conceptual, architectural and practical aspects."
            },
            {
                "title": "Machine Learning at Discord",
                "link": "http://thedataexchange.media/machine-learning-at-discord/",
                "content": "Machine Learning at Discord The Data Exchange podcast comes back this week with an insightful conversation with Discord ML Leader Gaurav Chakravorty on building industrial grade machine learning systems for search, recommenders, and personalization systems."
            },
            {
                "title": "Faceboook\u2019s 175B Model Release",
                "link": "http://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/",
                "content": "Faceboook\u2019s 175B Model Release The AI team at Facebook has provided access to large-scale language models, sharing their release of the Open Pretrained Transformer (OPT) 175 Billion parameter model, as well as some of their plans to continue contributing to open research resources."
            },
            {
                "title": "Running Kubernetes in Production",
                "link": "http://betterprogramming.pub/6-important-things-you-need-to-run-kubernetes-in-production-d573d61258c5",
                "content": "Running Kubernetes in Production A great practical summary of key important areas to consider when running Kubernetes in production, as this tool becomes more ubiquitous in the MLOps space it\u2019s always key to ensure runtime infra is following best practice."
            }
        ]
    },
    {
        "issue": "178",
        "items": [
            {
                "title": "Enterprise Declarative ML System",
                "link": "https://medium.com/predibase/introducing-predibase-the-enterprise-declarative-machine-learning-platform-10e2a388d465",
                "content": "Enterprise Declarative ML System The team behind the OSS declarative ML framework Ludwig has launched an enterprise platform with an insightful article that covers some of the motivations, features and plans to grow their success in the open core space."
            },
            {
                "title": "DeepMind\u2019s Generalist Agent",
                "link": "http://www.deepmind.com/publications/a-generalist-agent",
                "content": "DeepMind\u2019s Generalist Agent The DeepMind team has released an interesting new large model under the name \u201cGato\u201d which is claimed to provide multi-modal, multi-task, multi-embodiment capabilities. In this article they provide some of the context, concepts and resources for this new large model."
            },
            {
                "title": "Alibaba Scale Recommenders",
                "link": "https://arxiv.org/abs/1803.02349",
                "content": "Alibaba Scale Recommenders An interesting overview of Alibaba\u2019s production machine learning system architecture and approach to recommendations at massive-scale, including some of the underlying techniques as well as systems design for powering recommendations at scale."
            },
            {
                "title": "Product Success DS Guide",
                "link": "https://shopifyengineering.myshopify.com/blogs/engineering/a-data-scientist-s-guide-to-measuring-product-success",
                "content": "Product Success DS Guide A practical guide from Shopify on data science techniques for measuring product success metrics, covering best practices, practical approaches and key takeaways."
            },
            {
                "title": "Transformers from Scratch",
                "link": "http://e2eml.school/transformers.html",
                "content": "Transformers from Scratch A comprehensive end to end guide that covers the concept of transformers from scratch, building on the foundational concepts towards transformers in machine learning."
            }
        ]
    },
    {
        "issue": "179",
        "items": [
            {
                "title": "PyCon Machine Learning Security",
                "link": "https://www.youtube.com/watch?v=82uiA5evtyU",
                "content": "PyCon Machine Learning Security The video for our talk on Machine Learning Security at PyCon & PyData Berlin 2022 is now live \ud83d\ude80 In this resource we cover a hands on overview of key security considerations at every stage of the machine learning model lifecycle."
            },
            {
                "title": "Approaching (Almost) all ML Book",
                "link": "https://github.com/abhishekkrthakur/approachingalmost",
                "content": "Approaching (Almost) all ML Book A fantastic and vastly comprehensive resources that provides best practices and foundational practical concepts that allow practitioners to tackle, as the book says, almost any machine learning problem."
            },
            {
                "title": "Airbnb\u2019s Microservice Architecture",
                "link": "https://medium.com/qe-unit/airbnbs-microservices-architecture-journey-to-quality-engineering-d5a490e6ba4f",
                "content": "Airbnb\u2019s Microservice Architecture An interesting resource from the airbnb engineering team sharing their key insights, concepts abd general learnings throughout their microservices architecture journey to quality engineering at AirBnb."
            },
            {
                "title": "Image Outlier Detection Tutorial",
                "link": "https://www.youtube.com/watch?app=desktop&v=Pql6ShORpNU&feature=youtu.be",
                "content": "Image Outlier Detection Tutorial Great resource from covering key concepts in image outlier detection, together with practical examples to perform detection of anomalies in image datasets using the alibi detect open source library."
            },
            {
                "title": "The HackerNews Algo Internals",
                "link": "https://medium.com/hacking-and-gonzo/how-hacker-news-ranking-algorithm-works-1d9b0cf2c08d",
                "content": "The HackerNews Algo Internals This article provides some interesting insights on the core concepts behind the hacker-news ranking algorithm, with key practical tips that allow practitioners to re-use in their own applications."
            }
        ]
    },
    {
        "issue": "180",
        "items": [
            {
                "title": "Netflix end-to-end MLOps System",
                "link": "http://netflixtechblog.com/evolution-of-ml-fact-store-5941d3231762",
                "content": "Netflix end-to-end MLOps System Feature stores have become a growingly popular topic in the MLOps space. Netflix engineering provides great insights on how they have built and evolved their feature store engines, together with architectural deep dives as well as lessons learned."
            },
            {
                "title": "Pick&Choose MyMLOps Stack",
                "link": "http://mymlops.com/",
                "content": "Pick&Choose MyMLOps Stack MLOps can be overwhelming; especially due to the sheer number of tools available in every stage of the ML model lifecycle. This\u00a0 initiative addresses this by providing a webapp to allow practitioners to experiment with different architectures considering different tools for their e2e MLOps requirements interactively."
            },
            {
                "title": "How to Avoid Pitfalls of MLOps",
                "link": "http://blog.zenml.io/zenml-mlops-framework/",
                "content": "How to Avoid Pitfalls of MLOps The MLOps journey is full of risks and pitfalls due to being an emerging field where best practices are still being defined. The ZenML team has put together a great overview of some of these challenges as well as best practices, tooling and their approach on solving it with the ZenML framework."
            },
            {
                "title": "Google Brain\u2019s Imagen Model",
                "link": "https://imagen.research.google/",
                "content": "Google Brain\u2019s Imagen Model We have all been blown away by the unexpectedly creative capabilities of the text-to-image DALL-E model. We are now starting to see a trend with Google Brain\u2019s release of the Imagen model, which suggests an unprecendented degree of photorealism, and delivers mind blowing results with humorous pictures such as \u201ca panda riding a skateboard\u2026\u201d."
            },
            {
                "title": "Airbnb Recommender Systems",
                "link": "http://www.kdd.org/kdd2018/accepted-papers/view/real-time-personalization-using-embeddings-for-search-ranking-at-airbnb",
                "content": "Airbnb Recommender Systems Recommender systems are fundamental to major internet companies. This resource is an insightful applied research effort from the Airbnb team showcasing how they were able to approach real-time and historical recommendations for listings by abstracting and applying the concept of embeddings into their data-usecases."
            }
        ]
    },
    {
        "issue": "181",
        "items": [
            {
                "title": "MLSecOps = ML \u222a Security \u222a DevOps",
                "link": "http://venturebeat.com/2022/06/03/adopting-mlsecops-for-secure-machine-learning-at-scale/",
                "content": "ML \u222a Security \u222a DevOps The rise of MLSecOps is helping identify critial security vulnerabilities at every stage of the MLOps lifecycle, and defining the best practices to mitigate security risks in the different machine learning data & model stages. For anyone interested on a deeper dive on MLSecOps you can check our ongoing initiative to create \u201cFlawed ML Security\u201d examples (and solutions)."
            },
            {
                "title": "Machine Learning Trends to Know",
                "link": "http://gradientflow.com/machine-learning-trends-you-need-to-know",
                "content": "Machine Learning Trends to Know The DataOps & MLOps space continues to bring exciting trends that are driving forward some of the most exciting challenges in applied AI in industry. The GradientFlow team has put together a fantastic forward-looking exploration on the key trends in the DataOps & MLOps space, and covers the areas of AutoML, Data-Centric AI, Data Stacks, AI Efficiency, and more."
            },
            {
                "title": "Observability Trends & AIOps",
                "link": "http://www.splunk.com/en_us/pdfs/resources/e-book/state-of-observability-2022.pdf",
                "content": "Observability Trends & AIOps The future of observability is bright; the 1000+ Splunk 2022 observability survey respondants provide interesting insight such as the reported downtime costs reductions by 90% and improved mean-time-to-resolution by 69%, between many other interesting insights."
            },
            {
                "title": "Featurestore Types for ML & Data",
                "link": "http://www.hopsworks.ai/post/feature-types-for-machine-learning",
                "content": "Featurestore Types for ML & Data Featurestores continue growing in popularity and adoption across production MLOps stacks. As these data-intensive components are used at larger-scale, these have uncovered architectural and conceptual challenges that have required new concepts and architectural patterns. This article provides an interesting introduction to some of these challenges, as well as proposed concepts that enable for online and offline ML features."
            },
            {
                "title": "Data Science and Storytelling",
                "link": "https://shopifyengineering.myshopify.com/blogs/engineering/data-storytelling-shopify",
                "content": "Data Science and Storytelling Data science is not just a science, and more often than not storytelling is key. The Shopify data science & engineering team has put together an insightful overview of the importance of storytelling in the field of data and data science, as well as a high level conceptual framework to present data insights with impactful results."
            }
        ]
    },
    {
        "issue": "182",
        "items": [
            {
                "title": "High Performance ML at Scale",
                "link": "https://www.youtube.com/watch?v=hj_lozIqo5M",
                "content": "High Performance ML at Scale Optimization of machine learning models can bring benefits beyond speed improvements, including reduced hardware requirements, smaller and more secure artifacts, and overall cost reductions. In this talk we cover practical steps and tools that can be leveraged to perform optimizations on machine learning models through scalable patterns, leveraging tools like Huggingface, ONNX, MLServer and Seldon Core."
            },
            {
                "title": "Orchestrating ML Applications",
                "link": "http://thedataexchange.media/orchestrating-machine-learning-applications/",
                "content": "Orchestrating ML Applications Flyte is a popular open source platform that enables complex mission-critical workflow automation for machine learning processes at scale. The data exchange podcast dives into conversation with the CTO of \u201cUnion\u201d, the open core company behind Flyte. In this conversation they dive into motivations for robust ML orchestration platforms, challenges and plans to grow the project & community."
            },
            {
                "title": "Kafka Streaming Patterns for ML",
                "link": "http://www.confluent.io/resources/presentation/3-kafka-patterns-to-deliver-streaming-machine-learning-models/",
                "content": "Kafka Streaming Patterns for ML Data-centric machine learning has become a growingly important topic of theoretical and applied research in the MLOps space, and implementations using streaming platforms such as Kafka have been leading the charge. This talk provides an insightful set of machine learning patterns inferred from large scale use of data streaming pipelines in ML at scale."
            },
            {
                "title": "The Go Programming Language",
                "link": "https://cacm.acm.org/magazines/2022/5/260357-the-go-programming-language-and-environment/fulltext",
                "content": "The Go Programming Language The Go programming language has been raising in popularity at breakneck speed since its inception. This insightful ACM Communications article explores the attributes and principles that contributed to the robust and widely-loved features of the Go programming language."
            },
            {
                "title": "The SPACE of Dev Productivity",
                "link": "https://dl.acm.org/doi/10.1145/3454122.3454124",
                "content": "The SPACE of Dev Productivity The topic of developer productivity is a growing field being explored, with often interesting and insightful perspectives. The Microsoft research team presents and debunks some of the common \u201cMyths\u201d in developer productivity, and provide a well-thought \u201cSPACE\u201d framework that presents the importance of concepts such as dev satisfaction and developer tooling as key considerations."
            }
        ]
    },
    {
        "issue": "183",
        "items": [
            {
                "title": "Reproducible Deep Learning",
                "link": "http://www.sscardapane.it/teaching/reproducibledl/",
                "content": "Reproducible Deep Learning Building a deep learning model is a complex task, full of interacting design decisions, data engineering, parameter tweaking, and experimentation. Having access to powerful tools for versioning, storing, and analyzing every step of the process (MLOps) is essential. This is a fantastic course that dives into end-to-end MLOps with practical and indepth lessons on various key topics."
            },
            {
                "title": "Trends to Watch in June 2022",
                "link": "https://www.oreilly.com/radar/radar-trends-to-watch-june-2022/",
                "content": "Trends to Watch in June 2022 The explosion of large models continues in the machine learning ecosystem. Several developments this month are especially noteworthy. The O\u2019Reilly team has put together a great compendium of key trends and resources for June 2022, covering machine learning, general programming, security, hardware and more."
            },
            {
                "title": "Embedding Search at Faceboook",
                "link": "https://arxiv.org/abs/2006.11632",
                "content": "Embedding Search at Faceboook Search in social networks such as Facebook poses different challenges than in classical web search: besides the query text, it is important to take into account the searcher\u2019s context to provide relevant results. The Facebook Engineering & AI team have an interesting paper that covers the architecture and lessons learned introducing embedding-based search retrieval at Facebook."
            },
            {
                "title": "Fallacies of Distributed Systems",
                "link": "http://architecturenotes.co/fallacies-of-distributed-systems/",
                "content": "Fallacies of Distributed Systems The mass adoption of microservices has forced more engineers to understand the implications of that decision within their systems. This is particularly important for practitioners entering and growing in the MLOps space. This article provides a great overview of the top fallacies generally ignored or downplayed by programmers new to distributed applications."
            },
            {
                "title": "Github Malware Store Database",
                "link": "http://github.blog/2022-06-15-github-now-publishes-malware-advisories-in-the-github-advisory-database/",
                "content": "Github Malware Store Database To combat the prevalence of malware in the open source ecosystem, GitHub now publishes malware occurrences in the GitHub Advisory Database. These advisories power Dependabot alerts and remain forever free and usable by the community. This is particularly important in the MLOps space, as we have emphasised as part of the rise of MLSecOps."
            }
        ]
    },
    {
        "issue": "184",
        "items": [
            {
                "title": "Andrew Ng New ML Course",
                "link": "http://www.coursera.org/specializations/machine-learning-introduction",
                "content": "Andrew Ng New ML Course The top machine learning course has historically been Andrew Ng\u2019s Stanford course, which although dated has continued to rise in popularity and attendence. This course has now been updated and superceeded a brand new one which kicks off this week, and is open for any interested practitioners to join."
            },
            {
                "title": "MLOps Open Source Course",
                "link": "http://madewithml.com/#mlops",
                "content": "MLOps Open Source Course Learning how to develop end to end MLOps systems becomes key as the production machine learning requirements and use-cases increase. This is the largest and fastest growing MLOps course in github, and includes an exhaustive list of themes covered in detail with practical examples and tips."
            },
            {
                "title": "Deep Learning RecSys Survey",
                "link": "http://arxiv.org/pdf/1707.07435.pdf",
                "content": "Deep Learning RecSys Survey Deep learning has had increasing impact acros various sub-fields of machine learning including recommender systems. This survey provides an excellent overview and deep dive into the broad range of use-cases where deep learning has been adopted throughout the field of recommender systems."
            },
            {
                "title": "Effective Software Testing Guide",
                "link": "http://henrikwarne.com/2022/06/19/effective-software-testing-a-developers-guide/",
                "content": "Effective Software Testing Guide A great summary for a great book on effective software testing, a topic that is of paramount experience not only in the general software space but it is becoming growingly critical in the ML and MLOps spaces. This article covers key learnings and summaries of software testing best practices, as well as references for suggested deeper reads of the book."
            },
            {
                "title": "Stackoverflow Developer Survey",
                "link": "http://survey.stackoverflow.co/2022/",
                "content": "Stackoverflow Developer Survey Every year the stackoverflow team releases their annual developer survey, this year containing answers from over 70,000 developers, and spanning across the areas of technology, tooling, methodologies and beyond."
            }
        ]
    },
    {
        "issue": "185",
        "items": [
            {
                "title": "Free Open Source MLOps Course",
                "link": "http://github.com/DataTalksClub/mlops-zoomcamp",
                "content": "Free Open Source MLOps Course Obtaining practical MLOps knowledge can often be hard for practitioners looking to get started in the field due to the sheer amount of growing tools. This open source course covers a an extensive breadth of content including best practices of the overarching topic, and practical insights on experiment tracking, model management, orchestration, model deployment, monitoring and beyond."
            },
            {
                "title": "MLOps Taxonomy & Methodology",
                "link": "http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9792270",
                "content": "MLOps Taxonomy & Methodology As the MLOps ecosystem continues to grow there is a need for a taxonomy to classify the different tools and frameworks in the field. This IEEE paper encompasses an attempt to provide a taxonomy and methodology to exactly this challenge, providing a summary of key areas and tools in the ecosystem."
            },
            {
                "title": "ML Tracking & Experiment Tools",
                "link": "http://gradientflow.com/experiment-tracking-and-experiment-management-tools/",
                "content": "ML Tracking & Experiment Tools The experimentation tracking and experiment management phase of the ML model lifecycle has seen a significant growth in maturity and consolidation in the last decade. This survey provides an interesting exploration on key metrics to compare popular open source and closed source tools used in for experimentation and model management."
            },
            {
                "title": "Shipping To Production Principles",
                "link": "http://blog.pragmaticengineer.com/shipping-to-production/",
                "content": "Shipping To Production Principles Shipping systems to production is an absolutely critical phase in the software development lifecycle, and particularly imporant in specialised field such as MLOps which focuses particularly on the operation of production-grade machine learning systems. This article provides a great intuition and set of best practices / principles involved in productionisation of software, such as testing, automation, bad practice and good practice, between other great insights."
            },
            {
                "title": "Reverse Interview Candidate Tips",
                "link": "http://github.com/viraptor/reverse-interview/",
                "content": "Reverse Interview Candidate Tips These reverse tech interview tips for interviewees are essential; there are extensive and growing number of resources to prepare for technical interviews, however this great resource provides a fantastic perspective - namely meaningful questions that candidate can ask interviewers, including questions about the tech, the team, coworkers, the company, and more."
            }
        ]
    },
    {
        "issue": "186",
        "items": [
            {
                "title": "MLOps Definition & Architecture",
                "link": "http://arxiv.org/abs/2205.02302",
                "content": "MLOps Definition & Architecture To unlock value from machine learning organisations continue to identify best practices for production MLOps capabilities. This is an excellent overview of the end-to-end components present in produciton machine learning operations architectures and emphasises the complexities in achieving best practice at every stage throughout the ML model lifecycles."
            },
            {
                "title": "When Language Models Too Big",
                "link": "http://www.turing.ac.uk/events/dangers-stochastic-parrots",
                "content": "When Language Models Too Big Large language models carry inherent risks that are still being explored and understood. Alan turing institute researchers have published an initeresting research initiative tha texplores the dangers of large language models, as well as areas and considerations that are key to mitigate undesired risks."
            },
            {
                "title": "No Language Left Behind LLM",
                "link": "http://research.facebook.com/publications/no-language-left-behind/",
                "content": "No Language Left Behind LLM Research in large language models continues to bring mind blowing breakthroughs, this time enabling for multimodal translation across 200+ languages. Meta has published an interesting resource showcasing their goal to bridge cultures and languages through a massive multi-language machine learning model under the codename of \u201cNo Language Left Behind\u201d."
            },
            {
                "title": "Software Dev Lifecycle Evolution",
                "link": "http://casberw.medium.com/evolution-of-the-software-development-life-cycle-sdlc-the-future-of-devops-38d1f68c6812",
                "content": "Software Dev Lifecycle Evolution As practitioners look to adopt and expand MLOps capabilities it is key to reflect on the retrospective evolution of DevOps during the last decade. This article provides an insightful analysis of the current state of DevOps, as well as key trends in the field, as well as key emerging concepts."
            },
            {
                "title": "Lessons From Chaos Monkey",
                "link": "http://www.spiceworks.com/tech/tech-general/guest-article/lessons-from-chaos-monkey-embracing-chaos-to-bring-order-to-service-disruptions/",
                "content": "Lessons From Chaos Monkey Chaos monkey is the codename for the service that Netflix once published showcasing how they test the resilience of their systems by simulating system, infrastructure and component failures. This article provides an intuition on the approach to introduce this as well as the benefits of chaos engineering as a whole."
            }
        ]
    },
    {
        "issue": "187",
        "items": [
            {
                "title": "MLOps Meetup Driverless & E2e",
                "link": "http://www.meetup.com/mlopslondon/events/286236611/",
                "content": "MLOps Meetup Driverless & E2e The MLOps meetup comes back this week with a fantastic set of seasoned MLOps practitioners sharing insights and best practices. This session Wayve Senior Software Engineer Alex Persin and Contino AI & ML Practice Lead Byron Allen will be diving into best practices and learnings around autonomous vehicles and enterprise production machine learning operaitons."
            },
            {
                "title": "Stitchfix and their MLOps Platform",
                "link": "http://multithreaded.stitchfix.com/blog/2022/07/14/deployment-for-free/",
                "content": "Stitchfix and their MLOps Platform Organisations continue to develop internal end-to-end MLOps platforms to service their data science operations at scale. The engineering team at Stitchfix provide an insight into the approach, principles, architectural foundations, adoption and next steps for the development of their internal MLOps platform."
            },
            {
                "title": "AI Infra Ecosystem Report 2022",
                "link": "https://ai-infrastructure.org/ai-infrastructure-ecosystem-report-of-2022/",
                "content": "AI Infra Ecosystem Report 2022 The AI Infrastructure alliance has released the 2022 AI Infra Ecosystem report. This report aims to provide team leads, tech executives and architects the key knowledge needed to build and expand producation-grade ML infrastructure."
            },
            {
                "title": "Stanford Transformers Course",
                "link": "http://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM",
                "content": "Stanford Transformers Course Since their introduction in 2017 transformers have revolutionised Natural Language Processing. Stanford has now published a fantastic free open course that dives into this field, covering conceptual and practical insights on transformers."
            },
            {
                "title": "Practical Guide to A/B Testing",
                "link": "http://towardsdatascience.com/a-practical-guide-to-a-b-testing-in-mlops-with-kubernetes-and-seldon-core-e75e91ef91ef",
                "content": "Practical Guide to A/B Testing A/B testing is key in production machine learning systems. This article provides a practical deep dive into the motivations as well as frameworks and techniques that can be leveraged to implement A/B tests at scale in Kubernetes."
            }
        ]
    },
    {
        "issue": "188",
        "items": [
            {
                "title": "Uber\u2019s OLAP Infra at Scale",
                "link": "http://eng.uber.com/operating-apache-pinot/",
                "content": "Uber\u2019s OLAP Infra at Scale During the last few years we have seen a growth in populary and adoption of Online Analytical Processing (OLAP) systems and databases due to the growing ubiquity of real time data. Uber showcases in this article how they have adopted the OLAP database Apache Pinot and scaled it for analytical queries on terabytes-scale data in real time."
            },
            {
                "title": "Netflix Scaling with GraphQL",
                "link": "http://netflixtechblog.com/how-netflix-scales-its-api-with-graphql-federation-part-1-ae3557c187e2",
                "content": "Netflix Scaling with GraphQL Netflix is known for its loosely coupled and highly scalable microservice architecture to process terabytes of data to deliver their streaming services. This Netflix Engineering article dives into how they avoid exposing hundreds of microservices to UI developers by providing an univied API aggregation layer at the edge leveraging GraphQL federation."
            },
            {
                "title": "Scaling Microservices at Lyft",
                "link": "http://eng.lyft.com/scaling-productivity-on-microservices-at-lyft-part-1-a2f5d9a77813",
                "content": "Scaling Microservices at Lyft Late in 2018, Lyft engineering completed decomposing our original PHP monolith into a collection of Python and Go microservices. This four-part series will walk through the development environments that served Lyft\u2019s engineering team as it grew from 100 engineers and a handful of services to 1000+ engineers and hundreds of large-scale data services, including challenges, solutions and lessons learned."
            },
            {
                "title": "Data Annotation & Synthetic Gen",
                "link": "http://gradientflow.com/data-annotation-synthetic-data/",
                "content": "Data Annotation & Synthetic Gen Data anotation tools and synthetic data generation systems continue to become growingly key in large scale produciton machine learning systems. This article provides a bird\u2019s eye overview of the state of data annotation & synthetic data generation tools, including trends, concepts and frameworks."
            },
            {
                "title": "NVIDIA on Practical Art with AI",
                "link": "http://blogs.nvidia.com/blog/2021/06/23/studio-canvas-app/",
                "content": "NVIDIA on Practical Art with AI Large language models such as the more recent text-to-image DALL-E model suggest a promise to advance the creative sectors. NVIDIA has released an interesting and innovative implementation of their GAN based prototype presented at SIGGRAPH as the GauGAN AI Art Tool, which now lets anyone convert simple stick-figure like drawings into impressive creative paintings."
            }
        ]
    },
    {
        "issue": "189",
        "items": [
            {
                "title": "MLSecOps Top 10 Vulnerabilities",
                "link": "http://ethical.institute/security.html",
                "content": "MLSecOps Top 10 Vulnerabilities Identifying best practices and tools for Machine Learning Security is key, which is why we are thrilled to release \u201cThe MLSecOps Top 10\u201d. This is an initiative that aims to further the field of machine learning security by identifying the top 10 most common vulnerabiliites in the machine learning lifecycle. This project aims to provide an evaluation of security vulnerabilities analogous to the \u201cOWASP Top 10 Report\u201d but with a focus on machine learning security. The resources are open source and include examples, tools, best practices and next steps, including our contributions to the Linux Foundation Trusted AI"
            },
            {
                "title": "Uber\u2019s Data Workflows at Scale",
                "link": "http://eng.uber.com/managing-data-workflows-at-scale/",
                "content": "Uber\u2019s Data Workflows at Scale At Uber\u2019s scale, thousands of microservices serve millions of rides and deliveries a day, generating more than a hundred petabytes of raw data. This article provides a great insight on how Uber built their centralized workflow management system based on Airflow and re-architected to achieve massive scale. This includes core principles, previous systems, considerations, challenges and next steps."
            },
            {
                "title": "Implementing Research Papers",
                "link": "http://nn.labml.ai/",
                "content": "Implementing Research Papers Research papers can provide machine learning practitioners with fantastic state-of-the-art capabilities which is why developing the skill to implement papers into code can be key. This fantastic resource has put together a set of well documented and intuitively explained implementations of research papers into PyTorch code, providing line-by-line explanations of the approach."
            },
            {
                "title": "DeepMind AlphaFold Universe",
                "link": "http://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe",
                "content": "DeepMind AlphaFold Universe DeepMind shares an exciting milestone releasing an open resource containing a vast amount protein structures predicted from the AlphaFold project. This is quite an exciting milestone as it promises significant advancement with the vast applicability of this resource, and it has already been seen to enable for outstanding case studies."
            },
            {
                "title": "Statistical ML Summer School",
                "link": "http://leshouches2022.github.io/",
                "content": "Statistical ML Summer School Building a robust understanding on statistical foundations can be key for machine learning practitioners. This resource provides freely available videos and lecture notes from the \u201cSummer school on Statistical Physics & Machine learning\u201d that took place this month, containing a vast range of key content on statistical foundations."
            }
        ]
    },
    {
        "issue": "190",
        "items": [
            {
                "title": "FastAI Practical ML Course",
                "link": "http://course.fast.ai/",
                "content": "FastAI Practical ML Course Developing practical deep learning knowledge can be challenging with the growing number of educational resources. The FastAI course has established itself as a fantastic resource to develop practical knowledge in real-world machine learning use-cases. The core team has just released the updated v5 version with great new content and resources."
            },
            {
                "title": "Golang Based ML Framework",
                "link": "http://gorgonia.org/tutorials/mnist/",
                "content": "Golang Based ML Framework Productionisation of machine learning models at scale can be challenging, particularly due to the stringent high-performant requirements of large-scale production services. This framework provides an interesting way to implement production machine learning services directly in high performant Golang code, enabling for the high-performance features of the language whilst introducing a tradeoff on conversion from data science tools."
            },
            {
                "title": "JuliaCon Recordings Released",
                "link": "http://www.youtube.com/playlist?list=PLP8iPy9hna6TRg6qJaBLJ-FRMi9Cp7gSX",
                "content": "JuliaCon Recordings Released The Julia language continues to grow in popularity as well as feature stability. The videos from the most recent JuliaCon conference are now released for free. These include updates on the language itself, as well as practical case-studies and implementations of various practical use-cases using the Julia language."
            },
            {
                "title": "MLSecOps Top 10 Vulnerabilities",
                "link": "http://ethical.institute/security.html",
                "content": "MLSecOps Top 10 Vulnerabilities Identifying best practices and tools for Machine Learning Security is key, which is why we are thrilled to release \u201cThe MLSecOps Top 10\u201d. This is an initiative that aims to further the field of machine learning security by identifying the top 10 most common vulnerabiliites in the machine learning lifecycle. This project aims to provide an evaluation of security vulnerabilities analogous to the \u201cOWASP Top 10 Report\u201d but with a focus on machine learning security. The resources are open source and include examples, tools, best practices and next steps, including our contributions to the Linux Foundation Trusted AI."
            },
            {
                "title": "Building Containers From Scratch",
                "link": "http://www.youtube.com/watch?v=8fi7uSYlOdc",
                "content": "Building Containers From Scratch Containers continue to become ubiquitous in the general software and data science space. Often practitioners may wonder how the dev tooling they use on their day to day works under-the-hood. This talk provides an extremelly intuitive explanation of how containers work by building the simplest form of a container from scratch."
            }
        ]
    },
    {
        "issue": "191",
        "items": [
            {
                "title": "O\u2019Reilly Radar Trends to Watch",
                "link": "http://www.oreilly.com/radar/radar-trends-to-watch-august-2022/",
                "content": "O\u2019Reilly Radar Trends to Watch Keeping with growing trends in key emerging technologies is key. The O\u2019Reilly team has published the \u201cRadar Trends\u201d which compiles key trends to watch for the month of August. This dives into a broad range of areas including AI, Security, Programming, Web, Quantum and more."
            },
            {
                "title": "Advanced ML Model Monitoring",
                "link": "http://www.fuzzylabs.ai/blog-post/model-monitoring-with-seldon-alibi",
                "content": "Advanced ML Model Monitoring The lifecycle of a machine learning model begins once it\u2019s deployed to production. This article provides a great practical tutorial introducing advanced data science monitoring techniques to have real-time observability through outlier detectors, drift detectors, etc."
            },
            {
                "title": "Building Prod MLOps Pipelines",
                "link": "http://thedataexchange.media/building-production-ready-machine-learning-pipelines/",
                "content": "Building Prod MLOps Pipelines\u00a0 The vast amount of options and tools available for each stage throughout the machine learning lifecycle make the ability to select relevant technologies a growing challenge. The ZenML team has put together a platform that brings together the best tools at each phase of the ML lifecycle. In this podcast ZenML cofounders Hamza & Adam dive into the topic of end to end MLOps, including trends, challenges and opportunities."
            },
            {
                "title": "Building a Two-Layered RecSys",
                "link": "http://medium.com/@FunCorp/practical-guide-to-create-a-two-layered-recommendation-system-5486b42f9f63",
                "content": "Building a Two-Layered RecSys Developing end-to-end recommender systems introduce complex infrastructure demands from an MLOps perspective. This article provides an interesting practical example developing a two-layered recommender systems, introducing the key requirements, architecture, data sources, inference, scheduler, feature store, and several other deeper dives."
            },
            {
                "title": "SciPy 2022 Conference Videos",
                "link": "http://www.youtube.com/playlist?list=PLYx7XA2nY5Ge3LsWy500pi5bdHEiAdQB5",
                "content": "SciPy 2022 Conference Videos The SciPy 2022 conference videos are out now avilable for free. This year\u2019s event brought togeter insightful sessions providing useful practical and conceptual deep dives."
            }
        ]
    },
    {
        "issue": "192",
        "items": [
            {
                "title": "Data Quality Mgmt at Linkedin",
                "link": "http://engineering.linkedin.com/blog/2022/towards-data-quality-management-at-linkedin",
                "content": "Data Quality Mgmt at Linkedin Data is at the heart of all products and decisions at modern organisations, and the quality of data is vital to long-term success. Linkedin shares insightful lessons on tackling the challenge of data quality at massive scale, providing usecases in context to AI, as well as challenges, architectures, and next steps."
            },
            {
                "title": "Design Patterns in ML Systems",
                "link": "http://eugeneyan.com/writing/design-patterns/",
                "content": "Design Patterns in ML Systems Design patterns are not just a way to structure code. They also communicate the problem addressed and how the code or component is intended to be used. This blog post explores some interesting design patterns in data and machine learning including practical examples with various datasets, models and frameworks."
            },
            {
                "title": "Debt in ML Maintenance at Scale",
                "link": "http://www.youtube.com/watch?v=7Mf4jNux4T8",
                "content": "Debt in ML Maintenance at Scale Data debt in machine learning systems is a non-trivial challenge arising in production ML systems. D. Sculley joins the TWIML podcast to dive into the topic of data-centric machine learning and the importance of best practices to reduce legacy debt and management overhead of large-scale long-living changing MLOps / DataOps systems."
            },
            {
                "title": "Data-Oriented Design in Software",
                "link": "http://dataorienteddesign.com/dodbook/",
                "content": "Data-Oriented Design in Software Although data-centered design is becoming growingly popular in ML, it is not a new concept in the general development space. This resource in particular is a great introduction to development with a focus on data processing instead to create more maintainable, more affordable and more efficient scalable systems."
            },
            {
                "title": "Data Visualisation in Python",
                "link": "https://blog.resolvingpython.com/04-data-visualization-in-python",
                "content": "Data Visualisation in Python Data visualisation with languages like python provide a fantastic resource for building robust stories around decisions that need to be made with data. This article provides a practical overview of the frameworks and concepts in data visualiasation with Python, as well as practical code to use when building capturing narratives with data."
            }
        ]
    },
    {
        "issue": "193",
        "items": [
            {
                "title": "Deploying ML at NeurIPS 2022",
                "link": "http://sites.google.com/view/dmmlsys-neurips2022",
                "content": "Deploying ML at NeurIPS 2022 Responsible AI best practices are now growingly critical as Machine Learning becomes growingly ubiquitous in cross-industry use-cases at higher impact and scale. Because of this, we are thrilled to be contributing to this year\u2019s NeurIPS 2022 \u201cDeploy & Monitor ML\u201d workshop, where key insights will be shared on best-practices across security, privacy, data-centricity and beyond."
            },
            {
                "title": "Scaling AI Education at Uber",
                "link": "http://www.uber.com/en-PL/blog/ml-education-at-uber/",
                "content": "Scaling AI Education at Uber At Uber, millions of machine learning (ML) predictions are made every second, and hundreds of applied scientists, engineers, product managers, and researchers work on ML solutions daily. Uber mentions they \u201cwin by scaling machine learning\u201d, and in this interesting article they share how they have scaled education of machine learning across their workforce, including core principles, topics and plans."
            },
            {
                "title": "Scale System Design Knowledge",
                "link": "http://www.karanpratapsingh.com/courses/system-design",
                "content": "Scale System Design Knowledge Designing scalable systems continues to be highlighted as one of the subjects that machine learning practitioners struggle to build the strong capabilities required when the AI system use-cases start reaching certain scale. This free course provides a great introduction into the typical set of concepts covered in general systems design, together with practical examples with common system design exercises."
            },
            {
                "title": "Confidential Computing in ML",
                "link": "http://gradientflow.com/confidential-computing-and-machine-learning/",
                "content": "Confidential Computing in ML In order to have a comprehensive data protection and privacy policy, organizations must ensure the confidentiality and integrity of your data in these states: at rest, in use, and in transit. This post provides a comprehensive assessment of the state of confidential computing, including an overview of practical demand vs supply relative to the different topics in this field."
            },
            {
                "title": "Open Source Ecosystem at Wolt",
                "link": "http://blog.wolt.com/engineering/2022/08/24/wolt-loves-open-source-software/",
                "content": "Open Source Ecosystem at Wolt Open source strategies become growingly critical across every organisation, and consistently it\u2019s highlighted as a challenging value proposition to verbalise and quantify. Food delivery service Wolt has put together a great overview of their open source ecosystem around data, ML & observability, as well as the core principles that drive their involvement, adoption and contributions. They also cover a success story and a set of plans for long term involvement in OSS."
            }
        ]
    },
    {
        "issue": "194",
        "items": [
            {
                "title": "Secure Machine Learning Talk",
                "link": "http://www.linkedin.com/posts/seldon_mlops-machinelearning-opensource-activity-6970064552415682560-OTuB/",
                "content": "Secure Machine Learning Talk Machine learning security continues to grow in popularity. This week we will host an online webinar to cover the topic of ML security through common vulnerabilities throughout the e2e ML lifecycle, as well as best practices, and share the news of our latest initiative to tackle this challenge in collaboration with the Linux Foundation."
            },
            {
                "title": "Stable Diffusion Public Release",
                "link": "http://stability.ai/blog/stable-diffusion-public-release",
                "content": "Stable Diffusion Public Release The global race for text-to-image models continues to astonish with mind blowing releases. Stable difussion was released as an open source model just a few weeks ago, and it has already been making strides with community contributions, getting the model working on laptop-sized >4GB GPUs."
            },
            {
                "title": "Popular NLP Projects 2022",
                "link": "http://odsc.com/blog/12-most-popular-nlp-projects-of-2022-so-far/",
                "content": "CompSci Papers We Love"
            },
            {
                "title": "CompSci Papers We Love",
                "link": "http://odsc.com/blog/12-most-popular-nlp-projects-of-2022-so-far/",
                "content": "CompSci Papers We Love"
            },
            {
                "title": "Code Performance Speed Limits",
                "link": "http://travisdowns.github.io/blog/2019/06/11/speed-limits.html",
                "content": "Code Performance Speed Limits Sometimes you just want to know how fast your code can go, without benchmarking it. Sometimes you have benchmarked it and want to know how close you are to the maximum speed. Often you just need to know what the current limiting factor is, to guide your optimization decisions. This article provides a fantastic resource on building strong intuition towards determining the \u201cspeed limit\u201d of programs."
            }
        ]
    },
    {
        "issue": "195",
        "items": [
            {
                "title": "Best Practices for ML Engineering",
                "link": "http://developers.google.com/machine-learning/guides/rules-of-ml",
                "content": "Best Practices for ML Engineering Defining standardised best practices analogous to team / code standards is key for scalable Machine Learning projects and systems. This document presents a style for machine learning, similar to the Google C++ Style Guide and other popular guides to practical programming."
            },
            {
                "title": "NCSC Principles for ML Security",
                "link": "http://www.ncsc.gov.uk/collection/machine-learning",
                "content": "NCSC Principles for ML Security The National Cyber Security Center has released a fantastic resource on Machine Learning Security that provides a framework to ensure best practices at every stage of the model lifecycle. This resource covers quite a comprehensive set of applicable best practices."
            },
            {
                "title": "Practical OCR with PaddleOCR",
                "link": "http://github.com/PaddlePaddle/PaddleOCR/blob/release/2.5/doc/doc_en/whl_en.md",
                "content": "Practical OCR with PaddleOCR The challenge of extracting text from images has seen evolving tools, progressively introducing more impressive capabilities. It is great to see the open source solutions taking the lead by leveraging state of the art machine learning models. This tutorial showcases how to use PaddleOCR with pretrained and custom models for text extraction and visualisation of results."
            },
            {
                "title": "Large Scale RecSys at Alibaba",
                "link": "http://arxiv.org/abs/2005.12002",
                "content": "Large Scale RecSys at Alibaba Applications of machine learning in graph-like structures continues to become a growingly popular due to the applicability to real world challenges. The team at Alibaba presented an interesting approach to leveraging these relationships and provided insights into a practical usecase introducing it to large scale online and offline recommendations based on click-through-rate."
            },
            {
                "title": "PapersWithCode Annual Trends",
                "link": "http://paperswithcode.com/trends",
                "content": "PapersWithCode Annual Trends PapersWithCode is a fantastic initiative that advocates for reproducible research, relating a large repository of research papers that are accompanied by reproducible code. They also provide insigthful temporal analytics and insights that showcase popularity metrics for frameworks and code."
            }
        ]
    },
    {
        "issue": "196",
        "items": [
            {
                "title": "PyTorch Joins Linux Foundation",
                "link": "http://www.linuxfoundation.org/blog/blog/welcoming-pytorch-to-the-linux-foundation",
                "content": "PyTorch Joins Linux Foundation PyTorch is one of the most important and successful machine learning software projects in the world today. Last week the PyTorch project joined the Linux Foundation, a neutral home where it can continue to enjoy strong growth and rapid innovation. This is fantastic news for the open innovation and evolution of the fast growing AI ecosystem."
            },
            {
                "title": "Deploy & Monitor ML at NeurIPS",
                "link": "http://sites.google.com/view/dmmlsys-neurips2022/home",
                "content": "Deploy & Monitor ML at NeurIPS Responsible AI best practices are now growingly critical as Machine Learning becomes growingly ubiquitous in cross-industry use-cases at higher impact and scale. Because of this, we are thrilled to be contributing to this year\u2019s NeurIPS 2022 \u201cDeploy & Monitor ML\u201d workshop, where key insights will be shared on best-practices across security, privacy, data-centricity and beyond. The CFP is still open until the end of this week so be sure to submit ahead of then."
            },
            {
                "title": "Trends to Watch September",
                "link": "http://www.oreilly.com/radar/radar-trends-to-watch-september-2022/",
                "content": "Trends to Watch September The O\u2019Reilly team has put together an overview of key trends to watch for the month of September. These span interesting developments across artificial intelligence, general programming, security, privacy, quantum and more."
            },
            {
                "title": "Curated List of Awful AI Cases",
                "link": "http://github.com/daviddao/awful-ai",
                "content": "Curated List of Awful AI Cases Awful AI is a curated list to track current scary usages of AI. It consists of a long and growing list of examples showcasing case studies of AI bad practices. The objective of this resource is to raise awareness to its misuses in society."
            },
            {
                "title": "ML Algorithms from Scratch",
                "link": "http://www.youtube.com/watch?v=p1hGz0w_OCo&list=PLcWfeUsAys2k_xub3mHks85sBHZvg24Jd&index=2",
                "content": "ML Algorithms from Scratch Understanding the internals of the machine learning algorithms we use on our day-to-day as data science practitioners can be highly beneficial. This free course dives into a set of practical exercises implementing a broad range of machine learning algorithms from scratch using Python."
            }
        ]
    },
    {
        "issue": "197",
        "items": [
            {
                "title": "Instacart Real Time ML Journey",
                "link": "http://tech.instacart.com/lessons-learned-the-journey-to-real-time-machine-learning-at-instacart-942f3a656af3",
                "content": "Instacart Real Time ML Journey Real time machine learning continues to be adopted by organisations at growing speed. This insightful article by the Instacart engineering team covers an insightful deep dive into how they have been able to move from batch inference into real time processing & serving of machine learning insights."
            },
            {
                "title": "Operationalising ML Survey",
                "link": "http://arxiv.org/abs/2209.09125",
                "content": "Operationalising ML Survey Berkeley researchers have released an interesting interview study exploring the ecosystem operationalising machine learning. This resource shares findings from interviews across 18 ML engineers working across a wide variety of sectors, and shares challenges, trends and more."
            },
            {
                "title": "Building NoSQL from Scratch",
                "link": "http://betterprogramming.pub/build-a-nosql-database-from-the-scratch-in-1000-lines-of-code-8ed1c15ed924",
                "content": "Building NoSQL from Scratch Building an intuition around how data storage & processing work under the hood can help enrich the technical capabilities of ML practitioners. This resource attempts to share insights on database-internals by building a simple NoSQL database from scratch using the Golang programming language."
            },
            {
                "title": "Automate with Python in K8s",
                "link": "http://martinheinz.dev/blog/73",
                "content": "Automate with Python in K8s One of the core trends of data processing frameworks are adoption of Kubernetes as their backend runtime scheduler engine. This article provides practical examples that can be adopted to \u201cautomate the boring stuff\u201d around administration of kubernetes clusters."
            },
            {
                "title": "Green Programming Languages",
                "link": "http://medium.com/codex/what-are-the-greenest-programming-languages-e738774b1957",
                "content": "Green Programming Languages Energy consumption has become growingly important due to growing climate concerns. This article asks the interesting question of what programming languages require most / least energy to carry out a simple set of instructions (spoiler: low-level > high level languages)."
            }
        ]
    },
    {
        "issue": "198",
        "items": [
            {
                "title": "Pro-Innovation AI Regulation",
                "link": "http://www.linkedin.com/posts/axsaucedo_acm-europe-tpc-comments-on-uk-regulation-activity-6980167082206191617-lznm/",
                "content": "Pro-Innovation AI Regulation We have published our submission on the \u201cUK\u2019s Pro-Innovation AI Regulatory Proposal\u201d \ud83d\ude80 This is a fantastic contribution to a very important policy document where we outline four key recommendations: 1) Environmental risks should be considered; 2) regulation must be compatible to enable technological interoperability; 3) Critical elements should be clearly defined; and, 4) Development must remain a highly transparent process."
            },
            {
                "title": "Full Stack Deep Learning Course",
                "link": "http://fullstackdeeplearning.com/course/2022/",
                "content": "Full Stack Deep Learning Course A fantastic free course on MLOps and full stack deep learning. This great resource covers great topics ranging across both technical and non-technical/business considerations. It covers practical examples around defining business needs, performing data wrangling, choosing frameworks, testing, deploment, monitoring and more."
            },
            {
                "title": "Netflix on Large Scale RecSys",
                "link": "http://netflixtechblog.medium.com/recsysops-best-practices-for-operating-a-large-scale-recommender-system-95bbe195a841",
                "content": "Netflix on Large Scale RecSys Operating a large-scale recommendation system is a complex undertaking: it requires high availability and throughput, involves many services and teams, and the environment of the recommender system changes every second. In this blog post the Netflix team provides best practices and lessons learned operating large scale recommender systems across their organisation."
            },
            {
                "title": "Meta New Text-to-Video Model",
                "link": "http://makeavideo.studio/",
                "content": "Meta New Text-to-Video Model Following the trend of text-to-image models, this week we now see a growing trend of text-to-video models. Meta has published a new initiative that provides another mind-blowing model which now allows for the creation of arbitrary videos from text input."
            },
            {
                "title": "The Vector Database Index",
                "link": "http://gradientflow.com/the-vector-database-index/",
                "content": "The Vector Database Index Vector databases and vector search are on the radar of a growing number of technical teams. A key driver is that advances in neural networks have made dense vector representations of data more common. Interest has also grown due to the decision of technology companies to open source their core systems for vector search. This resource provides a great overview of the vector database ecosystem, including concepts, trends and popularity."
            }
        ]
    },
    {
        "issue": "199",
        "items": [
            {
                "title": "AI Infrastructure Landscape",
                "link": "http://ai-infrastructure.org/ai-infrastructure-landscape/",
                "content": "AI Infrastructure Landscape The MLOps ecosystem continues to evolve at breakneck speed with tools coming out at equal speed. The AI Infrastructure alliance has released a fantastic resource that maps the ecosystem of MLOps tools together with the capabilities, limitations and features of each of the tools, providing a central resource when evaluating different tools."
            },
            {
                "title": "RecSys Recap & Best Papers",
                "link": "http://eugeneyan.com/writing/recsys2022/",
                "content": "RecSys Recap & Best Papers RecSys 2022 was held from 18th - 23rd September in Seattle. There were 50% more industry submissions relative to 2021, and 260% more relative to 2020. This article provides a fantastic overview of key papers and lessons learned from this year\u2019s event."
            },
            {
                "title": "DoorDash Recommendations",
                "link": "http://doordash.engineering/2022/10/05/homepage-recommendation-with-exploitation-and-exploration/amp/",
                "content": "DoorDash Recommendations Building quality recommendations and personalizations requires delicately balancing what is already known about users while recommending new things that they might like. As one of the largest drivers of DoorDash\u2019s business, the homepage contributes a significant portion of their total conversions. This article provides a practical insight on recommendations at Doordash with Exploration and Exploitation."
            },
            {
                "title": "Google Cloud Architecture Centre",
                "link": "http://cloud.google.com/architecture",
                "content": "Google Cloud Architecture Centre Best practice in large scale architectures is key for scaling MLOps systems. The Google Architecture Framework is a fantastic resource that contains best practices for architecture design, including a set of principles as well as practical case studies and examples."
            },
            {
                "title": "AlphaTensor Matrix Multiplication",
                "link": "http://www.youtube.com/watch?v=3N3Bl5AA5QU",
                "content": "AlphaTensor Matrix Multiplication Matrix multiplication is the most used mathematical operation in all of science and engineering. Speeding this up has massive consequences. Thus, over the years, this operation has become more and more optimized. A fascinating discovery was made when it was shown that one actually needs less than N^3 multiplication operations to multiply to NxN matrices and this video provides an intuitive explanation of the accompanying paper."
            }
        ]
    },
    {
        "issue": "200",
        "items": [
            {
                "title": "The State of AI Report is Out",
                "link": "http://www.stateof.ai/",
                "content": "The State of AI Report is Out The State of AI Report analyses the most interesting developments in AI. This report aims to trigger an informed conversation about the state of AI and its implication for the future. It includes fantastic insigths around revelopments and predictions across research, industry, politics and beyond."
            },
            {
                "title": "Kubernetes AI Day North America",
                "link": "http://events.linuxfoundation.org/kubernetes-ai-day-north-america/",
                "content": "Kubernetes AI Day North America Kubernetes is becoming a common substrate for AI that allows for workloads to be run either in the cloud or in its own data center, and to easily scale. Join us next week at the Kubernetes AI Day where we\u2019ll be doing the opening keynote, following a fantastic set of sessions on cloud native AI."
            },
            {
                "title": "Bert, LSTMs & Toxic Detection",
                "link": "http://www.kaggle.com/code/rasbtn/distilbert-v0/notebook",
                "content": "Bert, LSTMs & Toxic Detection A brief but insightful twitter discussion involving DL Reseracher Sebastian Raschka highlights the astonishing developments in the NLP space which allows for almost any individual to easily achieve state-of-the-art-level perfromance on text classification tasks through available open pre-trained models. This example showcases astonishing results with truly minimal effort."
            },
            {
                "title": "Stripe with Migrations at Scale",
                "link": "http://stripe.com/blog/online-migrations",
                "content": "Stripe with Migrations at Scale Engineering teams often face the redesign the data models & systems they use. In production environments, this might mean migrating millions of active objects and refactoring thousands of lines of code. Stripe provides a fantastic resource where they summarise their experience and lessons learned performing a large scale migration."
            },
            {
                "title": "OpenAI Introducing Whisper",
                "link": "http://openai.com/blog/whisper/",
                "content": "OpenAI Introducing Whisper OpenAI introduces an exciting new initiative through the codename \u201cWhisper\u201d, a neural net that approaches human level robustness and accuracy on speech recognition. This article provides intuitive details on the approach, architecture and results."
            }
        ]
    },
    {
        "issue": "201",
        "items": [
            {
                "title": "Kubernetes AI Opening Keynote",
                "link": "http://events.linuxfoundation.org/kubernetes-ai-day-north-america/",
                "content": "Kubernetes AI Opening Keynote Kubernetes is becoming a common substrate for AI that allows for workloads to be run either in the cloud or in its own data center, and to easily scale. Join this next week at the KubeCon North America 2022 where we\u2019ll be doing the opening keynote at the Kubernetes AI Day, followed by a fantastic set of sessions on cloud native AI."
            },
            {
                "title": "Data Mesh Architecture Definition",
                "link": "http://www.datamesh-architecture.com/",
                "content": "Data Mesh Architecture Definition Many organizations have invested in a central data lake, ofter realising the solution becomes the bottleneck. The concept of the data mesh has grown in popularity - this article provides an architectural and practical definition of this paradigm. It covers principles, concepts and practical examples."
            },
            {
                "title": "NVIDIA Optimizing Data Collect",
                "link": "http://nv-tlabs.github.io/LearnOptimizeCollect/",
                "content": "NVIDIA Optimizing Data Collect Collecting data for machine learning and analytics projects can be time consuming as well as costly. This paper provides an interesting approach to data collection, where a process is introduced to optimize the amount of data collected through an iterative cycle that can help lead to comparable results with less resources."
            },
            {
                "title": "Growing Metadata Mgmt Systems",
                "link": "http://gradientflow.com/the-growing-importance-of-metadata-management-systems/",
                "content": "Growing Metadata Mgmt Systems Metadata will be the foundation for data governance solutions, data catalogs, and other enterprise data systems. This article provides a great overview of the current state of the metadata management landscape, as well as the tools in the ecosystem."
            },
            {
                "title": "Data Product Management",
                "link": "http://www.montecarlodata.com/blog-what-good-data-product-managers-do-and-why-you-probably-need-one/",
                "content": "Data Product Management As organisations adopt data-driven decision making through robust and scalable infrastructure, there is a realisation of the importance for moving from a project mentality into a product/platorm mentality. This has come with the rise of the data product manager role - this article provides a great overview of what this role consists of, and how it\u2019s been evolving based on the still-evolving data ecosystem."
            }
        ]
    },
    {
        "issue": "202",
        "items": [
            {
                "title": "ACM US & Europe AI Principles",
                "link": "http://www.linkedin.com/posts/axsaucedo_principles-for-responsible-algorithmic-systems-activity-6991449227516067840-_mms",
                "content": "ACM US & Europe AI Principles the ACM Joint Statement on Principles for Responsible Algorithmic Systems has now been published \ud83d\ude80 It has been an honour to contribute to this initiative co-led by Professor Jeanna Matthews and Professor Ricardo Baeza-Yates as it is a huge milestone for European + US ACM technology policy. This publication proposes nine instrumental principles for responsible algorithmic systems which complement ACM Code of Ethics and Professional Conduct."
            },
            {
                "title": "Prometheus The Documentary",
                "link": "http://www.youtube.com/watch?v=rT4fJNbfe14",
                "content": "Prometheus The Documentary A growing number of organisations adopting MLOps capabilities are starting to face the same observability challenges in large scale distributed systems. This fantastic documentary on Prometheus provides an in-depth view of how the most popular observability of large (and small) scale systems was developed."
            },
            {
                "title": "Healthcare Causal Inference ML",
                "link": "http://www.youtube.com/watch?v=gRkUhg9Wb-I",
                "content": "Healthcare Causal Inference ML Correlation does not imply causation. This MIT lecture provides a practical intuition on an exciting area of research focusing on deriving causality with advanced/complex machine learning methods. This lecture is part of the broader free MIT course on Machine Learning for healthcare."
            },
            {
                "title": "Bias Bounty on Algorithmic Bias",
                "link": "http://biasbounty.ai/",
                "content": "Bias Bounty on Algorithmic Bias Bug bounties are a standard practice in cybersecurity that has yet to find footing in the algorithmic bias community. Outlined in the latest NIST AI Risk Management Framework, bias bounties should be a part of any gold-star algorithmic ethics program. This interesting initiative has set up a structured programme for interested practitioners to get involved for prizes and rewards."
            },
            {
                "title": "Designing Data Product Canvas",
                "link": "http://www.datamesh-architecture.com/data-product-canvas",
                "content": "Designing Data Product Canvas In data science and data engineering the mentality is shifting from data projects into data products. This article provides an interesting resource to design data products with a product canvas specialised for the domain."
            }
        ]
    },
    {
        "issue": "203",
        "items": [
            {
                "title": "Kubernetes AI Keynote & Videos",
                "link": "http://www.youtube.com/watch?v=xymbp8RWaCQ&list=PLj6h78yzYM2M9oVaU3amsqL5RXUwcugJ2&index=3",
                "content": "Kubernetes AI Keynote & Videos Operating machine learning systems at scale introduces complex challenges that go beyond traditional software systems. In this opening keynote at the KubeCon Kubernetes AI day I covered key trends that have been developing in the MLOps ecosystem, diving not only into technological trends, but also growing trends around organisational / team structures and processes."
            },
            {
                "title": "Metadata for End to End MLOps",
                "link": "http://go.seldon.io/l/702803/2022-10-04/ksdfn",
                "content": "Metadata for End to End MLOps If you missed the KubeCon conference, you can still catch up with my talk on Metadata for End-to-End MLOps systems by joining our upcoming webinar this Thursday! In this session I provide an intuition for the need of robust metadata; I cover how production MLOps systems introduce different challenges to the traditional data management space, as well as robust solutions available today."
            },
            {
                "title": "Tech Trends to Watch Nov 2022",
                "link": "http://www.oreilly.com/radar/radar-trends-to-watch-november-2022/",
                "content": "Tech Trends to Watch Nov 2022 The O\u2019Reilly team explores growing trends in November 2022 across the technological landscape. This resource dives into a broad range of areas, including AI, General Programming, Security, Quantum and more."
            },
            {
                "title": "Andrej Karpathy NN Zero to Hero",
                "link": "http://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ",
                "content": "Andrej Karpathy NN Zero to Hero Former Tesla AI Director Andrej Karpathy has released a free online course covering Neural Networks \u201cZero to Hero\u201d. In this course he dives into the foundational theory and practical examples to develop a robust understanding on the core concepts that revolve around Neural Networks."
            },
            {
                "title": "Maths for CompSci & ML Book",
                "link": "http://www.cis.upenn.edu/~jean/math-deep.pdf",
                "content": "Maths for CompSci & ML Book Reviewing mathematical foundations is key for both computer science and machine learning. This great resource from the University of Pensilvania contains a comprehensive compendium of algebra, topology, differential calculus and optimization theory, which provide fantastic content for technical practitioners that want to develop and polish their foundational knowledge."
            }
        ]
    },
    {
        "issue": "204",
        "items": [
            {
                "title": "Metadata In End To End MLOps",
                "link": "http://www.youtube.com/watch?v=wzbj7LcQ2Ek",
                "content": "Metadata In End To End MLOps As MLOps systems scale we may lose sight of the risks and opportunities available, resulting in duplicated efforts, cost overheads, unmanaged risks and many more challenges. In this recent KubeCon 2022 NA conference session we dive into how to address these issues with end-to-end MLOps metadata capabilities."
            },
            {
                "title": "NeurIPS on Prod ML Challenges",
                "link": "http://sites.google.com/view/dmmlsys-neurips2022/home",
                "content": "NeurIPS on Prod ML Challenges Production ML is hard. We are thrilled to join NeurIPS 2022 for the workshop tackling challenges in deployment and monitoring in production machine learning systems. We will be contributing a keynote session on machine learning security - do join us at this as well as the many other exciting sessions."
            },
            {
                "title": "The Modern Startup Architecture",
                "link": "http://betterprogramming.pub/architecture-of-modern-startup-abaec235c2eb",
                "content": "The Stream Processing Index"
            },
            {
                "title": "TikTok SotA Recommender Sys",
                "link": "http://arxiv.org/abs/2209.07663",
                "content": "TikTok SotA Recommender Sys Building a scalable and real-time recommendation system is vital"
            },
            {
                "title": "The Stream Processing Index",
                "link": "http://betterprogramming.pub/architecture-of-modern-startup-abaec235c2eb",
                "content": "The Stream Processing Index"
            }
        ]
    },
    {
        "issue": "205",
        "items": [
            {
                "title": "The Complete Guide to NLP",
                "link": "http://www.deeplearning.ai/resources/natural-language-processing/",
                "content": "The Complete Guide to NLP Natural Language Processing (NLP) is one of the hottest areas of artificial intelligence (AI) thanks to applications like text generators that compose coherent essays, chatbots that fool people into thinking they\u2019re sentient, and text-to-image programs that produce photorealistic images of anything you can describe. This is a comprehensive deep dive from the DeepLearning.AI team."
            },
            {
                "title": "Galactica The Scientific LLM",
                "link": "http://galactica.org/explore/",
                "content": "Galactica The Scientific LLM Information overload is a major obstacle to scientific progress. The explosive growth in scientific literature and data has made it ever harder to discover useful insights in a large mass of information. The META AI team published a large language model trained from technical and scientific data which can generate impressive results through question-answering interfaces."
            },
            {
                "title": "Thoughts on ML Engineering",
                "link": "https://www.shreyashankar.com/phd-year-one/",
                "content": "Thoughts on ML Engineering Automating the end-to-end machine learning (ML) lifecycle, even for a specific prediction task, is neither easy nor obvious. Organisational roles have emerged to address these challenges, however they have not been robustly defined. This post explores the role of the ML Engineer and provides interesting throughs from experience."
            },
            {
                "title": "Monzo on Argo Rollouts at Scale",
                "link": "http://monzo.com/blog/2022/11/02/argo-rollouts-at-scale",
                "content": "Monzo on Argo Rollouts at Scale Progressive rollouts enable organisations to automate their continuous delivery and overal system reliability, which is also being adopted in MLOps. In this post, Monzo engineering covers how they have been able to adopt Argo Rollouts to programmatically automate the rollback or promotion of new deployments based on operational metrics, such as prometheus metrics (errors, failures, etc)."
            },
            {
                "title": "NeurIPS on Prod ML Challenges",
                "link": "https://sites.google.com/view/dmmlsys-neurips2022/home",
                "content": "NeurIPS on Prod ML Challenges Production ML is hard. We are thrilled to join NeurIPS 2022 for the workshop tackling challenges in deployment and monitoring in production machine learning systems. We will be contributing a keynote session on machine learning security - do join us at this as well as the many other exciting sessions."
            }
        ]
    },
    {
        "issue": "206",
        "items": [
            {
                "title": "PyData Global 2022 Coming Up",
                "link": "http://global2022.pydata.org/cfp/speaker/87KPQJ/",
                "content": "We are EXCITED for NeurIPS 2022 coming up next week \ud83e\udd29 Join us next week on Friday at the Workshop on \u201cChallenges in Deploying & Monitoring ML Systems\u201d where we\u2019ll give a Keynote on Security in Prod ML \ud83d\ude80 We\u2019ll also be participating in a panel this week on Algorithmic Responsibility with the ACM, as well as presenting TWO Talks at the PyData Global 2022 \ud83d\udcab We hope to see you there in one of those!"
            },
            {
                "title": "Algorithmic Responsibility Panel",
                "link": "http://www.acm.org/public-policy/ustpc/hottopics/algorithmic-responsibility",
                "content": "We are EXCITED for NeurIPS 2022 coming up next week \ud83e\udd29 Join us next week on Friday at the Workshop on \u201cChallenges in Deploying & Monitoring ML Systems\u201d where we\u2019ll give a Keynote on Security in Prod ML \ud83d\ude80 We\u2019ll also be participating in a panel this week on Algorithmic Responsibility with the ACM, as well as presenting TWO Talks at the PyData Global 2022 \ud83d\udcab We hope to see you there in one of those!"
            },
            {
                "title": "Securing ML Algorithms in EU",
                "link": "http://www.enisa.europa.eu/publications/securing-machine-learning-algorithms",
                "content": "Securing ML Algorithms in EU The EU expects an annual cost reduction of \u20ac180b - \u20ac290b from their recent initiative to revamp their cybersecurity regulation. Production machine learning systems are a critical part of the infrastructure to secure. The European Union Agency for Cyber published a report exploring the securing of machine learning algorithms."
            },
            {
                "title": "Large Language Models Review",
                "link": "http://crfm.stanford.edu/2022/11/17/helm.html",
                "content": "Large Language Models Review Standford\u2019s Center for Research on Foundation Models has published a fantastic analysis of thirty well-known large language models, compared against various metrics including accuracy, robustness, fariness, toxicity, bias and efficiency. This is a fantastic initiative as it provides a step towards standardised evaluation and assessment of this fast-evolving area of large foundational models."
            },
            {
                "title": "SICP: Key CompSci Foundation",
                "link": "http://ocw.mit.edu/courses/6-001-structure-and-interpretation-of-computer-programs-spring-2005/",
                "content": "SICP: Key CompSci Foundation The text-book on Structure and Interpretation of Computer Programs, more popularly known as SICP is a key resource for practitioners looking to build a strong foundation in computer science. This MIT Open Courseware provides an in-depth accompanying resource for anyone looking to dive into (or review) this fantastic book; thorowly recommended for MLE practitioners."
            }
        ]
    },
    {
        "issue": "207",
        "items": [
            {
                "title": "NeurIPS on Prod ML Challenges",
                "link": "http://sites.google.com/view/dmmlsys-neurips2022/home",
                "content": "NeurIPS on Prod ML Challenges Production ML is hard. We are thrilled to join NeurIPS 2022 for the workshop tackling challenges in deployment and monitoring in production machine learning systems. We will be contributing a keynote session on machine learning security - do join us at this as well as the many other exciting sessions."
            },
            {
                "title": "ChatGPT Continues to Surprise",
                "link": "http://www.engraved.blog/building-a-virtual-machine-inside/",
                "content": "ChatGPT Continues to Surprise Thoughout the last week we have continued to see a large number of mind blowing examples of ChatGPT interactions. This recent post shows how they were able to perform what is described as building a virtual machine inside ChatGPT."
            },
            {
                "title": "Advent of Code Skill Polishing",
                "link": "http://adventofcode.com/2022",
                "content": "Advent of Code Skill Polishing The time has arrived to brush up our skills and jump into the advent of code. There will be one programming challenge released every day to take your skills to the test and have some fun, this is a great time to also pick up a new programming language if you\u2019ve been wanting to explore one for a while."
            },
            {
                "title": "Binance MLOps Architecture",
                "link": "http://www.binance.com/en/blog/all/using-mlops-to-build-a-realtime-endtoend-machine-learning-pipeline-3820048062346322706",
                "content": "Binance MLOps Architecture Beyond the hype and madness, organisations in the crypto industry also face interesting ML engineering challenges that require innovative solutions. The binance engineering team puts together an overview of their end to end MLOps architecture throughout their whole model lifecyle."
            },
            {
                "title": "PyTorch 2.0 Has Been Released",
                "link": "http://pytorch.org/get-started/pytorch-2.0/",
                "content": "PyTorch 2.0 Has Been Released A fantastic milestone on the newly Linux Foundation adopted project, Pytorch has released its 2.0 major version release. An exciting achievement for the whole ML community, with a lot of fantstic improvements and plans for the near and long term future."
            }
        ]
    },
    {
        "issue": "208",
        "items": [
            {
                "title": "NeurIPS Workshop Keynote Video",
                "link": "https://www.youtube.com/watch?v=7XSy5aw8oU8",
                "content": "NeurIPS Workshop Keynote Vid NeurIPS 2022 as been another fantastic event. We have been thrilled to contribute to this year\u2019s workshop exploring Challenges in Deploying and Monitoring ML. You can now check out the recording of our talk where we provide a hands on overview of ML security \ud83d\ude80"
            },
            {
                "title": "How Production ML Breaks",
                "link": "http://www.usenix.org/conference/opml20/presentation/papasian",
                "content": "How Production ML Breaks Daniel Papasian and Todd Underwood from Google on \u201cHow ML Breaks: A Decade of Outages for One Large ML Pipeline\u201d. In this presentation they examine one of Google\u2019s largest and oldest ML pipelines, looking at the outages and causes - a must-see for anyone involved in managing large-scale ML pipelines."
            },
            {
                "title": "The Illustrated Stable Diffusion",
                "link": "http://jalammar.github.io/illustrated-stable-diffusion/",
                "content": "The Illustrated Stable Diffusion A fantastic resource that provides \u201cThe Illustrated Stable Diffusion\u201d - an intuitive breakdown of how difussion models generate images. This post helps demsytify this area of generative AI and provide tangible knowledge beyond the hype."
            },
            {
                "title": "The McKinsey State of AI Report",
                "link": "http://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review",
                "content": "The McKinsey State of AI Report The McKinsey State of AI Report is out, outlining interesting trends in the AI ecosystem. Some highlights include the continuous adoption which has more than doubled since 2017, with a select group of companies seeing the highest financial returns from AI continue to pull ahead of competitors."
            },
            {
                "title": "Anomaly Detection Benchmark",
                "link": "http://arxiv.org/abs/2206.09426",
                "content": "Anomaly Detection Benchmark ADBench is a comprehensive benchmark for evaluating anomaly detection algorithms. This paper conducts experiments with 30 algorithms on 57 datasets to identify meaningful insights into the role of supervision and anomaly types, and unlock future directions for researchers in algorithm selection and design."
            }
        ]
    },
    {
        "issue": "209",
        "items": [
            {
                "title": "O\u2019Reilly Trends December 2022",
                "link": "http://www.oreilly.com/radar/radar-trends-to-watch-december-2022/",
                "content": "O\u2019Reilly Trends December 2022 The O\u2019Reilly team has published their monthly Radar Trends, outlining key highlights in the tech ecosystem, ranging across AI, Security, Quantum, General Programming and more."
            },
            {
                "title": "Stanford ML Systems Design",
                "link": "http://stanford-cs329s.github.io/syllabus.html",
                "content": "Stanford ML Systems Design Stanford releases a really interesting new course on ML systems design, put together by thought leaders in the space. The sylabus provides a very comprehensive range of topics, and makes available the slides and resources on further reading."
            },
            {
                "title": "Linux Foundation 2022 Report",
                "link": "http://www.linuxfoundation.org/resources/publications/linux-foundation-annual-report-2022",
                "content": "Linux Foundation 2022 Report The Linux Foundation continues to drive further the computing industry as a whole. In their recently released 2022 anual report they outline some key highlights including the creation of the PyTorch foundation, the impact in security and more."
            },
            {
                "title": "OSS Insights at Scale with TiDB",
                "link": "http://ossinsight.io/blog/why-we-choose-tidb-to-support-ossinsight/",
                "content": "OSS Insights at Scale with TiDB Developing data intensive applications is challenging. This article showcases the approach to ingest the data from the entirity of github.com and extract both historical an real time insights with an extremely simple archiveture, whilst achieving business requirements and short timeframes using TiDB."
            },
            {
                "title": "Statistical vs DL Forecasting",
                "link": "http://github.com/Nixtla/statsforecast/tree/main/experiments/m3",
                "content": "Statistical vs DL Forecasting Although the deep learning hype has continuously delivered, most of the times we benefit from going back to the foundations. This great resource provides a comparison of statistical vs deep learning forecasting methods, emphasising the advantages on speed, explainability, and even accuracy of going back to basics."
            }
        ]
    },
    {
        "issue": "210",
        "items": [
            {
                "title": "The History of AI & Deep Learning",
                "link": "http://people.idsia.ch/~juergen/deep-learning-history.html",
                "content": "The History of AI & Deep Learning The history of Modern AI and Deep Learning has an ambiguous and bumpy lineage. J\u00fcrgen Schmidhuber has put together a fantastic annotated history timeline highlighting key \u201cmost important / relevant\u201d events in the history of neural networks, deep learning, computer science, and mathematics in general, crediting those who laid the foundations of the field."
            },
            {
                "title": "Trends and Insights from Github",
                "link": "http://ossinsight.io/2022/",
                "content": "Trends and Insights from Github The ability to data-mine the entirity of github.com can provide absolutely insightful results. The team behind the OSS Insights project has put together a fantstic analysis extracted from crunching the entirity of github.com 2022 data, showcasing insights on top programming languages, repositories, tech trends, activity and more."
            },
            {
                "title": "AI Generation Text to 3D Models",
                "link": "http://dagshub.com/blog/overview-of-point-e/",
                "content": "AI Generation Text to 3D Models It is indeed hard to believe that only a few weeks ago, the OpenAI team released ChatGPT, a state-of-the-art chatbot model that has taken the world by storm. Now OpenAI has done it again with the release of Point-E, a new model for generating 3D models from text. This article from DagsHub provides a fantastic overview of this new model together with an interactive application."
            },
            {
                "title": "ForwardForward Algorithm Insight",
                "link": "http://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/forward_forward",
                "content": "ForwardForward Algorithm Insight Geoffrey Hinton published the Forward Forward Algorithm last week, an interesting alternative approach to backpropagation which does not require calculating the gradient of the loss function with respect to the network parameters. This codebase provides an intuitive explanation together with an implementation of the algorithms, as well as insightul results against the traditional backprop algorithm."
            },
            {
                "title": "The T-Shaped MLOps Engineer",
                "link": "http://medium.com/@sashman90/mlops-the-evolution-of-the-t-shaped-engineer-a4d8a24a4042",
                "content": "The T-Shaped MLOps Engineer Developing production machine learning infrastructure is challenging, but finding individuals with the right skills to deliver these systems in an organisation is even harder. Exscientia\u2019s MLOps Lead Oleksandr Stasyk has put together insightful thoughts on their journey building MLOps teams and finding the right talent, described as the T-shaped machine learning + engineering + devops skillsets."
            }
        ]
    },
    {
        "issue": "211",
        "items": [
            {
                "title": "2022-2023 Reviews & Predictions",
                "link": "https://github.com/EthicalML/awesome-annual-reviews-and-trends",
                "content": "2022-2023 Reviews & Predictions"
            },
            {
                "title": "Algos & Data Structures to Try",
                "link": "http://austinhenley.com/blog/challengingalgorithms.html",
                "content": "Algos & Data Structures to Try Reviewing computer science foundations seems to always lie within a standardised subset of data structures; linked lists, binary trees, hashmaps, stacks and the usual suspects. However as practitioners we benefit from learning more advanced concepts, and this article providers a great set of algos and data structure every programmer should try, including bloom filters, splay trees, topological sort and more."
            },
            {
                "title": "Day-1 Decisions Make or Break",
                "link": "http://devinterrupted.substack.com/p/the-day-1-decisions-that-make-or",
                "content": "Day-1 Decisions Make or Break Former Github VP Engineering, and current PlanetScale CEO Sam Lambert joins the \u201cDev Interrupted\u201d Podcast in a thoroughly insightful conversation. In this episode he reflects about his time at GitHub, where he helped the then 40th most-trafficked website in the world run on just 2 servers, as well as his experience working at Facebook where he learned that you don\u2019t need to sacrifice quality in order to move fast."
            },
            {
                "title": "Math for Computer Science & ML",
                "link": "http://www.cis.upenn.edu/~jean/gbooks/geomath.html",
                "content": "Math for Computer Science & ML Learning and revewing the mathematical foundations for computer science & machine learning can be a huge booster for practitioner\u2019s core knowledge beyond the hype. This 2000+ page book seems to be the most thorough and complete resource covering the core foundations around Algebra, Topology, Differential Calculus, and"
            },
            {
                "title": "Which AI Explanation to Choose",
                "link": "http://arxiv.org/abs/2206.01254",
                "content": "Which AI Explanation to Choose Explainability in machine learning is a hot topic, but one problem is that different methods for post hoc explanations have different goals, which can lead to a fragmented understanding and make it difficult to know which method to use. This research paper unifies eight popular post hoc explanation methods, showing that they all perform local function approximation of a black-box model. This not only advances our understanding of these methods, but also provides a guiding principle for choosing among them in practice."
            },
            {
                "title": "Annual Year in Review and Tech Predictions",
                "link": "https://github.com/EthicalML/awesome-annual-reviews-and-trends",
                "content": "2022-2023 Reviews & Predictions"
            }
        ]
    },
    {
        "issue": "212",
        "items": [
            {
                "title": "Production MLOps at Ubisoft",
                "link": "http://www.the-odd-dataguy.com/2022/12/29/recap_pydata_mtl_june22/",
                "content": "Production MLOps at Ubisoft Production machine learning use-cases continue to grow in the gaming industry \ud83c\udfae Ubisoft has put together an insightful overview of their journey developing their end to end machine learning systems inspired from Uber\u2019s Michelangelo - they cover design, components, use-cases and beyond."
            },
            {
                "title": "Measuring an Engineering Org",
                "link": "http://lethain.com/measuring-engineering-organizations/",
                "content": "Measuring an Engineering Org Measuring engineering success can be challenging and ambiguous. Will Lethain, author of \u201cAn Elegant Puzzle\u201d and \u201cStaff Engineer\u201d has put together an insightful article exploring effective ways on measuring engineering teams and organizations. He proposes a template for identifying some initial metrics that can provide meaningful value, as well as approaches to expand further."
            },
            {
                "title": "2022-2023 Reviews & Predictions",
                "link": "http://github.com/EthicalML/awesome-annual-reviews-and-trends",
                "content": "Annual Year in Review and Tech Predictions"
            },
            {
                "title": "Reinforcement Learning Summary",
                "link": "http://arxiv.org/abs/2301.01379",
                "content": "Reinforcement Learning Summary A Succinct Summary of Reinforcement Learning. This document is a concise summary of many key results in single-agent reinforcement learning. The intended audience are those who already have some familiarity with RL and are looking to review, reference and/or remind themselves of important ideas in the field."
            },
            {
                "title": "FastAPI Framework Best Practice",
                "link": "http://github.com/zhanymkanov/fastapi-best-practices",
                "content": "FastAPI Framework Best Practice FastAPI is continuously adopted for productionisation of machine learning powered applications. This resource provides an opinionated list of best practices and conventions. It covers project structure, formatting, tools, frameworks, documentation and much more."
            },
            {
                "title": "Annual Year in Review and Tech Predictions",
                "link": "https://github.com/EthicalML/awesome-annual-reviews-and-trends",
                "content": "2022-2023 Reviews & Predictions As 2023 begins we look forward to reading the numerous & exciting year-in-review & tech predictions articles \ud83e\udd13However instead of filling this newsletter with these, we have put together a comprehensive list of \u201cAwesome Annual Tech Reviews & Predictions\u201d, containinga long list of year-in-review & tech predictions articles for 2022-2023. This list covers resources from open source projects, tech companies, thought leaders and NGOs ranging across AI, Data, GameDev, General Tech, Security and beyond \ud83d\ude80 This is still a list in progress - please help us by adding a pull request with any relevant resources you find!"
            }
        ]
    },
    {
        "issue": "213",
        "items": [
            {
                "title": "Doordash from Heuristic to ML",
                "link": "http://doordash.engineering/2023/01/10/how-doordash-upgraded-a-heuristic-with-ml-to-save-thousands-of-canceled-orders/amp/",
                "content": "Doordash from Heuristic to ML Heuristics can become expensive, especially when manual work is involved. Doordash shares their interesting journey introducing ML image classification to automate closed-store validation, ultimately improving their customer experience and operational efficiency with real-world machine learning."
            },
            {
                "title": "Big Data with P(X) Data Structures",
                "link": "http://www.kdnuggets.com/2019/08/count-big-data-probabilistic-data-structures-algorithms.html",
                "content": "Big Data w P(X) Data Structures How do you count big data? Probabilistic data structures have answered this question across a large number of usecases. This article provides an intuition to traditional probabilistic data structures like Bloom filters, and introduces other insightful ones such as HyperLogLog, q-digest, Count-Min-Sketch, SimHash, and others."
            },
            {
                "title": "ML Papers Explained",
                "link": "http://github.com/dair-ai/ML-Papers-Explained",
                "content": "ML Papers Explained A fantastic TLDR; for research papers - this repository \u201cML Papers Explained\u201d provides a great summary and intuitive overview of a long and actively growing list of research papers in ML. Check it out and if you\u2019re able to do contribute."
            },
            {
                "title": "Myths and Legends in HPC",
                "link": "http://arxiv.org/pdf/2301.02432.pdf",
                "content": "Myths and Legends in HPC Myths and legends in high performance computing \u26a1 this humorous and thought provoking article dives into common myths such as quantum computing vs HPC, deep learning, GPU/TPU accelerators and much more."
            },
            {
                "title": "Talking AI with AI from Greylock",
                "link": "http://greylock.com/greymatter/reid-hoffman-chatbots-talking-ai-with-ai/",
                "content": "Talking AI with AI from Greylock We had to see this coming, a live podcast conversating with ChatGPT \ud83e\udde0 Greylock Partner and Linkedin Founder Reid Hoffman has put together a podcast where he talks about AI with ChatGPT in a podcast-conversation medium, and it is what it basically what you can expect."
            }
        ]
    },
    {
        "issue": "214",
        "items": [
            {
                "title": "Karpathy Building 0->1 ChatGPT",
                "link": "https://www.youtube.com/watch?v=kCc8FmEb1nY",
                "content": "Karpathy Building 0->1 ChatGPT Andrej Karpathy has put together a fantastic 2-hour tutorial where he builds a Generative Pretrained Transformer (GPT). He goes through a step-by-step walkthrough starting from the basics, and following OpenAI\u2019s GPT2/GPT3 paper \u201cAttention is All You Need\u201d."
            },
            {
                "title": "Raschka on Model Eval/Selection",
                "link": "http://arxiv.org/pdf/1811.12808.pdf",
                "content": "Raschka on Model Eval/Selection Sebastian Raschka on best practices in Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning. This paper contains a comprehensive techniques in ML for essential model evaluation techniques, and covers into foundations such as cross-validation, hyperparam optimization, algorithm comparison, and more."
            },
            {
                "title": "Deep Learning Tuning Playbook",
                "link": "http://github.com/google-research/tuning_playbook",
                "content": "Deep Learning Tuning Playbook Google Research on their Deep Learning Tuning Playbook. In collaboration with the Google Brian team, this great resource covers topics relevant for practitioners interested in maximizing the performance in deep learning models, and emphasises the process of hyperparameter tuning techniques and best practices."
            },
            {
                "title": "Hidden Tech Debt in Prod ML",
                "link": "http://www.linkedin.com/pulse/hidden-tech-debts-machine-learning-systems-frank-teoh/",
                "content": "Hidden Tech Debt in Prod ML The Director of Machine Learning Platform at Chime shares his thoughts on Hidden Tech Debts in Machine Learning system. This interesting article covers 5 key tech debt areas together with suggested mitigation approaches that can be explored."
            },
            {
                "title": "Working with Golang and SQL",
                "link": "http://betterstack.com/community/guides/scaling-go/sql-databases-in-go/",
                "content": "Working with Golang and SQL Golang has become a highly popular language for distributed systems as well as data intensive applications. This article provides a comprehensive overview of the principles, concepts and basics of interacting with a postgres database with the built-in database/sql package."
            }
        ]
    },
    {
        "issue": "215",
        "items": [
            {
                "title": "AI-Assisted Programming Costs",
                "link": "http://arxiv.org/abs/2210.14306",
                "content": "AI-Assisted Programming Costs The hidden costs of AI-Assisted Programming from Microsoft Research \ud83e\udd16 The Microsoft Research team has released a very insightful study that evaluates the benefits of AI-assisted programming with tools like copilot. Kudos for sharing quite insightful results as well as a surprising overview of the high overhead added from double-checking and verifying the results. What is more, the accompanying code was shared as well in an OSS repo which is always welcome for reproducible openresearch."
            },
            {
                "title": "Text-to-basically-any-sound-effect",
                "link": "http://text-to-audio.github.io/",
                "content": "Text-to-basically-any-sound-effect The day has come; a text-to-basically-any-sound-effect has been released \ud83e\udd2f We keep getting surprised every week with the new creative approaches to Generative AI. This week ByteDance, the company behind Tiktok, has released the output from an academic collaboration on what is a text-to-sound-effect model. As the caption suggests, it provides interesting results providing creative prompts with surprising results. Certainly an exciting time to be in the field of AI."
            },
            {
                "title": "The Illustrated Stable Diffussion",
                "link": "http://jalammar.github.io/illustrated-stable-diffusion/",
                "content": "The Illustrated Stable Diffussion The Illustrated Stable Diffusion \ud83c\udfa8\ud83d\udd8c\ufe0f One of the most intuitive and comprehensive overviews of the internals and components of stable difussion models. This article keeps getting better with consistent updates, references, and resources."
            },
            {
                "title": "Transformer Models Introduction",
                "link": "http://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/",
                "content": "Transformer Models Introduction Transformer models: an introduction and catalog \u2014 2023 Edition \ud83d\udcc7 A great resource that collected over 50 transformer models into a single catalogue, together with an overview of transformer models, and several taxonomies exploring the chronological perspective, groupings across model families, and short overviews for each of the models, together with its respective code implementation if anyone is looking to add a PR."
            },
            {
                "title": "SQLAlchemy 2.0 Release Post",
                "link": "http://www.sqlalchemy.org/blog/2023/01/26/sqlalchemy-2.0.0-released/",
                "content": "SQLAlchemy 2.0 Release Post The first production release of SQLAlchemy 2.0, is now available \ud83d\ude80 This is an exciting milestone which started almost 5 years ago, and brings substantial usability updates to a framework that has become one of the cornerstone ORM frameworks. Taking inspiration from the now growingly popular SQLModel project, it\u2019s brought tons of usability and core improvements. If you haven\u2019t tried it (or haven\u2019t in a while) do check it out at the SQLAlchemy/Sqlalchemy repo."
            }
        ]
    },
    {
        "issue": "216",
        "items": [
            {
                "title": "GitHub CEO on Europe & AI Act",
                "link": "http://www.linkedin.com/pulse/europes-chance-leader-age-ai-thomas-dohmke/",
                "content": "GitHub CEO on Europe & AI Act Github CEO Thomas Dohmke shares thoughts on the AI act supporting Open Source developers \ud83d\udcbb During this open letter he also maks a call-to-action to Europe to drive forward this chance to be a leader in the age of AI. For anyone interested in this area, you can also check out the contributions we made during the open European Commission consultation."
            },
            {
                "title": "Google\u2019s AI Text-Video Editing",
                "link": "http://dreamix-video-editing.github.io/",
                "content": "Google\u2019s AI Text-Video Editing Google releases a Generative AI Text-to-Video-Editing Project \ud83e\udd2f This latest release showcases impressive realistic performance of video editing, as well as custom-video-creation from a stale image. In the demos they show how an input video can be modified with a text input, as well as how it also works with stale images which are converted into a custom-modified video with relatively high fidelity. Demos: https://dreamix-video-editing.github.io/. Paper: https://arxiv.org/pdf/2302.01329.pdf."
            },
            {
                "title": "Data Version Control AI Course",
                "link": "http://learn.iterative.ai/",
                "content": "Data Version Control AI Course The team behind the highly popular Data Version Control (DVC) project have released a highly comprehensive online course \ud83e\udd16 This online course covers Best practices for going from Jupyter Notebook to Production for Data Scientists and Analysts. This resource covers tools for efficient collaboration, pipelines, model & data versioning, metrics, experiment management and more."
            },
            {
                "title": "Andrew Ng on Data Centric AI",
                "link": "http://www.youtube.com/watch?v=avoijDORAlc",
                "content": "Andrew Ng on Data Centric AI Andrew Ng on Data Centric AI \u262f\ufe0f Data-centric AI is a growing movement which shifts the engineering focus in AI systems from the model to the data. However, Data-centric AI faces many open challenges, including measuring data quality, data iteration and engineering data as part of the ML project workflow, data management tools, crowdsourcing, data augmentation & data synthesis as well as responsible AI. This talk names the key pillars of Data-centric AI, identifies the trends in Data-centric AI movement, and sets a vision for taking ideas applied intuitively by a handful of experts and synthesizing them into tools that make the application systematic for all."
            },
            {
                "title": "Monitoring at Scale Prom Tutorial",
                "link": "http://grafana.com/blog/2023/01/19/how-to-monitor-kubernetes-clusters-with-the-prometheus-operator/",
                "content": "Monitoring at Scale Prom Tutorial Kubernetes has become the preferred tool for DevOps engineers to deploy and manage containerized applications (including ML workloads) at scale. Observability has now become a core requirement in any production machine learning system. This comprehensive tutorial from Grafana Labs covers in detail how to introduce observability at scale in Kubernetes through the prometheus operator and beyond."
            }
        ]
    },
    {
        "issue": "217",
        "items": [
            {
                "title": "Awesome Production ML OSS",
                "link": "http://github.com/EthicalML/awesome-production-machine-learning",
                "content": "Awesome Production ML OSS Our Prod ML List has reached over 13,000 stars \u2b50\u2b50\u2b50 It is quite an honour to celebrate this milestone together with the growing list of 154 (!) contributors that have made this milestone possible \ud83d\ude80\ud83d\ude80\ud83d\ude80 The growth of the list continues, adding new sections that cover the end-to-end production lifecycle of machine learning \ud83e\udd16 if you havent done so, do check it out, and if something is missing we would be very grateful for an issue or a PR \ud83d\ude4f"
            },
            {
                "title": "Tech Behind Github Code Search",
                "link": "http://github.blog/2023-02-06-the-technology-behind-githubs-new-code-search/",
                "content": "Tech Behind Github Code Search The technology behind GitHub\u2019s new code search \ud83d\udd0e An interesting analysis on what went into building the world\u2019s largest public code search index (spoiler: not ChatGPT). This post covers the approach Github took towards indexing 45m+ repositories, the nuances of building an index, the distributed architecture, life of a query and more."
            },
            {
                "title": "Preparing for the Europe AI Act",
                "link": "http://thedataexchange.media/preparing-for-the-implementation-of-the-eu-ai-act-and-other-ai-regulations/",
                "content": "Preparing for the Europe AI Act Are you prepared for the Implementation of the EU AI Act and Other AI Regulations? \ud83d\udd12 This Data Exchange podcast invites tech and legal expert practitioners to dive into the soon-to-be-introduced AI Act. This provides one of the more intuitive overviews of this policy, as well as references to resources that can be explored as we approach the looming introduction-deadline. For anyone interested in AI regulation, you can also check out the contributions we made during the AI act consultation."
            },
            {
                "title": "Rise of Enterprise AI Leadership",
                "link": "http://www.linkedin.com/pulse/rise-ai-leadership-enterprise-hussein-mehanna/",
                "content": "Rise of Enterprise AI Leadership The rise of AI leadership in the enterprise \ud83d\udca1 Cruise Head of AI & Machine Learning Hussein Mehanna dives into the emergence of AI leadership in industry. A very interesting post that highlights the difference between traditional software leaders from AI leaders, ranging across experience, knowledge, a hypothesis mindset, and data; lots of data."
            },
            {
                "title": "React.js The Documentary",
                "link": "http://www.youtube.com/watch?v=8pDqJVdNa44",
                "content": "React.js The Documentary React.js: The Documentary \ud83e\uddd1\u200d\ud83d\udcbb Following the success of the Kubernetes Documentary and the Prometheus documentary (both which were excellent and recommended watches), this documentary covers the creation, growth and evolution of one of the most popular frameworks for web user interface development. I\u2019ve had the pleasure to work in many (ML) products developed in React.JS, and would recommend watching it to get an intutiion on how it\u2019s become such a popular and highly used tool."
            }
        ]
    },
    {
        "issue": "218",
        "items": [
            {
                "title": "Incredible PyTorch Ecosystem",
                "link": "http://github.com/ritchieng/the-incredible-pytorch",
                "content": "Incredible PyTorch Ecosystem The Incredible PyTorch \ud83d\udd25 A curated list of tutorials, papers, projects, communities and more relating to PyTorch. This resource does seem to put together a really comprehensive set of resources which would be useful for practitioners interested to dive deeper into the PyTorch ecosystem."
            },
            {
                "title": "Large Scale RecSys Architectures",
                "link": "http://amatriain.net/blog/RecsysArchitectures",
                "content": "Large Scale RecSys Architectures The evolution of Recommender Systems; Architectural Blueprints \ud83d\udca1 This resource does a great job of compiling several of the most comprehensive end-to-end recommender system architectural blueprints, providing a high level overview of each as well as interesting thoughts. Finally it proposes its own take with a blueprint that encompasses all the relevant components through a data-centric perspective."
            },
            {
                "title": "Technology Trends 2023 February",
                "link": "http://www.oreilly.com/radar/radar-trends-to-watch-february-2023/",
                "content": "Technology Trends 2023 February O\u2019Reilly shares technology trends for February 2023 \ud83e\udd16 This article dives into interesting resources around technology across various fields including AI, Data, Security, General Programming and more"
            },
            {
                "title": "Flask to FastAPI Migration Series",
                "link": "http://engineering.forethought.ai/blog/2023/02/14/migrating-from-flask-to-fastapi-part-2/#",
                "content": "Flask to FastAPI Migration Series A comprehensive migration guide and comparison of Flask to FasfAPI by its author Author Sebastian Ramirez \ud83d\udd0d This resource provides a step by step walkthrough of the conceptual and practical steps required to migrate a Flask project into FastAPI. It also provides a set of examples for the most common features for each of the frameworks."
            },
            {
                "title": "The ArXiv of ChatGPT Failures",
                "link": "http://arxiv.org/abs/2302.03494",
                "content": "The ArXiv of ChatGPT Failures A Categorical Archive of ChatGPT Failures \ud83d\ude05 Throughout the last couple of weeks we have seen the highs and the lows of generative AI - this paper provides a taxonomy-like overview of failure-themes of ChatGPT. Resources like these provide an interesting perspective to ensure continued improvement for what is still a very emerging and fast evolving field."
            }
        ]
    },
    {
        "issue": "219",
        "items": [
            {
                "title": "NeurIPS 2022 Prod ML Videos",
                "link": "https://nips.cc/virtual/2022/workshop/49982",
                "content": "NeurIPS 2022 Prod ML Videos The NeurIPS 2022 Workshop on Challenges in ML Systems has now released the recordings, including our keynote on ML Security \ud83d\ude80 This was a fantastic resource diving into real world use-cases and best practices\u00a0Deploying and Monitoring machine learning systems, and has a fantastic set of speakers across industry and academy covering topics in ML Security, federated learning, monitoring and more. You can find our keynote on Production ML Security directly together with the respective slides and resources."
            },
            {
                "title": "MIT Intro to Data-Centric ML",
                "link": "http://dcai.csail.mit.edu/",
                "content": "MIT Intro to Data-Centric ML MIT launches a course on Data-Centric AI \ud83d\ude80 This is the first-ever course on Data-Centric AI. This class covers algorithms to find and fix common issues in ML data and to construct better datasets, concentrating on data used in supervised learning tasks like classification. All material taught in this course is highly practical, focused on impactful aspects of real-world ML applications, rather than mathematical details of how particular models work. You can take this course to learn practical techniques not covered in most ML classes, which will help mitigate the \u201cgarbage in, garbage out\u201d problem that plagues many real-world ML applications. Videos are available on Youtube, together with the respective course materials."
            },
            {
                "title": "MAD: ML, AI & Data Landscape",
                "link": "http://mattturck.com/mad2023/",
                "content": "MAD: ML, AI & Data Landscape The 2023 MAD (Machine Learning, Artificial Intelligence & Data) Landscape has now been released \ud83d\ude08 The MAD landscape is now an annualy-released resource covering the AI/ML landscape, together with market trends, trends in data infrastructure and trends in general ML & AI."
            },
            {
                "title": "Curated List on Applied ML",
                "link": "http://github.com/eugeneyan/applied-ml",
                "content": "Curated List on Applied ML Applied ML Repo (23k+ \u2b50) A fantastic resource containing curated papers, articles and blogs on data science and machine learning in production. For anyone figuring out how to implement ML in your projects, this resource provides how organisations did it: 1) How the problem is framed, 2) what machine learning techniques worked, 3) why it works, 4) what real-world results were achieved."
            },
            {
                "title": "ML Innovation at Spotify with Ray",
                "link": "http://engineering.atspotify.com/2023/02/unleashing-ml-innovation-at-spotify-with-ray/",
                "content": "ML Innovation at Spotify with Ray Unleashing ML Innovation at Spotify with Ray \ud83d\udca1 Spotify founded its machine learning (ML) platform in 2018 to provide a gold standard for reliable and responsible production ML. In early 2020, their ML Platform expanded to cover the ML production workflow for Spotify\u2019s ML practitioners with four core product offerings. This article dives into the next evolution of Spotify\u2019s ML infrastructure."
            }
        ]
    },
    {
        "issue": "220",
        "items": [
            {
                "title": "Large Language & Image Models",
                "link": "http://www.youtube.com/watch?v=RVUi_rAFfzU",
                "content": "Large Language & Image Models Productionising Machine Learning Systems at Scale is one of the biggest challenges this year, and Large Language/Image models introduce complex challenges \ud83d\udca1 Our talk from PyData Global 2022 is now on YouTube, and provides a detailed overview of the challenges and solutions for productionising Large Image/Text/Anything Models. In this resource we take a relatively amusing approach, where we deploy a ML Pipeline with a GPT model as the pre-processor and a text-to-image GenAI model as the post-processor. This allowed for a \u201ccreative\u201d workflow where images are created from a single word, into a generated phrase, into an image. The code is fully open source so do test it out or please do contribute with a PR \ud83d\udd28"
            },
            {
                "title": "Real World ML Systems Survey",
                "link": "http://arxiv.org/abs/2302.04810",
                "content": "Real World ML Systems Survey Real-world Machine Learning Systems: A survey from a Data-Oriented Architecture Perspective \ud83e\udd16 Cambridge researchers share an insigthful and comprehensive survey on production machine learning systems demystifying the emerging topic of data-centric ML. This research paper focuses particularly on challenges and insights around deployment, monitoring and maintenance of machine learning systems."
            },
            {
                "title": "Coinbase High-Perf Data Series",
                "link": "http://www.coinbase.com/blog/soon-for-near-real-time-data-at-coinbase-part-1",
                "content": "Coinbase High-Perf Data Series Real time high-performance data at Coinbase \ud83e\ude99 An interesting series from Coinbase discussing their journey tackling high-performance data challenges across their organisations at scale. In this resource they provide useful information on their architecture, technologies, benchmarks, principles and next steps."
            },
            {
                "title": "NVIDIA OSS RecSys Ecosystem",
                "link": "http://medium.com/nvidia-merlin/nvidia-merlin-meets-the-mlops-ecosystem-building-a-production-ready-recsys-pipeline-on-cloud-1a16c156166b",
                "content": "NVIDIA OSS RecSys Ecosystem NVIDIA OSS Recommender System meets the MLOps ecosystem: building a production-ready RecSys pipeline on cloud \ud83d\udd0dThis post provides a high level overview of production challenges when adopting and productionising recommender systems. It provides a practical example to tackle a real-life challenge, providing an intuition on the architecture as well as code for training, testing, serving and beyond using ecosystem tooling such as Metaflow, DBT, and more."
            },
            {
                "title": "20 Lessons in 20 Years of Dev",
                "link": "http://www.simplethread.com/20-things-ive-learned-in-my-20-years-as-a-software-engineer/",
                "content": "20 Lessons in 20 Years of Dev 20 Lessons from 20 years in developing software \ud83d\udda5\ufe0f A great high level article providing 20 points of advise from a long career in software engineer, aiming to outline a set of principles that are important to consider for a meaningful and consciencious approach to software as a applicable and useful craft."
            }
        ]
    },
    {
        "issue": "221",
        "items": [
            {
                "title": "LLM Stable Diffussion Moment",
                "link": "http://simonwillison.net/2023/Mar/11/llama/",
                "content": "LLM Stable Diffussion Moment Large language models are having their Stable Diffusion moment \ud83d\udca1 Running GPT-3 equivallent models in a higher end laptops is now possible. This blog post shows how you can use the recently released Llama.cpp package to run Meta\u2019s released models in a Mac M1 Ultra by running the model using 4-bit quantization. This resource also provides insightful resources covering useful informal use-cases in practical scenarios."
            },
            {
                "title": "The Utility DataFlow Computing",
                "link": "http://www.sigops.org/2020/the-remarkable-utility-of-dataflow-computing/",
                "content": "The Utility DataFlow Computing the abstraction of dataflow computing is a remarkably powerful one \ud83e\uddbe Mapping computations into dataflow graphs has given us better, more fault-tolerant and scalable distributed systems, better compilers, and better databases. This is the underlying concept behind the now emerging field of data-centric machine learning. This post provides a comprehensive overview and review of the potential of dataflow computing."
            },
            {
                "title": "Postgres Architecture Explained",
                "link": "http://www.youtube.com/watch?v=Q56kljmIN14",
                "content": "Postgres Architecture Explained A deep dive into the postgres architectrural internals \ud83d\udd0e This resource does a great job to dissect and explore one of the most ubiquitous tools in production systems, the postgres database. This covers an intuitive overview of the various components, as well as commentary on assumptions and tradeoffs that the internals introduce in practice."
            },
            {
                "title": "Cost of Architectural Complexity",
                "link": "http://www.linkedin.com/pulse/cost-architectural-complexity-abi-noda/",
                "content": "Cost of Architectural Complexity It can often be hard to quantify and verbalise the business impact of technical debt \ud83d\udcb8 This article provides an intutiive overview of a 2013 MIT paper on the cost of Architectural Complexity. This is a fantastic resource for practitioners that are looking to understand the costs of complexity, as well as the number of bugs/deffects, the productivity costs and more."
            },
            {
                "title": "Migrating from Flask to FastAPI",
                "link": "http://engineering.forethought.ai/blog/2023/02/28/migrating-from-flask-to-fastapi-part-3/",
                "content": "Migrating from Flask to FastAPI A comprehensive migration guide and comparison of Flask to FasfAPI by its author Author Sebastian Ramirez \ud83d\udd0d This is the third part for the migration resource that provides a step by step walkthrough of the conceptual and practical steps required to migrate a Flask project into FastAPI. It also provides a set of examples for the most common features for each of the frameworks."
            }
        ]
    },
    {
        "issue": "222",
        "items": [
            {
                "title": "Language Models ArXiv Paper",
                "link": "http://arxiv.org/abs/2303.05759",
                "content": "Language Models ArXiv Paper Language modeling studies probability distributions over text strings, and is used in NLP for various applications such as text generation, speech recognition, and machine translation \ud83d\udca1 Conventional language models (CLMs) predict linguistic sequences, while pre-trained language models (PLMs) have broader applications and are trained in a self-supervised manner. This paper provides an introduction to both CLMs and PLMs and discusses their linguistic units, structures, training and evaluation methods, applications, relationship, and future directions in the LLM era."
            },
            {
                "title": "Discord\u2019s Trillions of Messages",
                "link": "http://discord.com/blog/how-discord-stores-trillions-of-messages",
                "content": "Discord\u2019s Trillions of Messages Discord, the instant messaging app with over 300 million active users, has shared insights into how they store trillions of messages \ud83e\udd16 The article explains how they transitioned from MongoDB to Cassandra and then to ScyllaDB due to scalability requirements of trillions of messages. The case study demonstrates the challenges in managing and scaling a distributed database to store and retrieve large amounts of data for applications with significant user activity."
            },
            {
                "title": "LLM Prompt Engineering Guide",
                "link": "http://www.promptingguide.ai/",
                "content": "LLM Prompt Engineering Guide Prompt engineering is a new discipline that helps to develop and optimize prompts for efficient use of large language models (LLMs) in various applications and research topics \u2699\ufe0f It enables better understanding of the capabilities and limitations of LLMs and is used to improve the capacity of LLMs on common and complex tasks like question answering and arithmetic reasoning. This new prompt engineering guide contains papers, learning guides, models, lectures, references, new LLM capabilities, and more."
            },
            {
                "title": "Fully OSS Alternative to ChatGPT",
                "link": "http://github.com/LAION-AI/Open-Assistant/",
                "content": "Fully OSS Alternative to ChatGPT Open Assistant is an open-source project that aims to provide a chat-based large language model to everyone \ud83e\udd17 The project is also enabling data collection to submit, rank, and label model prompts and responses to train models via crowd-sourcing and enable an open accessible AI assistant framework that can perform meaningful tasks, research information, and be personalized and extended by anyone."
            },
            {
                "title": "Airflow and Great Expectations",
                "link": "http://eliasbenaddouidrissi.dev/posts/data_engineering_project_monzo/",
                "content": "Airflow and Great Expectations A great tutorial to automate your personal finances with Airflow \ud83c\udf00 This tutorial walks throug the steps to automate budget tracking and generate a dashboard for visualizing personal financial data. It involves common used tools across the ecosystem including containers, great expectations, airflow, postgres and more."
            }
        ]
    },
    {
        "issue": "223",
        "items": [
            {
                "title": "ChatGPT Internals and Interface",
                "link": "http://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/",
                "content": "ChatGPT Internals and Interface What Is ChatGPT Doing \u2026 and Why Does It Work? \ud83e\udd14 This article covers the inner workings of ChatGPT and its ability to generate human-like text. It dives into the intuition on how tokens are selected\u00a0 with a \u201ctemperature\u201d parameter controlling randomness, as well as the different compoents. The article also demonstrates the process using the GPT-2 model and Wolfram Language code."
            },
            {
                "title": "Training ML Across 1000 GPUs",
                "link": "http://www.anyscale.com/blog/training-175b-parameter-language-models-at-1000-gpu-scale-with-alpa-and-ray",
                "content": "Training ML Across 1000 GPUs Training a 175B param model across 1000 GPUs \ud83e\udd2f This blogpost provides an overview on how Alpa and Ray can be used to train a 175B parameters OPT-175B model (equivalent to GPT-3) with pipeline parallelism up to 1024 A100 GPUs. The benchmarks show that Alpa can scale beyond 1000 GPUs for 175 billion parameter scale LLMs and achieve SOTA peak GPU utilization and HW FLOPs per GPU. The article also provides background information on large language models (LLM) and discusses the challenges of training these models with billions of parameters."
            },
            {
                "title": "Early Experiments with GPT4",
                "link": "http://arxiv.org/abs/2303.12712",
                "content": "Early Experiments with GPT4 The Microsoft Research team publishes their early access experience with GPT4 \u2712\ufe0f This paper covers a comprehensive overview of the development of OpenAI\u2019s GPT-4, and dives into multiple use-cases and analysis across different aras including multi-modality, code, mathematical abilities, interaction with the world, and more."
            },
            {
                "title": "The AI-Powered Dev Experience",
                "link": "http://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/",
                "content": "The AI-Powered Dev Experience GitHub Copilot X has been making waves \ud83c\udf0aThis AI assistant for software developers is now being used across the end-to-end development lifecycle. The github post showcases fantastic features including chat and voice interfaces, support for pull requests, and AI-generated answers to questions on project documentation. This will introduce interesting advancements together with open questions for AI-to-AI/Human interactions across developer tooling."
            },
            {
                "title": "Google ML Crashcourse w TF",
                "link": "http://developers.google.com/machine-learning/crash-course",
                "content": "Google ML Crashcourse w TF Google\u2019s free onlien Machine Learning Crash Course \ud83d\udcb8 A course designed to provide a basic understanding of machine learning concepts, tools, and techniques, intended for programmers with little or no experience in machine learning. It covers topics such as supervised and unsupervised learning, neural networks, feature engineering, regularization, and evaluation of machine learning models."
            }
        ]
    },
    {
        "issue": "224",
        "items": [
            {
                "title": "Facebook\u2019s MLOps Ecosystem",
                "link": "http://ai.facebook.com/blog/meta-ai-ecosystem-management-metrics/",
                "content": "Facebook\u2019s MLOps Ecosystem Facebook/Meta shares their approach to organisation-wide MLOps \ud83d\udca1 Facebook/Meta has developed measurement processes to manage AI models effectively and efficiently, and shares techniques that can be applied broadly in other organizations. They discuss the goals and principles of AI model management, Meta\u2019s ML-Ops ecosystem, and the importance of consistently defining key concepts in AI model management. The taeam also emphasize the need for a clear metadata architecture to bridge specific system implementations via common labels. If you are interested in the topic you can check out the recording of our talk on Metadata Systems for End-to-End Data & Machine Learning at PyData Global 2022."
            },
            {
                "title": "Twitter OSS Recommender Algo",
                "link": "http://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm",
                "content": "Twitter OSS Recommender Algo Twitter Open Sources its tweet-recommendation algorithm \u26a1 This is a fascinating resource, as it showcases the recommendation algorithm internals, which uses a set of core models and features to extract latent information from tweet, user, and engagement data. The algorithm is composed of candidate sourcing, ranking, and filtering stages. The ranking stage uses a neural network trained on tweet interactions to optimize for positive engagement, and heuristics and filters are applied to create a balanced and diverse feed. We have also seen already some controversial code being removed followed by a swarm of comments / gifs / memes in the commit hash."
            },
            {
                "title": "Large Language Models MLOps",
                "link": "http://www.youtube.com/watch?v=RVUi_rAFfzU",
                "content": "Large Language Models MLOps Productionising Machine Learning Systems at Scale is one of the biggest challenges this year, and Large Language/Image models introduce complex challenges \ud83d\udca1 Our talk is now on YouTube, and provides a detailed overview of the challenges and solutions for productionising Large Image/Text/Anything Models. In this resource we take a relatively amusing approach, where we deploy a ML Pipeline with a GPT model as the pre-processor and a text-to-image GenAI model as the post-processor. This allowed for a \u201ccreative\u201d workflow where images are created from a single word, into a generated phrase, into an image. The code is fully open source so do test it out or please do contribute with a PR \ud83d\udd28"
            },
            {
                "title": "GPT-4-ALL Access with LLaMa",
                "link": "http://github.com/nomic-ai/gpt4all",
                "content": "GPT-4-ALL Access with LLaMa GPT-4-ALL making the ChatGPT experience accessible to all \ud83e\udd16 Following the fascinating developments from last week which saw LLaMa 30b running on 6GB RAM via mmap fundamentals, we now see projects like GPT-4-ALL providing tooling to leverage these innovations at the application level in ever-simpler workflows. These projects are fully open source and benefit from community interactions and feedback so do feel free to contribute."
            },
            {
                "title": "Finance GenAI with BloombergGPT",
                "link": "http://arxiv.org/abs/2303.17564",
                "content": "Finance GenAI w BloombergGPT Bloomberg has released a new language model called BloombergGPT, specifically trained on financial data \ud83d\udcb8 With 50 billion parameters and 363 billion tokens it claims itself as the largest domain-specific dataset. The model has outperformed existing models on financial tasks without sacrificing performance on general LLM benchmarks, such as those of GPT-NeoX and OPT 66B. BloombergGPT can perform financial question answering, sentiment analysis, NER, and generate valid Bloomberg Query Language and short headline suggestions."
            }
        ]
    },
    {
        "issue": "225",
        "items": [
            {
                "title": "Stanford\u2019s AI Index Report 2023",
                "link": "http://aiindex.stanford.edu/report/?sf176386094=1",
                "content": "Stanford\u2019s AI Index Report 2023 Stanford releases the annual AI Index Report \ud83d\udca1 The AI Index Report is an annual report that tracks and visualizes data related to artificial intelligence with the aim of enabling decision-makers to advance AI responsibly and ethically with humans in mind. The 2023 report indicates that industry has overtaken academia in producing significant machine learning models, and AI is both helping and harming the environment. The demand for AI-related professional skills is increasing across virtually every American industrial sector, and policymaker interest in AI is on the rise. Additionally, the number of incidents concerning the misuse of AI is rapidly rising, and it highlights that Chinese citizens feel more positively about AI products and services than Americans do."
            },
            {
                "title": "FastAI New Advanced ML Course",
                "link": "http://www.fast.ai/posts/part2-2023.html",
                "content": "FastAI New Advanced ML Course The article announces the release of a new course, \u201cFrom Deep Learning Foundations to Stable Diffusion,\u201d which is part 2 of Practical Deep Learning for Coders. The course covers over 30 hours of video content and includes the implementation of the Stable Diffusion algorithm from scratch, along with other diffusion methods. The course also covers essential deep learning topics such as neural network architectures, data augmentation approaches, loss functions, and deep learning optimizers, among others."
            },
            {
                "title": "Top ML Papers to Read in 2023",
                "link": "http://www.kdnuggets.com/2023/03/top-machine-learning-papers-read-2023.html",
                "content": "Top ML Papers to Read in 2023 The article highlights 9 top machine learning papers that production machine learning practitioners should read in 2023, covering a range of topics such as generative models, time series analysis, optimization algorithms, synthetic data generation, natural language processing, text-to-video generation, and workflow efficiency. The papers include research on neural singing voice beautification, a new optimization algorithm for neural networks, a method for transforming 1D time series data into 2D data, an open pre-trained transformer language model, a model for generating realistic relational and tabular data, benchmarks for natural language policy optimization using reinforcement learning, a method for tuning text-to-video generation, and a library for efficiently sharing machine learning ideas."
            },
            {
                "title": "OpenAI Approach to AI Safety",
                "link": "http://openai.com/blog/our-approach-to-ai-safety",
                "content": "OpenAI Approach to AI Safety OpenAI publishes their approach to AI Safety \ud83e\udd16 This approach encompasses rigorous testing, engaging external experts for feedback, building monitoring systems, and using reinforcement learning with human feedback to improve the model\u2019s behavior. OpenAI outlines the importance of substantial safeguards to make continuous improvements based on lessons learned from real-world use. There is also emphasis on protecting children, respecting privacy, and improving factual accuracy."
            },
            {
                "title": "Facebook\u2019s MLOps Ecosystem",
                "link": "http://ai.facebook.com/blog/meta-ai-ecosystem-management-metrics/",
                "content": "Facebook\u2019s MLOps Ecosystem Facebook/Meta shares their approach to organisation-wide MLOps \ud83d\udca1 Facebook/Meta has developed measurement processes to manage AI models effectively and efficiently, and shares techniques that can be applied broadly in other organizations. They discuss the goals and principles of AI model management, Meta\u2019s ML-Ops ecosystem, and the importance of consistently defining key concepts in AI model management. The taeam also emphasize the need for a clear metadata architecture to bridge specific system implementations via common labels. If you are interested in the topic you can check out the recording of our talk on Metadata Systems for End-to-End Data & Machine Learning at PyData Global 2022."
            }
        ]
    },
    {
        "issue": "226",
        "items": [
            {
                "title": "The Actually Open AI Chat-GPT",
                "link": "http://www.youtube.com/watch?v=ddG2fM9i4Kk",
                "content": "The Actually Open AI Chat-GPT The Actually Open AI Chat-GPT is now officially released \ud83d\ude80 Open Assistant is an open-source project that aims to provide a chat-based large language model to everyone - the project is also enabling data collection to submit, rank, and label model prompts and responses to train models via crowd-sourcing and enable an open accessible AI assistant framework that can perform meaningful tasks, research information, and be personalized and extended by anyone."
            },
            {
                "title": "Building the Future with LLMs",
                "link": "http://www.youtube.com/watch?v=nMniwlGyX-c",
                "content": "Building the Future with LLMs Large Language Models are driving exciting and high-potential use-cases through agent-chain-tool architectures\ud83d\udca1 This is a fantastic tutorial by LangChain creator which dives into the concepts that are powering the ever-more-mind-blowing use-cases with Large Language Models. This dives into practical examples showing how to supercharge LLMs with agents, tools and chains, as well as enhancing through external sources to unlock advanced capabilities."
            },
            {
                "title": "Evolution of RecSys Architectures",
                "link": "http://amatriain.net/blog/RecsysArchitectures",
                "content": "Evolution of RecSys Architectures One of the best resources for Recommender Systems architectures \ud83e\udd16 The evolution of Recommender Systems through architectural Blueprints. This resource does a great job of compiling several of the most comprehensive end-to-end recommender system architectural blueprints, providing a high level overview of each as well as interesting thoughts. Finally it proposes its own take with a blueprint that encompasses all the relevant components through a data-centric perspective."
            },
            {
                "title": "Google\u2019s Responsible AI Agenda",
                "link": "http://blog.google/technology/ai/a-shared-agenda-for-responsible-ai-progress/",
                "content": "Google\u2019s Responsible AI Agenda Google shares their agenda for Responsible AI progress \ud83d\udca1 They emphasise the importance of a collective effort from citizens, educators, academics, civil society, and governments to shape the development and use of AI. They also cover the principles proposed for the development of responsible AI policies and frameworks, such as building on existing regulations and promoting transparency that facilitates accountability."
            },
            {
                "title": "ChatGPT Productivity Hacks",
                "link": "http://www.youtube.com/watch?v=9W_U1y7RYuE",
                "content": "ChatGPT Productivity Hacks ChatGPT hacks to increase developer productivity \ud83e\udd14 This video dives into some of the recent growingly popular productivity hacks that developers have started adopting to increase their productivity. These include describing code, supporting on debugging, translating across programming languages, requesting snippets, writing unit tests, modifying existing code and writing documentation."
            }
        ]
    },
    {
        "issue": "227",
        "items": [
            {
                "title": "MIT Course Foundation Models",
                "link": "http://www.futureofai.mit.edu/",
                "content": "MIT Course Foundation Models Exciting new resource for the Machine Learning community from MIT on Foundation models \ud83e\udd16 MIT has released a free course on \u201cSelf-Supervised Learning & Foundation Models\u201d. This comprehensive program covers state-of-the-art topics and techniques. Topics covered include ChatGPT, Stable-Diffusion & Dall-E, Neural Networks, Supervised Learning, Representation & Unsupervised Learning, Reinforcement Learning, Generative AI, Self-Supervised Learning, Foundation Models, GANs, Contrastive Learning, Denoising & Diffusion Auto-encoders. A fantastic resource from MIT\u2019s renowned experts and dive deep into the fascinating world of AI and machine learning."
            },
            {
                "title": "The MLOps Bookshelf Collection",
                "link": "http://medium.com/softwareydata/my-mlops-bookshelf-c27f6e29370d",
                "content": "The MLOps Bookshelf Collection The MLOps Bookshelf Collection \ud83d\udcda A great resource for practitioners looking to upgrade their knowledge in production machine learning operations. The list includes books such as \u201cBuilding Machine Learning Powered Applications\u201d by Emmanuel Ameisen, \u201cReliable Machine Learning\u201d by Cathy Chen et al., \u201cMachine Learning Engineering in Action\u201d by Ben Wilson, \u201cEffective Data Science Infrastructure\u201d by Ville Tuulos, \u201cMachine Learning Design Patterns\u201d by Valliappa Lakshmanan, and \u201cDesigning Machine Learning Systems\u201d by Chip Huyen. The article also provides brief reviews and recommendations for each book."
            },
            {
                "title": "Curated Set of Key LLM Papers",
                "link": "http://projects.laion.ai/Open-Assistant/docs/research/general",
                "content": "Curated Set of Key LLM Papers The team behind one the Open-Assistant project making available an Open Source version of ChatGPT has put together a fantastic compilation of research papers on conversational LLMs \ud83d\udca1\u00a0 The article provides a list of research papers relevant to production machine learning practitioners. The papers cover various topics such as reinforcement learning from human feedback, generating text from language models, automatically generating instruction data for training, uncertainty estimation of language model outputs, evidence-guided text generation, reward model optimization, dialogue-oriented RLHF, and reducing harms in language models. The papers discuss various methods for fine-tuning language models, improving the quality of generated text, reducing the need for manually annotated data, teaching models to express their uncertainty, and reducing harms caused by language models."
            },
            {
                "title": "AI Practical Codebase Analysis",
                "link": "http://www.activeloop.ai/resources/lang-chain-gpt-4-for-code-understanding-twitter-algorithm/",
                "content": "AI Practical Codebase Analysis Using LLMs to understand large-scale complex codebases \ud83e\udd2f This article demonstrates how LangChain, Deep Lake, and GPT-4 revolutionize code comprehension, enabling developers to understand complex codebases like Twitter\u2019s recommendation algorithm effectively and efficiently. The new method involves four key steps: indexing the codebase, storing embeddings and code in Deep Lake, using LangChain\u2019s Conversational Retriever Chain, and asking questions in natural language. The result is a faster, more efficient code understanding process that streamlines learning for machine learning practitioners."
            },
            {
                "title": "RocksDB Under The Hood",
                "link": "http://artem.krylysov.com/blog/2023/04/19/how-rocksdb-works/",
                "content": "RocksDB Under The Hood RocksDB Under The Hood \ud83d\udee0\ufe0f RocksDB is an embeddable persistent key-value store that has gained popularity in recent years, with its adoption by major tech companies like Meta, Microsoft, Netflix, and Uber. This article provides a very insightful and thorough analysis of the internals, together with the concepts, theory and examples of actions such as flushes, merges, etc."
            }
        ]
    },
    {
        "issue": "228",
        "items": [
            {
                "title": "Call to Protect OSS AI in EU",
                "link": "http://laion.ai/notes/letter-to-the-eu-parliament/",
                "content": "Call to Protect OSS AI in EU \u201cA call to protect Open Source AI in the EU\u201d \ud83c\udf0e In an open letter to the European Parliament, LAION together with other prominent research institutions and developers express concerns about the draft AI Act\u2019s potential impact on open-source AI R&D in Europe. The letter emphasizes the importance of open-source AI for safety, competition, and security, and warns against the negative consequences of stifling such innovation. The letter makes three key recommendations: ensuring open-source R&D can comply with the AI Act, imposing requirements proportional to risk, and establishing public research facilities for compute resources. With support from numerous organizations and professionals, the letter aims to protect open-source AI for the future of Europe."
            },
            {
                "title": "Large Language Models Survey",
                "link": "http://arxiv.org/abs/2303.18223",
                "content": "Large Language Models Survey This survey presents advances in large language models (LLMs), focusing on four major aspects: pre-training, adaptation tuning, utilization, and capacity evaluation. LLMs, such as GPT-3, have shown emergent abilities not observed in smaller pre-trained language models (PLMs) and are revolutionizing AI research and applications. The article highlights key differences between LLMs and PLMs, including emergent abilities, human interaction, and the integration of research and engineering. Although LLMs have made significant progress, their underlying principles remain underexplored, and challenges persist in training, controlling, and aligning them with human values."
            },
            {
                "title": "Growth of AI Through Cloud Lens",
                "link": "http://mitchellh.com/writing/ai-through-a-cloud-lens",
                "content": "Growth of AI Through Cloud Lens HashiCorp Founder on the growth of AI through a Cloud Lens \ud83d\udcb9 AI is experiencing a platform shift similar to the rise of cloud computing, with significant potential to change the way we build and deliver software. Mitchel Hashimoto shares his thoughts on the growth of AI from a perspective of developer tooling and cloud infrastructure, and presents various general thoughts on progression and potential."
            },
            {
                "title": "Free LangChain Course Online",
                "link": "http://www.youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5",
                "content": "Free LangChain Course Online The LangChain video playlist on the \u201cData Independent\u201d YouTube channel explores various topics related to natural language processing (NLP) and machine learning. The playlist includes six videos that cover topics such as text preprocessing, sentiment analysis, text classification, and neural machine translation. Each video provides a brief introduction to the topic and presents practical examples using Python and popular libraries such as NLTK, Scikit-learn, and PyTorch. The videos are suitable for beginners in NLP and machine learning, as well as those who want to refresh their knowledge and improve their skills in these areas."
            },
            {
                "title": "Neural Nets from Scratch in Zig",
                "link": "http://monadmonkey.com/dnns-from-scratch-in-zig",
                "content": "Neural Nets from Scratch in Zig The article describes building a simple deep neural network (DNN) from scratch in Zig, a new system\u2019s programming language that aims to be for C what rust is to C++. The DNN is written using only Zig\u2019s standard library, without utilizing high-level Python libraries like Tensorflow. The article covers the architecture of the DNN, including the forward & backward prop, and the comptime feature of Zig that allows for writing code interpreted at compile time. The DNN is trained on the MNIST dataset and achieves a 96% accuracy rate, and outlines suggestions for improving the performance."
            }
        ]
    },
    {
        "issue": "229",
        "items": [
            {
                "title": "LLM Applications for Production",
                "link": "http://huyenchip.com/2023/04/11/llm-engineering.html",
                "content": "LLM Applications for Production Building LLM applications for production \ud83e\udd16 A fantastic article by Chip Huyen discussing the challenges of building production-ready applications using large language models. This comprehensive and practical overview dives into prompt engineering techniques, as well as the composability of tasks and the use of agents, tools, and control flows for more complex applications. It is interesting to see that although there is not yet consensus on terminology, we are seeing fast evolution on core concepts. Finally, the article explores promising use cases for LLMs, such as AI assistants, chatbots, programming and gaming, and search and recommendation, among others."
            },
            {
                "title": "AI Generating Music from Text",
                "link": "http://google-research.github.io/seanet/musiclm/examples/",
                "content": "AI Generating Music from Text Generating Music from Text with AI \ud83c\udfb5 The paper introduces MusicLM, a generative model that creates high-fidelity music from text descriptions which not only are impressive but have led to even more impressive practical applications. It utilizes AudioLM\u2019s multi-stage autoregressive modeling for generating music, while extending it to incorporate text conditioning. It outperforms previous systems in audio quality and adherence to text prompts. The authors also introduce MusicCaps, a dataset with 5.5k music-text pairs for evaluation, and discuss potential risks and future improvements related to music generation."
            },
            {
                "title": "The Little Book of Deep Learning",
                "link": "http://fleuret.org/public/lbdl.pdf",
                "content": "The Little Book of Deep Learning The Little Book of Deep Learning offers a concise introduction to deep learning techniques, covering foundational concepts, model components, and various applications \ud83d\udcda It addresses the challenges of training deep neural network architectures and presents solutions to overcome them. This accessible guide is essential for machine learning practitioners seeking to understand the fundamentals of deep learning and its role in the future of AI."
            },
            {
                "title": "Google Leaked Memo on OSS AI",
                "link": "http://www.semianalysis.com/p/google-we-have-no-moat-and-neither",
                "content": "Google Leaked Memo on OSS AI Google\u2019s leaked memo on Open Source AI \ud83d\udcdd A leaked internal Google document reveals that the employee believes the company isn\u2019t positioned to win the AI race against open source AI projects given how it is outpacing closed-source approaches. The article argues that open-source models evolve at faster pace becoming more customizable, private, and capable, with rapid advancements in low-cost, scalable, and efficient solutions. The document highlights the importance of collaboration and learning from the open-source community, reevaluating Google\u2019s value proposition, and focusing on smaller, more agile models."
            },
            {
                "title": "New AI Programming Language",
                "link": "http://docs.modular.com/mojo/notebooks/HelloMojo.html",
                "content": "New AI Programming Language Mojo is a new programming language designed to bridge the gap between research and production by combining Python syntax with systems programming and metaprogramming features \ud83d\udd25 Having authored the Vulkan Kompute framework I can see this bridging a very important gap across high level and compute-optimized languages referred here to as the \u201cnth-[-domain]-world\u201d problem. Developed by Modular, Mojo aims to simplify programming across the entire ML/AI stack and target accelerators and heterogeneous systems common in machine learning. Really keen to see how this develops together with other innovative languages such as JuliaLang, Jax, etc."
            }
        ]
    },
    {
        "issue": "230",
        "items": [
            {
                "title": "The MLOps Fundamentals Guide",
                "link": "http://huyenchip.com/mlops/",
                "content": "The MLOps Fundamentals Guide This MLOps guide by Claypot AI Founder Chip Huyen is a fantastic resource for machine learning practitioners at all levels \ud83d\udca1 This resource covers foundational machine learning concepts, offers an in-depth exploration of MLOps, and provides career development advice. Additionally, it includes real-world case studies from companies like Airbnb, Netflix, Booking.com, and Uber to demonstrate practical applications of machine learning in production environments. The guide concludes with miscellaneous resources such as coding exercises and Python tips. It serves as a valuable tool for anyone working in machine learning production."
            },
            {
                "title": "AI Prompt Injection Explained",
                "link": "http://simonwillison.net/2023/May/2/prompt-injection-explained/",
                "content": "AI Prompt Injection Explained AI Prompt Injection explained, with video, slides, and a transcript \ud83d\udc89Insightful resource which discusses the security vulnerability of prompt injection in applications built on AI models. Prompt injection involves injecting unauthorized instructions into user input to manipulate an AI system\u2019s behavior. The potential implications are significant, including AI assistants being manipulated to leak confidential information. While the solutions are complex and challenging to implement, this resource emphasizes the importance of community awareness, discussion, and research to combat these vulnerabilities."
            },
            {
                "title": "Binance Real Time ML for Fraud",
                "link": "http://www.binance.com/en/blog/tech/why-and-how-we-use-realtime-machine-learning-to-monitor-fraudulent-activity-at-binance-7972341655591522254",
                "content": "Binance Real Time ML for Fraud Binance on Why and How they use real-time Machine Learning to monitor fraudulent activity \ud83e\ude99 Binance uses real-time machine learning to detect and prevent fraudulent activities on their cryptocurrency platform. To counter \u201cmodel staleness\u201d where predictions become inaccurate over time, they employ both batch and streaming data pipelines, with a particular emphasis on real-time (streaming) data. Their real-time machine learning pipeline comprises data processing and data serving components, incorporating stream computing, ingestion, and sinking for data processing and online prediction, and batch computing for data serving. Balancing data freshness and latency, the system supports continuous monitoring and protection in the 24/7 crypto market."
            },
            {
                "title": "Scaling Prime Video Infrastructure",
                "link": "http://www.primevideotech.com/video-streaming/scaling-up-the-prime-video-audio-video-monitoring-service-and-reducing-costs-by-90",
                "content": "Scaling Prime Video Infrastructure Prime Video significantly scaled up its audio/video monitoring service and reduced costs by 90% by transitioning from a distributed microservices architecture to a monolithic application \ud83d\udcb8 The original serverless design led to scaling bottlenecks and high costs due to expensive AWS orchestration workflows and data transfer between distributed components. The new monolithic architecture, running on Amazon EC2 and Amazon ECS, simplified orchestration, eliminated the need for intermediate data storage, and improved scaling capabilities. This change also enhanced the overall customer experience by enabling monitoring of all streams. The experience highlights the importance of selecting between microservices and monolith architectures based on specific use-cases."
            },
            {
                "title": "CMU Database Group Youtube",
                "link": "http://www.youtube.com/@CMUDatabaseGroup/playlists",
                "content": "CMU Database Group Youtube The Carnegie Mellon University (CMU) Database Group YouTube"
            }
        ]
    },
    {
        "issue": "231",
        "items": [
            {
                "title": "Interactive AI GAN Image Editing",
                "link": "http://vcai.mpi-inf.mpg.de/projects/DragGAN/",
                "content": "Interactive AI GAN Image Editing Researchers from the Max Plank Institute for Informatics present DragGAN, a method for interactively manipulating GAN-generated images. Users can \u201cdrag\u201d points within an image, controlling attributes such as pose, shape, expression, and layout across diverse object categories. Unlike previous methods that relied on manual annotation or 3D models, DragGAN provides a more flexible, precise, and general approach. The system has two components: a feature-based motion supervision and a novel point tracking approach. The DragGAN method results in realistic outputs, even for challenging scenarios, outperforming prior methods in image manipulation and point tracking tasks."
            },
            {
                "title": "O\u2019Reilly Trends to Watch 2023",
                "link": "http://www.oreilly.com/radar/radar-trends-to-watch-may-2023/",
                "content": "O\u2019Reilly Trends to Watch 2023 The O\u2019Reilly team has released an overview of key highlights identified in the areas of artificial intelligence, ethcis in technology, general programming, security, infrastructure, IOT, web and quantum computing. In this trends edition they dive into the increasingly accelerating growth of generative AI with a particular focus on Large Language Models."
            },
            {
                "title": "U.S AI Policy Turning Point",
                "link": "http://cacm.acm.org/blogs/blog-cacm/273011-a-turning-point-for-us-ai-policy-senate-explores-solutions/fulltext",
                "content": "U.S AI Policy Turning Point In a recent congressional hearing on AI policy titled \u201cOversight of A.I: Rules for Artificial Intelligence\u201d, experts from industry and academia testified to the Senate Judiciary Committee, calling for clear rules, regulatory measures, and guardrails to govern the rapid development and deployment of AI technology. OpenAI\u2019s Sam Altman, IBM\u2019s Christina Montgomery, and AI expert Gary Marcus proposed a series of measures to guide AI policy, including transparency requirements, privacy rules, and limits on compute and AI capability."
            },
            {
                "title": "Developer Experience Framework",
                "link": "http://queue.acm.org/detail.cfm?id=3595878",
                "content": "Developer Experience Framework A fantastic article from the authors of the SPACE and DORA frameworks for developer productivity, which advocates a developer-centric approach which emphasizes lived experiences and daily challenges. DevEx focuses on three dimensions: feedback loops, cognitive load, and flow state. Optimizing these can boost productivity and business performance. The article proposes as well a measurement framework combining developer feedback and engineering system data is proposed to assess DevEx."
            },
            {
                "title": "Battle of Large Language Models",
                "link": "http://lightning.ai/pages/community/community-discussions/the-ultimate-battle-of-language-models-lit-llama-vs-gpt3.5-vs-bloom-vs/",
                "content": "Battle of Large Language Models Lightning AI has released an insightful evaluation across large language models, assessing the performance of various Large Language Models (LLMs), including GPT-3, GPT-4, Flan-t5, and Lit-LLaMA. T GPT-3 and GPT-4 stood out for response quality but require a paid subscription and data sharing with OpenAI. Flan-t5 and Lit-LLaMA performed accurately and are publicly available. Models under OpenRail License, like Bloom, are notable but may present usage restriction challenges. LLaMA 7B was good at explaining but relied heavily on quoting for context. Private models like GPT-3 and GPT-4 provided detailed summaries and displayed humor, but they are costly and less suitable for handling sensitive information. Overall, the initiative of diving into model evaluation is something that can only support improving the GenAI ecosystem."
            }
        ]
    },
    {
        "issue": "232",
        "items": [
            {
                "title": "Water Footprint of Deep Learning",
                "link": "http://arxiv.org/pdf/2304.03271.pdf",
                "content": "Water Footprint of Deep Learning Training GPT-3 in a state-of-the-art U.S. data center could consume up to 700,000 liters of freshwater \ud83d\udebf The article discusses the often overlooked water footprint of AI models and reveals that training large models like GPT-3 or GPT-4 can consume vast amounts of water in data centers, which is concerning due to freshwater scarcity. The authors explain water usage in data centers, highlighting both direct consumption for cooling servers and indirect consumption for electricity generation. They suggest that the \u2018when\u2019 and \u2018where\u2019 of AI model training can greatly influence water usage effectiveness, proposing a methodology for fine-grained water footprint estimation and advocating for transparency in disclosing such information. They emphasize the need for a holistic approach to sustainability, considering both water and carbon footprints."
            },
            {
                "title": "Karpathy on the State of GPT",
                "link": "http://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2",
                "content": "Karpathy on the State of GPT In this talk, Andrej Karpathy shares insights into the training and application of large language models (LLMs), like GPT-4. The training process involves four major stages: pre-training, supervised fine-tuning, reward modeling, and reinforcement learning. He highlights the importance of tokenization during pre-training and discusses \u2018constraint prompting\u2019 for controlling LLM outputs. He also touches upon the practice of model fine-tuning, suggesting the use of techniques like LoRA, while warning against the complexity of reinforcement learning from human feedback (RLHF). Karpathy recommends using detailed prompts and experimenting with tools to optimize LLM use. Despite their limitations, such as bias and susceptibility to attacks, he views LLMs as valuable co-pilots in low-stake applications, while expressing admiration for the breadth of knowledge encapsulated by models like GPT-4."
            },
            {
                "title": "2023 State of AI from Databricks",
                "link": "https://www.databricks.com/discover/state-of-data-ai",
                "content": "2023 State of AI from Databricks The 2023 State of Data + AI report examines trends in data and AI based on data from over 9,000 global Databricks customers. Key findings include a significant increase in the use of Natural Language Processing and Large Language Models, dominance of open-source and data integration tools in data and AI stacks, with Microsoft Power BI leading, and a rising trend of unifying data, analytics, and AI on platforms like Lakehouse."
            },
            {
                "title": "Lessons Creating GPT4 Plugin",
                "link": "http://bit.kevinslin.com/p/leveraging-gpt-4-to-automate-the",
                "content": "Lessons Creating a GPT4 Plugin This article outlines insights and learnings from experimenting with GPT-4 to autonomously create a VSCode extension for adjusting the heading level of selected Markdown text. The code was generated using the smol-ai framework. Despite a simplified prompt, GPT-4 generated the necessary files and satisfactory code, handling commands and edge cases. The author observed that improvements could be achieved by providing more detailed prompts, utilizing up-to-date information, generating tests, and defining a checklist for high-quality VSCode extensions."
            },
            {
                "title": "Andrew Ng Next on 10 Years of AI",
                "link": "http://venturebeat.com/ai/andrew-ng-predicts-the-next-10-years-in-ai/",
                "content": "Andrew Ng Next on 10 Years of AI In this article, AI pioneer Andrew Ng discusses his shift from \u201cbits to things,\u201d focusing on applying AI to the manufacturing industry. He highlights the challenges faced from data-centric AI, emphasizing that data is becoming more important than models. This approach involves empowering domain experts to express their knowledge through data engineering, especially where data is scarce. Andrew also anticipates the rise of foundation models in computer vision, similar to GPT3 in natural language processing. Looking forward, he believes the AI industry should concentrate more on small data and data-centric AI, a process which he admits will require substantial work and innovation."
            }
        ]
    },
    {
        "issue": "233",
        "items": [
            {
                "title": "Deep Learning GenAI Courses",
                "link": "http://www.deeplearning.ai/short-courses/",
                "content": "Deep Learning GenAI Courses DeepLearning.AI has released a set of free courses on various practical generative AI areas. The courses, ranging from beginner to advanced levels, and include: Building Systems with the ChatGPT API, ChatGPT Prompt Engineering for Developers, LangChain for LLM Application Development and How Diffusion Models Work. Each course requires basic Python knowledge and are a good way to break into the practical concepts and use-cases for real-world large language models."
            },
            {
                "title": "Industral Transformer Forecasting",
                "link": "http://arxiv.org/abs/2305.14406",
                "content": "Industral Transformer Forecasting This paper presents an insightful use-case applying transformer-based models to forecasting problems at scale through a practical application in pricing at European fashion e-commerce company Zalando. The model uses a transformer-based architecture, and highlights the advantages of transformer-based models for forecasting when dealing with large datasets, and provide evidence of scaling laws for transformers in forecasting, which suggests that predictive performance continues to increase with the size of the training set. They also discuss challenges such as cold start problems, short history, and sparsity, intermittency, and integration of both past and future coveariates, providing examples of how these are addressed in the model."
            },
            {
                "title": "Ride Sharing App From Scratch",
                "link": "http://jurajmajerik.com/",
                "content": "Ride Sharing App From Scratch One of the most complete and real-life-like practical and guided projects to take development skills to the next level by building a fully fledged ride sharing application and learn about distributed systems. It begins with foundational server setup and progresses through more complex aspects such as backend and frontend development, database connectivity, Docker deployments, and managing environment variables. The latter part of the blog posts focus on the specific functionalities of the app simulation, including car animation, route planning, and driver-customer matching."
            },
            {
                "title": "Writing LLM-Powered Applications",
                "link": "http://blog.streamlit.io/langchain-tutorial-1-build-an-llm-powered-app-in-18-lines-of-code/amp/",
                "content": "Writing LLM-Powered Applications LangChain is an open-source framework that uses large language models to build real-world applications for various use cases. It connects LLM models, such as OpenAI and HuggingFace Hub, to external sources and provides abstractions and tools to interface between text input and output. LangChain\u2019s key modules include Models, Prompts, Indexes, Memory, Chains, Agents, and Callbacks. This is an insightful resource that explains how to build an LLM-powered app using LangChain and Streamlit, which involves obtaining an OpenAI API key, setting up the coding environment, building the app, and deploying it\u200b."
            },
            {
                "title": "Programmer Interrupted Cost",
                "link": "http://contextkeeper.io/blog/the-real-cost-of-an-interruption-and-context-switching/",
                "content": "Programmer Interrupted Cost An interesting resource that explores the real-cost of programmer interruptions and context switching. It outlines how interruptions can take at least 10-15 minutes to recover from, with complex tasks taking longer. Context switching, or moving between different tasks, is even more mentally demanding and requires significant effort to rebuild the working state. Modern Integrated Development Environments (IDEs) can help mitigate these issues by remembering the last working state, including files, cursor positions, breakpoints, and more. Additionally, larger screen real estate can enhance productivity by allowing more code visibility, facilitating denser contexts."
            }
        ]
    },
    {
        "issue": "234",
        "items": [
            {
                "title": "OWASP Top 10 for Generative AI",
                "link": "http://owasp.org/www-project-top-10-for-large-language-model-applications/descriptions/",
                "content": "OWASP Top 10 for Generative AI The OWASP Top 10 for Large Language Model Applications project lists the most common security risks in large language models (LLMs), aiming to educate developers and organizations. This is fantastic to see as a growing trend since we published the MLSecOps Top 10 Vulnarabilities almost 2 years ago! The risks in this new resource include vulnerabilities like prompt injections, data leakage, inadequate sandboxing, unauthorized code execution, SSRF vulnerabilities, overreliance on LLM-generated content, inadequate AI alignment, insufficient access controls, improper error handling, and training data poisoning. The project is community-driven and encourages broad participation so do contribute."
            },
            {
                "title": "Architectural Tech Debt Costs",
                "link": "http://dspace.mit.edu/handle/1721.1/79551",
                "content": "Architectural Tech Debt Costs It can often be hard to quantify and verbalise the business impact of technical debt \ud83d\udcb8 This MIT paper provides a comprehensive approach to assessing the cost of Architectural Complexity,\u00a0 demonstrating that it can lead to significant productivity drops, increased defect density, and higher staff turnover. The research emphasizes the importance of hierarchy and modularity in system design. For machine learning practitioners, this underscores the importance of maintaining simplicity in system architecture to optimize productivity and minimize costs."
            },
            {
                "title": "Harvard\u2019s Intro to AI with Python",
                "link": "http://www.i-programmer.info/news/150-training-a-education/16361-take-harvards-cs50-introduction-to-artificial-intelligence-with-python-for-free.html",
                "content": "Harvard\u2019s Intro to AI with Python Harvard\u2019s CS50\u2019s Introduction to Artificial Intelligence with Python \ud83e\udd16 A fantastic free self-paced online course from Harvard which explores key AI concepts and algorithms such as search algorithms, knowledge representation, uncertainty handling, optimization problems, supervised and reinforcement learning, neural networks, and language understanding. The course blends theory and practice effectively, and can be accessed on Harvard\u2019s official site or edX with free resources and an optional paid certificate\u200b."
            },
            {
                "title": "MLOps at Reasonable Scale",
                "link": "http://www.youtube.com/watch?v=Ndxpo4PeEms",
                "content": "MLOps at Reasonable Scale Building MLOps at Reasonable Scale:\u00a0You Don\u2019t Need a Bigger Boat \u26f5 A fantastic paper which addresses the challenges of implementing recommender systems at a \u201creasonable scale\u201d with a case study in the retail industry. It advocates for serverless, open-source tools to minimize infrastructure work, and proposes guiding principles for ML practitioners, including the emphasis on data quality, the separation of data ingestion and processing, and the use of platform as a service (PaaS) or function as a service (FaaS) instead of infrastructure as a service (IaaS). The paper also outlines the functional requirements of a recommender system, such as raw data ingestion, data preparation, model training, model serving, and orchestration\u200b."
            },
            {
                "title": "Securing AI Systems Series",
                "link": "http://medium.datadriveninvestor.com/securing-ai-systems-defensive-strategies-6b1fd6ad33fa",
                "content": "Securing AI Systems Series Securing AI Systems \u2014 Defensive Strategies \ud83e\udd77 A great article that explores the risks and defenses associated with AI systems, focusing on intentional and unintentional failures. It emphasizes adversarial robustness as a key defensive strategy, which requires building machine learning models with strict adherence to security, privacy, and regulatory principles. This resource also dives into the challenges in implementing these defenses, including slow performance, decreased accuracy, and issues with scalability and transferability."
            }
        ]
    },
    {
        "issue": "235",
        "items": [
            {
                "title": "Machine Learning Security at NeurIPS",
                "link": "http://lfaidata.foundation/blog/2023/06/15/machine-learning-system-security-risks-best-practices/",
                "content": "Machine Learning Security at NeurIPS Machine Learning System Security: Risks & Best Practices \ud83e\udd77 The Linux Foundation has published a fantastic writeup from our NeurIPS workshop keynote last year on ML Security, which showcases key vulnerabilities throughout the ML Lifecycle as the \u201cMLSecOps Top 10\u201d, together with best practices to mititage them. This is critical due to the inherent complexity and nuanced security risks in ML systems. Mitigation strategies involve artifact signing, adversarial detectors, code reviews, secure deployment practices, and enhanced dependency management. Beyond tool usage, a holistic approach considering infrastructure security, access control, encryption, and pipeline hardening is needed, as well as effective collaboration among various teams is essential and staying updated on the latest ML security developments is also crucial"
            },
            {
                "title": "Google\u2019s Secure AI Framework",
                "link": "http://blog.google/technology/safety-security/introducing-googles-secure-ai-framework/",
                "content": "Google\u2019s Secure AI Framework Google has launched the Secure AI Framework (SAIF), aiming to set security standards for responsible AI development and deployment \ud83d\udca1 SAIF is designed to mitigate AI-specific risks, such as model theft and data poisoning, inspired by established best practices from software development. The framework has six core elements, which include: 1) extending strong security foundations to the AI ecosystem; 2) incorporating AI into organizational threat detection and response; 3) automating defenses; 4) harmonizing platform-level controls; 5) adapting controls for faster feedback loops during AI deployment;\u00a0and 6) contextualizing AI system risks in business processes. Google is actively fostering support for SAIF and plans to release open-source tools to help implement its elements"
            },
            {
                "title": "AI Fairness Across Linkedin",
                "link": "http://arxiv.org/abs/2306.00025",
                "content": "AI Fairness Across Linkedin Disentangling and Operationalizing AI Fairness at LinkedIn \ud83e\udd1d This insightful paper from Linkedin R&D presents a comprehensive approach to integrating fairness into AI systems, using LinkedIn as a case study. The authors propose a framework that considers fairness throughout the AI product lifecycle, from problem formulation to model training, evaluation, and deployment. They emphasize the importance of defining fairness metrics, using fairness-enhancing interventions during model training, and conducting thorough evaluations before and after deployment. The paper also highlights the potential unintended consequences of fairness interventions and encourages ongoing monitoring and collaboration to address AI fairness challenges."
            },
            {
                "title": "META\u2019s AI Music Generation",
                "link": "http://ai.honu.io/papers/musicgen/",
                "content": "META\u2019s AI Music Generation META\u2019s AI Music Generation + mind blowing text-to-music demos \ud83c\udfb6\ud83e\udd2f This paper introduces MUSICGEN, a novel single-stage transformer Language Model for conditional music generation. Unlike previous models, MUSICGEN operates over multiple streams of compressed discrete music representation, eliminating the need for cascading models and enabling high-quality music generation conditioned on textual description or melodic features. The authors also present a chromagram-based conditioning method to preserve the melodic structure during music generation. It has been fantastic to see the surge of models for music generation take off following Google\u2019s MusicLM, creating new opportunities across research and industry."
            },
            {
                "title": "How Google Manages Tech Debt",
                "link": "http://www.linkedin.com/pulse/how-google-measures-manages-tech-debt-abi-noda/",
                "content": "How Google Manages Tech Debt The insightful article discusses Google\u2019s method to understand and reduce technical debt. Motivated by their quarterly engineering satisfaction survey results, Google identified ten categories of technical debt from interviews with experts. Despite unsuccessful attempts to develop predictive metrics from log data, they continued to measure technical debt via their survey. Google also created a technical debt management framework, organized educational courses, and provided tools to help teams identify and manage technical debt. These efforts resulted in a significant reduction in technical debt, with most Google engineers reporting minimal or no hindrance from it."
            }
        ]
    },
    {
        "issue": "236",
        "items": [
            {
                "title": "The State of Production ML 2023",
                "link": "http://www.youtube.com/watch?v=xRFX5taXNcA&list=PLGVZCDnMOq0peDguAzds7kVmBr8avp46K&index=6",
                "content": "The State of Production ML 2023 The state of production ML in the Python ecosystem \ud83d\udca1 As the number of production machine learning use-cases increase, we find ourselves facing new and bigger challenges where more is at stake. Because of this, it\u2019s critical to identify the key areas to focus our efforts, so we can ensure our machine learning pipelines are reliable and scalable. In this talk we dive into the state of production machine learning in the Python Ecosystem, and we will cover the concepts that make production machine learning so challenging, as well as some of the recommended tools available to tackle these challenges."
            },
            {
                "title": "Economic Potential of Gen AI",
                "link": "http://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#introduction",
                "content": "Economic Potential of Gen AI McKinsey has released an extensive report on Generative AI outlining its economic potential. The report is primarily targeted at business leaders and decision-makers who are interested in leveraging AI strategically and tactically. The report is proken down into four main chapters covering 1) Generative AI as a technology catalyst 2) Generative AI use cases across functions and industries, 3) The generative AI future of work, 5) Considerations for businesses and society. The report also outlines recommendations for business leaders, policymakers, individuals and society."
            },
            {
                "title": "Playing with Steamlit & LLMs",
                "link": "http://lethain.com/streamlit-llms/",
                "content": "Playing with Steamlit & LLMs A great practical insight diving into practical LLM applications by Will Lethain, author of \u201cThe Staff Engineer\u201d. The use-case explores LLM applications using Streamlit, and demonstrates how to build interactive tools, allowing users to query OpenAI models, select a specific model, and operate on CSV files in a spreadsheet-like manner. Will concludes that personal LLM tooling could offer more customization than pre-made solutions and may represent an intriguing startup idea, despite potential challenges due to the saturation of startups in this space."
            },
            {
                "title": "MITRE ML Security Mitigations",
                "link": "http://atlas.mitre.org/mitigations/",
                "content": "MITRE ML Security Mitigations The article outlines a set of security mitigation strategies for machine learning systems based on MITRE ATLAS case studies. These strategies include the following mitigation registers: 1) limiting public release of technical information, 2) passive ML output obfuscation, 3) model hardening, 4) query restrictions, 5) access control for ML models and data, 6) ensemble methods, 7) sanitizing training data, 8) validating ML models, 9) input restoration, 10) library loading restriction, 11) encryption of sensitive data, 12) code signing, 13) verifying ML artifacts, 14) adversarial input detection, 15) vulnerability scanning, 16) strategic model distribution, and 17) user training. These techniques aim to prevent adversaries from exploiting system vulnerabilities, ensure the security of ML systems, and maintain the integrity of ML models and data."
            },
            {
                "title": "A/B Testing Problems & Learnings",
                "link": "http://posthog.com/blog/ab-testing-mistakes",
                "content": "A/B Testing Problems & Learnings 8 annoying A/B testing mistakes every engineer should know \ud83d\udca1 This article highlights common A/B testing pitfalls, which encompasses: 1) including unaffected users in experiments, 2) only viewing aggregate results and neglecting subgroup insights, 3) not setting a predetermined experiment duration, 4) running full-scale experiments without preliminary testing, 5) neglecting counter metrics that measure unintended negative effects, 6) failing to account for seasonality in user behavior, 7) testing unclear hypotheses, and 8) relying too heavily on A/B tests for decision-making. This resource also highlights useful learnings, including the importance of careful experiment design, thoughtful data analysis, and considering qualitative factors along with quantitative metrics\u200b\u200b."
            }
        ]
    },
    {
        "issue": "238",
        "items": [
            {
                "title": "ML System Design Case Studies",
                "link": "http://www.evidentlyai.com/ml-system-design",
                "content": "ML System Design Case Studies Evidently AI created a fantastic resource containing 200 real-word case studies of ML Systems from 64 companies including Netflix, Airbnb, and Doordash. Each of these contain further resources that cover the ML use cases in more detail and provide insights from the design of ML systems. This airtable database allows for filtering by industry or ML use case, and tags are added based on recurring themes. The most popular use cases are recommender systems, search and ranking, and fraud detection. The database also highlights instances where ML powers a specific user-facing \u201cproduct feature\u201d, such as grammatical error correction or generating outfit combinations."
            },
            {
                "title": "Future of Custom Tuned LLMs",
                "link": "http://outerbounds.com/blog/custom-llm-tuning/",
                "content": "Future of Custom Tuned LLMs A great article from Outerbounds, the company behind Metaflow, which explores instruction tuning for large language models. Here they dive into customisations to enable these models to generate appropriate responses to specific instructions. The authors discuss the rise of open-source LLMs, the role of commercial entities in the field, and the challenges of applying LLMs, including hardware access, real-world application, and ethical issues. Instruction tuning is presented as a valuable tool for fine-tuning LLMs, offering developers greater control over LLM behavior and enabling the creation of unique, functional product experiences."
            },
            {
                "title": "LLM App to Prod Databaricks",
                "link": "http://www.edx.org/course/large-language-models-application-through-production",
                "content": "LLM App to Prod Databaricks New free online course on \u201cLarge Language Models: Application through Production\u201d \ud83d\udca1 A great resource for developers, data scientists, and engineers who aim to build applications powered by large language models. The course covers the application of LLMs on real-world natural language processing problems, the integration of domain knowledge into LLM pipelines, the nuances of pre-training and fine-tuning models, and the implementation of LLMOps best practices. It also addresses the societal, safety, and ethical considerations of using LLMs. By the end of the course, participants will have built an end-to-end LLM workflow ready for production."
            },
            {
                "title": "Facebook Ranking Explained",
                "link": "http://transparency.fb.com/features/explaining-ranking/",
                "content": "Facebook Ranking Explained Meta / Facebook has released their \u201capproach to explaining (ML) ranking\u201d \ud83d\udca1 This resource provides a set of deep dives that contribute to their attempt to provide transparency on their AI-powered algorithms across their platform; this includes how posts are ranked in newsfeed, recommendations, ranking of comments, friend recommendations, notifications and more. This resource also covers some of their perspective towards battling misinformation, detailing how they work with independent fact-checkers to identify and take action on misinformation."
            },
            {
                "title": "Python at Netflix in Production",
                "link": "http://www.youtube.com/watch?v=yPBslOXTdc0",
                "content": "Python at Netflix in Production Fantastic episode of\u201dTalk Python Podcast\u201d on\u201dPython at Netflix\u201d featured two guests from Netflix\u2019s Python Infrastructure team, Amjith Ramanujam and Srinivasan Ramanujam. In this podcast they dive into the extensive use of Python across various teams at Netflix, including security, machine learning, data science, and animation studios. They also touched on tools like Security Monkey and Portable Python, and how they support different teams by building personas for various Python use cases."
            }
        ]
    },
    {
        "issue": "237",
        "items": [
            {
                "title": "UK Government AI Regulation",
                "link": "http://www.linkedin.com/feed/update/urn:li:activity:7079345143601844224/",
                "content": "UK Government AI Regulation The UK Government has adopted 3 of the 4 recommendations we made for the initial UK AI Regulation proposal - we are now thrilled to announce we have submitted further recommendations as part of the current open policy consultation for the UK AI Regulation Proposal \ud83d\ude80 The adopted recommendations include 1) Technological Interoperability, 2) Comprehensive Definitions, 3) Transparent Process. The recommendation on 4) Environmental Risks\u201d has now been emphasised and extended. Further ecommendations are now made including 5) encompassing matters of legitimacy\u201d and \u201ccontestability\u201d, 6) align definition of AI with OECD and European Commission, 7) machine learning security to be aligned with the UK NCSC, 8) informatics education be promoted, 9) \u201copen models\u201d to be considered, and 10) the UK\u2019s risk management framework align with the EU\u2019s."
            },
            {
                "title": "Andrew Ng Generative AI Course",
                "link": "http://www.deeplearning.ai/courses/generative-ai-with-llms/",
                "content": "Andrew Ng Generative AI Course New course from Andrew Ng\u2019s DeepLearning.AI in collaboration with AWS on Generative AI \ud83d\ude80 This free course is aimed at machine learning practitioners seeking a comprehensive understanding of generative AI. The course covers key aspects of generative AI, including data gathering, model selection, performance evaluation, deployment, and how to adapt and optimize models to various use cases. The course draws on the latest research and offers insights from industry practitioners, preparing learners to implement generative AI in real-world applications."
            },
            {
                "title": "MLOps at Reasonable Scale",
                "link": "https://github.com/jacopotagliabue/you-dont-need-a-bigger-boat",
                "content": "MLOps at Reasonable Scale Building MLOps at Reasonable Scale: You Don\u2019t Need a Bigger Boat \u26f5 A fantastic github repo providing a practical implementation to the previously shared paper on MLOps at Reasonable scale. This resource addresses the challenges of implementing recommender systems at a \u201creasonable scale\u201d with a case study in the retail industry. This repo provides an implementation of an end-to-end MLOps pipeline with: 1) Metaflow for ML DAGsSnowflake as a data warehouse solution (Alternatives: Redshift), 2) Prefect as a general orchestrator (Alternatives: Airflow, or even Step Functions on AWS), 3) dbt for data transformation, 4) Great Expectations for data quality (Alternatives: dbt-expectations plugin), 5) Weights&Biases for experiment tracking (Alternatives: Comet, Neptune), and 6) Sagemaker / Lambda for model serving."
            },
            {
                "title": "Foundation Model Transparency",
                "link": "http://github.com/stanford-crfm/TransparencyIndex/tree/main",
                "content": "Foundation Model Transparency Stanford has put together an informative repo which introduces the \u201cFoundation Model Transparency Index\u201d; a framework which rates major AI providers like OpenAI and Google on their adherence to requirements specified in the EU Parliament\u2019s draft AI Act. After identifying 22 relevant requirements from the AI Act, the authors evaluated 12 that apply directly to foundation model providers, using a custom 5-point rubric for each. The resulting ratings aim to foster greater transparency and accountability among AI model providers and ensure alignment with ethical and user protection principles."
            },
            {
                "title": "Train Serve Skew in ML Models",
                "link": "http://building.nubank.com.br/dealing-with-train-serve-skew-in-real-time-ml-models-a-short-guide/",
                "content": "Train Serve Skew in ML Models Dealing with Train-serve Skew in Real-time ML Models: A Short Guide \ud83d\udd2d A comprehensive article that demystifies the training-serving skew on ML models, which arises due to differences between training and serving environments in real-time machine learning models. To mitigate this issue, the guide recommends monitoring and debugging discrepancies, particularly with high-importance features, by collecting and comparing data from both training and serving paths. Other suggested strategies include using a feature store for feature calculation, maintaining clear communication between data scientists and machine learning engineers, and deploying models in \u201cshadow-mode\u201d to test for train-serve skew without impacting business operations."
            }
        ]
    },
    {
        "issue": "240",
        "items": [
            {
                "title": "Principles for Responsible Gen AI",
                "link": "http://www.linkedin.com/posts/axsaucedo_acm-generative-ai-principles-activity-7086597518955814912-1D7Y/",
                "content": "Principles for Responsible Gen AI Generative AI introduces complex challenges for its responsible design, development & operation across society - we have published a set of principles together with the ACM to support this endevour \ud83d\ude80 It was a pleasure to lead this initiative together with Facebook Senior Director Dr.\u00a0Ravi Jain and Clarkson University Professor Jeanna Matthews. Furthermore it has been an honour to get assistance from computer science legends such as TCP/IP creator vint cerf! These principles expand from the ACM Principles for Algorithmic Responsibility, and provide a set of pertinent recommendations for practitioners."
            },
            {
                "title": "ML Feature Store at DeliveryHero",
                "link": "http://tech.deliveryhero.com/leveraging-the-feature-store-for-fast-tracking-ml-model-development/",
                "content": "ML Feature Store at DeliveryHero Feature stores in the real world at Delivery Hero \u26a1 Delivery Hero\u2019s ML Platform team has developed a Feature Store to streamline the feature engineering process in machine learning model development. In this article they dive into how the Feature Store serves as a centralized hub for creating, monitoring, and serving features, promoting consistency and efficiency across teams. By leveraging BigQuery, Redis, and Feast for feature storage and serving, the Feature Store enhances feature reusability, reduces redundancy, and standardizes feature generation and quality processes, leading to more robust ML pipelines and reduced engineering efforts."
            },
            {
                "title": "Generative AI Video Editing",
                "link": "http://diffusion-tokenflow.github.io/",
                "content": "Generative AI Video Editing Editing videos with Generative AI is now a reality \ud83e\udd2f This paper presents \u201cTokenFlow\u201d, a text-driven video editing framework to generate high-quality videos that align with a given text prompt while preserving the spatial layout and dynamics of the input video. The key innovation is enforcing consistency in the diffusion feature space to maintain consistency in the edited video, achieved by propagating diffusion features based on inter-frame correspondences. The framework requires no training or fine-tuning and can work with any off-the-shelf text-to-image editing method, demonstrating state-of-the-art results on various real-world videos."
            },
            {
                "title": "Meta Public Release of Llama 2",
                "link": "http://ai.meta.com/llama/",
                "content": "Meta Public Release of Llama 2 Meta AI has published Llama version 2 \ud83e\udd73 This is the next-generation iteration of its open large language model, with model sizes ranging from 7 billion to 70 billion parameters. Trained on 2 trillion tokens and boasting double the context length of its predecessor, Llama 2 also incorporates over 1 million human annotations in its fine-tuned models. The model outperforms other open-source language models on various benchmarks, including reasoning, coding, proficiency, and knowledge tests. Meta highlights the support of global partners and encourages users to download the Llama 2 model for research and commercial use."
            },
            {
                "title": "Learn Self-Attention from Scratch",
                "link": "http://sebastianraschka.com/blog/2023/self-attention-from-scratch.html",
                "content": "Learn Self-Attention from Scratch The one and only Sebastian Raschka on \u201cUnderstanding and Coding the Self-Attention Mechanism of Large Language Models From Scratch\u201d \u2139\ufe0f Thoroughly comprehensive article which provides a detailed guide on implementing the self-attention mechanism, a key component of many state-of-the-art deep learning models. Sebastian explains the concept of attention in deep learning, demonstrates how to code the self-attention mechanism, and introduces the concepts of multi-head attention and cross-attention. The article is a valuable resource for machine learning practitioners interested in understanding and applying these mechanisms in their models."
            }
        ]
    },
    {
        "issue": "241",
        "items": [
            {
                "title": "Building a ChatGPT Terminal UI",
                "link": "http://chaoticengineer.hashnode.dev/textual-and-chatgpt",
                "content": "Building a ChatGPT Terminal UI Building a Terminal UI application (TUI) for ChatGPT in Python \ud83d\udc0dA comprehensive tutorial using the Python Textual framework to create an interface for users to interact with OpenAI\u2019s ChatGPT directly from the terminal. The tutorial covers setting up the visual chat interface, handling input, dynamically adding components, and integrating the TUI with ChatGPT. The article concludes with usability improvements to the chatui app and showcases how Textual can be used as a powerful tool for creating TUI apps."
            },
            {
                "title": "HuggingFace Audio ML Course",
                "link": "http://huggingface.co/learn/audio-course/chapter0/introduction",
                "content": "HuggingFace Audio ML Course HuggingFace has put together an extensive course on Audio Machine Learning processing using transformers \ud83d\udee0\ufe0f The course is taught by a team of Hugging Face\u2019s machine learning engineers, and covers a range of topics including audio data processing, audio classification, speech recognition, and generating speech from text. The course offers theoretical knowledge, quizzes, and hands-on exercises to help learners understand and apply transformer architectures to various audio-related tasks. And the course is free, open-source, and offers certification upon completion of the hands-on exercises."
            },
            {
                "title": "Migrations as the Fix to Tech Debt",
                "link": "http://lethain.com/migrations/",
                "content": "Migrations as the Fix to Tech Debt Migrations as the sole scalable fix to tech debt \ud83d\udca1 A classic article on software migrations which emphasizes their crucial role in managing technical debt as businesses and codebases expand. Using Uber\u2019s shift from Puppet-managed services to a self-service provisioning model as an example, the author outlines a three-step approach to effective migrations: Derisk, Enable, and Finish. Derisking involves iterative design and testing with the most challenging teams, enabling requires building tools for programmatic migration and providing self-service tooling, and finishing involves deprecating the legacy system and ensuring 100% adoption. The author underscores the importance of celebrating completed migrations and warns against the technical debt incurred by unfinished ones."
            },
            {
                "title": "Vision & Language to Action ML",
                "link": "http://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action",
                "content": "Vision & Language to Action ML DeepMind\u2019s Robotic Transformer 2 (RT-2) is a \u201cvision-language-action\u201d model that learns from both web and robotics data to generate generalized instructions for robotic control. Building upon its predecessor, it demonstrates improved generalization, semantic understanding, and visual comprehension which showcases quite some potential. It can interpret and respond to new commands, perform rudimentary reasoning, and execute multi-stage semantic reasoning. The model uses high-capacity vision-language models trained on web-scale datasets, with actions represented as tokens similar to language tokens. Tested in over 6,000 robotic trials, RT-2 showed increased generalization performance and the ability to generalize to novel objects in real-world tasks, demonstrating the significant benefits of large-scale pre-training."
            },
            {
                "title": "Tutorial Estimating Causal Effects",
                "link": "https://medium.com/riskified-technology/unlocking-insights-estimating-causal-effect-using-propensity-score-matching-12ad8bafe006",
                "content": "Tutorial Estimating Causal Effects Estimating Causal Effect Using Propensity Score Matching \ud83d\udd0e A great hands on article that provides an in-depth guide on using retrospective data to estimate causal effects, focusing on handling confounders and utilizing Propensity Score Matching. The author discusses the limitations of experiments, the concept of confounders, and the assumptions needed for using retrospective data. The article then delves into the use of PSM, explaining how to estimate propensity scores, handle the bias-variance tradeoff, select covariates, and set the matching caliper. The article also provides a real-life example of using PSM to estimate the causal effect of routing online transactions to different acquirer banks to improve the bank authorization rate, offering a step-by-step guide on creating a balanced dataset, evaluating it, and estimating the causal effect."
            }
        ]
    },
    {
        "issue": "242",
        "items": [
            {
                "title": "MadeWithML MLOps Course",
                "link": "http://madewithml.com/#course",
                "content": "MadeWithML MLOps Course \u201cMadeWithML\u201d is one of the most comprehensive end-to-end production machine learning course. This course is designed to guide developers in integrating machine learning into software applications. Covering topics from design to production, the curriculum emphasizes understanding ML from first principles, implementing best practices, and connecting MLOps components."
            },
            {
                "title": "Instruction Tuning Llama 2",
                "link": "http://www.philschmid.de/instruction-tune-llama-2",
                "content": "Instruction Tuning Llama 2 The Extended Guide for Instruction-tune Llama 2 \ud83d\udca1 The article offers a comprehensive guide on instruction-tuning Llama 2 from Meta AI, outlining the ability to create an instruction dataset. This dataset aids in fine-tuning Llama 2 to generate specific instructions based on input, facilitating tasks like personalized email writing. The tutorial covers defining use cases, creating prompt templates, and using TRL and the SFTTrainer for instruction-tuning, all executed on an AWS EC2 instance with an NVIDIA A10G GPU."
            },
            {
                "title": "Transparency LLMs Beyond OSS",
                "link": "http://lfaidata.foundation/blog/2023/08/01/open-source-is-crucial-for-ai-transparency-but-needs-more-tooling/",
                "content": "Transparency LLMs Beyond OSS Going beyond Open Source to ensure transparency in large language models \ud83e\udd16 An insighful perspective that highlights the importance of AI model traceability, making the case that while open-source practices are vital for transparency, these are not the \u201csilver bullet\u201d. The ecosystem currently has a gap on tooling required to enable the provenance of AI models, meaning the specific code and data used during training. It is proposed that to ensure a transparent AI supply chain, a combination of open-source methods and traceability tools is essential, especially given the risks associated with AI models being perceived as \u201cblack boxes\u201d and potential hidden malicious behaviors within them."
            },
            {
                "title": "AI Music Generation from META",
                "link": "http://huggingface.co/spaces/facebook/MusicGen?s=09",
                "content": "AI Music Generation from META Mind blowing text-to-music demos from META\u2019s AI Music Generation \ud83c\udfb6\ud83e\udd2f This paper introduces MUSICGEN, a novel single-stage transformer Language Model for conditional music generation. Unlike previous models, MUSICGEN operates over multiple streams of compressed discrete music representation, eliminating the need for cascading models and enabling high-quality music generation conditioned on textual description or melodic features. The authors also present a chromagram-based conditioning method to preserve the melodic structure during music generation. It has been fantastic to see the surge of models for music generation take off following Google\u2019s MusicLM, creating new opportunities across research and industry."
            },
            {
                "title": "How Google Manages Tech Debt",
                "link": "http://www.linkedin.com/pulse/how-google-measures-manages-tech-debt-abi-noda/",
                "content": "How Google Manages Tech Debt The insightful article discusses Google\u2019s method to understand and reduce technical debt. Motivated by their quarterly engineering satisfaction survey results, Google identified ten categories of technical debt from interviews with experts. Despite unsuccessful attempts to develop predictive metrics from log data, they continued to measure technical debt via their survey. Google also created a technical debt management framework, organized educational courses, and provided tools to help teams identify and manage technical debt. These efforts resulted in a significant reduction in technical debt, with most Google engineers reporting minimal or no hindrance from it."
            }
        ]
    },
    {
        "issue": "243",
        "items": [
            {
                "title": "Stanford Course on Intro to ML",
                "link": "http://www.youtube.com/watch?app=desktop&v=Bl4Feh_Mjvo&list=PLoROMvodv4rNyWOpJg_Yh4NSqI4Z4vOYy",
                "content": "Stanford Course on Intro to ML Stanford releases an updated version of their classic introduction to machine learning course. This is available for free online and offers a comprehensive exploration of machine learning, starting with foundational concepts like supervised learning and linear algebra, and advancing to complex topics such as deep learning, neural networks, and reinforcement learning. The sessions dive into the practical tools such as Python/Numpy covering evaluation metrics, bias-variance trade-offs, etc. Special highlights include a guest lecture on the societal impact of ML and insights into decision trees, boosting, and model-based RL."
            },
            {
                "title": "ML Models Learn vs Generalise",
                "link": "http://pair.withgoogle.com/explorables/grokking/",
                "content": "ML Models Learn vs Generalise Do Machine Learning models only memorize or do they actually generalize? In 2021, researchers identified a \u201cgrokking\u201d phenomenon where certain machine learning models transition from memorizing to generalizing after extended training. Using modular addition and binary sequences as test cases, this study reveal that the occurrence of grokking is contingent on specific hyperparameters like weight decay. While observed in smaller models, there\u2019s evidence to suggest that larger models might also exhibit grokking. The article emphasizes the importance of understanding these dynamics, and explores a step-by-step approach to interpret larger models by starting with simpler ones."
            },
            {
                "title": "Building Llama from Scratch",
                "link": "http://blog.briankitano.com/llama-from-scratch/",
                "content": "Building Llama from Scratch Inspired by Karpathy\u2019s Makemore series, this article offers a step-by-step guide on implementing the Llama starting small using the TinyShakespeare dataset. The approach in this tutorial is iterative, starting with basic models and gradually integrating Llama\u2019s unique features like RMSNorm, Rotary embeddings, and the SwiGLU activation function. There are various tips included, such as consistently checking tensor shapes, testing layers across different sizes, and ensuring model components function as intended. This article underscores the importance of simplicity and iterative testing in successfully implementing complex machine learning models."
            },
            {
                "title": "MLFlow Tracking and MinIO",
                "link": "http://blog.min.io/mlflow-tracking-and-minio/",
                "content": "MLFlow Tracking and MinIO The MinIO team has put together an overview on how to use MLflow for managing the machine learning lifecycle with a focus on tracking experiments, logging parameters, metrics, and artifacts. Using the MNIST dataset as an example, this tutorial demonstrates how to utilize MLflow\u2019s Tracking API to log experiment details and visualize them via the MLflow UI. This article also shows how to integrate MLflow with MinIO as an object store interface for efficient and reliable storage of large artifacts, such as trained model artifacts, ensuring streamlined tracking and storage in machine learning workflows."
            },
            {
                "title": "MLSecOps Kubeflow Exploration",
                "link": "http://mlsecops.com/resources/hacking-ai-account-hijacking-and-internal-network-attacks-in-kubeflow",
                "content": "MLSecOps Kubeflow Exploration An interesting security vulnerability report has been published on the machine learning pipelines framework Kubeflow. This article encompasses a reported vulnerability. These vulnerabilities emphasise the importance of machine learning security and MLSecOps; in this case these can lead to account hijacking, internal network attacks, and unauthorized data access. The research also unveiled simple exploit tool Kubejack.py which demonstrates the potential risks. Users of Kubeflow are urged to be cautious and consider necessary security measures, but for broader machine learning practitioners this serves as a reminder of the importance of security in machine learning."
            }
        ]
    },
    {
        "issue": "244",
        "items": [
            {
                "title": "Stanford\u2019s New NLU Course",
                "link": "https://www.youtube.com/playlist?app=desktop&list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp",
                "content": "Stanford\u2019s New NLU Course Stanford a new online course available to everyone for free on Natural Language Understanding \ud83d\udca1 This course offers a deep dive into the mechanics of NLU, blending theoretical insights from linguistics, NLP, and machine learning. The curriculum is delives into foundational topics like contextual language representation and information retrieval, followed by hands-on model building and an original NLU project. Tailored for real-world application, the course emphasizes best practices, ensuring participants are equipped to deploy robust NLU systems in production environments."
            },
            {
                "title": "Out-of-distribution Detection in DL",
                "link": "http://github.com/continuousml/Awesome-Out-Of-Distribution-Detection",
                "content": "Out-of-distribution Detection in DL OOD Detection represents an emerging trend in deep learning research, focusing on a critical deficiency that often limits the deployment of neural networks in real-world scenarios \ud83e\udd16 This Awesome Out-Of-Distribution Detection repository contains a comprehensive list of research papers, code implementations, insightful blogs, datasets, and tutorials. This repository is an invaluable resource for production machine learning practitioners aiming to enhance model robustness and stay updated on the latest OOD detection techniques and methodologies."
            },
            {
                "title": "Vector Databases 4-Part Series",
                "link": "http://thedataquarry.com/posts/vector-db-4/",
                "content": "Vector Databases 4-Part Series Vector databses are have been taking the world by storm, and this 4-part guide provides a comprehensive introduction and deep dive \ud83e\udd16 This article provides specifically guidelines on selecting the right vector database solution. It emphasizes the trade-offs between on-premises vs.\u00a0cloud hosting, client-server vs.\u00a0embedded architectures, and the benefits of purpose-built vector DBs over incumbent solutions. The piece also delves into performance metrics, storage considerations, vector types, hybrid search strategies, and filtering techniques. Conclusively, while there\u2019s no universal solution, Rust-built databases like Qdrant and LanceDB, with their developer-centric approach, are highlighted as promising options in the vector DB landscape."
            },
            {
                "title": "How is LLaMa.cpp Possible",
                "link": "http://finbarr.ca/how-is-llama-cpp-possible/",
                "content": "How is LLaMa.cpp Possible An interesting article written back in March trying to answer how it can run in a single CPU. The article explores the feasibility of running the LLaMa inference code in raw C++ on various devices, from smartphones to laptops and Raspberry Pis. It emphasizes that while GPUs are traditionally preferred for deep learning due to their vast memory bandwidth and compute capabilities, memory bandwidth often becomes the bottleneck for inference. By employing techniques like quantization, which reduces precision, the memory requirements of models can be significantly decreased, enabling them to run on devices with limited resources. The article provides specific performance calculations for different devices, underscoring the importance of memory bandwidth in transformer model sampling."
            },
            {
                "title": "CAP Theorem Plain English Intro",
                "link": "http://ksat.me/a-plain-english-introduction-to-cap-theorem",
                "content": "CAP Theorem Plain English Intro A plain english introduction to CAP Theorem \ud83d\udca1 For practitioners working with production systems, understanding the CAP theorem is crucial as it informs the trade-offs in data consistency, system availability, and fault tolerance. The article uses an intuitive example to simplify the understand the CAP theorem, which posits that it\u2019s impossible for a system to simultaneously achieve Consistency (every read gets the most recent write), Availability (every request gets a response), and Partition Tolerance (the system operates despite network failures). As the venture faces challenges, the article demonstrates these concepts, emphasizing that while two of the three properties can be optimized, all three can\u2019t be achieved together. An additional section introduces \u201ceventual consistency\u201d, where updates occur in the background, sacrificing immediate consistency for improved availability and fault tolerance."
            }
        ]
    },
    {
        "issue": "245",
        "items": [
            {
                "title": "Patterns for LLM-based Systems",
                "link": "http://eugeneyan.com/writing/llm-patterns/",
                "content": "Patterns for LLM-based Systems Patterns for Building LLM-based Systems & Products is one of the most comprehensive deep dive articles on LLM-systems literature \ud83d\udca1 The article identifies key patterns and concepts related to LLM-application design. It covers topics such as evaluations to measure performance, Retrieval-Augmented Generation to enhance LLM outputs with external data, and fine-tuning to tailor pre-trained models for specific tasks. Additionally, caching is highlighted as a method to store and quickly access previously computed data, reducing latency and costs. The content provides a broad range of academic research, industry resources, and practitioner expertise, underscoring the need for thoughtful system design based on user request patterns."
            },
            {
                "title": "Meta\u2019s CodeLlama Released",
                "link": "http://ai.meta.com/blog/code-llama-large-language-model-coding/",
                "content": "Meta\u2019s CodeLlama Released Facebook/Meta has unveiled \u201cCode Llama\u201d, a new specialized version of their Llama 2 model tailored for coding tasks which works out-of-the-box with Llama.cpp. This model can generate code, assist with code completion, and support debugging across several languages, including Python and Java. The relase includes three model sizes (7B, 13B, and 34B parameters) which provide differnet levels of quality and computational overhead. Code Llama has outperformed other code-specific LLMs in benchmarks which is great news for an open-source-ish (as the license is still limited on permissions) model."
            },
            {
                "title": "An Elegant Puzzle Book Notes",
                "link": "http://github.com/keyvanakbary/learning-notes/blob/master/books/an-elegant-puzzle.md",
                "content": "An Elegant Puzzle Book Notes \u201cAn Elegant Puzzle\u201d by Will Larson is one of the best books on management of highly technical teams. For anyone that has had the change to read the book this is a fantastic resource to provide a set of key points for robust resources (if you haven\u2019t I certainly recommend it). This book delves into technical people management, emphasizing systems thinking, organizational structures, and career progression. It underscores the significance of mentorship, managing technical debt, data-driven decision-making, and effective time management. The book also touches upon the nuances of hiring and onboarding. These insights are particularly relevant for production ML practitioners, guiding them in understanding their role within larger systems and optimizing their workflows."
            },
            {
                "title": "Hands on Train & Deploy ML",
                "link": "http://github.com/Paulescu/hands-on-train-and-deploy-ml",
                "content": "Hands on Train & Deploy ML Hands on crash-course on end-to-end MLOps \ud83e\udd16 This repository provides MLOps resources to build a Serverless ML-powered API to predict crypto prices showcasing popular MLOps tools and frameworks. It guides users through model training, deploying the model as a REST API, and automating deployments using GitHub Actions and the Model Registry. This tutorial leverages various tools lincluding CometML, Cerebrium, and GitHub Actions."
            },
            {
                "title": "Advanced Probabilistic ML Book",
                "link": "http://probml.github.io/pml-book/book2.html",
                "content": "Advanced Probabilistic ML Book Probabilistic Machine Learning: Advanced Topics - a fantastic free book to dive into the advanced topics of probabilistic machine learning. Bridging foundational concepts with cutting-edge techniques, this book delves into topics from inference methods to generative models, seamlessly integrating classic teachings with modern advancements like denoising diffusion models. This resource has contributions from leading figures in the machine learning community including Google, Deepmind, UBC, Stanford, and many others."
            }
        ]
    },
    {
        "issue": "246",
        "items": [
            {
                "title": "Generative Agents & Forums",
                "link": "http://nlpnewsletter.substack.com/p/generative-agents-forums-for-foundation#%C2%A7generative-agents",
                "content": "Generative Agents & Forums Sebastian Ruder has put together a fantastic overview of LLM capabilities in creating generative agents \ud83d\udca1 In these various references we can see an interesting sandbox environment with 25 LLM agents interacting in a \u201cThe Sims\u201d-like setting. These agents simulate memory, reflection, and planning capabilities, highlighting the versatility of LLMs in various tasks. This resources provide interesting examples of the potential of LLMs in a broad range of interactive usecases."
            },
            {
                "title": "LangChain Cheat Sheet",
                "link": "http://www.kdnuggets.com/2023/08/langchain-cheat-sheet.html",
                "content": "LangChain Cheat Sheet A comprenehsive cheat-sheet for building LLM-powered AI applications with LangChain \ud83e\udd16 LangChain is an open-source Python library designed to enable agentive-LLM-powered applications. It offers an intuitive API, supports chaining of model actions, integrates external knowledge, and provides modular prompt engineering. This resource seems quite useful to accelerates prototyping but also for general development with LangChain."
            },
            {
                "title": "Measuring Developer Productivity",
                "link": "http://newsletter.pragmaticengineer.com/p/measuring-developer-productivity?utm_source=substack&utm_medium=email",
                "content": "Measuring Developer Productivity Measuring Developer Productivity: The topic of conversation following the critique\u2019s of McKinsey\u2019s published framework for developer productivity \ud83c\udf1f Tech industry thought leaders have put together a comprehensive critique and review discussing the learnings/risks of measuring effort vs outcome. This includes deriving cautionary tales from Tech Giants, where initially helpful developer sentiment surveys eventually became performance review metrics, leading to a skewed view of productivity as teams began to game the system. A great resource for a topic that is not only relevant in general software development but is now emerging in specialised sub-fields such as data engineering and machine learning."
            },
            {
                "title": "Retrieval-Augmented Generation",
                "link": "http://outerbounds.com/blog/retrieval-augmented-generation/",
                "content": "Retrieval-Augmented Generation Retrieval-Augmented Generation: How to Use Your Data to Guide LLMs \u2692\ufe0f An interesting article from Outerbounds which delves into Retrieval Augmented Generation, a technique to enhance the output of large language models. Generic LLMs can produce plausible but inaccurate answers - RAG improves their relevancy by merging prompt engineering with custom datasets. Using vector embeddings and databases, RAG provides the model with context, such as relevant documentation, during generation. Practical applications of RAG, like Perplexity.ai and Bing AI chat, demonstrate its efficacy in producing more accurate and context-aware responses."
            },
            {
                "title": "Intro to Fourier Transforms",
                "link": "https://www.jezzamon.com/fourier/",
                "content": "Intro to Fourier Transforms This is one of the best resources out there to build an intuitive understanding of the foundations and potential of Fourier Transforms \ud83c\udf0a Fourier transforms are essential mathematical tools that decompose signals into constituent sine waves, revealing underlying frequencies. This article provides an intuition on the role of Fourier Transforms in a broad range of use-cases in industry and academia, such as understanding sound frequencies, data compression techniques like MP3s and JPEGs, and creating visual animations using complex sinusoids. Beyond these, Fourier transforms find applications in diverse fields such as circuit design, mobile communications, MRI, and quantum physics."
            }
        ]
    },
    {
        "issue": "247",
        "items": [
            {
                "title": "Andrew Ng: Opportunities in AI",
                "link": "http://www.youtube.com/watch?app=desktop&v=5p248yoa3oE",
                "content": "Andrew Ng: Opportunities in AI The one and only Andrew Ng shares actionable thoughts on opportunities and methodologies for successful AI opportunities in 2023 \ud83d\udca1 In this short but insightful 30 minute session, Andrew Ng shares a conceptual foundation for his excitement behind the latest developments in AI and how they are disrupting the more traditional approaches in ML. He also covers practical examples where he has been implementing these methodologies to develop new successful startups disrupting industries through democratisation of AI-tooling that before would\u2019ve otherwise be limited to top tech companies. A lot of high level learnings that machine learning practitioners can take as they are exploring emerging fields and technologies in the space."
            },
            {
                "title": "10y of Forecast Reconciliation",
                "link": "http://robjhyndman.com/seminars/reconciliation_review_talk/",
                "content": "10y of Forecast Reconciliation Forecasting and time series legend Rob Hyndman is speaking this week on hierarchical forecasting accessible in an online livestream thanks to Zalando\u2019s Pricing Platform Director Tim Januschowski who is coordinating this event \ud83d\ude80 This is an interesting fied of forecasting that enables the need for different levels of forecasting aggregation; for example a retail company that needs forecasts at the national-, state- and store-level for all products, for groups of products, and for individual products. You can find details of the event and how to join here and the livestream here, you can also find more information about the topic and resources here."
            },
            {
                "title": "Glassdoor\u2019s ML Platform Registry",
                "link": "http://medium.com/glassdoor-engineering/introducing-glassdoors-ml-registry-a-centralized-artifact-management-solution-8bff3151cd9d",
                "content": "Glassdoor\u2019s ML Platform Registry Glassdoor has developed and open-sourced its Machine Learning Registry as part of its commitment to becoming an ML-driven company \ud83d\udca1 An ML Registry is a component in the ML stack that stores model artifacts and related metadata to support consistent and reliable access to ML data across various teams and applications. Glassdoor built its registry from scratch rather than using existing solutions for reasons including complete customization, immediate support, seamless integration within the Glassdoor ecosystem, and cost considerations. The company has adopted a Git-centric approach for metadata management, this ML Registry synchronizes metadata from Git into a Redis cache and uses S3 for data storage."
            },
            {
                "title": "Advanced NLP Course with SpaCy",
                "link": "http://course.spacy.io/en/",
                "content": "Advanced NLP Course w SpaCy The Advanced NLP Course with SpaCy: Natural Language Processing has a vast and growing number of real-world applications across academia and industry, this spaCy online course offers a deep dive into text processing, starting with foundational concepts like word and phrase identification, progressing to large-scale data analysis techniques, and delving into the intricacies of spaCy\u2019s processing pipelines. For advanced practitioners, it provides guidance on customizing and training neural network models, ensuring practitioners have the tools to tailor spaCy for specific production needs."
            },
            {
                "title": "Privacy Nightmare on Wheels",
                "link": "http://foundation.mozilla.org/en/blog/privacy-nightmare-on-wheels-every-car-brand-reviewed-by-mozilla-including-ford-volkswagen-and-toyota-flunks-privacy-test/",
                "content": "Privacy Nightmare on Wheels \u201cPrivacy Nightmare on Wheels\u201d: \u2019Mozilla carried out a privacy review of car brands\u2014Including Ford, Volkswagen and Toyota \u2014 reveals concerning findings on how 25 major car brands collect and share deeply personal data, including sexual activity, facial expressions, and genetic and health information. Notably, Nissan was identified as collecting extensive personal data without clear usage specifications. Brands like Volkswagen and Toyota also raised concerns due to their data collection and complex privacy policies. The study underscores the growing privacy challenges in the automotive sector, emphasizing the need for better data protection practices as cars become increasingly connected and data-centric."
            }
        ]
    },
    {
        "issue": "248",
        "items": [
            {
                "title": "StabilityAI\u2019s Text-to-Song Model",
                "link": "http://stability.ai/research/stable-audio-efficient-timing-latent-diffusion",
                "content": "StabilityAI\u2019s Text-to-Song Model The new Text-to-Song model from StabilityAI is a reminder for the exciting journey we are in the AI ecosystem \ud83e\udd14 Stability AI introduces a\u00a0 latent diffusion model for audio generation, \u201cStable Audio\u201d. A model that accepts inputs as text description, audio duration, and start time, it addresses the challenge of producing varying audio lengths, such as full songs. The model leverages a variational autoencoder, a text encoder, and a U-Net-based conditioned diffusion model for efficient generation. Trained on over 800,000 audio files totaling 19,500 hours, Stable Audio promises faster inference times and enhanced controllability, with future releases set to include open-source models and training code."
            },
            {
                "title": "Dataset-Driven LLM Optimiztion",
                "link": "http://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html",
                "content": "Dataset-Driven LLM Optimiztion Sebastian Raschka reminds us that quality over quantity and less is more is key when it comes to Large Language Model optimizations\u00a0 \ud83d\udca1 In his most recent article, \u201cOptimizing LLMs From a Dataset Perspective\u201d, he delves into optimizing Large Language Models by finetuning them with curated datasets. This basically emphasises the importance of instruction-based finetuning, contrasting human-created and LLM-generated datasets. It delves into the LIMA dataset\u2019s effectiveness, emphasizing quality over quantity, and offers a walkthrough for finetuning LLMs using the Lit-GPT repository."
            },
            {
                "title": "Google\u2019s MLP for Forecasting",
                "link": "http://blog.research.google/2023/09/tsmixer-all-mlp-architecture-for-time.html?m=1",
                "content": "Google\u2019s MLP for Forecasting Google contributes to the interesting discourse of transformer-based forecasting with the release of \u201cTSMixer,\u201d an MLP architecture for time series forecasting that merges the strengths of univariate linear models with multivariate models. Unlike traditional Transformer architectures, TSMixer replaces attention mechanisms with linear layers, inspired by the computer vision MLP-Mixer method. In evaluations, TSMixer matched top univariate models on long-term forecasting benchmarks and showcased superior performance on the M5 retail dataset, emphasizing its potential in real-world applications and suggesting a reevaluation of the role of cross-variate information in forecasting."
            },
            {
                "title": "Hallucination Detection for LLMs",
                "link": "http://eugeneyan.com/writing/abstractive/",
                "content": "Hallucination Detection for LLMs Hallucination Detection for LLM-Based Abstractive Summaries. Eugene Yan shares another insightful article on LLMs that analyses the topic of summarization, and delves into evaluation challenges, discussing metrics like ROUGE, METEOR, BERTScore, MoverScore, ROUGE-C, and G-Eval. It also makes suggestions on key areas, such as being careful from being over-reliant on reference summaries, as well as to keep an eye on such as consistency in summaries."
            },
            {
                "title": "Death by 1000 Microservices",
                "link": "http://renegadeotter.com/2023/09/10/death-by-a-thousand-microservices.html",
                "content": "Death by 1000 Microservices Death by a thousand microservices \ud83e\udd77 A great critique on the tech industry\u2019s over-reliance on microservices, highlighting inherent complexities and pitfalls. This article emphasises the importance of the ever long advice in the software engineering: \u201cDon\u2019t solve problems you don\u2019t have\u201d. Although microservice architectures can be revolutionary, there is a time and a place for every design decisions, and many successful companies began with simpler monolithic architectures, suggesting that the blind adoption of microservices often leads to redundancy, decreased developer efficiency, and testing challenges. The article also outlines a trend towards returning to simpler architectures such as monolithic architectures, which urges companies to assess the genuine necessity of microservices based on their specific needs and scale."
            }
        ]
    },
    {
        "issue": "249",
        "items": [
            {
                "title": "MIT on Efficient Deep Learning",
                "link": "http://efficientml.ai/",
                "content": "MIT on Efficient Deep Learning MIT has a new freely available course material on efficient deep learning \ud83d\udca1 This course on TinyML / EfficientML focuses on enhancing the efficiency of large models for deployment on resource-limited devices, covering large models such as language and diffusion models. The curriculum delves into techniques like model compression, neural architecture search, on-device fine-tuning, and quantum machine learning. Practical components include deploying models like LLaMA 2 on laptops, with resources like lecture slides, lab assignments, and online lectures available to students and enthusiasts."
            },
            {
                "title": "DALL-E 3 Text-to-Image Release",
                "link": "http://openai.com/dall-e-3",
                "content": "DALL-E 3 Text-to-Image Release OpenAI releases version 3 of DALL-E, the mind blowing text-to-image system now integrated with ChatGPT which enabling users to generate artwork through conversation. This version simplifies the image generation process by removing the need for prompt engineering and will be available via ChatGPT and API for certain users from October. Notably, DALL-E 3 offers enhanced image quality, ensures images are copyright-free, and has implemented safety measures against biases. OpenAI is also developing a tool to detect AI-created images which is hoped to have better luck than their discontinuied AI-generated-text-detection attempt."
            },
            {
                "title": "InfoQ AI, ML & Data Eng Trends",
                "link": "http://www.infoq.com/articles/ai-ml-data-engineering-trends-2023/",
                "content": "InfoQ AI, ML & Data Eng Trends InnoQ releases an interesting report on 2023 trends in the AI, ML, and Data Engineering landscape: Insights include the rise of Generative AI, with Large Language Models like GPT-3 and GPT-4 taking center stage driven by platforms like ChatGPT. Vector databases are emerging as essential tools for enhancing search processes in LLM applications. The field is also witnessing a shift towards decentralized data engineering approaches such as Data Mesh, and a heightened emphasis on responsible and ethical AI. Meanwhile AI Coding Assistants and other GenAI-powered solutions are advancing in the technology adoption curve, indicating broader industry acceptance."
            },
            {
                "title": "Guide to Contributing to OSS",
                "link": "http://dev.to/srbhr/hacktoberfest-2023-the-complete-guide-1lkj",
                "content": "Guide to Contributing to OSS The Complete Guide to contributing to open source celebrating Hacktoberfest 2023 \ud83c\udf89 Hacktoberfest 2023 celebrates open-source contributions throughout October, emphasizing the professional growth, skill development, and networking opportunities it offers. The guide highlights top repositories that can be used to get started on open source contributions. This resource also shares lessons learned in the learning journey emphasising the value of community engagement and gradual progression in open-source contributions."
            },
            {
                "title": "Key Knowledge: Idempotency",
                "link": "http://www.berkansasmaz.com/every-programmer-should-know-idempotency/",
                "content": "Key Knowledge: Idempotency Every Programmer Should Know #1: Idempotency \ud83d\udca1 In the world of programming, there are many concepts that every developer should understand in order to build efficient and reliable systems. One such vital concept is idempotency, which refers to the property of an operation or function that produces the same result when applied multiple times as it does when applied only once. This may seem like a simple concept, but it has significant implications for building robust distributed systems. Grasping idempotency is vital for developers to build efficient and reliable systems."
            }
        ]
    },
    {
        "issue": "250",
        "items": [
            {
                "title": "GPT-4V(ision) First Impressions",
                "link": "http://blog.roboflow.com/gpt-4-vision/",
                "content": "GPT-4V(ision) First Impressions OpenAI\u2019s new version of GPT-4V is straight out of a scifi movie introducing computer-vision capabilities: GPT-4V(ision) is capable of processing both text and image inputs. This article does a great job at exploring GPT-4V\u2019s capabilities, revealing its proficiency in visual question answering, optical character recognition, and math problem-solving from images. There are interesting insights on the model limitations such as in object detection, CAPTCHA interpretation, and certain games like crosswords and sudokus. GPT-4V represents a significant advancement in machine learning, so it\u2019s essential to be aware of its potential and constraints, especially in considering production and real world scenarios."
            },
            {
                "title": "Causality for Machine Learning",
                "link": "http://ff13.fastforwardlabs.com/",
                "content": "Causality for Machine Learning Machine learning has made significant strides, but as its applications expand into decision-making, the importance of understanding causality becomes evident - this resource provides a comprehensive overview on Causality. Causality, as opposed to mere correlation, offers deeper insights into \u201cwhy\u201d something happens, allowing for better reasoning during interventions. The integration of causal inference with ML, championed by researchers like Judea Pearl, is an emerging field that promises to enhance the robustness, adaptability, and fairness of ML systems, moving beyond just predictions to understanding the underlying causal relationships."
            },
            {
                "title": "Hardest Part of Building Software",
                "link": "http://stackoverflow.blog/2023/06/26/the-hardest-part-of-building-software-is-not-coding-its-requirements/",
                "content": "Hardest Part of Building Software StackOverflow on how the hardest part of building software is not coding, it\u2019s requirements: Drawing parallels between AI\u2019s proficiency in tasks with finite parameters like chess and its struggles in complex tasks like self-driving cars, the author emphasizes that software development\u2019s intricacies resemble the latter. While AI can produce code, it can\u2019t inherently grasp or set nuanced software requirements. The transition from waterfall to agile methodologies is highlighted, with the assertion that AI might be efficient in rewriting existing software but can\u2019t replace the human element essential for determining software requirements."
            },
            {
                "title": "Habits of Effective Engineers",
                "link": "http://makingsmallercircles.com/articles/7-habits-of-highly-effective-software-engineers/",
                "content": "Habits of Effective Engineers 7 Habits of Highly Effective Software Engineers: 1) prioritize prototyping to test ideas, 2) refine their effort estimation skills, 3) conduct prompt code reviews, 4) maintain comprehensive documentation, 5) engage in open technical discussions, 6) focus on task completion, and 7) exhibit an innate curiosity about new technologies and broader contexts. Great article which highlights habits that underscore the significance of hands-on engagement, clear communication, and continuous learning in software and ML development."
            },
            {
                "title": "CMU Deep Learning Systems",
                "link": "http://dlsyscourse.org/lectures/",
                "content": "CMU Deep Learning Systems The Deep Learning Systems course from CMU is now available on YouTube offering a comprehensive materian on the intricacies of deep learning. The course blends theoretical insights with hands-on implementation sessions, covering topics from foundational ML concepts to advanced topics like transformers, hardware acceleration, and model deployment. It\u2019s tailored for machine learning practitioners aiming to bolster their expertise in deep learning systems, punctuated by student project showcases and interactive Q&A sessions."
            }
        ]
    },
    {
        "issue": "251",
        "items": [
            {
                "title": "The State of Production ML",
                "link": "http://www.youtube.com/watch?v=kMb4TmhTlbk",
                "content": "The State of Production ML The state of production ML in 2023: As the number of production machine learning use-cases increase, we find ourselves facing new and bigger challenges where more is at stake. Because of this, it\u2019s critical to identify the key areas to focus our efforts, so we can ensure our machine learning pipelines are reliable and scalable. In this talk we dive into the state of production machine learning in the Python Ecosystem, and we will cover the concepts that make production machine learning so challenging, as well as some of the recommended tools available to tackle these challenges."
            },
            {
                "title": "How Linkedin Uses Embeddings",
                "link": "http://engineering.linkedin.com/blog/2023/how-linkedin-is-using-embeddings-to-up-its-match-game-for-job-se",
                "content": "How Linkedin Uses Embeddings LinkedIn is enhancing its recommendation and search systems using Embedding based retrieval, a method that identifies relevant items based on their proximity in an embedding space. This technique captures the contextual intent of search or recommendation requests, ensuring geometrically close matches in the embedding space are retrieved. To support this, LinkedIn has developed new infrastructure components and introduced composite and multi-task learning models, streamlining the process of capturing user interests and delivering more personalized experiences."
            },
            {
                "title": "Large Language Models in 2023",
                "link": "http://www.youtube.com/watch?app=desktop&v=dbo3kNKPaUA&feature=youtu.be",
                "content": "Large Language Models in 2023 One of OpenAI ChatGPT core engineers shared insightful views in a recent presentation at Seoul National University on \u201cLarge Language Models (in 2023)\u201d. This highlights the evolving nature of LLMs, emphasizing the need for a perspective shift as abilities emerge at larger scales. The technical intricacies of scaling Transformers were discussed, emphasizing efficient matrix multiplications across multiple machines. An interesting perspective identified the maximum likelihood objective function as a potential bottleneck and advocated for a paradigm shift towards learning this function with a more expressive neural network, emphasizing the importance of first-principles understanding in this rapidly advancing field."
            },
            {
                "title": "StableDiffusion XL in 298mb RAM",
                "link": "http://github.com/vitoplantamura/OnnxStream/tree/846da873570a737b49154e8f835704264864b0fe#onnxstream",
                "content": "StableDiffusion XL in 298mb RAM OnnxStream is a specialized inference library designed to run large transformer models, particularly Stable Diffusion 1.5 and XL 1.0, on low-memory devices like the Raspberry Pi Zero 2. By focusing on minimizing memory consumption, OnnxStream can operate with up to 55x less memory than OnnxRuntime. The repository offers techniques like \u201cattention slicing\u201d and quantization to achieve these results and provides detailed build instructions for various platforms. This tool is ideal for ML practitioners aiming to deploy heavyweight models on memory-constrained devices."
            },
            {
                "title": "Picking a Vector DB in 2023",
                "link": "http://benchmark.vectorview.ai/vectordbs.html",
                "content": "Picking a Vector DB in 2023 A comprehensive comparison of leading vector databases in 2023, emphasizing their pivotal role in semantic search and retrieval-augmented generation. Among the databases analyzed, including Pinecone, Weviate, Milvus, Qdrant, Chroma, Elasticsearch, and PGvector, Milvus stands out in performance and community strength, while Pinecone shines for its developer experience and hosted solution. The ideal choice varies based on specific needs, with the author favoring Pinecone and Milvus for their performance, community engagement, and pricing flexibility."
            }
        ]
    },
    {
        "issue": "252",
        "items": [
            {
                "title": "Multimodality and LLMs Overview",
                "link": "http://huyenchip.com/2023/10/10/multimodal.html",
                "content": "Multimodality and LLMs Overview Chip Huyen has put together a comprehensive overview of Multimodality and Large Multimodal Models. The article delves into the rise of LLMs that operate beyond single data modalities, marking a shift from traditional ML models limited to text, image, or even audio. This article covers quite an extensive case for the potential of multimodality in LLMs following from DeepMind\u2019s recent GPT4V release. The article dives into: 1) exploring multimodality\u2019s context, 2) discussing fundamental multimodal systems like CLIP and Flamingo, and 3) highlighting ongoing research areas in LMMs such as efficient training techniques + new systems like BLIP-2 and LLaVA.\u200b"
            },
            {
                "title": "State of AI Report for 2023",
                "link": "http://www.stateof.ai/",
                "content": "State of AI Report for 2023 The State of AI Report for 2023 is out: This edition discusses key trends like GPT-4\u2019s surprise to the world, the efforts to mimic proprietary model performance, and real-world breakthroughs driven by Language Models and diffusion models in life sciences. The report also highlights the booming compute industry led by NVIDIA, the rise in generative AI startups amidst a tech valuation slump, and the ongoing global safety debate concerning AI, emphasizing the necessity for robust evaluations of state-of-the-art models."
            },
            {
                "title": "Stable Difussion from Scratch",
                "link": "http://www.youtube.com/watch?v=ZBKpAp_6TGI",
                "content": "Stable Difussion from Scratch A great resource to build a strong intuition on the fundamentals of Stable Difussion by building it from scratch. This video covers a deep dive starting with foundational concepts, including the intricacies of generative models, the mathematics behind them, and their applications, including text-to-image, image-to-image, and inpainting processes. You can also access the repository and the PDF slides."
            },
            {
                "title": "Inverted Transformer Forecasting",
                "link": "http://notes.aimodels.fyi/inverting-transformers-for-time-series-forecasting/",
                "content": "Inverted Transformer Forecasting Transformer-based forecasting continues to see insightful developments, this time from Tsinghua University researchers on an inverted transformer architecture. This is an interesting development similar to the TSMixer architecture that Google released a few months ago. This \u201ciTransformer\u201d architecture leverages an inverted which instead of treating each time step as a token, it embeds the entire variable history as individual tokens, addressing the typical Transformer limitations in this domain. It is suggested that this better captures multivariate correlations and encodes temporal series representations."
            },
            {
                "title": "Introduction to Modern Statistics",
                "link": "http://openintro-ims2.netlify.app/",
                "content": "Introduction to Modern Statistics A fantastic book providing an in-depth introduction to modern statistics with great accompanying resources, and for free (with a pay-what-you-wish option)! This v2 resource is in progress but with the first edition available online covering a broad range of topics including data introduction, exploratory data analysis, regression modeling, foundations of inference, statistical inference, and inferential modeling. The textbook comes with supplementary materials like slides, labs, and interactive tutorials, which would be useful for practitioners aiming to enhance their understanding of modern statistics in the context of production machine learning."
            }
        ]
    },
    {
        "issue": "253",
        "items": [
            {
                "title": "META/FB Decoding Brain Images",
                "link": "http://ai.meta.com/blog/brain-ai-image-decoding-meg-magnetoencephalography/",
                "content": "META/FB Decoding Brain Images Meta/Facebook on Towards a Real-Time Decoding of Images from Brain Activity: Meta has announced a significant development in understanding how the brain processes visual information, research which seems from scify and opening a large amount of ethical questions. Using magnetoencephalography (MEG), a non-invasive technique, they have developed an AI system that can decode and reconstruct images from brain activity in real-time. This system comprises three parts: an image encoder, a brain encoder, and an image decoder. When trained on a public dataset, the system showed that modern AI models, especially self-supervised ones like DINOv2, align well with brain signals, suggesting that these AI models learn representations similar to how the brain does. While the reconstructed images from MEG are not as precise as those from fMRI, a more spatially accurate but slower technique, they capture high-level features of the original images."
            },
            {
                "title": "Every Dev Should Know on GPUs",
                "link": "http://codeconfessions.substack.com/p/gpu-computing",
                "content": "Every Dev Should Know on GPUs What Every Developer Should Know About GPU Computing: GPUs are designed for massive parallelism and high throughput, this article delves into key GPU concepts such as architecture, streaming multiprocessors, memory hierarchies, and CUDA. Execution on GPUs involves launching threads in grids, grouped into warps for simultaneous processing which requires a different conceptual paradigm. Dynamic resource partitioning is crucial for optimizing GPU performance, with \u201coccupancy\u201d measuring resource utilization. The piece underscores the importance of understanding GPUs for modern engineers, especially in the realm of machine learning."
            },
            {
                "title": "Reflections on AI Summit 2023",
                "link": "http://eugeneyan.com/writing/aieng-reflections/",
                "content": "Reflections on AI Summit 2023 Eugene Yan on Reflections on AI Engineer Summit 2023: At the AI Engineer Summit 2023, key takeaways included the challenges of evaluations and serving costs in deploying large language models. While evaluation techniques vary, there\u2019s no universally accepted method, though code generation offers a more straightforward evaluation path. LLMs prove cost-effective for complex tasks but are expensive for simple ones. Integration with existing systems, the potential of caching, the prominence of retrieval-augmented generation (RAG), the rise of coding assistants, and the anticipated growth of multimodal models were also discussed. The summit underscored the importance of finetuning, self-hosting, and the remarkable work ethic of San Francisco engineers."
            },
            {
                "title": "Multimodal Architecture Agents",
                "link": "http://www.adept.ai/blog/fuyu-8b",
                "content": "Multimodal Architecture Agents Adept.ai has released a multimodal foundation model available on HuggingFace under the name Fuyu-8B, which is designed to natively understand both images and text. Unlike traditional multimodal models, Fuyu-8B boasts a simpler architecture without a separate image encoder, allowing it to support arbitrary image resolutions and deliver fast response times. The model is particularly adept at interpreting charts, diagrams, and documents, and Adept.ai\u2019s internal versions showcase additional capabilities like OCR and UI element localization, hinting at features for their upcoming product release."
            },
            {
                "title": "The Startup CTO Handbook",
                "link": "https://github.com/ZachGoldberg/Startup-CTO-Handbook",
                "content": "The Startup CTO Handbook \u201cThe Startup CTO\u2019s Handbook\u201d by Zach Goldberg is a comprehensive guide tailored for technical leaders in startups, emphasizing the importance of continuous learning and adaptability. Drawing from his experiences across various startups, it\u2019s an interesting resource that offers insights into both technical and managerial aspects of leadership. The book serves as a reference guide, covering a broad spectrum of topics from business processes to people management, underscoring the significance of viewing managers as coaches and the value of mentorship in leadership development."
            }
        ]
    },
    {
        "issue": "254",
        "items": [
            {
                "title": "Text Embeddings Visual Overview",
                "link": "http://txt.cohere.com/text-embeddings/",
                "content": "Text Embeddings Visual Overview Text Embeddings Visually Explained: Great article from Cohere covering the intuition behind text embeddings. This article covers the numerical representations of text that capture its meaning visualizations, showcasing a practical example with the Airline Travel Information System dataset. The article demonstrates how embeddings can transform unstructured text into structured data, enabling context-aware search, clustering, and classification. The piece also highlights the benefits of finetuning models on specific data to enhance performance, emphasizing the potential of text embeddings in handling vast amounts of unstructured data for various applications."
            },
            {
                "title": "Lessons from 20 Years at Scale",
                "link": "http://sre.google/resources/practices-and-processes/twenty-years-of-sre-lessons-learned/",
                "content": "Lessons from 20 Years at Scale Lessons from 20 years of SRE at Google: A very practical and insightful article sharing actionable learnings for the operation of production systems, which include: 1) importance of proportional risk assessment; 2) testing of recovery mechanisms; 3) canary all changes; 3) emergency reversion mechanisms; 4) ensuring diverse communication channels; 5) designing for graceful degradation; 6) emphasizing disaster resilience; 7) automating mitigations; 8) maintaining frequent rollout cadence, and; 9) diversifying infrastructure to prevent single points of failure"
            },
            {
                "title": "Advanced Python Mastery Course",
                "link": "http://github.com/dabeaz-course/python-mastery",
                "content": "Advanced Python Mastery Course Advanced Python Mastery Free Open Course: A fantastic comprehensive exercise-driven course designed for intermediate Python programmers! This course delves deep into advanced programming techniques commonly used in popular libraries and frameworks, including detailed slides, exercises, and solutions. It excludes certain modern features like async and typing but dives into some of the core foundations of the Python language - a very valuable resource for those aiming to elevate their Python skills."
            },
            {
                "title": "Linkedin Managed Search Infra",
                "link": "http://engineering.linkedin.com/blog/2022/hosted-search--linkedin-search-as-a-cloud-service",
                "content": "Linkedin Managed Search Infra LinkedIn shares interesting insights of their internal fully managed search platform designed to streamline and democratize search integration for product teams. Their system has allowed to offloads setup, maintenance, and operational tasks from application teams, simplifying the previously complex SeaS verticals. In its inaugural year, Hosted-Search onboarded more use cases than the legacy SeaS did throughout its lifetime, and is now also supporting Global Secondary Indexes in Espresso tables, enhancing the overall search experience for LinkedIn members."
            },
            {
                "title": "Bare Min Knowledge on Unicode",
                "link": "http://tonsky.me/blog/unicode/",
                "content": "Bare Min Knowledge on Unicode Any ML practitioner working with text will be caught by the intricacies of unicode at one point; this article dives into the absolute minimum every developer should know about unicode. This article dives into the intricacies of Unicode, highlighting its evolution from a challenge of identifying text encoding to the widespread adoption of UTF-8. It also touches into key concepts such as normalization, locale dependence in rendering, and the continued relevance of UTF-16 in some systems. Some of these tips can save long-afternoons of debugging trying to figure out what is wrong with something which may seem unintuitive."
            }
        ]
    },
    {
        "issue": "255",
        "items": [
            {
                "title": "ACM TPC & State of Tech Policy",
                "link": "http://docs.google.com/presentation/d/15DvVUG4knD3czYTWoEm6OfW_DjW09-mhr_5rHqEChwQ/edit#slide=id.g13d1f7cbf12_0_0",
                "content": "ACM TPC & State of Tech Policy The regulatory ecosystem for AI & Data is moving at breakneck speed; this resource summarises our major contributions in 2023 across the AI Act, Data Act, Digital Services Act and beyond. We have also included some of the most interesting trends in the AI regulatory policy landscape in the EU, which we will continue to explore through the Association for Computing Machinery\u2019s Europe Technology Policy Committee (ACM EuropeTPC)."
            },
            {
                "title": "Python 17,000x Faster Data",
                "link": "http://sidsite.com/posts/python-corrset-optimization/",
                "content": "Python 17,000x Faster Data Analyzing Data 170,000x Faster with Python: Great article showcasing a journey optimizing Python code to achieve a significant speed increase in data analysis tasks. This includes a practical example with an unoptimized Python exerpt, showing various improvements and optimisations to reduce execution time. Techniques include using dictionaries for faster lookups, leveraging NumPy for efficient numerical computations, and introducing Numba for just-in-time compilation. The article serves as a case study in Python optimization, demonstrating that with careful profiling and targeted improvements, Python can be made vastly more efficient for data-heavy computations."
            },
            {
                "title": "Google\u2019s ML Weather Forecast",
                "link": "http://blog.research.google/2023/11/metnet-3-state-of-art-neural-weather.html?m=1",
                "content": "Google\u2019s ML Weather Forecast MetNet-3 has been released by Google Research and DeepMind; is a state-of-the-art neural weather prediction model that surpasses traditional numerical weather prediction models in accuracy for up to 24-hour forecasts. It leverages a novel densification technique to integrate high-resolution direct atmospheric observations into dense, granular forecasts with 2-minute intervals and 1-4 km spatial resolutions. MetNet-3\u2019s real-time, hyperlocal weather forecasts are now operational within various Google products, providing users with precise weather information, particularly for precipitation, across the contiguous United States and parts of Europe. This showcases the practical application of machine learning in real-time, large-scale systems for critical information."
            },
            {
                "title": "Most Valuable Traits of Top Devs",
                "link": "http://engineercodex.substack.com/p/the-1-trait-of-the-most-valuable",
                "content": "Most Valuable Traits of Top Devs The most valuable trait of top software engineers; engineering codex on the mindset shift that changed the way they approach software development. Insigthful article coverign the growing role of \u201cproduct engineering\u201d which extends to user-centric solutions and overall product direction. Key traits highlighted include comprehensive product skills, emphasizing direct user engagement, feedback integration, and user-focused metrics. While technical expertise remains crucial, the most valuable engineers are those who can apply their skills to significantly advance their product, a mindset that is particularly vital in startup environments but less common in larger tech companies."
            },
            {
                "title": "Animated AI Neural Architectures",
                "link": "http://animatedai.github.io/",
                "content": "Animated AI Neural Architectures Animated AI: A great resource that provides intuitive visual explanations of different convolutional neural network operations. This includes images as well as videos that dive into operations like padding, stride, and different convolutional architectures. Additionally, it covers the pixel shuffle technique for changing resolution in neural networks, demonstrated with different block sizes and corresponding animations\u200b."
            }
        ]
    },
    {
        "issue": "256",
        "items": [
            {
                "title": "Building AI Products Differently",
                "link": "http://www.builder.io/blog/build-ai",
                "content": "Building AI Products Differently Don\u2019t Build AI Products The Way Everyone Else Is Doing It: A great reminder on the value of defensibility in technology vs surface-level value. Key advices for production machine learning practitioners to avoid over-reliance on LLM services like ChatGPT for AI product development. Although this can be great for rapid prototyping, this can lead to a lack of differentiation, inefficiency and lack of value add. Instead, focusing on the value adding overarching use-case whilst leveraging specialised toolchains that combine fine-tuned models, custom compilers, and specialised models."
            },
            {
                "title": "Vector Databases Applications",
                "link": "http://www.deeplearning.ai/short-courses/vector-databases-embeddings-applications/",
                "content": "Vector Databases Applications New free online course from DeepLearning.ai on Vector Databases & Embeddings Applications: A great new specialized resource for machine learning practitioners, focusing on the use of vector databases in enhancing large language models. It covers the significance of embeddings in understanding data and measuring vector similarities, crucial for fields like NLP, image recognition, and semantic search. The course offers practical skills in using vector databases with LLMs, building labs for embeddings, and exploring algorithms for efficient data searches, making it ideal for professionals aiming to develop advanced data retrieval and analysis applications."
            },
            {
                "title": "Misconceptions in Engineering",
                "link": "http://www.mensurdurakovic.com/hard-to-swallow-truths-they-wont-tell-you-about-software-engineer-job/",
                "content": "Misconceptions in Engineering Hard to Swallow Truths They Won\u2019t Tell You About The Software Engineer Job. An insigthful and pragmatic perspective on the software engineering profession, including: 1) the gap between academic preparation and real-world demands, 2) working on existing vs new projects, 3) value creation over code perfection, 4) challenges of workplace incompetence, 5) importance of effective communication and meetings, 6) difficulties in making accurate project estimates, 7) inevitability of encountering bugs, 8) constant presence of uncertainty, 9) struggle to maintain work-life balance, and 10) crucial role of soft skills over technical skills in career advancement. This candid overview is particularly relevant for machine learning practitioners, who face similar challenges in our field."
            },
            {
                "title": "Takeaways on AI Executive Order",
                "link": "http://www.ey.com/en_us/public-policy/key-takeaways-from-the-biden-administration-executive-order-on-ai",
                "content": "Takeaways On AI Executive Order Key takeaways from US executive order on AI: The global AI regulatory ecosystem is seeing surprisingly fast developments, recently seeing the US joining the AI regulation theme with the AI Executive order. This is a great resource summarising some of the key takeaways of the Executive Order, which broadly defines AI, encompassing a wide range of systems, and is structured around eight guiding principles focusing on safety, security, innovation, equity, and governance. NIST is also positioned to play a key role in developing AI guidelines and best practices. This order impacts organizations across all sectors, requiring a reassessment of AI use and reliance on third-party AI capabilities. There will be a growing importance in ensuring sound international interoperability; if you are interested in this space, check out our awesome AI guidelines repo which includes a broad section on policy."
            },
            {
                "title": "OECD New Definition on AI",
                "link": "http://oecd.ai/en/ai-principles",
                "content": "OECD New Definition on AI The OECD adopted a new definition for AI systems: \u201cAn AI system is a machine-based system that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments. Different AI systems vary in their levels of autonomy and adaptiveness after deployment.\u201d This comes as part of the OECD Principles for responsible development and deployment of AI. This resource provides a deeper dive into some of the core themes and definitions that are being adopted, reviewed and iterated as part of this increasingly fast evolution of AI regulation and industry standards."
            }
        ]
    },
    {
        "issue": "257",
        "items": [
            {
                "title": "TimeGPT: Magical Auto Forecast",
                "link": "http://www.youtube.com/watch?v=n7luRRyxLoQ",
                "content": "TimeGPT: Magical Auto Forecast TimeGPT introduces magical auto-forecast capabilities that leverage GPT breakthroughs, making advanced forecasting accessible to anyone. The team behind the highly popular open source packages statsforecast, neuralforecast and mlforecast have released TimeGPT, a cutting-edge generative pre-trained transformer model dedicated to forecasting tasks. This showcases innovative application of SOtA technology in a traditional field of ML, allowing users to benefit from forecasts with a handful lines of code, automating standard tasks with best practices across cleaning datasets, perform hyperparam optimisation, cross validation, as well as concepts such as seasonality, trends, uncertainty estimation, etc."
            },
            {
                "title": "tldraw; When UX and AI Intersect",
                "link": "http://tldraw.substack.com/p/make-real-the-story-so-far",
                "content": "tldraw; When UX and AI Intersect When UI/UX design and AI intersect we get mind-blowing results: In this case TLDraw is bridging design and implementation by introducing a ChatGPT powered tool that converts sketches into real-life web applications that can be iterated. Their free OSS tool is live at\u00a0https://makereal.tldraw.com/, where users can sketch a user interface and convert it into a functional website using OpenAI\u2019s GPT-4 with Vision model. This tool, leveraging the tldraw component, enables an interactive and iterative design process directly on the canvas, where users can draw, edit, and refine their UI designs with AI assistance. This development captures the significant leap we are seeing in in AI-assisted web design, offering practitioners a novel and efficient method for rapid prototyping and development of web interfaces."
            },
            {
                "title": "Deep Learning Weather Forecast",
                "link": "http://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting/",
                "content": "Deep Learning Weather Forecast DeepMind on a new Weather forecasting\u00a0Deep Learning model: GraphCast is a groundbreaking AI model for weather forecasting, outperforming traditional systems with its ability to deliver highly accurate 10-day forecasts in under a minute. Utilizing machine learning and Graph Neural Networks, and trained on four decades of weather data, GraphCast excels in predicting various atmospheric and Earth-surface variables, including extreme weather events. Its efficiency and accuracy, demonstrated in surpassing over 90% of traditional forecast variables, mark a significant advancement in weather prediction technology. What is best is that it has been Open-sourced for broader use; GraphCast represents a major leap in AI\u2019s application to environmental challenges, and suggests offering both practical forecasting tools and insights into climate pattern understanding."
            },
            {
                "title": "Geneva Uni Neural Nets Course",
                "link": "http://fleuret.org/dlc/",
                "content": "Geneva Uni Neural Nets Course A new free online course on Deep Learning by the University of Geneva, Switzerland: This course covers a wide range of topics, including machine learning fundamentals, tensor operations, deep learning techniques, and applications in computer vision and natural language processing, using the PyTorch framework. The course materials, including detailed slides, handouts, and screencasts, are well-suited for professionals seeking to deepen their understanding of modern deep learning concepts and practices. Additionally, it provides practical sessions and a virtual machine setup for hands-on experience, although with noted performance and security limitations."
            },
            {
                "title": "Humans vs GPT-4 on Reasoning",
                "link": "http://arxiv.org/abs/2311.09247",
                "content": "Humans vs GPT-4 on Reasoning Following the broad range of benchmarks across transformer-based LLMs, we now see are starting to see evaluations that compare human performance across relevant tasks. This insightful paper examines the abstract reasoning capabilities of GPT-4 and its multimodal variant, GPT-4V, using the ConceptARC benchmark. It extends previous research by applying more complex one-shot prompts to GPT-4 and evaluating GPT-4V with both zero- and one-shot prompts on simpler tasks. The findings reveal that neither version of GPT-4 currently matches human-level abstraction abilities, offering insights for machine learning practitioners in AI and language model development."
            }
        ]
    },
    {
        "issue": "258",
        "items": [
            {
                "title": "AI Policy, Principles & Guidelines",
                "link": "http://github.com/EthicalML/awesome-artificial-intelligence-guidelines",
                "content": "Awesome AI Guidelines to check out this week"
            },
            {
                "title": "Neural Networks: Zero to Hero",
                "link": "https://karpathy.ai/zero-to-hero.html",
                "content": "Neural Networks: Zero to Hero Andrej Karpathy\u2019s course on Deep Learning - From Zero to Hero: A great advanced course for machine learning practitioners, focusing on building neural networks from the ground up with emphasis on deep learning and language models. It covers the fundamentals of neural networks and backpropagation, dives into language modeling with a focus on character-level models and multilayer perceptrons (MLPs), and progresses to more complex topics like Batch Normalization, manual backpropagation techniques, and constructing architectures akin to WaveNet. The course also delves into building a Generatively Pretrained Transformer (GPT) from scratch, providing practical, hands-on experience in deep learning, particularly beneficial for those with a solid Python background and basic math knowledge."
            },
            {
                "title": "Stable Difussion Video Release",
                "link": "http://stability.ai/news/stable-video-diffusion-open-ai-video-model",
                "content": "Stable Difussion Video Release Generative AI is now reaching mainstream high quality video generation with Stable Diffusion\u2019s Video model release: Stability AI\u2019s Video Diffusion model is a new addition to their suite of AI models, currently focused on research and not intended for real-world or commercial use. They are soliciting feedback for its refinement and highlight its potential applications in sectors like Advertising, Education, and Entertainment. The model is part of a broader range of open-source models across various modalities, with the waitlist open for this new Text-To-Video interface."
            },
            {
                "title": "Hidden Tech Debt in ML Systems",
                "link": "http://papers.nips.cc/paper_files/paper/2015/hash/86df7dcfd896fcaf2674f757a2463eba-Abstract.html",
                "content": "Hidden Tech Debt in ML Systems Hidden Technical Debt in Machine Learning Systems: A great resource to revisit from time to time, which has provided a pioneering view to the challenges of production machine learning, together with one of the most re-used images in MLOps. It was published in NeurIPS back in 2015by D. Sculley and colleagues, and warns production machine learning practitioners about the often-overlooked long-term maintenance costs or \u201ctechnical debt\u201d of ML systems. It highlights critical risk factors such as boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, configuration issues, changes in the external world, and system-level anti-patterns. This work emphasizes the importance of careful system design and maintenance considerations in ML projects to prevent accruing hidden costs and complexities over time."
            },
            {
                "title": "Hacking Google Bard Vulnerability",
                "link": "http://embracethered.com/blog/posts/2023/google-bard-data-exfiltration/",
                "content": "Hacking Google Bard Vulnerability Machine Learning security continues to grow in importance across production systems; this article \u201cHacking Google Bard\u201d dives into a vulnerability reported (and resolved) reminding us the importance: Google Bard, is Google\u2019s version of ChatGPT - this article showcases data exfiltration through Indirect Prompt Injection attacks. This vulnerability was exploited by using Bard\u2019s new Extensions feature to access personal documents and emails, and manipulating its markdown rendering capability to create image tags that connected to an attacker-controlled server. The exploit involved bypassing Google\u2019s Content Security Policy using Google Apps Script, enabling the exfiltration of chat history to a Google Doc. The issue was reported to Google and fixed within a month, highlighting the security challenges in LLM applications, especially when handling sensitive data."
            }
        ]
    },
    {
        "issue": "259",
        "items": [
            {
                "title": "Instacart\u2019s Prod ML Platform",
                "link": "http://tech.instacart.com/unveiling-the-core-of-instacarts-griffin-2-0-8ecb310c8d32",
                "content": "Instacart\u2019s Prod ML Platform Instacart\u2019s Machine Learning Platform Griffin 2.0: A great overview on Instacart\u2019s advanced machine learning platform, extending to model management, and deployment automation. It showcases a unified web interface, supports distributed ML tasks, and is built on a Kubernetes platform for centralized training workloads. They introduce important features in the MLOps space including standardized ML runtimes, horizontal scalability using Ray, and a comprehensive metadata store for effective model lineage management. The platform streamlines the model development lifecycle, offering a balanced approach between flexibility and standardization, and integrates model serving and feature engineering for a holistic ML workflow. This evolution reflects interesting lessons learned in unifying ML training solutions and considering broader application contexts."
            },
            {
                "title": "AI Self-Operating Computer",
                "link": "http://github.com/OthersideAI/self-operating-computer",
                "content": "AI Self-Operating Computer You can now enable large language models run your computer: An innovative project designed to enable multimodal models like GPT-4v to autonomously operate a computer using human-like mouse and keyboard actions. It provides some interesting results even though it currently faces limitations, particularly in accurately estimating mouse click locations. The project is open source, and with opportunities for the broader AI community to support the evolution of this interesting framework."
            },
            {
                "title": "Statistical vs DL Forecasting",
                "link": "http://github.com/Nixtla/statsforecast/tree/main/experiments/m3",
                "content": "Statistical vs DL Forecasting Statistical vs Deep Learning forecasting methods: In Nixtla\u2019s analysis comparing deep learning (DL) models with statistical ensembles for time series forecasting in the M3 competition, they showcased how a simple statistical ensemble could outperform most individual DL models in these contexts. This raised an interesting tradeoff that also showcased the advantages in efficiency and cost; namely running 25,000x faster at a cost of $0.5c, compared to over 14 days and approximately USD 11,000 for the DL ensemble. This suggests that in contexts where resources and simplicity are critical, statistical methods should be considered before moving to more complex and costly DL models. These outcomes are complementary to the growing opportunities arising in deep learning transformed based architetures for forecasting, supporting accurate forecasting at massive-scale; we are expceted to see an interesting development across both DL and Stat FC in the near term."
            },
            {
                "title": "Google DeepMind Music Model",
                "link": "http://deepmind.google/discover/blog/transforming-the-future-of-music-creation/",
                "content": "Code is Run more than Read"
            },
            {
                "title": "Code is Run more than Read",
                "link": "http://deepmind.google/discover/blog/transforming-the-future-of-music-creation/",
                "content": "Code is Run more than Read"
            }
        ]
    },
    {
        "issue": "260",
        "items": [
            {
                "title": "Practical Deep Learning FastAI",
                "link": "http://course.fast.ai/",
                "content": "Practical Deep Learning FastAI Practical Deep Learning for Coders is one of the staple Free courses to build a solid foundation in hands-on machine learning: Jeremy Howard\u2019s advanced 30+ hour video course targeting individuals with coding experience, focusing on applying deep learning in real-world scenarios. The course covers building and training models for various domains using PyTorch, fastai, and Hugging Face libraries, with a strong emphasis on practical skills and minimal prerequisites. Great course for ML practitioners looking to enhance their skills in model building, deployment, and understanding deep learning mechanics. It includes 9 detailed lessons teaching through hands-on exercises using tools like Jupyter Notebooks, Kaggle Notebooks, and Paperspace Gradient."
            },
            {
                "title": "AI Generating Triangle Meshes",
                "link": "http://nihalsid.github.io/mesh-gpt/",
                "content": "AI Generating Triangle Meshes MeshGPT follows the text-to-image models with a mind-blowing text-to-3d-mesh model: MeshGPT represents a significant advancement in 3D mesh generation, utilizing a transformer-based approach to autoregressively generate high-fidelity, compact triangle meshes. This method involves learning a vocabulary of geometric embeddings, informed by local mesh geometry and topology, and using these to sequence and decode triangles. MeshGPT significantly outperforms existing methods, yielding meshes with sharp details and efficient triangulation. Quite interesting to see its applicability for tasks like shape completion and 3D asset generation, which can mark a substantial improvement in both the quality and utility of generated 3D meshes."
            },
            {
                "title": "Extracting Data from ChatGPT",
                "link": "http://not-just-memorization.github.io/extracting-training-data-from-chatgpt.html",
                "content": "Extracting Data from ChatGPT Google DeepMind, University of Washington, Cornell, CMU, UC Berkeley, and ETH Zurich demonstrates a novel method to extract substantial amounts of training data from ChatGPT: An insightful research paper that re-emphasises the importance of security in production machine learning system. In this paper they show how prompting ChatGPT to repetitively use a word (e.g., \u201cpoem\u201d), they bypassed its alignment safeguards, revealing sensitive information and highlighting significant vulnerabilities in production models. This emphasises the importance of patching specific exploits and addressing underlying vulnerabilities. The findings emphasize the importance of understanding and mitigating fundamental vulnerabilities in language models, contributing to the field\u2019s knowledge of securing machine learning systems in production environments."
            },
            {
                "title": "Stable Difussion Visual Anagrams",
                "link": "http://dangeng.github.io/visual_anagrams/",
                "content": "Stable Difussion Visual Anagrams Generating Multi-View Optical Illusions with Diffusion Models: A novel zero-shot method for generating multi-view optical illusions using pretrained diffusion models. This method estimates and averages the noise in different image transformations, such as rotations, flips, and color inversions, using a diffusion model. The approach requires the transformations to be linear and statistically consistent, with a focus on orthogonal transformations like pixel permutations. This advancement in creating optical illusions demonstrates a unique application of diffusion models, offering significant improvements over previous works in terms of illusion quality and range of transformations, and has potential applications in artistic and visual media domains."
            },
            {
                "title": "Designing Distributed SQL Engine",
                "link": "http://en.oceanbase.com/blog/2596985600",
                "content": "Designing Distributed SQL Engine Challenges & Decisions of Designing a Distributed SQL Engine: An insightful resource discussing the intricacies of designing an SQL engine, which focuses on the architecture decisions, including the Plan Cache, Query Optimizer, and various execution engines (Volcano, Parallel, Vectorized). Some of the key highlights include the efficiency of Plan Cache in OLTP workloads, the use of the System-R approach in the Query Optimizer, and the distinct features of each execution engine to optimize SQL query processing. This information is particularly relevant for MLOps / ML Platform practitioners dealing with large datasets, as it offers insights into efficient data querying, optimization techniques, and execution strategies crucial for managing and processing big data in machine learning pipelines."
            }
        ]
    },
    {
        "issue": "261",
        "items": [
            {
                "title": "Billion Scale Vector Search",
                "link": "http://haystackconf.com/us2022/talk-6/",
                "content": "Billion Scale Vector Search A recent NeurIPS competition challenged Meta, Google, Microsoft & other Tech companies on vector search & ANN algorithms on massive-scale billion-sized datasets: The \u201cBillion-Scale Approximate Nearest Neighbor Search\u201d challenge challenges advancements in Approximate Nearest Neighbor (ANN) search algorithms for large-scale datasets, focusing on the first Billion-Scale Approximate Nearest Neighbors. This challenge was sponsored by NeurIPS in 2021 and marked a significant step in evaluating ANN algorithms at the billion-scale, assessing their performance, accuracy, and hardware cost across six billion-scale datasets. The results highlight the need for efficient ANN solutions in large-scale data environments, particularly relevant for production machine learning practitioners dealing with high-dimensional nearest neighbor searches."
            },
            {
                "title": "Mozilla\u2019s MemoryCache Local AI",
                "link": "http://future.mozilla.org/blog/introducing-memorycache/",
                "content": "Mozilla\u2019s MemoryCache Local AI The Mozilla Innovation Project introduces Local AI with their new private AI-model product \u201cMemoryCache\u201d: An interesting experimental initiative by Mozilla aimed at enhancing personal AI models by integrating locally-saved browser data, focusing on privacy and individualized experiences. It includes a Firefox extension for saving web pages, a script for processing saved data with privateGPT, and an optional PDF saving feature for readability. Currently it is in sandbox stage, and is being tested on specific hardware and software configurations, which has highlighted challenges in balancing personalization with the risk of over-generalization in AI responses. This project offers valuable insights for machine learning practitioners interested in personalized & private AI development."
            },
            {
                "title": "Deep Learning Foundations Book",
                "link": "http://www.bishopbook.com/",
                "content": "Deep Learning Foundations Book A new (freely available!) book on Deep Learning foundations authored by experts and endorsed by renowned figures like Hinton, LeCun, Bengio and others: The new book \u201cDeep Learning Foundations & Concepts\u201d is a great comprehensive resource tailored for both newcomers and seasoned machine learning practitioners. It delves into the core concepts of deep learning, offering a structured approach suitable for academic courses and self-study. The book emphasizes practical applications over abstract theory, providing a blend of textual explanations, diagrams, and mathematical formulations. It is also available for free as an online copy if you want to read it at no costs."
            },
            {
                "title": "Google\u2019s Machine Learning for ML",
                "link": "http://blog.research.google/2023/12/advancements-in-machine-learning-for.html",
                "content": "Google\u2019s Machine Learning for ML Google\u2019s recent initiative to leverage machine learning to optimize machine learning: The team at Google highlights advancements in using machine learning to optimize ML compilers which is key for optimisations of ML model efficiency on hardware. The introduction of the \u201cTpuGraphs\u201d dataset marks a significant step in this direction, offering a large-scale resource for developing learned cost models, particularly for Google\u2019s TPUs. The post also discusses innovative techniques like Graph Segment Training for managing large graphs and insights from a Kaggle competition, which revealed novel approaches like graph pruning and cross-configuration attention. These developments are particularly relevant for ML practitioners focused on optimizing model performance and efficiency."
            },
            {
                "title": "Probabilistic Data Structures",
                "link": "http://highlyscalable.wordpress.com/2012/05/01/probabilistic-structures-web-analytics-data-mining/",
                "content": "Probabilistic Data Structures As we growingly interact with billion-scale datasets we require new paradigms to extract insights at scale, this is where probabilistic data structures come in - this is one of the best articles out there on this topic: This article provides a strong intuition on various efficient methods for analyzing large-scale data sets leveraging probabilistic data structures. The article provides a deep dive on each of these key data structures with practical case studies, covering Linear Counters, Loglog Counters, Count-Min Sketches, Count-Mean-Min Sketches, Stream-Summary, and Bloom Filters. The article discusses their applications in various scenarios, such as tracking unique website visitors or monitoring IP traffic, and highlights their adaptability for complex queries. This approach is particularly relevant for machine learning practitioners dealing with big data, as it provides a means to optimize system performance in data-intensive tasks."
            }
        ]
    },
    {
        "issue": "262",
        "items": [
            {
                "title": "Machine Learning at Stanford",
                "link": "https://www.youtube.com/playlist?app=desktop&list=PLoROMvodv4rNyWOpJg_Yh4NSqI4Z4vOYy&cbrd=1",
                "content": "Machine Learning at Stanford"
            },
            {
                "title": "Don\u2019t Build a Vector Database",
                "link": "https://blog.elicit.com/search-vs-vector-db/",
                "content": "Don\u2019t Build a Vector Database"
            },
            {
                "title": "LLM 3D Visualisation Demo",
                "link": "https://bbycroft.net/llm",
                "content": "LLM 3D Visualisation Demo"
            },
            {
                "title": "Scaling Pinterest to Millions Users",
                "link": "https://read.engineerscodex.com/p/how-pinterest-scaled-to-11-million",
                "content": "Scaling Pinterest to Millions Users"
            },
            {
                "title": "Optimising LLMs from Datasets",
                "link": "https://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html",
                "content": "Optimising LLMs from Datasets"
            }
        ]
    },
    {
        "issue": "263",
        "items": [
            {
                "title": "\ud83e\udd73 Celebrating 5 years towards 2024 \ud83e\udd73",
                "link": "https://www.linkedin.com/feed/update/urn:li:activity:7146802107847757824/",
                "content": "\ud83e\udd73 Celebrating 5 years towards 2024 \ud83e\udd73"
            },
            {
                "title": "Real Time AI Image Generation",
                "link": "https://github.com/cumulo-autumn/StreamDiffusion",
                "content": "Real Time AI Image Generation"
            },
            {
                "title": "Deep Learning 33 years vs now",
                "link": "https://karpathy.github.io/2022/03/14/lecun1989/",
                "content": "Deep Learning 33 years vs now"
            },
            {
                "title": "Cohere LLM Foundation Course",
                "link": "https://docs.cohere.com/docs/llmu",
                "content": "Cohere LLM Foundation Course"
            },
            {
                "title": "Habits of Great Engineers",
                "link": "https://vadimkravcenko.com/shorts/habits-of-great-software-engineers/",
                "content": "Habits of Great Engineers"
            }
        ]
    },
    {
        "issue": "264",
        "items": [
            {
                "title": "\ud83e\udd73 Celebrating 5 years towards 2024 \ud83e\udd73",
                "link": "https://www.linkedin.com/feed/update/urn:li:activity:7146802107847757824/",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "Databases 2023 Year in Review",
                "link": "https://ottertune.com/blog/2023-databases-retrospective",
                "content": "Databases in 2023: A Year in Review (with AI at the helm!) \ud83d\udca1 In 2023, the database industry was marked by the rise of vector databases, fueled by the growing interest in Large Language Models like ChatGPT, which revolutionized semantic search in unstructured data. This trend led to rapid adoption by various DBMS vendors and significant venture capital investment. Concurrently, SQL continued to evolve with the SQL:2023 specification, enhancing graph-structured queries and array data handling. The industry also faced challenges, exemplified by MariaDB Corporation\u2019s struggles and the FAA\u2019s NOTAM system outage, underscoring the risks of legacy systems. Oracle (under Larry Ellison) achieved significant milestones, reflecting the dynamic and evolving nature of the database sector, increasingly influenced by AI and ML technologies."
            },
            {
                "title": "Meta\u2019s Audio2Animation AI Model",
                "link": "https://github.com/facebookresearch/audio2photoreal",
                "content": "Meta\u2019s new Audio-to-3D-Animation AI model with open source code, pretrained models and datasets: An insightufl new research project from Meta Research which presents a framework for generating photorealistic, full-bodied human avatars from audio inputs, focusing on conversational gestures. They have also made available an OSS PyTorch implementation, including training and testing code, pretrained models, and a specialized dataset. The paper highlights the use of vector quantization and diffusion processes to create dynamic and expressive avatar motions, outperforming existing methods. This work is significant for applications in general computer animated interactions, which for meta seems to continue on their Metaverse quest."
            },
            {
                "title": "Efficient Multimodal OSS LLMs",
                "link": "https://github.com/DLYuanGod/TinyGPT-V",
                "content": "TinyGPT-V brings us an exciting step forward towards high-performance LLMs that can run in modest hardware: TinyGPT-V is an innovative multimodal large language model designed for efficient performance on commodity hardware, requiring only a 24G GPU for training and an 8G GPU or CPU for inference. Both the code and the model have now been open sourced, which were built upon the Phi-2 architecture and integrate pre-trained vision modules, boasting 2.8 billion parameters. It stands out for its unique quantization process, making it suitable for various devices including devices with limited memory. TinyGPT-V represents a breakthrough in making advanced MLLMs accessible for a broader range of applications, significantly reducing the computational resources required for high-level multimodal learning tasks."
            },
            {
                "title": "Deep Learning on Relational DBs",
                "link": "https://arxiv.org/abs/2312.04615",
                "content": "Introducing Deep Learning for Relational Database Data Structures and Graph Relationships: Relational Deep Learning is a groundbreaking approach introduced for efficiently utilizing data from relational databases in machine learning. This method treats databases as heterogeneous graphs, where rows are nodes and primary-foreign key relations are edges, enabling the use of Message Passing Graph Neural Networks for direct learning from multi-table data without manual feature engineering. RDL enhances model accuracy and reduces data preparation time, representing a significant advancement for practitioners dealing with complex, relational datasets. The paper also introduces RelBench, a set of diverse benchmark datasets and an RDL implementation framework, marking a new direction in graph machine learning research applicable to a wide array of AI use cases."
            }
        ]
    },
    {
        "issue": "265",
        "items": [
            {
                "title": "Survey of Vector Databases",
                "link": "https://arxiv.org/abs/2310.14021",
                "content": "2023 Survey of Vector Database Management Systems; a great and comprehensive overview of the recent advancements and challenges in vector database management systems, essential for managing unstructured data in applications like large language models: This paper discusses the unique challenges of vector data management, including issues related to semantic similarity, vector size, and indexing difficulties. The survey delves into various techniques for query processing, storage, and indexing, including vector compression and novel query optimization strategies. It categorizes VDBMSs into native and extended systems, highlighting their specific characteristics. The paper also identifies unresolved issues like selecting appropriate similarity scores and designing efficient hybrid operators. This survey is crucial for machine learning practitioners, offering insights into managing large-scale unstructured data in modern applications."
            },
            {
                "title": "Microsoft & LF on Recommenders",
                "link": "https://github.com/recommenders-team/recommenders",
                "content": "This github repo provides a fantastic compendium of best practices on Recommender Systems, initially maintained by Microsoft and now under the Linux Foundation: This comprehensive toolkit for building recommendation systems offers resources across wide range of classical and deep learning algorithms, detailed Jupyter notebook examples, and utilities for tasks like data preparation, model evaluation, and operationalization. This resource is ideal for production machine learning practitioners, providing robust tools and best practices for developing and deploying recommendation systems in various environments, including extensive documentation and community support for both small-scale and large-scale applications."
            },
            {
                "title": "Stanford on LLM Hallucination",
                "link": "https://github.com/stanford-oval/WikiChat",
                "content": "Stopping the hallucination of Large Language Models through few-shot grounding on Wikipedia (97% vs 50% OpenAI): An insightful paper which reinforces the potential of RAG introducing WikiChat, a novel LLM grounded in Wikipedia, designed to address the issue of misinformation in large language model chatbots. By combining LLM-generated responses with Wikipedia-sourced information, WikiChat significantly reduces hallucinations, maintaining high conversational quality and low latency. It achieves 97.3% factual accuracy in simulated conversations, outperforming existing models, especially in handling recent and less popular topics. The system, distilled from GPT-4 to a 7B-parameter LLaMA model, demonstrates the feasibility of creating more reliable, engaging, and efficient chatbots for open-domain conversations. The paper also emphasizes ethical considerations in AI development, including user privacy and fair compensation in crowdsourcing."
            },
            {
                "title": "DeepMind vs Doctors Turing Test",
                "link": "https://aimodels.substack.com/p/googles-new-llm-doctor-is-right-way",
                "content": "Google DeepMind\u2019s latest turing test against Human Doctors (Top-10 Accuracy 59% vs 34%): An insightful research initiative from Google DeepMind based on fine-tuned large language models showing significant promise in medical diagnostics, outperforming human doctors (within specific test cases) in creating differential diagnoses. Their AI system \u201cArticulate Medical Intelligence Explorer (AMIE)\u201d was tested in complex case reports, and included the correct diagnosis in its top 10 list 59% of the time, surpassing board-certified physicians who achieved 34%. Additionally, when used as an interactive assistant, the AI enhanced physicians\u2019 diagnostic accuracy from 36% to 52%. Despite its potential, there is an emphasize needed for further real-world testing and consideration of safety and fairness before deploying such AI in healthcare settings."
            },
            {
                "title": "AI in RecSys Ranking",
                "link": "https://recsysml.substack.com/p/how-to-reduce-cost-of-ranking-by",
                "content": "How to reduce cost of ranking by knowledge distillation in Recommender Systems: This article from RecsysML focuses on optimizing machine learning ranking systems by introducing an \u201cearly ranker\u201d to reduce computational costs. This early ranker, which uses only about 5% of the compute cost per item compared to the final ranker, is trained through \u201cKnowledge Distillation\u201d to closely mimic the final ranker\u2019s decisions, rather than just learning from user actions. This approach addresses alignment issues between the early and final rankers, ensuring more effective and cost-efficient filtering of candidates for final ranking. The article suggests two methods for knowledge distillation and refers to further in-depth resources for interested practitioners."
            }
        ]
    },
    {
        "issue": "266",
        "items": [
            {
                "title": "Forecasting & Causal Inference",
                "link": "https://arxiv.org/abs/2310.14021",
                "content": "Causal inference in forecasting can unlock actionable insights for practical applications; this research paper presents a case study applying causal forecasting in e-commerce with transformer models and double-ML: This insightful paper on \u201cCausal Forecasting for Pricing\u201d introduces a novel method is introduced for demand forecasting in retail pricing, emphasizing the causal relationship between price and demand. This approach combines Double Machine Learning with advanced transformer-based models to enhance pricing decisions by accurately predicting and understanding the impact of price changes on demand. The methodology stands out for its superior performance in estimating causal effects in controlled synthetic environments and real-world off-policy settings, while also being competitive in on-policy scenarios."
            },
            {
                "title": "Value of Open Source Software",
                "link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4693148",
                "content": "The $4.15 billion quantified value of Open Source Software analysis: A great paper that quantifies the economic impact of Open Source Software by evaluating both its supply-side value ($4.15 billion) and its significantly larger demand-side value ($8.8 trillion). The study leverages global data to assess the costs firms would incur if they had to internally develop software in the absence of OSS, revealing that firms would spend 3.5 times more on software without OSS. A notable finding is that a small group of developers (5%) contributes to 96% of OSS\u2019s demand-side value, with the top six programming languages accounting for 84% of this value."
            },
            {
                "title": "TextToSpeech Inverting Whisper",
                "link": "https://github.com/collabora/WhisperSpeech",
                "content": "Inverting OpenAI\u2019s Whisper model to create an impressive text-to-spech ML model that is open source and free to use for day-to-day tasks: WhisperSpeech is an open-source text-to-speech system that inverts the OpenAI Whisper model for safe commercial use with licensed text-to-speech recordings. Key features include optimized performance with over 12x real-time processing speed, multilingual support, and voice cloning capabilities. It is available on HuggingFace, and supported by Collabora, LAION, and the J\u00fclich Supercomputing Centre, making it a promising tool for production machine learning practitioners in text-to-speech applications."
            },
            {
                "title": "ISO Global Standards on AI",
                "link": "https://www.iso.org/obp/ui/en/#iso:std:iso-iec:42001:ed-1:v1:en",
                "content": "The first ISO standard on AI - the ISO/IEC 42001:2023(en) provides guidelines for organizations on establishing, implementing, maintaining, and continually improving an AI management system: This standard focuses on the unique characteristics and challenges of AI, such as continuous learning, transparency, and explainability, and emphasizes a risk-based approach tailored to different AI use cases and products. The standard is designed to integrate with an organization\u2019s existing management structures and processes, addressing issues like security, fairness, and data quality. It is applicable to any organization using or providing AI-based services or products, regardless of size or nature, and aligns with other management system standards to ensure consistency and comprehensive coverage of AI-specific considerations."
            },
            {
                "title": "Meta Large Scale Infrastructure",
                "link": "https://engineering.fb.com/2023/12/19/core-infra/how-meta-built-the-infrastructure-for-threads/",
                "content": "Meta\u2019s Threads app achieved rapid success, garnering over 100 million sign-ups in five days, this post provides a great insights on the infrastructure behind the success: Threads was developed in just five months with minimal lead time, and leveraged key components such as the a scalable distributed key/value datastore \u201cZippyDB\u201d, and a serverless-functions platform Async. These tools enabled seamless scaling and efficient handling of massive user influx and operations, showcasing the importance of quick adaptation and deployment."
            }
        ]
    },
    {
        "issue": "267",
        "items": [
            {
                "title": "Sampling in Large Language Models",
                "link": "https://huyenchip.com/2024/01/16/sampling.html",
                "content": "Chip Huyen dives into solutions for the probabilistic undeterminism of Large Language Models through robust sampling methods: In order to address the probabilistic nature of machine learning models in text generation we have to focusing on the challenges and strategies for achieving desired outputs. Sampling methods can be explored to address this, such as top-k, temperature and top-p sampling, highlighting their impact on the balance between creativity and consistency in model responses. The article also discusses test time sampling, a technique for improving model performance by generating multiple outputs and selecting the best one, and the concept of structured outputs, emphasizing the importance of guiding models to produce specific formats, especially in applications requiring precise structures like text-to-SQL. This piece is particularly insightful for ML practitioners looking to optimize text generation models in production environments."
            },
            {
                "title": "UK Govt\u2019s GenAI Framework",
                "link": "https://www.gov.uk/government/publications/generative-ai-framework-for-hmg",
                "content": "The UK government releases their framework (and principles) for generative AI use, quite a lot of insightful takeaways from a public sector perspective: The UK Govt\u2019s GenAI framework was put together with a particular focus on Large Language Models, aiming to provide guidance for public sector applications. It emphasizes the importance of understanding AI\u2019s capabilities and limitations, advocating for lawful, ethical, and responsible usage - this is backed with sound deep dives for each of these topics. The framework outlines ten principles covering aspects such as security, human oversight, lifecycle management, and skill development. It addresses challenges like accuracy, bias, and environmental impacts, highlighting the need for transparency and meaningful human control."
            },
            {
                "title": "Why Machine Learning is Hard",
                "link": "https://ai.stanford.edu/~zayd/why-is-machine-learning-hard.html",
                "content": "Why is machine learning hard? The machine learning field is considered \u2018hard\u2019 not only due to the scientific concepts involved, but due to the complexity in the workflows involved in the ML lifecycle, together with the intuition needed to select appropriate models and algorithms. Debugging in ML is uniquely challenging as it involves four dimensions: algorithm, implementation, data, and the model itself, making it more complex than traditional software debugging. This complexity is compounded by long feedback loops in training models, necessitating parallel experimentation and hindering sequential knowledge building. The core skill in ML, therefore, lies in developing an intuition for diagnosing and solving problems across these multiple dimensions, a skill honed through continuous practice and experience."
            },
            {
                "title": "Hand-picked AI Fundamentals",
                "link": "https://aman.ai/primers/ai/",
                "content": "An extensive and comprehensive hand-picked list of AI Fundamentals: The article provides a comprehensive guide for machine learning practitioners, encompassing a wide array of topics crucial to AI and ML. It covers design and architecture, including analysis of ML algorithms and training methodologies. The guide also delves into speech, vision and NLP (together with models like BERT and GPT). It covers multimodality, as well as privacy-preserving AI, evaluation techniques, MLOps considerations, miscellaneous foundational concepts, hyperparameter management, together with practice interview questions."
            },
            {
                "title": "Building a Brag-List for Success",
                "link": "https://newsletter.eng-leadership.com/p/keep-a-brag-list-of-the-wins-you",
                "content": "Top life-hack, keep a brag list of the wins you achieved: A great call to action for professionals in tech (+machine learning) fields, to maintain a \u201cbrag list\u201d of your accomplishments. This enables you to effectively presenting your achievements during career advancements and helps you fight the annoying impostor syndrome by reminding yourself of your past successes. This is a technique that many practitioners (including myself) follow, and this has positive impact not only in career progression but even when colloquially discussing specific achievements. This article offers a great template to assist you in tracking your achievements."
            }
        ]
    },
    {
        "issue": "268",
        "items": [
            {
                "title": "Democratising LLM Inference",
                "link": "https://github.com/KomputeProject/kompute?tab=readme-ov-file#projects-using-kompute-%EF%B8%8F--",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "Google Forecast Foundation Model",
                "link": "https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html",
                "content": "Google\u2019s new deep learning model for zero-shot time-series forecasting with 200m parameters pre-trained on 100B time-series data-points: The time-series forecasting space continues to see innovative developments, in this case we see Google showcasing \u201cTimesFM\u201d, a novel 200 million parameter model pre-trained on 100 billion real-world time-points for time-series forecasting. This model is designed for zero-shot performance, which means that it\u2019s expected to provide predictions without being trained, only by providing the input similar to something like ChatGPT. This model leverages a decoder-only architecture adapted from large language models, enabling it to provide accurate forecasts across various domains without additional training. TimesFM demonstrates its efficacy by closely matching or outperforming state-of-the-art supervised and traditional statistical forecasting methods on diverse datasets, including the Monash Forecasting Archive. The model\u2019s success highlights its potential to significantly improve forecasting tasks in retail, finance, and other sectors by reducing the need for extensive model training and validation, making advanced forecasting more accessible to users."
            },
            {
                "title": "Cyber-resilience Act and OSS",
                "link": "https://berthub.eu/articles/posts/eu-cra-what-does-it-mean-for-open-source/",
                "content": "EU\u2019s new Cyber-resilience Act: What does it mean for open source? The EU Cyber Resilience Act has raised concerns within the open source community regarding its impact on software development, testing, auditing, and support. However since its first inception, this policy has adopted feedback from the community, now explicitly targets commercial activities, exempting non-commercial open source projects and contributors from its regulations. It specifies conditions under which open source could be considered commercial, thereby subject to the CRA, and introduces a \u201clight-touch\u201d regulatory regime for open-source software stewards supporting commercial use. While the CRA does not directly regulate most open source software, it mandates due diligence from commercial users, potentially benefiting open source security. Production machine learning practitioners engaged in commercial open source activities should be aware of this new policy, which will most likely influence the security practices within the open source machine learning ecosystem."
            },
            {
                "title": "Stanford\u2019s Modern Algorithms",
                "link": "https://web.stanford.edu/class/cs168/index.html",
                "content": "Stanford is providing a refresher of the traditional computer science course on \u201cData Structures and Algorithms\u201d focusing on the Modern Algorithmic Toolbox: Stanford has ran a course in Spring 2023 focusing on the core algorithms that power modern machine learning and data analysis. This course is led by by Gregory Valiant and combines theoretical insights with practical applications to guide students through a series of weekly mini-projects covering topics such as hashing, dimension reduction, gradient descent, and linear-algebraic techniques like PCA and SVD. It is aimed at fostering a hands-on understanding of how and when to apply these algorithms. Additionally, the course structure encourages collaboration on projects, making it highly relevant for machine learning practitioners looking to deepen their algorithmic knowledge and apply it in real-world scenarios."
            },
            {
                "title": "LLaVA 1.16 OCR & Reasoning",
                "link": "https://llava-vl.github.io/blog/2024-01-30-llava-1-6/",
                "content": "LLaVA-1.6 is released with improved reasoning, OCR, and world knowledge: An interesting advancement in large multimodal ML models with the release of LLaVA\u2019s new model surpassing its predecessor and outperforming competitors like Gemini Pro in various benchmarks. Key enhancements include quadrupled image resolution, superior visual reasoning and OCR capabilities, expanded world knowledge, and efficient deployment with SGLang, all while maintaining the minimalist design and data efficiency of LLaVA-1.5. The model also was created with lower training costs, requiring less than 1M visual instruction tuning samples and about a day\u2019s training on 32 A100 GPUs. LLaVA-1.6 represents a leap forward in LMM efficiency, power, and versatility, offering new opportunities for research and application in the field."
            }
        ]
    },
    {
        "issue": "269",
        "items": [
            {
                "title": "Writing a Search Engine in 80 Lines of Python",
                "link": "https://www.alexmolas.com/2024/02/05/a-search-engine-in-80-lines.html",
                "content": "Writing a search engine in 80 lines of Python: In order to built an intuition on search engines, what better way to learn about a topic than with a hands on exercise. This endeavor showcases 80 likes of code for the core components of a micro search engine: 1) a crawler that leverages asynchronous programming for efficiency, 2) an inverted index for mapping keywords to documents, 3) a BM25 ranker for sorting search results, 4) and a simple user interface built with FastAPI. Despite its limitations, such as the lack of query operators and semantic search capabilities, the project serves as a practical learning tool, offering insights into search engine operations and the advantages of asynchronous code in handling I/O-bound tasks, with future plans to incorporate semantic search features. This is a great exercise for production machine learning practitioners interested in the foundational aspects and development process of a basic search engine."
            },
            {
                "title": "One Trillion Row Challenge",
                "link": "https://blog.coiled.io/blog/1trc.html",
                "content": "The One Trillion Row Challenge is launched and tackled by the Python Dask team calling for ever-faster and more optimised submissions: A recent extension of the One Billion Row Challenge now taken to the trillion-mark, designed to be a catalist for innovation by testing and comparing the performance of big data tools on a significantly larger scale. You are tasked with writing a program to calculate the minimum, mean, and maximum temperature per weather station from a dataset of one trillion rows, stored across 100,000 Parquet files on AWS S3. This challenge is open to any tool or method, with the primary objective being to foster innovation and discussion within the data science community rather than competition. Participants are encouraged to share their solutions in the 1TRC repository, including hardware used, runtime, and a reproducible code snippet, to facilitate community learning and exploration of different big data tools and techniques."
            },
            {
                "title": "Comparing LLMs to Lawyers",
                "link": "https://arxiv.org/abs/2401.16212",
                "content": "Better Call GPT instead of your lawyer? An insightful study comparing large language models against (junior & senior) lawyers with promising results: This study explores the efficacy of Large Language Models in legal contract review, comparing them with Junior Lawyers and Legal Process Outsourcers (LPOs) across accuracy, speed, and cost-efficiency metrics. It concludes that LLMs, particularly GPT4-1106, offer comparable or superior accuracy in identifying legal issues, drastically reduce review times to seconds, and cut costs by approximately 99.97% compared to traditional methods. These findings indicate a significant shift towards LLMs in the legal sector, suggesting they could greatly enhance the efficiency and accessibility of legal services, while potentially disrupting current legal practices and employment. The paper underscores the need for further research, especially in contract negotiation, and highlights LLMs\u2019 potential to transform the legal industry fundamentally."
            },
            {
                "title": "Infra Decisions Endrose or Regret",
                "link": "https://cep.dev/posts/every-infrastructure-decision-i-endorse-or-regret-after-4-years-running-infrastructure-at-a-startup/",
                "content": "Every infrastructure decision endorsed or regretted after 4 years running infrastructure at a startup: A great resource that retrospectively analyses infra choices and their impact down the line, categorising them as \u201cEndorse\ud83d\udfe9\u201d or \u201cRegret \ud83d\udfe7\u201d. Endorse\ud83d\udfe9: AWS services, EKS for Kubernetes, and RDS for database management for their reliability and seamless integration. Endorse\ud83d\udfe9: praising tools like GitOps, Notion, Slack, and Terraform for enhancing operational efficiency and team collaboration. Regret \ud83d\udfe7: EKS managed addons, the costly AWS premium support, and not adopting an identity platform like Okta sooner. Key lessons highlight the importance of selecting scalable, flexible infrastructure tools and processes that balance cost, efficiency, and the ability to customize, underscoring the continuous evolution and learning in infrastructure management for startups."
            },
            {
                "title": "AI Generated Calls Now Illegal",
                "link": "https://www.fcc.gov/document/fcc-makes-ai-generated-voices-robocalls-illegal",
                "content": "The US FCC (ie Federal Communications Commission) has declared AI-generated voices in robocalls illegal under the Telephone Consumer Protection Act, granting State Attorneys General new enforcement tools against voice cloning scams: This measure addresses the rising concern over AI-enabled fraud, which can impersonate individuals for malicious purposes, by expanding legal actions against the use of such technology in unsolicited calls. The ruling is enforced effective immediately and is part of a broader effort to combat the misuse of AI in communication technologies, with a coalition of 26 State Attorneys General supporting the move. While this represents a significant step in regulating AI-generated content, experts argue that further legislation is needed to fully tackle the dissemination of AI-manipulated media, highlighting the ongoing challenge of adapting legal frameworks to evolving technological threats."
            }
        ]
    },
    {
        "issue": "270",
        "items": [
            {
                "title": "META\u2019s V-JEPA vs OpenAI Sora",
                "link": "https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/",
                "content": "As the world continues to make waves with OpenAI\u2019s text-to-video model \u201cSora\u201d, META has released V-JEPA as a proposed alternative to ML intelligence for the physical world: META\u2019s V-JEPA (Video Joint Embedding Predictive Architecture) is a novel model introduced by Meta. This architecture leverages a self-supervised learning framework which learns from unlabeled video data by predicting masked portions in an abstract representation space, focusing on understanding complex interactions between objects without the need for detailed pixel reconstruction. This approach enhances training and sample efficiency but also enables the model to adapt to various tasks with minimal additional training, and is being released as an open model to encourage research."
            },
            {
                "title": "The MLOps Bookshelf",
                "link": "https://medium.com/softwareydata/my-mlops-bookshelf-c27f6e29370d",
                "content": "The MLOps Bookshelf Collection \ud83d\udcda A great resource for practitioners looking to upgrade their knowledge in production machine learning operations. The list includes:"
            },
            {
                "title": "Google DeepMind Gemini 1.5",
                "link": "https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/",
                "content": "Google DeepMind introduces Gemini 1.5 with astonishing advancements standing up to the GPT Giant OpenAI ChatGPT: This release is announced directly bySundar Pichai and Demis Hassabis, highlighted as a significant advancement in AI with an alleged dramatically enhanced performance, efficiency, and groundbreaking long-context understanding capability, processing up to 1 million tokens. Gemini 1.5 Pro is built on a Mixture-of-Experts architecture and offers comparable quality to its predecessor while being more compute-efficient, excelling across a wide range of tasks and modalities. This model is initially available in a limited preview which will allow for further insights from the feedback."
            },
            {
                "title": "Unit Tests using LLMs at Meta",
                "link": "https://arxiv.org/pdf/2402.09171.pdf",
                "content": "Automated unit test generation using LLMs at Meta: Meta\u2019s TestGen-LLM tool leverages LLMs to automate the enhancement of existing unit tests for Android applications, focusing on increasing test coverage by identifying and covering previously missed scenarios. This tool aims to embody Assured Offline LLM-Based Software Engineering, generating test cases that try to offer improvements without regressing existing functionalities. This model was deployed during \u201ctest-a-thons\u201d at Instagram and Facebook, showing significant efficacy of 75% of generated test cases correctly built, 57% passing reliably, and 25% with enhanced coverage, and with 73% of recommendations accepted for production. This initiative underscores the potential of integrating LLMs with software engineering workflows to augment human efforts in test development, marking a notable advancement in the automation and optimization of software testing processes at an industrial scale."
            },
            {
                "title": "Mistral-7B on an Acid Trip",
                "link": "https://vgel.me/posts/representation-engineering/",
                "content": "Control vectors in LLMs introduce a promising concept that can be used to direct and restrict the outputs of LLMs which can further augment other concepts such as RAG: The article introduces the concept of \u201ccontrol vectors\u201d as a novel method for manipulating AI model behavior without prompt engineering or fine-tuning, showcasing its application on the Mistral-7B model. By adjusting model activations during inference, control vectors enable precise behavioral modifications, such as inducing states of happiness, laziness, or creativity. This article is very well written and intuitive, showcasing how these vectors can be used to enahnce model performance or bypass safety mechanisms. This approach presents a significant advancement for machine learning practitioners interested in AI transparency, interpretability, and customized model behavior, offering a practical and efficient tool for tailoring AI outputs to specific needs or research inquiries."
            }
        ]
    },
    {
        "issue": "271",
        "items": [
            {
                "title": "Salesforce Forecasting Foundation Model",
                "link": "https://arxiv.org/abs/2402.02592",
                "content": "Salesforce enters the competition with their latest foundation model for Forecasting, following Google\u2019s announcement of their foundation model TimesFM: Salesforce introduces MOIRAI, a groundbreaking Large Time Series Model for universal time series forecasting. This new foundation model has been trained on the extensive Large-scale Open Time Series Archive with over 27 billion observations across nine domains. MOIRAI addresses key challenges in time series forecasting, including cross-frequency learning, multivariate data handling, and flexible distributional adaptation, through innovative approaches like multiple input/output projection layers, Any-variate Attention, and a mixture of parametric distributions. MOIRAI sets a new benchmark in the field demonstrating superior zero-shot forecasting capabilities compared to traditional full-shot models, offering a scalable and adaptable solution that significantly advances the potential for universal forecasting models in practical applications. The commitment to open-source the model weights, code, and LOTSA dataset further is a great contribution to the community, highlighting its potential impact on the industry, enabling widespread adoption and innovation in time series forecasting."
            },
            {
                "title": "Google DeepMind Gemma.cpp",
                "link": "https://github.com/google/gemma.cpp",
                "content": "As the world continues to make waves from Google DeepMind\u2019s open source release of Gemma, the open source community already released an optimised C++ engine through \u201cgemma.cpp\u201d: Following the steps of LLaMa.cpp, we now see the release of Gemma.cpp, bridging the gap between deployment-oriented runtimes and Python ML frameworks. This project leverages SIMD optimizations for the Gemma 2B and 7B models, including its large vocabulary and unique features like RMSNorm normalization and GeGLU activations. Open source contributions are key to unlock opportunities such as the finetuning from Sebastian Raschka, as well as important scrutinisation especially following the controversy surrounding Google\u2019s Gemini AI when skewing racial representation in image generation."
            },
            {
                "title": "Stanford Privacy in the AI Era",
                "link": "https://hai.stanford.edu/white-paper-rethinking-privacy-ai-era-policy-provocations-data-centric-world",
                "content": "Stanford has releases a whitepaper proposing the ecosystem to rethink privacy in the AI era: This whitepaper addresses the critical intersection of privacy, data protection, and artificial intelligence, highlighting the challenges and risks posed by the current and future landscape of AI development. It underscores the insufficiency of existing privacy laws to manage the escalating demand for data by AI systems, which not only threatens individual privacy but also poses broader societal risks. The paper advocates for a paradigm shift towards more stringent data collection norms, enhanced transparency and accountability throughout the AI data supply chain, and the development of new governance mechanisms to empower individuals in managing their data. Finally, the urgency for policymakers and stakeholders to adapt and enforce regulations that safeguard privacy while fostering responsible AI innovation, arguing that the future of AI and privacy is not predetermined but can be shaped by deliberate and thoughtful action."
            },
            {
                "title": "Graph Neural Nets at Linkedin",
                "link": "https://arxiv.org/abs/2402.11139",
                "content": "Linkedin Research showcases their organisational adoption and learnings using graph neural network across their social network ecosystem: \u201cLiGNN - Graph Neural Networks at LinkedIn\u201d presents a comprehensive framework for deploying large-scale Graph Neural Networks within LinkedIn\u2019s ecosystem, addressing challenges unique to GNN training at scale, managing diverse entities, handling cold starts, and adapting to dynamic systems. They leverage a suite of novel techniques - ie. temporal graph architectures, graph densification, and efficient multi-hop neighbor sampling - in order to achieve significant improvements in LinkedIn\u2019s key metrics across various domains such as job applications, ads click-through rates, and user engagement. The deployment of LiGNN leverages adaptive sampling, data batching optimizations, and specialized infrastructure to accelerate training by 7x, demonstrating the practical applicability and effectiveness of GNNs in enhancing recommendation systems and user interaction on LinkedIn\u2019s platform. This work not only showcases the tangible benefits of applying GNNs at scale but also provides valuable insights and methodologies for production machine learning practitioners looking to harness the power of graph neural networks in large-scale applications."
            },
            {
                "title": "GPT in 60 Lines of NumPy",
                "link": "https://jaykmody.com/blog/gpt-from-scratch/",
                "content": "Let\u2019s write GPT in 60 Lines of NumPy: What better way to learn a concept than implementing it ourselves; this is a great simplified yet complete introduction to the GPT architecture. In this case this leverages the trained GPT-2 model weights released by OpenAI, the implementation is capable of generating text, demonstrating the core functionalities of GPT models. This implementation intentionally omits many advanced features to maintain simplicity and understandability. The resource serves as a practical guide for machine learning practitioners interested in the inner workings of GPT models, providing insights into the model\u2019s architecture, including token and positional embeddings, the decoder stack, and the projection to the vocabulary layer."
            }
        ]
    },
    {
        "issue": "272",
        "items": [
            {
                "title": "UK AI Policy Adops Proposals",
                "link": "https://www.linkedin.com/posts/axsaucedo_uk-ai-regulation-acm-recommendations-activity-7165246131642290176-11kW/",
                "content": "We are very excited to announce that the UK Government has adopted 13 of the 14 recommendations we made for 2023 UK AI Regulation proposal! It feels sureal to see tangible positive change in such important policy documents that are furthering the global AI ecosystem \ud83d\ude80\ud83d\ude80\ud83d\ude80 It was an honour to lead this publication, and collaborate with renowned academics and industry throught leaders from across both Europe and the US."
            },
            {
                "title": "Alibaba\u2019s Realistic AI Video",
                "link": "https://humanaigc.github.io/emote-portrait-alive/",
                "content": "Alibaba has released a mind blowing new ML architecture to generate realistic videos from still images using Audio2Video Diffusion: A groundbreaking framework named EMO has been released by Alibaba, supporting generation of realistic and expressive \u201ctalking head videos\u201d directly from audio cues without relying on intermediate 3D models or facial landmarks. The methodology uses \u201cFrameEncoding\u201d for preserving character identity. The model was trained on a diverse audio-video dataset comprising over 250 hours of footage, and the results demonstrate that EMO surpasses current state-of-the-art methods in terms of realism and expressiveness."
            },
            {
                "title": "Don\u2019t Mock ML (in Unit Tests)",
                "link": "https://eugeneyan.com/writing/unit-testing-ml/",
                "content": "Don\u2019t mock machine learning (in Unit Tests): A great piece by Eugene Yan which showcases the unique challenges ML practitioners face in unit testing ML code, different to traditional software development. In ML we face logic that may not be static nor deterministic, instead we face dynamic entities that learn from data. However to tackle these challenges, we can using simple data samples, testing against models with random or empty weights, and writing critical tests against actual models while avoiding testing external libraries. Another great resource from Eugene Yan providing practical advice for practitioners that accommodate the complexities of ML code and models."
            },
            {
                "title": "Amazon Billion Param TTS ML",
                "link": "https://www.amazon.science/publications/base-tts-lessons-from-building-a-billion-parameter-text-to-speech-model-on-100k-hours-of-data",
                "content": "Amazon releases an indistinguishable-from-human text-to-speech large AI model trained on 100k hours of public domain speech data: BASE TTS represents a significant advancement in text-to-speech technology, being the largest TTS model to date with 1 billion parameters, trained on 100,000 hours of speech data. This model and architecture introduces a novel approach to TTS, utilizing autoregressive Transformers for converting texts into discrete speechcodes, which are then turned into waveforms by a convolution-based decoder, allowing for incremental, streamable speech synthesis. This model showcases emergent abilities for handling complex sentences with natural prosody as the dataset and model size increase, a phenomenon observed in large language models but relatively unexplored in TTS. BASE TTS employs a unique speech tokenization technique that disentangles speaker ID and compresses speech data using byte-pair encoding, significantly enhancing speech naturalness and efficiency compared to existing large-scale TTS systems like YourTTS, Bark, and TortoiseTTS."
            },
            {
                "title": "Karpathy Tutorial on GPT Tokens",
                "link": "https://www.youtube.com/watch?v=zduSFxRajkE",
                "content": "A significant number of the limitations we face in LLMs can arise from the tokenization process - Andrej Karpathy has put together a fantastic hands-on tutorial to build the intuition required on the tokenisation process: A great hands on tutorial by Andrej Karpathy for machine learning practitioners, focusing on developing a tokenizer for Large Language Models (LLMs). Karpathy outlines the tokenizer\u2019s role in converting strings to tokens and vice versa, using Byte Pair Encoding for its training. He highlights the impact of tokenization on LLM performance, including issues related to language handling, whitespace management, and the potential improvements in newer GPT versions. The video also includes practical coding examples, discussions on Unicode encodings, and insights into the tokenizer\u2019s influence on model behaviors."
            }
        ]
    },
    {
        "issue": "273",
        "items": [
            {
                "title": "ML Competitions in 2023",
                "link": "https://mlcontests.com/state-of-competitive-machine-learning-2023/",
                "content": "Analysis of Machine Learning Competitions in 2023: This past year has shown a significantly higher participation, with prize pools surpassing $7.8 million, with diverse challenges across platforms like Kaggle, AIcrowd, and Hugging Face. Looking at some of the key insights from 2023, Python continues to dominate (as expected), with clear bias towards PyTorch for deep learning, as well as an emergence on LLMs (although mostly for sinthetic data generation). A lot of great insights in this in-depth analysis, with an interesting glimps on what is yet to come in 2024!"
            },
            {
                "title": "How Discord Stores Trillion Msgs",
                "link": "https://discord.com/blog/how-discord-stores-trillions-of-messages?s=09",
                "content": "Discord has to handle massive-scale data across their system, making it a great case study for best practices on storing trillions of datapoints effectively: Discord shares their transition from MongoDB, to Cassandra, and finally to ScyllaDB for storing trillions of messages due to scalability and performance issues & requirements. Their journey showcases their learnings and best practices, with the end restult enabling them to enhance overall performance and latency, successfully managing trillions of messages and high-traffic events like the World Cup without substantial issues."
            },
            {
                "title": "5 Lessons in 6y the Hard Way",
                "link": "https://read.highgrowthengineer.com/p/5-lessons-i-learned-the-hard-way",
                "content": "5 Lessons in 6 Years as a Software Engineer - The Hard Way \ud83d\udd25 These are 5 great lessons for any software practitioner looking to take their craft to the next level: 1) Proposing solutions over problems, 2) collaboration over pristine code, 3) prioritizing team success over individual tasks, 4) the necessity of adapting to different managerial styles, and 5) the power of building trust-based relationships for genuine influence. These lessons serve as a practical guide for navigating the complexities of teamwork and leadership in the fast-paced field of machine learning."
            },
            {
                "title": "Neural Networks Zero to Hero",
                "link": "https://karpathy.ai/zero-to-hero.html",
                "content": "Neural Networks from Zero to Hero by Andrej Karpathy: This is a great in-depth course aimed at production machine learning practitioners with a solid Python and basic math background. It offers a thorough walkthrough from the basics of neural networks and backpropagation to constructing advanced models like GPT, with a focus on language models. The course covers essential deep learning concepts, including training principles, language modeling, Batch Normalization, and the intricacies of backpropagation, through hands-on coding and practical examples."
            },
            {
                "title": "70B Param Model at Home",
                "link": "https://www.answer.ai/posts/2024-03-06-fsdp-qlora.html",
                "content": "You can now train a 70b language model at home: Check out this interesting OSS framework capable of training a 70 billion parameter language model on desktops with just two gaming GPUs (e.g., RTX 3090 or 4090). This framework leverages methodologies such as Fully Sharded Data Parallel and Quantization and Low-Rank Adaptation (aka QLoRA). It\u2019s great to see a lowering of the barrier-to-entry for training large-scale AI models, making it feasible and cost-effective for individuals and small labs to undertake projects that were previously the domain of well-funded organizations with access to expensive data center hardware."
            }
        ]
    },
    {
        "issue": "274",
        "items": [
            {
                "title": "META\u2019s GenAI Infrastructure",
                "link": "https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/",
                "content": "Meta processes hundreds of trillions of AI model data inferences per day - they have announced how two 24,576-GPU clusters are taking their infra to the next level: Meta is advancing its AI infrastructure built on Grand Teton, OpenRack, and PyTorch to support the development of advanced AI models like Llama 3. Meta\u2019s AI infra enhancements cover novel network solutions, optimized storage with a focus on efficiency and scale, and significant performance optimizations for handling large-scale AI workloads. Meta\u2019s roadmap includes expanding its AI infrastructure to feature 350,000 NVIDIA H100 GPUs by the end of 2024, making it clear that the GPU-wars are at full force across all tech giants."
            },
            {
                "title": "MIT Course on Foundation Model",
                "link": "https://www.youtube.com/playlist?list=PLXV9Vh2jYcjbnv67sXNDJiO8MWLA3ZJKR",
                "content": "MIT Introduces a brand-new on Foundation Models & Generative AI in 2024: This is quite a comprehensive introduction and deep dive into the cutting edge ecosystem of foundation models and generative AI. In this course they cover a broad range of topics, including ChatGPT, Stable-Diffusion & Dall-E, Neural Networks, Supervised Learning, Representation & Unsupervised Learning, Reinforcement Learning, Generative AI, Self-Supervised Learning, Foundation Models, GANs (adversarial), Contrastive Learning, Auto-encoders, Denoising & Diffusion."
            },
            {
                "title": "Amazon\u2019s FC Foundation Model",
                "link": "https://github.com/amazon-science/chronos-forecasting",
                "content": "Amazon enters the race with their new large-scale zero-shot foundation model for time-series forecasting: Amazon introduces Chronos, a transformer-based architecture model often used for language models, leveraged for probabilistic time series modeling. One of the key innovations introduced is how they approach tokenization of time series data into a fixed vocabulary, which is done through scaling and quantization. Chronos leverages pretrained models, claiming to outperform traditional and deep learning methods in both known and unseen datasets. The paper also highlights future directions including fine-tuning for improved performance and extending the model\u2019s application beyond univariate forecasting, suggesting a promising avenue for leveraging developments in language modeling to address complex time series forecasting challenges. It will be interesting to see how the battle of the titans evolves with other giants such as Google and Salesforce launching their models (and how they hold their ground compared to traditional or even common baselines)."
            },
            {
                "title": "ML Engineering & Sys Design",
                "link": "https://transferlab.ai/trainings/beyond-jupyter/",
                "content": "Going Beyond Jupyter - a curated set of educational resources for best practices on engineering and system design in machine learning contexts: \u201cBeyond Jupyter\u201d is an excellent educational resource for production machine learning practitioners, which puts together best practices for software design principles within the ML domain. This resource covers practical examples with a case study on refactoring a Jupyter notebook-based project for better maintainability and efficiency, and a review of common anti-patterns."
            },
            {
                "title": "High Quality Local AI Images",
                "link": "https://www.felixsanz.dev/articles/pixart-a-with-less-than-8gb-vram",
                "content": "High quality image generation becomes more attainable for daily use in your personal computer: This resource provides a simple and practical method to reduce the VRAM requirement of the PixArt-\u03b1 diffusion model to under 8GB, making it accessible on mid-range GPUs like the NVIDIA RTX 2070 or M-series Macbooks. The optimization involves a different approach to loading model components, as well as a custom inference process, which allows the generation of high-quality 1024x1024 images in just 20 seconds."
            }
        ]
    },
    {
        "issue": "275",
        "items": [
            {
                "title": "Twitter/X Releases OSS Grok",
                "link": "https://x.ai/blog/grok",
                "content": "The internet has been discussing the release of Twitter / X\u2019s contender in the ChatGPT race with xAI: This comes as the latest release for a tech giant foundation model from X/Twitter with the release of Grok-1. This ML system was developed across four months, and has been published with open benchmarks that showcase performance better than GPT 3.5 and Llama 2.0 - although it\u2019s performance is not better than GPT 4.0, being an open-weights release it makes it a fantastic contribution. The team is exploring research avenues to address AI limitations and is offering early access to Grok in the US to gather feedback for further improvements."
            },
            {
                "title": "Mamba State Space Architecture",
                "link": "https://www.kolaayonrinde.com/blog/2024/02/11/mamba.html",
                "content": "Mamba is the novel \u201cstate space\u201d architecture that is taking transformers head-first with a promise of parallel computation benefits: The state-space architecture uses input-dependent dynamic state space matrices and Zero-Order Hold, which enables for long-term memory as well as highly-parallel processing capabilities, which tackles the limitations of several sequence modeling techniques of traditional RNNs and transformers."
            },
            {
                "title": "Microsoft GenAI Online Lessons",
                "link": "https://microsoft.github.io/generative-ai-for-beginners/#/",
                "content": "Microsoft\u2019s releases a set of Generative AI resources for Beginners, providing an 18-lesson program designed for production machine learning practitioners: This great resource offers a comprehensive introduction to building Generative AI applications, covering a broad spectrum of topics beyond the basics, including advanced LLM application development. This course encompasses text generation, image generation, chat applications, and AI security."
            },
            {
                "title": "An Intro to SQL for Scientists",
                "link": "https://gvwilson.github.io/sql-tutorial/",
                "content": "An Introduction to SQL for Weary Data Scientists: A great resource for practitioners and educators to demystify SQL with a comprehesive set of examples, and a wide range of topics. This resource covers the full end-to-end of SQL - from basic database management to advanced SQL functionalities like joins, window functions, and JSON data manipulation. The course also includes downloadable content for practical exercises which can serve both self-learners as well as instructors that want to leverage SQL resources."
            },
            {
                "title": "Forecasting Principles & Practice",
                "link": "https://otexts.com/fpp3/",
                "content": "The go-to resource to build strong practical foundations on forecasting is Rob Hyndman\u2019s free book \u201cForecasting: Principles & Practice\u201d. This free online textbook provides one of the most complete and comprehensive introducitons to forecasting methods. This edition introduces new content and reorganizes chapters for better understanding of time series analysis before forecasting. It is quite refreshing to see real-world data to teach forecasting, incorporating the latest methodologies and corrections based on feedback, whilst staying true to the key foundations that are key to build upon amid the many ongoing trends in machine learning."
            }
        ]
    },
    {
        "issue": "276",
        "items": [
            {
                "title": "Scaling ML Infrastructure at Uber",
                "link": "https://www.uber.com/en-DE/blog/scaling-ai-ml-infrastructure-at-uber/",
                "content": "Uber\u2019s journey scaling their AI/ML infrastructure: Uber\u2019s AI infra has evolved significantly in the past few years, transitioning to cloud infrastructure, enhancing CPU and GPU hardware, and refining their Michelangelo platform to meet growing model complexities. Uber measures AI infra efficiency through utilization, reliability and developer velocity, which they have managed through optimizing existing infra through unified workload scheduling, network and memory upgrades for training efficiency, and cost-effectiveness approaches to their cloud approach. A great compendium on large scale optimisations for machine learning systems and machine learning operations at a leading tech giant."
            },
            {
                "title": "Largest OSS LLM from Databricks",
                "link": "https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm",
                "content": "Databricks has released the largest and highest-performant LLM to date: Databricks releases their new language model under the codename \u201cDBRX\u201d, with benchmarks that suggest better performance compared to GPT-3.5, and on par with Gemini 1.0 Pro. As many other successful architectures, this mode consists of a mixture-of-experts architecture, showcasing performance that suggests 2x improvements. The best feature is that it is an open release, raising the bar for the open-AI-race which is seeing developments on a weekly basis!"
            },
            {
                "title": "Google AI Forecasting Floods",
                "link": "https://blog.google/technology/ai/google-ai-global-flood-forecasting/",
                "content": "Google Research releases their AI-forecasting approach for global flood forecasting: A great high level piece from google showcasting accurate prediction of riverine flooding up to seven days in advance across over 80 countries, including those with scarce data and vulnerable regions. This piece of research tackles advancement in the historical challenge of flood forecasting at scale, primarily due to the complex nature of the problem and the limited availability of streamflow gauges worldwide leveraging standard LSTM deep learning models."
            },
            {
                "title": "Big Data Skills through XKCD",
                "link": "https://www.quaxio.com/hackernews_xkcd_citations/",
                "content": "Learning big data skills with the internet\u2019s favourite XKCD comics: A great resource to learn best practices and of big data processing by identifying the most cited XKCD comics on Hacker News. In this resource we explore the nuances analyzing comments and stories in Hacker News using BigQuery, standard SQL and basic scripting. As part of this exercise we follow standard steps such as extract comic IDs, deduplicate entries, and resolve different URL formats to standardize comic references - resulting in the top ten most cited XKCD comics on Hacker News."
            },
            {
                "title": "AI Accountability Report from NTIA",
                "link": "https://www.ntia.gov/issues/artificial-intelligence/ai-accountability-policy-report/recommendations",
                "content": "\u00ad \u00ad"
            }
        ]
    },
    {
        "issue": "277",
        "items": [
            {
                "title": "Data Quality View of ML",
                "link": "https://arxiv.org/abs/2102.07750",
                "content": "A Data-Quality Driven View of MLOps from Microsoft: An insightful research article from Microsoft research that explores the role of data quality in Machine Learning Operations. The insights provided are still relevant today, including four main areas: 1) optimizing ML model quality through strategic data cleaning, 2) managing expectations with realistic feasibility studies, 3) preventing overfitting with innovative continuous integration techniques, and 4) efficiently selecting the best model for new data through continuous quality testing."
            },
            {
                "title": "3Blue1Brown on AI Transformers",
                "link": "https://www.youtube.com/watch?v=wjZofJX0v4M",
                "content": "3Blue1Brown has released a video covering a comprehensive deep dive into machine learning transformer architectures with top visualisations and content that will prove useful to both new and seasoned practitioners. This video does a fantastic job on breaking down how large language models work under the hood, and how these transformer architectures continue to revolutionise various sub-fields of machine learning."
            },
            {
                "title": "NLP Fundamentals Deep Dive",
                "link": "https://zilliz.com/learn/introduction-to-natural-language-processing-tokens-ngrams-bag-of-words-models",
                "content": "Natural Language Processing Fundamentals - Tokens, N-Grams, and Bag-of-Words Models: Amid the rise of LLMs it is still important to build a strong intuition on the fundamentals in NLP and ML, this series provides a great refresher across the basics of tokens and n-grams. Similarly n-gram models and bag-of-word models are key methodologies which provide their importance in the architecture of autoregressive and autoencoding models like ChatGPT."
            },
            {
                "title": "Cognitive Load in Software",
                "link": "https://github.com/zakirullin/cognitive-load",
                "content": "Cognitive load is how much a developer needs to think in order to complete a task, understanding this concept can help maximise productivity for the self and others: There are clear detrimental effects of excessive cognitive complexity arising from intricate code structures, inappropriate use of programming paradigms, and excessive reliance on complex language features or frameworks. Advocating for simplicity is important in pertinent contexts through minimizing unnecessary complexity, favoring clear and concise code, and critically evaluating established best practices to reduce cognitive strain. This approach aims to improve developer productivity and reduce errors by making codebases more accessible and easier to understand, and this repo provides a great resource to explore this topic further."
            },
            {
                "title": "How to Think of Eng Quality",
                "link": "https://www.evalapply.org/posts/how-to-not-die-by-a-thousand-cuts/index.html",
                "content": "How to not die by a thousand cuts; or, how to think about software quality: The concept of quality in software development has been explored across many resources and methodologies. This resource provides a great conceptual framework that breaks down linear workflows for their inefficiency in managing risks and feedback, and suggests that the accumulation of small errors (\u201ccuts\u201d) can significantly degrade software quality. Approaches to building quality include embracing diverse perspectives, stakeholder collaboration and viewing challenges as opportunities for growth."
            }
        ]
    },
    {
        "issue": "278",
        "items": [
            {
                "title": "Airbnb\u2019s New OSS Feature Store",
                "link": "https://medium.com/airbnb-engineering/chronon-airbnbs-ml-feature-platform-is-now-open-source-d9c4dba859e8",
                "content": "Airbnb has released their ML feature store framework as an open source project together with key partners and users such as Stripe: Chronon simplifies the management and integration of data for machine learning practitioners by providing tools that handle both batch and streaming data, support multiple data sources whilst ensuring low latency in feature serving. This is an area where feature stores tend to fall short, allowing ML features to be defined once and used both for offline training and online inference. They also tackle common challenges such as data observability, quality monitoring, and management / governance at scale."
            },
            {
                "title": "ML Books for Engineers",
                "link": "https://dehora.net/journal/2024/machine-learning-for-engineers-book-list",
                "content": "If you are looking for a book to expand your ML knowledge in 2024, check out this great list on ML books for Engineers: A great set of 11 essential titles across four categories: Machine Learning & Algorithms, Mathematics & Statistics, Data Science & Analysis, and Tools & Frameworks. The curated selection of books focuses on practical machine learning applications using popular Python frameworks such as Pytorch, Tensorflow, Sklearn, etc, and is designed to equip software engineers with a pragmatic understanding of machine learning technologies and theoretical knowledge, suitable for both newcomers and those expanding their expertise."
            },
            {
                "title": "300 ML Systems Design Usecases",
                "link": "https://www.evidentlyai.com/ml-system-design",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "Half Billion GPT Token Lessons",
                "link": "https://www.evidentlyai.com/ml-system-design",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "The Lifecycle of an AI Copilot",
                "link": "https://sourcegraph.com/blog/the-lifecycle-of-a-code-ai-completion",
                "content": "The lifecycle of a production-grade AI code assistant to generate code completions: A great insight on what goes through the nuances of AI code completion. This is covered across 4 stages: 1) Planning, where the code context is analyzed to set the approach; 2) Retrieval, which collects relevant code snippets and contextual data; 3) Generation, where the LLM produces the code based on the provided context; and 4) Post-processing, where the generated code is refined and filtered to ensure relevance and quality. A great resource that highlights the complexities involved in developing an AI system that not only generates code but also integrates deeply with user expectations and sophisticated language understanding tools"
            }
        ]
    },
    {
        "issue": "279",
        "items": [
            {
                "title": "Stanford State of AI Report",
                "link": "https://aiindex.stanford.edu/report/",
                "content": "The 2024 Stanford State of AI Report is out: Another fantastic annual report from Stanford providing a comprehensive overview of the evolving landscape of the AI ecosystem. Some key highlights this year includes noting the significant dominance of AI development in industry, and the steeply rising costs of training advanced models like Google\u2019s Gemini Ultra and OpenAI\u2019s GPT-4. Other key findings highlight the United States\u2019 leadership in global AI development and investment, alongside a growing concern over the lack of standardization in responsible AI practices which complicates the evaluation of AI systems\u2019 safety and fairness."
            },
            {
                "title": "Stripe Feature Store Airbnb OSS",
                "link": "https://stripe.com/blog/shepherd-how-stripe-adapted-chronon-to-scale-ml-feature-development",
                "content": "Following last week\u2019s announcement of Airbnb\u2019s newly open sourced Feature Store, Stripe releases a deep dive into how they\u2019ve adopted Chronon at scale: Stripe has partnered with Airbnb to adapt and implement the Chronon OSS framework to create their internal ML feature platform called \u201cShepherd\u201d. They showcase Shepherd as next-gen feature engineering platform that enhances feature development across massive datasets, meeting strict latency and freshness requirements. Stripe highlights that this has improved fraud detection by integrating over 200 new features and significantly reducing fraud. They also cover key adaptations to their internal systems, including leveraging Flink for streaming jobs and employing a dual key-value store system for efficient data handling."
            },
            {
                "title": "NSA Security Framework for AI",
                "link": "https://www.nsa.gov/Press-Room/Press-Releases-Statements/Press-Release-View/Article/3741371/nsa-publishes-guidance-for-strengthening-ai-system-security/",
                "content": "The NSA has released a comprehensive cybersecurity guideline titled \u201cDeploying AI Systems Securely: Best Practices for Deploying Secure and Resilient AI Systems\u201d: This security framework outlines essential security practices for AI systems, including securing deployment environments, maintaining continuous protection through monitoring and updates, enforcing strict access controls, and fostering collaboration and compliance with international cybersecurity standards. This framework is aimed at entities within the National Security System and applications with high-threat and sensitive operational contexts, and is designed to safeguard AI systems against theft and misuse."
            },
            {
                "title": "LLMs as Effective Regressors",
                "link": "https://arxiv.org/pdf/2404.07544.pdf",
                "content": "LLMs can effectively execute both linear and non-linear regression, often outperforming traditional supervised methods like Random Forest and Gradient Boosting: This research paper explores the ability of LLMs to perform regression tasks using in-context examples without additional training. The results suggest that LLMs inherently develop a sophisticated numerical reasoning ability during the training across these large text corpora, which allows them to adapt and refine their regression capabilities as they process more in-context examples. This insight is particularly interesting in context to the ongoing trend of foundation (transformer) model announcements from various of the major tech companies."
            },
            {
                "title": "Llama 3 Latest META\u2019s Release",
                "link": "https://ai.meta.com/blog/meta-llama-3/",
                "content": "Meta has launched Llama 3: This is META\u2019s latest iteration of its open large language model, featuring two models with 8 billion and 70 billion parameters that set new benchmarks in reasoning, code generation, and instruction-following. This release builds on a standard transformer architecture, leveraging a vast 15 trillion token dataset for training; it is also interesting to see the outline of safety tools (aka \u201cLlama Guard 2\u201d). Kudos for the availability as Meta Llama 3 is now available across major platforms such as AWS and Google Cloud, which promotes a spirit of benchmarking across the AI community."
            }
        ]
    },
    {
        "issue": "280",
        "items": [
            {
                "title": "Production ML Ecosystem 16k \u2b50\ufe0f",
                "link": "https://github.com/EthicalML/awesome-production-machine-learning/",
                "content": "Our Production Machine Learing repo continues to grow at a steady pace, recently hitting the milestone of 16k Github Stars \u2b50\ufe0f\ud83d\ude80 This list has grown thanks to the 100+ active contributors who continuously monitor for new tools and frameworks in the machine learning ecosystem. As of today this encompasses over 27 categories ranging across explainable AI, privacy preserving ML, model versioning, monitoring, serving and more. If there\u2019s any tools or frameworks missing please do contribute with a pull request as it would be greatly appreciated!"
            },
            {
                "title": "A Guide to Visual Transformers",
                "link": "https://blog.mdturp.ch/posts/2024-04-05-visual_guide_to_vision_transformer.html",
                "content": "A great visual guide to Transformers for image tasks in machine learning: This is one of the best and intuitive visualisations of the transformer architecture for image classification. This guide covers quite a comprehensive overview across data preparation, image patching and flattening, embedding, and the transformation process involving queries, keys, values, attention mechanisms, and positional embeddings. It also discusses the application of multi-head attention, residual connections, and feed-forward networks, including the training using cross-entropy loss. For anyone looking to get their hands dirty you can also try the Colab Notebook for the hands on example using Pytorch."
            },
            {
                "title": "Primer on Hacking LLM Models",
                "link": "https://kleiber.me/blog/2024/03/17/llm-security-primer/",
                "content": "Hacking Large Language Models for Beginners: As part of the growing adoption of LLMs, practitioners and researchers have found new and innovative ways to exploit machine learning systems involving these. This means that robust security measures are required in production applications that are powered by LLMs, as these models become integral to various applications. Common security vulnerabilities include data exfiltration and model misalignment, this article provides key resources, such as the OWASP and MITRE frameworks, and provides key guidance on approaches organisations are taking such as red teaming for security evaluation of ML systems."
            },
            {
                "title": "Snowflake\u2019s Largest LLM",
                "link": "https://www.snowflake.com/blog/introducing-snowflake-arctic-embed-snowflakes-state-of-the-art-text-embedding-family-of-models/",
                "content": "Snowflake has introduced a new text-embedding model designed specifically for retrieval applications, boasting an integration of 128 expert sub-models, a notable advancement over current offerings. This release is part of a broader trend where tech companies are increasingly releasing a plethora of open-source models, with Huggingface currently hosting over 600,000. These developments raise questions about the sustainability and economic rationale behind such heavy investments in model training and finetuning, especially considering the high costs associated with the computational resources required, predominantly provided by Nvidia. The strategic intent behind these widespread releases remains unclear, prompting further inquiry into the potential benefits and long-term viability of this approach in the tech industry."
            },
            {
                "title": "Foundational Tips for Engineers",
                "link": "https://grugbrain.dev/",
                "content": "A classic for excellent (and humourous) advice to software practitioners - The Grug Brained Developer: Key advice includes embracing the power of saying \u201cno\u201d to unnecessary features to maintain simplicity, utilizing the 80/20 rule to focus on delivering most of the value with minimal complexity, and being wary of adding early abstractions. This classic piece also emphasises the importance of factoring code wisely, advocating for small gradual refactoring, and highlighting the pitfalls of excessive abstractions which often complicate projects unnecessarily."
            }
        ]
    },
    {
        "issue": "281",
        "items": [
            {
                "title": "AI Generating Comics from Text",
                "link": "https://storydiffusion.github.io/",
                "content": "AI Video Generation - and now AI Comic Generation - are being taken to the next level, showcased by this research paper from ByteDance and various universities in China: StoryDiffusion introduces a novel framework for generating consistent sequences of images and videos from text prompts using diffusion-based models. It proposes two main components: Consistent Self-Attention, which enhances content consistency by incorporating reference image data into the self-attention process, and Semantic Motion Predictor, which facilitates smooth video transitions by predicting motions in a semantic space. These innovations enable the production of visually coherent narratives with very impressive stability and fidelity to the original text prompts - an exciting space."
            },
            {
                "title": "Stable Text-to-Motion Framework",
                "link": "https://sato-team.github.io/Stable-Text-to-Motion-Framework/",
                "content": "AI Generated 3D movies and video games are one step closer with this novel Stable Text-to-Motion Framework created through a collaboration from universities across US, China and Australia: This framework addresses instability issues in Text-to-Motion (T2M) models, which typically produce inconsistent motion sequences from similar textual inputs. This instability is traced back to erratic attention patterns in the text encoder module, primarily built on pre-trained CLIP models. To combat this, the authors propose the Stable Text-to-Motion Framework (SATO), comprising modules that enhance attention stability, prediction accuracy, and robustness. SATO shows significant improvements in stability and accuracy across tests with a new synonym perturbation dataset, together with impressive demos which make our imaginations run on how this will impact numerous industries."
            },
            {
                "title": "Tesla Autopilot Training 5m+ Cars",
                "link": "https://codecompass00.substack.com/p/tesla-data-engine-trigger-classifiers",
                "content": "A deep dive into how tesla continuously improves Self-driving capability on 5M+ cars by looking at a patent by Tesla\u2019s former Senior Director of AI Andrej Karpathy: In Testla\u2019s patent, the strategy for enhancing its Autopilot and Full Self-Driving features employs \u201ctrigger classifiers,\u201d which are specialized, lightweight machine learning models that detect unusual or rare driving conditions from data collected by its vast fleet of over 5 million vehicles. These classifiers help gather critical data, allowing Tesla to continually refine and update its models, ensuring better performance in edge cases and increasing overall system reliability. This dynamic method of targeted data acquisition and continuous model improvement demonstrates a scalable approach to advancing autonomous driving technologies. A great insight on a large-scale production machine learning system active globally."
            },
            {
                "title": "Reading Papers for Career",
                "link": "https://read.highgrowthengineer.com/p/why-reading-whitepapers-takes-your",
                "content": "Reading research papers can take your engineering career to the next level: Great advice on the benefits of reading whitepapers for engineers - clear benefits include expanding impact with innovative insights in team projects, fostering continuous personal and professional growth, and staying up-to-date with industry trends to secure career longevity. Often it is also beneficial to look at \u201cfoundational\u201d resources as opposed to the \u201clatest cutting edge\u201d, as this can serve to build a robust engineering knowledge and accelerate their advancement and establish themselves as key contributors within their organizations. Also some great papers suggested, including Google File System (GFS), Google Spanner (Globally Distributed Database), Google Chubby Locking Service, Meta XFaaS: Hyperscale and Low-cost serverless functions, Facebook Cassandra (Distributed NoSQL DB), Facebook Memcache (KV store), LinkedIn Kafka (PubSub), Amazon DynamoDB, and Bitcoin (yep)."
            },
            {
                "title": "Measuring Personal Growth",
                "link": "https://huyenchip.com/2024/04/17/personal-growth.html",
                "content": "Chip Huyen shares great introspective advice on how to measure (and augment) personal growth. She covers the concept of measuring personal growth using unique metrics beyond conventional means like net worth or social media followers. There are three main heuristics for personal development presented: the rate of change in identity every 3-6 years, the efficiency in solving life\u2019s significant problems such as career, family, and finance, and the number of future options available, akin to empowerment maximization principles used in reinforcement learning. Great advice on focusing on novelty and exploration, suggesting that personal growth can be quantified by one\u2019s ability to become a different person, resolve major life challenges quickly, and maximize potential future opportunities."
            }
        ]
    },
    {
        "issue": "282",
        "items": [
            {
                "title": "Stanford on Machine Unlearning",
                "link": "https://ai.stanford.edu/~kzliu/blog/unlearning",
                "content": "Stanford AI Lab researcher dives into Machine Unlearning in 2024, or the art of removing the influences of training data from a trained model: A really insightful view into the growing emerging need for \u201cmachine unlearning\u201d in machine learning systems, particularly as models and data sets grow. This ML unlearning is defined as the removal of specific data influences from a trained model to address issues such as privacy, outdated information, and unsafe content. There are a few interesting unlearning techniques (or perhaps more as \u201ccategories\u201d) ranging across 1) exact, 2) differential privacy, 3) empirical specific, 4) empirical underspecific, and 5) few-shot prompting. ML unlearning is clearly a topic that will continue growing for the immediate term, supported by initiatives such as the recent NeurIPS 2023 \u201cML unlearning challenge\u201d."
            },
            {
                "title": "StackOverflow and OpenAI",
                "link": "https://sato-team.github.io/Stable-Text-to-Motion-Framework/",
                "content": "An interesting development in the AI race with Stack Overflow and OpenAI announcing a partnership with OverflowAPI: This is an interesting collaboration, it\u2019s outlined as StackOverflow making their data available for OpenAI\u2019s models and services, most likely seeing an appearance in OpenAI models. However there has already been quite a mixed response online across various forums (hackernews, twitter, even linkedin) where active users are challenging this decision and even deactivating their accounts due to differing perspectives. It will certainly be interesting to see how this develops, however one thing that will be certain is that we will see interesting innovations in the space of developer productivity."
            },
            {
                "title": "Open Time Series Large Models",
                "link": "https://moment-timeseries-foundation-model.github.io/",
                "content": "Recently the release of time-series foundation models across Amazon, Google and beyond have highlighted challenges such as lack of benchmarks, datasets and even models; the MOMENT initiative aims to tackle this: A great initiative aiming to provide a compiled dataset for time-series foundation models, standardised benchmark to evaluate foundation models, and a suite of time-series foundation models that excel in multiple time-series contexts."
            },
            {
                "title": "Scraping with AI (Prompts)",
                "link": "https://read.highgrowthengineer.com/p/why-reading-whitepapers-takes-your",
                "content": "It was only about time until AI came into web scraping with ScrapeGraphAI: An interesting new initiative bringing specialised LLM agentic design into web scraping through graph-based logic. Quite interesting to see interfaces in SDKs that require prompting to specify the tasks, which open questions of reproducibility and debugging that will be interesting to see as production adoption of these tools increasese. Furthermore support for \u201cmultiple LLM backends\u201d also opens further considerations that although improve its ease, may have further nuances on how prompt engineering would be optimised as the libraries are expanded through maintenance."
            },
            {
                "title": "The Illustrated Word2Vec",
                "link": "https://jalammar.github.io/illustrated-word2vec/",
                "content": "The Illustrated Word2vec is a classic in ML for the key foundation concept of embeddings - this article provides a fantastic visual and intuitive overview: Word2vec has been quite influential upon its release, so it\u2019s a great opportunity for ML practitioners to brush up on how language embeddings underpin various applications, from language tasks to recommendation systems used by major companies. This is also a great overview of the technical details, including the mechanics and training processes of Word2vec, Continuous Bag of Words and Skipgram architectures, as well as advanced techniques like negative sampling."
            }
        ]
    },
    {
        "issue": "283",
        "items": [
            {
                "title": "Ways to Deploy an ML Model",
                "link": "https://outerbounds.com/blog/the-many-ways-to-deploy-a-model/",
                "content": "The many ways to deploy a machine learning model from the team at Outerbounds: A great overview for production ML practitioners on the diverse deployment strategies for ML/AI models, focusing on the critical considerations of scale, reliability, and iteration speed. It is often key to consider the broad range of technical requirements based on the application needs - i.e.\u00a0batch vs real time, reusable vs specialized, modalities, etc. Great practical examples and conceptual frameworks to identify the most suitable deployment approach."
            },
            {
                "title": "xLSTM Innovation in ML",
                "link": "https://arxiv.org/abs/2405.04517",
                "content": "xLSTM introducing the Extended Long Short-Term Memory as a challenger for the ever growing wave of transformer architectures: European innovation introduces an advanced version of the traditional LSTM model by incorporating exponential gating and innovative memory structures to address its limitations. These modifications allow xLSTMs to perform competitively with contemporary Transformer models in language processing tasks, showcasing improved capability in handling complex memory operations and scaling to large model architectures."
            },
            {
                "title": "Llama3 Implemented in NumPy",
                "link": "https://docs.likejazz.com/llama3.np/",
                "content": "Llama 3 implemented in pure NumPy - what better way to learn a concept than by implementing it: Great practical deep dive implementing Llama 3 model using only NumPy, demystifying the underlying model\u2019s architecture and nuances. Some of these include key components such as RoPE positional encoding, RMSNorm, and Scaled Dot-Product Attention, alongside optimizations like KV Cache for efficiency. This implementation serves as a great learning resource for machine learning practitioners interested in understanding the details under the hood."
            },
            {
                "title": "META Scaling Law for RecSys",
                "link": "https://arxiv.org/abs/2403.02545",
                "content": "META AI Research presents a scaling law for large-scale Recommendation Systems: As recsys grow in adoption and presence across tech companies, the need grows for a scaling law similar to those observed in large language models to understand relationships between considerations such as resources and limits. This design enables the model to effectively and efficiently scale by capturing any-order feature interactions through progressively deeper and wider layers."
            },
            {
                "title": "GPUs Go Brrr",
                "link": "https://hazyresearch.stanford.edu/blog/2024-05-12-tk",
                "content": "GPUs Go Brrr - or how to optimize AI compute on GPUs: Practical strategies and philosophical shifts are necessary to maximize hardware utilization in the world of machine learning compute. Some key best practices include leveraging asynchronous matrix multiplication instructions in GPUs directly from shared memory, and managing the quirks of shared memory to minimize latency and bank conflicts. This article provides an intuitive deep dive into how to streamline complex CUDA kernel programming, making it more accessible and efficient for developers working with intricate ML algorithms."
            }
        ]
    },
    {
        "issue": "284",
        "items": [
            {
                "title": "Stanford Foundation Model Index",
                "link": "https://crfm.stanford.edu/fmti/May-2024/index.html",
                "content": "Stanford has released this year\u2019s Foundation Model Transparency Index, which ranks the transparency of AI model governance across tech giants and AI research labs: Some of the models in scope for this report incude META\u2019s Llama2, Mistral\u2019s 7B, Anthrophic Claude3, OpenAI GPT4, Google Gemini and many others across Amazon, Adept, IBM, etc. Key results showcase a general improvement across the board on transparency, however highlighting there is still a way to go - certainly an interesting space to keep watch given the large gap."
            },
            {
                "title": "Diffusion Models Compendium",
                "link": "https://andrewkchan.dev/posts/diffusion.html",
                "content": "Stable Diffusion continues to make waves in high-quality generative AI image generation - this resource provides a great overview on the intuition on the intricacies behind stable difussion models. This article dives into how these models generate data, as well as the broader applications of these models in music, video, 3D modeling, and even computational biology. Furthermore it provides relevant perspectives on the ethical concerns regarding dataset sourcing as well as practical examples for ML practitioners."
            },
            {
                "title": "Continuous Delivery of AI Systems",
                "link": "https://outerbounds.com/blog/continuous-delivery-of-ml-ai/",
                "content": "The Outerbounds team shares a deep dive on how to organise continuous delivery of ML/AI systems through a 10-stage matury model. Produciton ML systems face challenges that go beyond traditional software systems, such as extensive computational needs, data unpredictability, and post-deployment validation; this demands specialised approaches when adopting standard methodologies such as CI/CD. Some of the key principles include GitOps integration, scalable compute resources, robust data and change management, and isolated environments for safe experimentation."
            },
            {
                "title": "Automated Vehicles Act UK",
                "link": "https://www.gov.uk/government/news/self-driving-vehicles-set-to-be-on-roads-by-2026-as-automated-vehicles-act-becomes-law",
                "content": "An insightful development in nation-wide embracing of AI with the UK\u2019s Self-Driving Vehicles Act enacted last week, with an exciting 2-year ambition: Quite insightful to see how governments progress in the adoption of production AI systems to integrate with society with safety in mind, specifically this regulatory framework introducing ambitious plans to have self-driving vehicles operating on UK roads by 2026. This legislation specifically establishes rigorous safety standards, independent incident investigations, and clear liability frameworks - it also highlights the creation of over 38,000 jobs by 2035, providing a practical view on the potential opportunity in the industry. This of course comes with key challenges, as well as critical considerations which have arisen in other contexts where (semi-)self-driving cars have slowly been introduced."
            },
            {
                "title": "GenAI Red Teaming Report 2024",
                "link": "https://www.humane-intelligence.org/grt",
                "content": "The Generative AI Red Teaming Challenge Transparency Report 2024 showcasing AI biases and ML vulnerabilities: This report brings together key insights discovered through various red teaming exercises by HumaneAI in collaboration with various leading tech organisations Nvidia, META, OpenAI, Stability, etc. Red teaming for ML systems is becoming growingly critical due to the cybersecurity risks posed in production AI models. Key findings in this 2024 report include the introduction of biases via challenge design, geographic and linguistic biases favoring U.S. and English-speaking contexts, and inconsistent model responses due to overcorrection for minority groups."
            }
        ]
    },
    {
        "issue": "285",
        "items": [
            {
                "title": "Lessons from a year of LLM Apps",
                "link": "https://applied-llms.org/",
                "content": "What We\u2019ve Learned From A Year of Building with LLMs - a comprehensive deep dive from Eugene Yan, Hamel Husain et. al: Building robust products in production that leverage LLMs remains challenging, but there are lessons learned from success stories. Some key insights include the importance of prompt engineering, structured outputs, and retrieval-augmented generation (RAG) to improve performance. Operationally it is key to consider data consistency, version control, and potentially using smaller models to optimize costs. Effective evaluation, monitoring, and involving design early in the process are crucial as well throughout the e2e lifecycel, as well as \u201cfocus on processes over tools\u201d to empower diverse roles within the team for successful execution."
            },
            {
                "title": "Andrew Ng on Real-World GenAI",
                "link": "https://www.oreilly.com/radar/podcast/generative-ai-in-the-real-world-andrew-ng-on-where-ai-is-headed-its-about-agents/",
                "content": "AI legend Andrew Ng discusses with Ben Lorica Generative AI in the Real World and where it is headed: A great podcast which dives into key aspects of production GenAI, such as the importance of scaling AI through agents, which enable LLMs to act as autonomous systems that can iteratively plan and execute tasks, which has the potential \u201cto go beyond Process Automation\u201d. There is also interesting discussion on the potential need for new hardware for AI inference, as well as the potential for what is referred to as \u201cagentic moments\u201d where LLMs can operate fully autonomously."
            },
            {
                "title": "McKinsey State of AI Report",
                "link": "https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai",
                "content": "McKinsey has released the State of AI in 2024 report with insightful metrics on AI in industry: The adoption of generative AI (gen AI) has surged with 65% of organizations now using it regularly, which is leading to significant business benefits such as cost reductions and revenue growth, particularly in marketing, sales, and product development. AI usage has increased globally with 72% of organizations implementing it across multiple functions. Investment in AI technologies is only growing - however, risks like inaccuracy and cybersecurity are also only on the rise. There are also insights from high-performing organizations using GenAI growingly/extensively, and attribute over 10% of their EBIT to AI (although IMO these days everything seems to fall on the AI bucket when it\u2019s not)."
            },
            {
                "title": "Tech Managers Anti-Patterns",
                "link": "https://review.firstround.com/unexpected-anti-patterns-for-engineering-leaders-lessons-from-stripe-uber-carta/",
                "content": "Unexpected Anti-Patterns for Engineering Leaders \u2014 Lessons From Stripe, Uber & Carta: CTO at Carta Will Larson shares three \u201cunconventional anti-patterns\u201d in engineering leadership: avoiding micromanagement, resisting flawed metrics, and shielding teams from problems. Some interesting insights for senior tech leaders, such as engaging deeply in team conflicts, documenting strategies thoroughly, using imperfect metrics for learning, and involving teams in decision-making."
            },
            {
                "title": "Japan\u2019s Push for Open Research",
                "link": "https://www.nature.com/articles/d41586-024-01493-8",
                "content": "Japan is launching a national initiative to make all publicly funded research open access by 2025, investing \u00a510 billion to standardize institutional repositories across universities: A fantastic initiative which hopefully is only a growing trend, with Japan\u2019s plan focusing on open access, where author-accepted versions of research papers are freely available, which would truly drive research collaboration. This move aims to address Japan\u2019s declining international research standing, but is a great step forward - other organisations like the ACM are investing in open access initiatives but it\u2019s great to see initiatives at the national level."
            }
        ]
    },
    {
        "issue": "286",
        "items": [
            {
                "title": "AI in Engineering at Google",
                "link": "https://research.google/blog/ai-in-software-engineering-at-google-progress-and-the-path-ahead/",
                "content": "Google just published promising results integrating AI/ML towards internal developer productivity, reporting 50% of their code being written by AI (which is indeed surprising): Google\u2019s analysis shows a clear double down towards AI services that aid software engineering, showcasing improvements across both dev productivity and dev satisfaction. Some of the key improvements stem from from high-quality data, iterative learning, and intuitive UX integration. They also highlight some strong ambitions expanding AI applications to testing, code understanding, and maintenance. This is both promising and interesting, certainly an interesting space to keep an eye on."
            },
            {
                "title": "The LLM Fine Tuning Index",
                "link": "https://predibase.com/fine-tuning-index",
                "content": "Finetuning LLMs is becoming growingly commoditised - this LLM Fine Tuning Index provides a great benchmark to even surpass GPT-4 performance with OSS models, and understand the \u201cwhat\u201d, \u201cwhen\u201d and \u201chow much $$\u201d of LLM finetuning: This LLM Fine Tuning Index from Predibase includes practical results from OSS models such as Llama, Zephyr, and Mistral across over 700 fine-tuning experiments."
            },
            {
                "title": "Free Bayesian Data Analysis Book",
                "link": "https://stat.columbia.edu/~gelman/book/",
                "content": "One of the best books on Bayesian Data Analysis is available for free, covering key fundamentals like probability and inference, single and multiparameter models, and hierarchical models. This is a great resource to go from basics to the more advanced nuances, such as computational techniques like Markov chain Monte Carlo and Hamiltonian Monte Carlo, as well as practical deep dives across other topics like regression models and nonparametric methods."
            },
            {
                "title": "Alibaba\u2019s Latest LLM Qwen2",
                "link": "https://qwenlm.github.io/blog/qwen2/",
                "content": "Alibaba\u2019s latest foundation model release has been taking the world by storm with a 0.5B parameter model with an impressive 32k context length (128k tokens for larger model). This new release comes with five models ranging from 0.5B to 72B parameters, support for 27 languages, and improved performance in coding, mathematics, and long-context tasks."
            },
            {
                "title": "Microsoft\u2019s Climate Foundation Model",
                "link": "https://www.microsoft.com/en-us/research/blog/introducing-aurora-the-first-large-scale-foundation-model-of-the-atmosphere/",
                "content": "Microsoft enters the Forecasting Foundation Model Race with their latest release of Aurora, tackling atmospheric forecasting trained on over a million hours of diverse weather and climate data. This 1.3 billion parameter model produces five-day global air pollution predictions and ten-day high-resolution weather forecasts, claiming higher performance compared to specialized models. Similar to previous foundation models from Amazon, Google, Nixtla, etc it will continue to be an important effort to verify performance against open benchmarks to continue to see innovation and improvement."
            }
        ]
    },
    {
        "issue": "287",
        "items": [
            {
                "title": "Chip Huyen on AI Engineering",
                "link": "https://x.com/acmeducation/status/1800614383258652990",
                "content": "Join AI founder & Author of O\u2019Reilly Book \u201cDesigning ML Systems\u201d Chip Huyen at this upcoming ACM fireside chat discussing practical advice on \u201cAI Engineering\u201d moderated by IEML Founder and Zalando Director Alejandro Saucedo. This session will explore the unique challenges of productionizing foundation models compared to traditional machine learning models. Despite sharing some core principles, foundation models introduce new complexities due to their open-ended nature, advanced capabilities, and computational demands. Key changes include shifting from closed-ended to open-ended evaluation, from feature engineering to context construction, and from structured data to unstructured data. This will be a great session so don\u2019t forget to RSVP!"
            },
            {
                "title": "How META Trains LLMs at Scale",
                "link": "https://engineering.fb.com/2024/06/12/data-infrastructure/training-large-language-models-at-scale-meta/",
                "content": "META recently made a massive investment to train large language models at scale - they now have shared a great overview of their learnings and challenges. Some of the key innovations that enabled META to succeed (so far) have included optimizing GPU connectivity, leveraging advanced scheduling algorithms, and adapting high-performance hardware. Meta has implemented robust network infrastructures that showcase the nuance required to support massive GPU clusters - this is an endevour that will only grow more ubiquitously across tech companies fighting across the AI race."
            },
            {
                "title": "AI Search The Bitter Lesson",
                "link": "https://yellow-apartment-148.notion.site/AI-Search-The-Bitter-er-Lesson-44c11acd27294f4495c3de778cd09c8d",
                "content": "The Bitter-er Lesson of AI search: opportunities integrating search capabilities with foundation models could revolutionize AI research and scaling laws. A great introspective analysis of search engines in context of the race between AI models and search. As history repeats, there is growing opportunity combining the power of human-crafted heuristics with advanced search capabilities, which can and is already unlocking new approaches for accelerating AI advancements."
            },
            {
                "title": "Uncensoring LLM Research",
                "link": "https://huggingface.co/blog/mlabonne/abliteration",
                "content": "The growing cybersecurity race in LLMs between safety mechanisms to limit undesirable content, and techniques to exploit these guardrails - this resource covers a great practical intution on how to uncensor any LLM using \u201cabliteration\u201d, namely a method to uncensor LLMs by removing their built-in refusal mechanisms without retraining. This technique involves identifying a specific \u201crefusal direction\u201d in the model\u2019s residual streams and either subtracting it during inference or modifying model weights to prevent its representation - by collecting activations from harmful and harmless prompts and computing the mean difference, practitioners can apply this technique to enable the model to respond to all prompts. Experiments like such put into perspective the challenges in technical safety considerations, highlighting the importance of security in context of agentic applications."
            },
            {
                "title": "Apple AI Private Cloud Compute",
                "link": "https://security.apple.com/blog/private-cloud-compute/",
                "content": "Apple\u2019s Private Cloud Compute: A new frontier for AI privacy in the cloud. A great insight into the shift in persepctive from consumers towards AI, highilighting the growing role of privacy and security. Apple presents key challenges in security and privacy in relation to data in context of AI systems, as well as their approach to improve the consumer sentiment. Some of these features include things like custom Apple silicon processors, \u201cprivacy-focused OS\u201d which is stateless, with ephemeral data processing, with no privileged access, making user data inaccessible to anyone, including Apple. Ultimately the secure, private and safe processing of AI systems will require considerations that go well beyond that of traditional software, and certainly will be a space worth keeping an eye."
            }
        ]
    },
    {
        "issue": "288",
        "items": [
            {
                "title": "Building a Multi-Petabyte Data Platform",
                "link": "https://www.youtube.com/watch?v=VxByJSMTSV8",
                "content": "Our talk from the Data & AI Summit is Live! Check out our overview of Zalando\u2019s journey \u201cBuilding a Multi-Petabyte Scale Data Platform\u201d \ud83d\ude80 At Zalando, data is at the core of everything\u2014as the organization has grown to 25 markets, 50M+ active customers, 1.8M+ articles and ~20K employees so has the multi-petabyte-scale data & AI opportunities. This talk provides a deep dive into the historical evolution of the Zalando data platform, an dives into some of the challenges and opportunities that it has unlocked. This is presented from the perspective of both, the central infrastructure and the data owning organisations, showcasing the importance of strong alliances between these for long term success."
            },
            {
                "title": "Chip Huyen on AI Engineering",
                "link": "https://twitter.com/acmeducation/status/1800614383258652990",
                "content": "Join AI founder & Author of O\u2019Reilly Book \u201cDesigning ML Systems\u201d Chip Huyen at this upcoming ACM fireside chat discussing practical advice on \u201cAI Engineering\u201d moderated by IEML Founder and Zalando Director Alejandro Saucedo. This session will explore the unique challenges of productionizing foundation models compared to traditional machine learning models. Despite sharing some core principles, foundation models introduce new complexities due to their open-ended nature, advanced capabilities, and computational demands. Key changes include shifting from closed-ended to open-ended evaluation, from feature engineering to context construction, and from structured data to unstructured data. This will be a great session so don\u2019t forget to RSVP!"
            },
            {
                "title": "META Multi-Modal Architecture",
                "link": "https://ai.meta.com/blog/meta-fair-research-new-releases",
                "content": "Meta releases Chameleon, a new multi-modality architecture that aligns text and image inputs through unified tokenisation as opposed to separate model architectures. Huge props for another open release with the open model weights, including the 7B and 34B models (albeit under a research only license). This includes a family of early-fusion token-based mixed-modal models capable of understanding and generating images and text in any arbitrary sequence, which suggests to match or exceed the performance of much larger models, including Gemini Pro and GPT-4V"
            },
            {
                "title": "Google Audio Gen Model",
                "link": "https://deepmind.google/discover/blog/generating-audio-for-video/",
                "content": "Google releases an interesting new model that generates audio from videos - although counterintuitive, this seems to open a lot of interesting opportunities across both real-world application, as well as research. Google showcases how they experimented with autoregressive and diffusion approaches to discover the most scalable architectures and ensuring synchronisation video and audio. Google also highlights interesting investments on safety with a \u201cwatermark tookit\u201d that aims to safeguard against misuse, which they will further evaluate before opening."
            },
            {
                "title": "Distributed Systems Fun & Profit",
                "link": "https://book.mixu.net/distsys/",
                "content": "Distributed systems are a fundamental concept to learn for practitioners in the DataOps and/or MLOps space; this free online book provides a great deep dive into key topics in distributed systems. This includes basic fundamentals such as scalability, availability, perfrmance, latency and fault tolerance. It also dives into key concepts such as abstractions, CAP theorem, time & order, and replication. For practitioners that are keen to dive deeper, it\u2019s always a great recommendation to check out the classic \u201cDesigning Data Intensive Systems\u201d from O\u2019Reilly."
            }
        ]
    },
    {
        "issue": "289",
        "items": [
            {
                "title": "Google Releases Gemma 2",
                "link": "https://blog.google/technology/developers/google-gemma-2/",
                "content": "Google releases the second generation of their Gemma model, bringing significant performance providing models that simplify productionisation with the more compact 9B and 27B models. In this release google focuses on inference efficiency ensuring execution works on single a GPU or TPU, and prioritise integration with Hugging Face and TensorFlow. Google also highlights the importance of responsible AI in context of LLMs, and dive into some of their approach to safety features and resources such as the Gemma Cookbook and the LLM Comparator."
            },
            {
                "title": "Learnings from 900 OSS AI Tools",
                "link": "https://huyenchip.com/2024/03/14/ai-oss.html",
                "content": "Chip Huyen shares an in-depth analysis of 900 popular open source AI tools, and highlights key learnings across infrastructure, model development, and application development layers. The study is based on 900 GitHub repositories with at least 500 stars, and it reveals a surge in AI applications post-2023 due to tools like Stable Diffusion and ChatGPT, with contributors dominating from both Western and Chinese developers. Some key trends showcase the fast-paced evolution (+ short-lived hype) of new tools, the collaborative nature of the community, and the growing divergence in China\u2019s AI landscape."
            },
            {
                "title": "LLMs for Compiler Optimisation",
                "link": "https://ai.meta.com/research/publications/meta-large-language-model-compiler-foundation-models-of-compiler-optimization/",
                "content": "Meta introduces their Large Language Model Compiler , designed for code and compiler optimization. This model compiler is built on Code Llama and trained on 546 billion tokens of LLVM-IR as well as assembly code, and is available in 7B and 13B parameter sizes. These models claim to enhance the understanding of compiler behaviors, and showcase results that suggest they significantly outperform previous models like GPT-4 Turbo in tasks such as flag tuning and disassembly."
            },
            {
                "title": "From Baremetal to 70b Model",
                "link": "https://imbue.com/research/70b-infrastructure/",
                "content": "The Imbue Team shares their experience of building and training a 70 billion parameter model on their own infrastructure surpassing GPT-4 in reasoning tasks. They detail the entire setup process: from provisioning machines and installing the OS to resolving hardware issues and ensuring network reliability with InfiniBand."
            },
            {
                "title": "Lessons from 15 Years of Coding",
                "link": "https://mbuffett.com/posts/programming-advice-younger-self/",
                "content": "Key lessons from 15 years of programming experience: A great resource that provides learnings from a life-long journey in the programming ecosystem. Some of the key learnings revolve enhancing programming efficiency, addressing recurring issues directly, balancing quality with speed based on context, mastering your tools, simplifying unnecessary complexities, fixing bugs at their root, utilizing version history for debugging, embracing imperfect code for feedback, streamlining debugging processes, leveraging team knowledge by asking questions, and prioritising frequent, efficient code shipping. For machine learning practitioners, these strategies can significantly boost productivity and reduce bugs in your machine learning projects as well."
            }
        ]
    },
    {
        "issue": "290",
        "items": [
            {
                "title": "META\u2019s Text-to-3D-Asset Model",
                "link": "https://ai.meta.com/research/publications/meta-3d-gen/",
                "content": "META releases an impressive Text-to-3D-Asset AI model: Meta comes back with an updated version of 3DGen, consisting of a cutting-edge pipeline for generating 3D assets from text with high prompt fidelity and high-quality outputs. The system supports physics-based rendering for realistic lighting, and enables retexturing of 3D shapes. Meta had previously released \u201c3D AssetGen\u201d and embeds it in this current release for text-to-3D generation together with their \u201c3D TextureGen\u201d model for text-to-texture generation, which has enabled them to outperform some of the current industry standards visual quality for models in this space."
            },
            {
                "title": "Sequoia on AI\u2019s $600B Question",
                "link": "https://www.sequoiacap.com/article/ais-600b-question/",
                "content": "Sequoia Capital takes on AI hype by bringing up the elephant in the room of high $500b compute costs, highlighting the ROI required to break even: Sequoia\u2019s David Cahn dives into the growing gap between AI infrastructure investments and revenue, now estimated at $500 billion annually. Indeed compute costs, such as investments in Nvidia\u2019s GPUs are crucial, however the costs keep piling up and the revenues need to match these in order to match its potential. Quite an interesting post which provides a current view on the status quo, namely with OpenAI dominating AI revenue - indeed with other few startups trailing, but with the speculative frenzy in AI investment posing return-on-investment risks akin to historical tech bubbles."
            },
            {
                "title": "Uber Modernising Batch & AI Infra",
                "link": "https://www.uber.com/en-AU/blog/modernizing-ubers-data-infrastructure-with-gcp/",
                "content": "Uber is migrating its batch data infrastructure from an on-prem massive-scale (exabyte-scale) Hadoop system to a cloud provider, and is sharing their learning and best practices. In the post they outline some of their motivations as well as approach and key principles. Migrations are a multi-year endevour, indeed interesting to see that Uber has made a public announcement in the beginning stages of their migration - this will certainly be a key resource to keep an eye on as it develops!"
            },
            {
                "title": "Machine Learning Operations",
                "link": "https://ml-ops.org/",
                "content": "MLOps continues to develop as an emerging field - the ml-ops.org website continues to be a great resource to find best practices and resources for practitioners looking to develop further knowledge in this space. The ML-Ops.org page provides great insights across model lifecycle management with traditional software engineering, including structured frameworks, principles, concepts and best practices across reproducibility, automation, and CI/CD, between many others. Do check it out."
            },
            {
                "title": "Runway\u2019s Text-to-Video Gen v3",
                "link": "https://runwayml.com/blog/introducing-gen-3-alpha/",
                "content": "AI Video generation continues to blow our minds - this last week we saw Runway\u2019s Gen-3 Alpha breaking through with high fidelity multimodal video generation. AI generated video only continues to get better and better - this model supports text prompts as well as image and video inputs to steer the generaiton of the scenes and transitions. It\u2019s interesting to see the required collaboration of scientists, engineers, and artists - although quite a competitive spce, it\u2019s certainly one to keep an eye on as we can be sure new (competing) models will continue to pop up across various different organisations and platforms."
            }
        ]
    },
    {
        "issue": "291",
        "items": [
            {
                "title": "Building Notion\u2019s Data Lake",
                "link": "https://www.notion.so/blog/building-and-scaling-notions-data-lake",
                "content": "Notion shares an insightful peek into their massive data growth, covering lessons learned and best practices building their org-wide data-lake: During their large-scale data journey Notion transitioned from a single Postgres instance to a sharded architecture and built an in-house data lake using S3, Kafka, Debezium, and Apache Hudi. This infrastructure was introduced to reduce costs and data ingestion times, whilst supporting update-heavy workloads and enabling advanced AI and Search features without fully replacing existing solutions like Snowflake and Fivetran."
            },
            {
                "title": "RouteLLM for Effective GenAI",
                "link": "https://lmsys.org/blog/2024-07-01-routellm/",
                "content": "The retrieval-augmented-generation innovations continue to grow, recently we saw RouteLLM as an alternative architecture toto reduce the costs of deploying large language models by routing queries between high-performance/expensive models and smaller/cheaper ones based on query complexity. RouteLLM achieves significant cost savings (up to 85%) while maintaining up to 95% of the performance of the top models like GPT-4 by utilizing preference data and various machine learning techniques."
            },
            {
                "title": "Goldman on GenAI Value Gap",
                "link": "https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf",
                "content": "Goldman Sachs talks about the GenAI elephant in the room, point out to the estimated ~$1tn AI capex spend from tech companies on GenAI and foundation models with the key need to see results: Goldman brings pragmatic insights on the opportunities and gaps in the AI gold rush, covering even the already-known supply constraints in AI chip production which is expected to lag with shortages beyond 2025. Even then, investment phases indicate immediate gains for companies like Nvidia producing, closley with infrastructure firms following - both which are bringing the \u201cpick-axes in the gold rush\u201d. Even with that in mind, there is a stern warning on economic risks due to high valuations, highlighting the obvious on the remaining need to see substantial productivity gains from AI to show the potential across the S&P 500 and beyond."
            },
            {
                "title": "How to Interview ML Engineers",
                "link": "https://eugeneyan.com/writing/how-to-interview/",
                "content": "Eugene Yan on how to effectively hire ML/AI engineers: A great resource covering best practices on MLOps recruitment, emphasising the importance of technical skills like software engineering, data literacy, and model evaluation, as well as non-technical traits such as handling ambiguity, influence and complexity. There are best practices from standard software interviews that can be leveraged, such as structured interviews using the STAR format, technical phone screens, and detailed debriefs to make informed decisions."
            }
        ]
    },
    {
        "issue": "292",
        "items": [
            {
                "title": "AI & Machine Learning Security",
                "link": "https://www.youtube.com/watch?v=sCOmXwFEVpI",
                "content": "Following the Crowdstrike global incident we are reminded of the risks in critical infrastructure, making it a great opportunity to dive into some of the risks in AI security. The operation and maintenance of large scale production machine learning systems has uncovered new challenges which require fundamentally different approaches to that of traditional software. In this talk I dive into a set of practical examples showcasing \u201cFlawed Machine Learning Security\u201d, together with best practices to tackle these."
            },
            {
                "title": "Goldman on GenAI Value Gap",
                "link": "https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf",
                "content": "Goldman Sachs talks about the GenAI elephant in the room, point out to the estimated ~$1tn AI capex spend from tech companies on GenAI and foundation models with the key need to see results: Goldman brings pragmatic insights on the opportunities and gaps in the AI gold rush, covering even the already-known supply constraints in AI chip production which is expected to lag with shortages beyond 2025. Even then, investment phases indicate immediate gains for companies like Nvidia producing, closley with infrastructure firms following - both which are bringing the \u201cpick-axes in the gold rush\u201d. Even with that in mind, there is a stern warning on economic risks due to high valuations, highlighting the obvious on the remaining need to see substantial productivity gains from AI to show the potential across the S&P 500 and beyond."
            },
            {
                "title": "Yoshua Bengio on AI Safety",
                "link": "https://yoshuabengio.org/2024/07/09/reasoning-through-arguments-against-taking-ai-safety-seriously/",
                "content": "Yoshua Bengio weighs in on the safety risks and considerations of Large Language Models, covering hallucinations, lack of confidence estimates, and missing citations. Hallucinations are incorrect yet plausible-sounding answers - a proposed solution to mitigate these issues involves a bootstrapping approach, namely curating a high-quality text corpus, training a base model, and using it to classify and expand training data iteratively."
            },
            {
                "title": "The Future of AI in Engineering",
                "link": "https://seanpedersen.github.io/posts/overcoming-llm-limits",
                "content": "GitHub\u2019s Chief Product Officer Inbal Shani dives into the transformative impact of AI on software development, covering the impact of AI augmenting (as opposed to replacing) developers soon, improving productivity through developer tools. Inbal highlights the underappreciated potential of AI-driven testing and predicts increased AI integration in development over the next few years, as well as shairng insights on fostering innovation and effective AI adoption within product teams."
            }
        ]
    },
    {
        "issue": "293",
        "items": [
            {
                "title": "Stackoverflow 2024 Dev Survey",
                "link": "https://survey.stackoverflow.co/2024/ai",
                "content": "The 2024 Stack Overflow Developer Survey is out! As always a stream of great insights, this edition bringing data on GenAI adoption for develope productivity: This year\u2019s data reveals that 76% of developers are using or planning to use AI tools, though only 43% trust their accuracy and 45% believe AI struggles with complex tasks. Despite this, 70% do not see AI as a threat to their jobs, viewing it instead as a complementary tool that reduces mundane tasks and allows for focus on more strategic work."
            },
            {
                "title": "Netflix\u2019s Workflow Orchestrator",
                "link": "https://netflixtechblog.com/maestro-netflixs-workflow-orchestrator-ee13a06f9c78",
                "content": "Netflix open sources their in-house alternative to Airflow, following Airbnb\u2019s release of Airflow as their solution to workflow management which has been adopted across the board. Netflix releases a new general-purpose, horizontally scalable workflow orchestrator designed to manage large-scale workflows like data pipelines and ML model training. This framework was designed to handle the entire workflow lifecycle, including retries and task distribution, with dynamic parameter support through a secure expression language ensuring scalability across thousands of workflow instances and half a million jobs daily."
            },
            {
                "title": "META Releases LLAMA 3",
                "link": "https://ai.meta.com/research/publications/the-llama-3-herd-of-models/",
                "content": "Meta release Llama3 with an exciting push challenging closed/proprietary models like OpenAI: The models released include up to 405 billion parameters, and support tasks across multilinguality, coding, and reasoning. What is most impressive as well is the infrastructure innovations required to achieve this, namely bringing together 16,000 NVIDOA H100 GPUs. The training infrastructure leverages Meta\u2019s production clusters for reliability and efficiency, adopting what they refer to as \u201c4D parallelism\u201d for scalable computation with reduced latency."
            },
            {
                "title": "Lessons from a Year of LLMs",
                "link": "https://applied-llms.org/",
                "content": "Lessons brought together by a group of experts building production LLM products throughout the last year: A great set of best practices in prompting, Retrieval-Augmented Generation, workflow optimization, and evaluation relevant for development of LLM-powered apps. Some of the key learnings include the importance of prompt engineering using structured outputs, employing deterministic workflows, and establishing robust evaluation and monitoring frameworks starting with inference APIs, avoiding unnecessary finetuning, focusing on domain-specific applications, and building LLMOps for faster iteration and product differentiation."
            },
            {
                "title": "The Future of AI in Engineering",
                "link": "https://seanpedersen.github.io/posts/overcoming-llm-limits",
                "content": "\u00ad \u00ad"
            }
        ]
    },
    {
        "issue": "294",
        "items": [
            {
                "title": "Building A Generative AI Platform",
                "link": "https://huyenchip.com/2024/07/25/genai-platform.html",
                "content": "Chip Huyen shares great insights and best practices on production-grade generative AI platforms: Great article detailing key best practices for production GenAI, including context enhancement, guardrails, model routers, gateways, and caching to optimize performance and security. This is quite an emerging field so it\u2019s interesting to see latest paradigms to address known challenges, including observability through metrics, logs, and traces, and the use of AI pipeline orchestration to manage complex workflows."
            },
            {
                "title": "Amazon\u2019s Exa-Migration to Ray",
                "link": "https://aws.amazon.com/blogs/opensource/amazons-exabyte-scale-migration-from-apache-spark-to-ray-on-amazon-ec2/",
                "content": "Amazon migrated their exabyte-scale BI data processing platfrom from Apache Spark to Ray on Amazon EC2, and they share key learnings through this journey. This switch was driven by some of the limitations they were facing with Spark when handling larger datasets requiring nuanced cost efficiency and faster processing times. Despite initial challenges across job success rates and suboptimal memory utilization, Ray has proven to be significantly more cost-effective, translating to substantial annual savings."
            },
            {
                "title": "10 Years of TPUs at Google",
                "link": "https://cloud.google.com/blog/transform/ai-specialized-chips-tpu-history-gen-ai",
                "content": "Google\u2019s Tensor Processing Units (TPUs) were developed over a decade ago to address the increasing AI compute demands - today Google shared their journey across the last 10 years: Throughout the last decade, TPUs have evolved significantly enhancing performance and efficiency across \u00a0large scale compute. These AI-specialized chips now support advanced models like Gemini 1.5 Flash and are integral to many Google (+ of course DeepMind\u2019s) products and services."
            },
            {
                "title": "A Visual Guide to Quantisation",
                "link": "https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization",
                "content": "A fantastic visual guide to quantization, explaining the most popular technique to reduce the size of Large Language/Foundation Models: This growing technique of quantisation lowers the bit-width of numerical representations, and leverages techniques such as post-training quantization (PTQ) and quantization-aware training (QAT) which optimize models to use lower precision without significant accuracy loss. There are also other methods like GPTQ, GGUF, and BitNet which allow for extreme reductions to 4-bit and even 1.58-bit representations, making it feasible to run large models on consumer hardware with limited VRAM whilst still maintaining reasonable performance."
            },
            {
                "title": "Lessons of 35 Years in Software",
                "link": "https://dev.jimgrey.net/2024/07/03/lessons-learned-in-35-years-of-making-software/",
                "content": "A great set of lessons learned from 35 years of software development: 1) Prioritize simplicity in solutions and frequent releases to create value swiftly; 2) build strong relationships within and outside your company to advance and realize your vision; ensure visibility of your work; 3) embrace new challenges to grow skills; 4) pursue passion over titles; 5) and remember that software is transient, so focus on delivering functional increments rather than perfect solutions."
            },
            {
                "title": "Source ML Frameworks",
                "link": "http://github.com/EthicalML/awesome-production-machine-learning/",
                "content": "\u00ad \u00ad"
            }
        ]
    },
    {
        "issue": "295",
        "items": [
            {
                "title": "Salesforce\u2019s New Foundation AI",
                "link": "https://blog.salesforceairesearch.com/mint-1t/",
                "content": "Salesforce AI steps into the foundation LLM race with their latest model MINT-1T as the first open-source multimodal dataset with one trillion tokens: MINT-1T drives quite a few interesting innovations such as expanding on the previously experimented datasets by incorporating diverse data sources including HTML documents, PDFs, and ArXiv papers. This scale seems to allow for better domain coverage, particularly in scientific documents with results suggesting that models trained on MINT-1T outperform those trained on prior datasets in tasks such as captioning and visual question answering."
            },
            {
                "title": "Building a Custom ML Platform",
                "link": "https://www.geteppo.com/blog/why-we-replaced-airflow-in-our-experimentation-platform",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "25 CompSci Papers to Read",
                "link": "https://www.geteppo.com/blog/why-we-replaced-airflow-in-our-experimentation-platform",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "Lessons on AI Training",
                "link": "https://gradientflow.substack.com/p/lessons-from-the-frontlines-of-ai",
                "content": "A great set of lessons from the Frontlines of AI Training from leading research labs in AI: This is a great resource that highlights how AI labs are innovating in data strategies, including the use of synthetic data, advanced data curation techniques, and scalable management solutions, to overcome challenges like potential data scarcity. This is a great reminder of how high-quality data is absolutely key in developing effective AI models."
            },
            {
                "title": "Introducing Apple Foundation AI",
                "link": "https://machinelearning.apple.com/research/introducing-apple-foundation-models",
                "content": "Apple also joins the race of foundation AI models with an advanced ~3 billion parameter AI system integrated into their devices: This is an insightful innovation in on-device / edge deep learning optimized for efficiency and tailored to everyday tasks like text editing, notifications, and image creation. Apple showcases how these models are trained using Apple\u2019s AXLearn framework, and how they were able to focus on privacy and responsible AI principles."
            },
            {
                "title": "Source ML Frameworks",
                "link": "http://github.com/EthicalML/awesome-production-machine-learning/",
                "content": "\u00ad \u00ad"
            }
        ]
    },
    {
        "issue": "296",
        "items": [
            {
                "title": "The State of Prod ML in 2024",
                "link": "https://www.youtube.com/live/AtA2XXo_b5s",
                "content": "Our talk on the main stage of WeAreDevelopers is out! This is a fresh view on the State of Production Machine Learning, highlighting key trends and opportunities for 2024: This year\u2019s edition on the State of Prod ML dives into the transition of AI models into complex data-centric systems that integrate deeply with organizational processes. We dive into the growing complexity of the machine learning ecosystem as well as how to navigate the growingly complex ecosystem of tools, ensuring robust security, advanced monitoring, and evolving roles within organizations to manage this complexity. We also dive into the impact of emerging compliance, which brings responsible AI deployment to the center."
            },
            {
                "title": "PyCon US Videos are Out",
                "link": "https://www.youtube.com/playlist?list=PL2Uw4_HvXqvYhjub9bw4uDAmNtprgAvlJ",
                "content": "PyCon US 2024 videos are out! As always there\u2019s a lot to catch up on, particularly for ML & Data practitioners, spanning across sessions on deep learning with PyTorch, building FPGA-based ML accelerators, AI document processing, improving ML reproducibility, advanced memory management techniques and many more. These videos are great resources for any practitioner working in the ML and data science space."
            },
            {
                "title": "Pop Culture in the Age of AI",
                "link": "https://www.wheresyoured.at/pop-culture/",
                "content": "A great write-up analysing the hype in AI, challenging specifically the return-on-investment in generative AI hype. Recently we saw the Goldman Sachs report highlighting \u201cToo Much Spend, Too Little Benefit?\u201d, with doubts on the economic viability and productivity benefits of generative AI based on costs, power demands, and limited real-world impact."
            },
            {
                "title": "PapersWeLove in CompSci",
                "link": "https://paperswelove.org/",
                "content": "One key advice for software practitioners looking to take their career to the next level is to read research papers! More specifically, dive into foundational resources that have changed the state of the development ecosystem - and the github repo on \u201cPapers We Love\u201dhas a massive curated collection of key computer science research papers, organized by themes. These can\u2019t be recommended enough as it contains relevant topics across machine learning, distributed systems, cryptography, and programming languages."
            },
            {
                "title": "Seeing Theory: Probability & Stats",
                "link": "https://seeing-theory.brown.edu/#firstPage",
                "content": "Really awesome (and visually pleasing) introduction to probability and statistics. \u201cSeeing theory\u201d is a short course that introduces basic probability, compound probability, probability distributions, frequentist inference, bayesian inference and regression analysis. This resource came out a while back but it\u2019s still providing quite an intuitive and visual view on an important topic."
            },
            {
                "title": "Source ML Frameworks",
                "link": "http://github.com/EthicalML/awesome-production-machine-learning/",
                "content": "\u00ad \u00ad"
            }
        ]
    },
    {
        "issue": "297",
        "items": [
            {
                "title": "On Being a Senior Engineer",
                "link": "https://www.kitchensoap.com/2012/10/25/on-being-a-senior-engineer/",
                "content": "A classic on the expectations and traits of a \u201csenior engineer\u201d across both technical and non-technical areas: Some of the key traits of a senior role include seeking constructive criticism, understanding the importance of collaboration and communication, being comfortable with making estimates, and recognizing the trade-offs in engineering decisions. It\u2019s also clear on the importance of soft strengths such as empathy, mentorship, and the ability to navigate the complexities of team dynamics."
            },
            {
                "title": "Postgres as a Search Engine",
                "link": "https://anyblockers.com/posts/postgres-as-a-search-engine",
                "content": "Postgres as the solution for everything - this time, on postgres as a Search Engine (yes, even for your shiny RAG application): Quite an insightful deep dive into PostgreSQL latest extensions to build a versatile search engines integrating full-text search, semantic search, and fuzzy matching. The architecture involves a single PostgreSQL instance for advanced strategies like result re-ranking with cross-encoders and boosting for enhanced user experience, making PostgreSQL a surprisingly powerful tool for search."
            },
            {
                "title": "What\u2019s Going on in ML",
                "link": "https://writings.stephenwolfram.com/2024/08/whats-really-going-on-in-machine-learning-some-minimal-models/",
                "content": "A fantastic practical and philosophical article from Stephen Wolfram on foundational machine learning: Great insights from Wolfram arguing that the current success of ML lies in leveraging computational irreducibility, where complex behaviors emerge from simple rules. This article introduces examples with minimal models that show how ML doesn\u2019t create structured mechanisms but instead exploits complexity to drive value, introducing newer trade-offs such as model interpretability and performance/accuracy."
            },
            {
                "title": "How Google Search Works",
                "link": "https://searchengineland.com/how-google-search-ranking-works-445141",
                "content": "A set of leaked court documents gives us an in-depth insight into how Google Search Ranking really works: This is a great deep dive into Google\u2019s complex search ranking system which focuses on how internal components impact how search results are determined. It\u2019s also interesting to see the increasing complexity of ranking algorithms driven by machine learning, which make it difficult even for Google engineers to fully explain rankings. The internal components also have traditionally creative names such as \u201cAlexandria\u201d, which handles indexing, and \u201cMustang\u201d + \u201cSuperroot\u201d, which refine and filter search results. What is also quite interesting is that these insights are also relevant to understanding these systems for SEO, which make it clear that traditional on-page and off-site optimization may be less effective than understanding and adapting to these dynamic ranking factors."
            },
            {
                "title": "Good vs Bad Code Refactoring",
                "link": "https://www.builder.io/blog/good-vs-bad-refactoring",
                "content": "Good Refactoring vs Bad Refactoring, a great reminder that not all refactors are committed equal: We have to remind ourselves on common pitfalls on refactoring, such as overcomplicating code with unnecessary abstractions, introducing inconsistent coding styles, and failing to understand the code before making changes. This resource has some great reminders on best practices such as maintaining consistency with the existing codebase, avoiding drastic shifts in paradigms without team consensus, and prioritizing readability and maintainability over perceived \u201ccleanliness.\u201d"
            }
        ]
    },
    {
        "issue": "298",
        "items": [
            {
                "title": "Raschka\u2019s 3hr Coding Workshop",
                "link": "https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up",
                "content": "Sebastian Raschka has dropped a 3-hour workshop on building LLMs from the Ground Up! This resource comes with great timing as LLMs continue to grow in popularity, covering the foundations across input data preparation, model architecture coding, pretraining, and fine-tuning. This is quite a comprehensive resource as it dives into practical coding examples using PyTorch and LitGPT, building the core fundamentals from scratch and training simplified LLM versions like GPT-2."
            },
            {
                "title": "Lessons on Four Years of MLOps",
                "link": "https://mburaksayici.com/blog/2024/08/29/what-ive-learned-building-mlops-systems-for-four-years.html",
                "content": "Lessons learned from building MLOps systems across Four Years: Key lessons from complexity of ML problems such as consumption forecasting where the need for robust MLOps is critical include transitioning from ML to software engineering, encompassing the difficulty in defining the many roles and responsibilities across MLOps Engineer versus ML Engineer. As production ML systems mature, it is also challenging to juggle multiple roles as well as the pressure to keep up with rapidly evolving trends."
            },
            {
                "title": "150% Productive with CursorAI",
                "link": "https://www.youtube.com/watch?v=yk9lXobJ95E",
                "content": "There is an ongoing revolution on AI powered IDEs, and spending a weekend taking the latest AI Editor \u201cCursorAI\u201d shows exciting potential to make developers more productive across the board: This video showcases how integrating AI tools like Cursor and Claude Sonnet 3.5 into your coding workflow can significantly help launch productivity for experienced developers. CursorAI is a code editor built on Visual Studio Code with native AI features that streamline the coding process - really cool to see it in action to perform automated code generation and intelligent code refactoring across multiple files. There are clear limitations - testing it in low level codebases such as C++ GPU acceleration or complex distributed computing libraries it clearly struggles to provide suggestions that are actually useful, however it is still quite exciting to see the developments in this space, definitely one to keep an eye."
            },
            {
                "title": "Time Management Techniques",
                "link": "https://www.lennysnewsletter.com/p/time-management-techniques-that-actually",
                "content": "Time management and productivity techniques that actually work: A great set of tips from the one and only Lenny on productivity: 1) using your calendar for tasks, 2) applying the two-minute rule, 3) scheduling deep work time, 4) minimizing meetings, 5) delegating low-impact tasks. This are a great set of tips that I actually have been using myself for the last few years which I certainly recommend."
            },
            {
                "title": "Convincing PMs to Tech Debt",
                "link": "https://newsletter.eng-leadership.com/p/engineers-guide-to-convincing-your",
                "content": "The article \u201cEngineer\u2019s Guide to Convincing Your Product Manager to Prioritize Technical Debt\u201d provides a comprehensive approach for machine learning and software engineers to effectively communicate the importance of addressing technical debt to their product managers (PMs). The key strategy involves aligning technical debt with business goals by demonstrating how it impacts developer velocity, time to market, customer experience, and long-term scalability. The guide offers a five-step process: understanding the business strategy, quantifying the problem with metrics, linking technical debt to business outcomes, proposing a phased solution, and presenting the proposal empathetically in a format the PMs can easily understand. By framing technical debt as a value proposition, engineers can better advocate for its prioritization alongside new features."
            }
        ]
    },
    {
        "issue": "299",
        "items": [
            {
                "title": "Canva\u2019s 25B Events per Day",
                "link": "https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up",
                "content": "Canva\u2019s product analytics pipeline processes 25 billion events daily, with growing use-cases across A/B testing, personalization, and insights - this is a great deep dive into how they make it happen: Canva has adopted key principles to enable massive-scale processing, such as ensuring events following a strict schema (using Protobuf), and enforcing schema with their internal service Datumgen. They collect events through a unified client, which they then ensure are validated, enriched, and routed via AWS Kinesis."
            },
            {
                "title": "Uber\u2019s Kafka Tiered Storage",
                "link": "https://www.uber.com/en-DE/blog/kafka-tiered-storage/",
                "content": "Uber brings together their approach to supporting Tiered Storage in Kafka, which ensures decoupling between Kafka\u2019s storage and compute resources, which enables scalable and cost-efficient data retention. Uber achieves this by introducing local storage for recent data and remote storage (e.g., S3, HDFS) for older data, which supports for optimisation \u00a0of resource use and reduces operational complexity. This is quite a practical deep dive, and it is great to see the close collaboration with the open source community, with the core Kafka team also contributing closely to extend and support these use-cases."
            },
            {
                "title": "DB Lessons to Know for Devs",
                "link": "https://rakyll.medium.com/things-i-wished-more-developers-knew-about-databases-2d0178464f78",
                "content": "Things I Wished More Developers Knew About Databases: Often fundamentals of database design are overlooked by developers when working with databases, which can have a substantial benefit to their day to day development. Some of the key lessons include: 1) the fallibility of network reliability, 2) the varied interpretations of ACID across databases, and 3) the trade-offs between consistency, isolation, and performance."
            },
            {
                "title": "Effects of Gen AI on High Skill",
                "link": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566",
                "content": "The Effects of Generative AI on High Skilled Work: Evidence from Three Field Experiments with Software Developers. A great review on the state of GenAI bringing together three field experiments that examining the impact of GitHub Copilot on software developers\u2019 productivity. This study was conducted at Microsoft, Accenture, and an anonymous company - the study evaluates the effect of Copilot on metrics such as pull requests, commits, and successful builds (indeed not optimal metrics but still relevant insights). The results show that Copilot increases developer productivity by approximately 26%, with a particularly strong effect on the number of pull requests and builds. Junior and short-tenure developers exhibited higher adoption rates and saw the most significant productivity gains. However, the effects were not consistently statistically significant across all metrics or companies - this is obviously key, but it\u2019s great to see investments towards quantifying the causal impact of AI tools in development."
            },
            {
                "title": "Explicit is Better than Implicit",
                "link": "https://www.trevorlasn.com/blog/-explicit-is-better-than-implicit/",
                "content": "One of the age-old lessons on clean-code: the importance of writing explicit, clear code over implicit, ambiguous code in software development. For machine learning practitioners, this is especially relevant when working in large, collaborative codebases, as maintainability and clarity are always important. Implicit code can introduce confusion and increase the cognitive load for developers, leading to higher \u201cWTF per Minute\u201d (WTFPM) rates - indeed a great standardised quantifiable metric across industry (!)."
            },
            {
                "title": "Upcoming events on Production ML",
                "link": "https://ethical.institute",
                "content": "\u00ad \u00ad"
            }
        ]
    },
    {
        "issue": "300",
        "items": [
            {
                "title": "Survey: The State of Prod ML 2024",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "OpenAI Reasoning with LLMs",
                "link": "https://openai.com/index/learning-to-reason-with-llms/",
                "content": "OpenAI has introduced O1 - a new large language model trained with reinforcement learning to perform complex reasoning using a hidden chain of thought to improve problem-solving abilities. This new release seems to introduce a different approach over previous models like GPT-4o, which is now specialising on benchmarks for mathematics and science expertise, and programming competence. In practice there has been a broad range of mixed responses, but there seems to be a strong claim for this approach to have some strong potential for improving safety and alignment by allowing the model to internally reason about safety rules."
            },
            {
                "title": "Copilot is making Devs Worse",
                "link": "https://www.darrenhorrocks.co.uk/why-copilot-making-programmers-worse-at-programming/",
                "content": "Copilot is Making Programmers Worse at Programming: AI code-generation tools like GitHub Copilot have potential to improve productivity, however they can also be double-edged sword which may worsen programmers\u2019 fundamental skills by introducing over-reliance on auto-generated code. This reliance can then lead into hindering development on core programming competencies, such as reducing problem-solving abilities, and introducing a lack of ownership over code quality. Someone is going to have to maintain all the code that is written by AI, so we need to be mindful that the age-old \u201cclean-code\u201d principles are not going anywhere even with these intelligent tools rising."
            },
            {
                "title": "The ML Engineering Open Book",
                "link": "https://github.com/stas00/ml-engineering?tab=readme-ov-file",
                "content": "A great resource diving into Machine Learning Engineering, providing resources specialised for large language models (LLMs) and multi-modal models (VLMs): Great repo that provides practical methodologies, tools, and step-by-step instructions covering critical aspects across the production ML lifecycle such as hardware considerations (compute, storage, network), orchestration with SLURM, training and inference strategies, debugging techniques, and performance optimization."
            },
            {
                "title": "Rise of OSS Time Series DBs",
                "link": "https://victoriametrics.com/blog/the-rise-of-open-source-time-series-databases/index.html",
                "content": "Open source time series databases like Prometheus and InfluxDB have become growingly popular for production machine learning practitioners to efficiently store and query large volumes of time-stamped data needed for monitoring models, detecting anomalies, and forecasting resources: Traditional relational databases may struggle with the scale and performance demands of time series data if not optimized accordingly - this has led to the rise of open source solutions that offer better stability, efficiency, and scalability for these use-cases. This is an interesting deep dive from VictoriaMetrics, which covers some of the shortcomings from existing solutions as well as their approach to addtessing these."
            },
            {
                "title": "Upcoming events on Production ML",
                "link": "https://ethical.institute",
                "content": "\u00ad \u00ad"
            }
        ]
    },
    {
        "issue": "301",
        "items": [
            {
                "title": "State of Prod ML: 2024 Survey",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "Learnings from 100k A/B Tests",
                "link": "https://www.youtube.com/watch?v=VIYbA3mbfWQ",
                "content": "What do you learn from running 100,000 A/B tests? Despite the disproportionately larger A/B-testing culture at billion-user scale, companies like Amazon and Meta still face significant challenges in large-scale experimentation, and this is resource captures some of these challenges. Some of the key issues that these type of organisations face include information overload from numerous concurrent experiments, diminishing returns on the approaches to extract causal insights, infrastructural limitations affecting scalability, and cultural differences in experimentation practices. This is a great insight for organisations that are building their experimentation practices, although we have to remember that only a small subset of companies have the scale of some of these tech giants."
            },
            {
                "title": "Pragmatic Machine Learning Eng",
                "link": "https://ppml.dev/",
                "content": "Free Online Book: The Pragmatic Programmer for Machine Learning Engineering, A Practical Deep Dive. This is a great resource on the role of software engineering in developing robust, efficient, and maintainable machine learning systems for production. The book bridges the gap between machine learning and software engineering by offering best practices for designing, coding, deploying, documenting, and testing machine learning pipelines, and provides key lessons on recognizing that poor software practices can lead to technical debt, reproducibility issues, and costly failures."
            },
            {
                "title": "Stanford\u2019s ML System Seminars",
                "link": "https://www.youtube.com/channel/UCzz6ructab1U44QPI3HpZEQ",
                "content": "Stanford has been publishing seminar videos on the frontier of machine learning systems, covering key concepts around challenges and solutions in AI research and industry in conversation with thought leaders in the space. This is quite a great video series as it features expert speakers from academia and industry, the series covers a wide range of topics including programming ML systems with frameworks like JAX, data labeling with tools like Snorkel, deploying robust models, hyperparameter optimization, and end-to-end ML pipelines."
            },
            {
                "title": "PolaRS GPU Accel DataFrames",
                "link": "https://pola.rs/posts/gpu-engine-release/",
                "content": "Exciting to continue seeing developments in GPGPU with PolaRS (aka Pandas in Rust) which has integrated GPU acceleration into its Python library. It\u2019s quite interesting to see the initial release leveraging NVIDIA RAPIDS\u2019 cuDF which provides production machine learning practitioners up to 13x speed improvements on compute-intensive data processing tasks like joins and GROUP BYs. It will certainly be an exciting space to keep an eye on - indeed it is exciting for the opportunity for leveraging Vulkan-based GPGPU backends for support across 1000s of GPU cards, such as with our GPU acceleration framework Vulkan Kompute."
            }
        ]
    },
    {
        "issue": "302",
        "items": [
            {
                "title": "State of Prod ML 2024 Survey",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "34% of organisations take between 1-3 months to productionise a machine learning model, and over 20% take even longer up to 6 months - fantastic insights only a few weeks from launching the Prod ML 2024 Survey! We have designed the questions to provide meaningful insights on the current landscape of production ML in 2024 - if you have a chance we would be grateful if you could spend a few minutes on the survey, as you\u2019ll contribute valuable information about the machine learning tools and platforms you use in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80 We are also working on an interactive visualisation for everyone to be able to slice and dice across the data to derive meaningful insights on the production ML ecosystem!"
            },
            {
                "title": "ML Optimization Gone Wrong",
                "link": "https://sohl-dickstein.github.io/2022/11/06/strong-Goodhart.html",
                "content": "When a measure becomes a target, it ceases to be a good measure; Goodhart\u2019s law showcasing when too much optimization is deterimenal - great deep dive from Anthropic (+ former Google Brain) researcher. Increased efficiency can paradoxically worsen outcomes, which is a phenomenon termed by the strong version of Goodhart\u2019s Law, which is compared to the concept of overfitting in machine learning. Overfitting occurs when an ML model over-optimizes a specific dataset instead of the generalised distribution expected to be seen in the real world. It is possible to mitigate these isuses by better aligning proxy objectives with true goals, introducing regularization penalties, injecting noise, applying early stopping, and adjusting system capacities."
            },
            {
                "title": "Google Measuring Dev Goals",
                "link": "https://research.google/pubs/measuring-developer-goals/",
                "content": "Google on Measuring Machine Learning Productivity Goals across organisations: A great paper from Google\u2019s Developer Productivity team on the importance of understanding and measuring overarching developer goals to enhance productivity and experience, especially in complex, iterative workflows common in production machine learning. Google developed a concise list of 30 durable and observable developer goals spanning the software development lifecycle by combining attitudinal data from surveys with behavioral data from usage logs."
            },
            {
                "title": "XKCD 10y: Hard vs Impossible",
                "link": "https://simonwillison.net/2024/Sep/24/xkcd-1425-turns-ten-years-old-today/",
                "content": "Thrilled to celebrate 10 years of XKCD, which now for over a decade have brought humorous and insightful comics reflecting the challenges and ironies in computer science. Today they share an ironic and comical post on foundation ML models in the context of how difficult it is to distinguish \u201ceasy\u201d tasks from \u201chard\u201d tasks in software development, but indeed in this case in context of LLMs. Here is to many more years of insightful and inspiring XKCD comics!"
            },
            {
                "title": "GPU Puzzles For Fun & Profit",
                "link": "https://github.com/srush/GPU-Puzzles",
                "content": "This is the time to learn General-Processing GPU compute programming, and GPU-Puzzles are a fantastic way to get started: This new interactive notebook tutorial is a great intro to GPGPU designed for research & production machine learning practitioners to learn GPU programming fundamentals using Python\u2019s NUMBA, which compiles Python code into CUDA kernels. This resource is quite comprehensive as it teaches essential concepts like thread and block management, shared memory usage, and efficient computation of core deep learning algorithms such as pooling, convolution, and matrix multiplication (of course)."
            }
        ]
    },
    {
        "issue": "303",
        "items": [
            {
                "title": "Meta\u2019s MovieGen Model",
                "link": "https://ai.meta.com/research/movie-gen/",
                "content": "META has released a mind blowing high-def AI text-to-video model that has been making waves in the AI ecosystem: This is quite an interesting release as this model encompasses also features for video editing through text prompts, personalized video creation by conditioning on user-provided images, and audio generation for sound effects and soundtracks. The space of text-to-video models is evolving quite fast - quite an exciting area to keep an eye on as we\u2019ll most likely see counter-releases from the usual suspect tech giants following this release."
            },
            {
                "title": "State of Prod ML 2024 Survey",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "Over 50% do not have any Machine Learning monitoring; important insights from 2024 Survey on The State of Production ML! We have designed the questions to provide meaningful insights on the current landscape of production ML in 2024 - if you have a chance we would be grateful if you could spend a few minutes on the survey, as you\u2019ll contribute valuable information about the machine learning tools and platforms you use in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80 We are also working on an interactive visualisation for everyone to be able to slice and dice across the data to derive meaningful insights on the production ML ecosystem!"
            },
            {
                "title": "Ngrok\u2019s Central Data Platform",
                "link": "https://ngrok.com/blog-post/how-we-built-ngroks-data-platform",
                "content": "A deep dive into ngrok\u2019s journey building their internal data platform with a small engineering team: An interesting case study building an internal data platform with lessons integrating data engineering into their broader software development practices, focusing on open-source tools and collaborative workflows within a Go monorepo. Ngrok transitioned from AWS services to a Kubernetes-based stack using tools like Dagster, Airbyte, Apache Flink, and dbt with a lot of interesting lessons learned along the way."
            },
            {
                "title": "Google\u2019s NotebookLLM Podcasts",
                "link": "https://simonwillison.net/2024/Sep/29/notebooklm-audio-overview/",
                "content": "Google\u2019s introduced an Audio Overview feature to their NotebookML product which has been used to generate custom podcasts from any content provided - people have been using instruction manuals, personal notes, newsletters and anything they get their hands on. This is quite an interesting use-case of Google Gemini integrated into a Google experimental product to generate audio content for what promises to be quite a lot of high potential user-level applications."
            },
            {
                "title": "LLMs Large-Scale Annotation",
                "link": "https://arxiv.org/pdf/2409.11860",
                "content": "A recent research paper from Zalando presenting a framework to leverage multimodal large language models to efficiently evaluate large-scale product retrieval systems by automating the relevance assessment of query-product pairs using both textual and visual product information. This is quite an interesting approach to reduce the time and cost associated with human annotations whilst keeping quality. This research initiative evaluates on datasets with 20,000 query-product pairs in English and German showing that MLLM-generated annotations align closely with human judgments, making it suitable for continuous, scalable, and multilingual evaluations in production environments, such as e-commerce search engines."
            }
        ]
    },
    {
        "issue": "304",
        "items": [
            {
                "title": "Building Virtual Worlds with ML",
                "link": "https://diamond-wm.github.io/",
                "content": "This is mind blowing: Who would\u2019ve thought that training Image Diffussion Models on Videogame visuals+player inputs would result in fully ML-generated virtual worlds \ud83e\udd2f Researchers from Microsoft and Geneva/Edinburgh University have released DIAMOND (DIffusion As a Model Of eNvironment Dreams) - a reinforcement learning agent that leverages diffusion models for world modeling in Atari games, eliminating the need for discretization and reducing mode collapse issues inherent in token-based approaches. DIAMOND enhances the modeling of visual details, and achieves a mean human-normalized score of 1.46 on the Atari 100k benchmark (a new state-of-the-art for agents trained entirely within a world model), and demonstrates that diffusion models can serve as effective drop-in replacements for real environments in reinforcement learning. And the code is open source and available in github - this is an exciting new domain I had not come across, certainly an area to keep an eye into."
            },
            {
                "title": "State of Prod ML 2024 Survey",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "Dire results on Diversity from the 2024 Survey on the State of Production Machine Learning; only under 5% of respondents identifying as female - there is a lot of work for all of us in the Prod ML ecosystem! These have been really important insights from 2024 Survey on The State of Production ML; we have designed the questions to provide meaningful insights on the current landscape of production ML in 2024 - if you have a chance we would be grateful if you could spend a few minutes on the survey, as you\u2019ll contribute valuable information about the machine learning tools and platforms you use in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80 We are also working on an interactive visualisation for everyone to be able to slice and dice across the data to derive meaningful insights on the production ML ecosystem!"
            },
            {
                "title": "Repo of ML Monitoring Metrics",
                "link": "https://github.com/NannyML/The-Little-Book-of-ML-Metrics",
                "content": "The Little Book of ML Metrics is an open-source handbook designed for production machine learning practitioners, and it is aiming to build a comprehensive reference to all-things-metrics in ML monitoring. This is a great ambitious project aiming to consolidate a comprehensive list of metrics in ML monitoring across the domains of regression, classification, clustering, ranking, computer vision, NLP, generative AI, probabilistic models, bias, fairness, and business metrics."
            },
            {
                "title": "Salesforce Red Teams for AI/LLMs",
                "link": "https://blog.salesforceairesearch.com/how-salesforce-builds-reproducible-red-teaming-infrastructure/",
                "content": "Salesforce\u2019s Responsible AI team presents a framework for reproducible red teaming that tackles the challenges of AI product testing. It is great to see organisations drive forward the discourse on red teaming for AI, Salesforce doubling down on four key areas: 1) High-quality, use case-specific data that is properly stored and maintained for reproducibility; 2) Programmatic access to products via APIs or clients to automate and scale testing efficiently; 3) Clear taxonomies for evaluating outputs to ensure stakeholder alignment and consistent assessments; and 4) Comprehensive test plans to manage expectations and scope technical work effectively."
            },
            {
                "title": "Cognitive Load in Developers",
                "link": "https://github.com/zakirullin/cognitive-load",
                "content": "One of the biggest challengers to productivity in development is cognitive load, and this is a great resource that dives into key areas to reduce the mental effort needed to understand code. Extraneous cognitive load, caused by overly complex conditionals, excessive small modules or microservices, and unnecessary abstractions, can be reduced by simplifying code, favoring deep modules with simple interfaces, and using language features sparingly. Properly applying principles like Domain-Driven Design (DDD) and avoiding unnecessary complexity ensures that code remains understandable and maintainable, improving productivity and collaboration across teams."
            }
        ]
    },
    {
        "issue": "305",
        "items": [
            {
                "title": "State of Prod ML 2024 Survey",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "Almost 60% of real-time machine learning is still powered by FastAPI/Flask or Custom Wrappers - it seems the MLOps ecosystem is not yet consolidated, showing huge opportunity in this space: These are really important insights from 2024 Survey on The State of Production ML; we have designed the questions to provide meaningful insights on the current landscape of production ML in 2024 - if you have a chance we would be grateful if you could spend a few minutes on the survey, as you\u2019ll contribute valuable information about the machine learning tools and platforms you use in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80 We are also working on an interactive visualisation for everyone to be able to slice and dice across the data to derive meaningful insights on the production ML ecosystem!"
            },
            {
                "title": "AirStreetCapital State of AI Report",
                "link": "https://www.stateof.ai/",
                "content": "The State of AI Report 2024 from AirStreet Capital is out! Really interesting insights from 2024, including highlights on the performance gap between proprietary models like GPT-4 and open-source alternatives has narrowed significantly, with advancements in planning, reasoning, and multimodal capabilities extending AI\u2019s applications into fields like mathematics, biology, and neuroscience. One interesting observation is that despite U.S. sanctions, Chinese labs continue to produce competitive AI models through alternative means. Similarly, the economic impact of global AI has surged, with public companies reaching a combined enterprise value of $9 trillion, although questions about long-term sustainability and viable business models remain. Check out the full insights on the report!"
            },
            {
                "title": "Real Time Data Infra at Uber",
                "link": "https://arxiv.org/pdf/2104.00087",
                "content": "Uber has built a robust real-time data infrastructure to process Petabyte-scale data per day, using open-source technologies like Apache Kafka, Flink and Apache Pinot - these support production machine learning applications that require processing massive data volumes with low latency. Uber enables scalable stream processing and low-latency analytics critical for ML workflows like real-time prediction monitoring by enhancing these tools through leveraging frameworks such as FlinkSQL for easier streaming job creation with SQL and adding upsert capabilities to Pinot for real-time data updates. This is quite an interesting deep dive from Uber into their challenges and lessons learned throughout their large-scale data journey."
            },
            {
                "title": "Microsoft\u2019s CPU Inference ML Lib",
                "link": "https://github.com/microsoft/BitNet",
                "content": "Microsoft has released an exciting project to bring GPU-native LLMs into CPUs with Bitnet.cpp; this is their official inference framework for 1-bit Large Language Models: This C++ library is inspired from Llama.cpp and provides optimized kernels for fast and energy-efficient inference on CPUs, with future support planned for NPUs and GPUs. This framework achieves significant speedups \u00a0of 6\u00d7+ and energy reductions up to 82.2% on both ARM and x86 architectures, which is quite exciting for even 100B-parameter models."
            },
            {
                "title": "Meta\u2019s Open AI Data & Models",
                "link": "https://ai.meta.com/blog/fair-news-segment-anything-2-1-meta-spirit-lm-layer-skip-salsa-lingua/",
                "content": "Meta\u2019s FAIR team has released several new AI research artifacts to continue supporting the advancement of science across the community: These open source releases include: SAM 2.1 dataset on image and video segmentation; Meta Spirit LM as multimodal language model integrating speech and text; Layer Skip to accelerate LLM performance; SALSA to validate security for post-quantum cryptography standards; Meta Lingua for large-scale language model training; Meta Open Materials 2024 to accelerate AI-assisted inorganic materials discovery, and more."
            }
        ]
    },
    {
        "issue": "306",
        "items": [
            {
                "title": "Top 3 Challenges in Prod ML",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "The Top 3 Challenges in Production Machine Learning include 1) ML Monitoring, 2) Data, and 3) Showcasing business value: The challenges highlighted in production machine learning seem to resonate quite a lot with what we see in practice; the top 3 challenges in are: 1) Monitoring - Establishing standardised and robust monitoring for ML systems; 2) Data - Access to relevant data for training (which is aligned data in production inference), and; 3) Impact - Showcasing business impact and business value on usecases. Further challenges highlighted include: 4) Inconsistency of training and experimentation environments; 5) Building production-grade ML pipelines; 6) Gaps in tooling and support for model productionisation, and 7) Governance and Domain Risks. These are really important insights from 2024 Survey on The State of Production ML - if you have a chance we would be grateful if you could spend a few minutes on the survey, as you\u2019ll contribute valuable information about the machine learning tools and platforms you use in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80"
            },
            {
                "title": "Google DeepMind Weather Forecast",
                "link": "https://www.youtube.com/watch?v=n4Rw3RlpyJw",
                "content": "Google DeepMind has released an exciting foundation model for weather forecasting - this is a hybrid approach that brings together traditional physics-simulations and deep learning to surpass the current best models for weather and climate forecasting: The Google team provides a great deep dive into how they implemented their new NeuralGCM model using JAX to overcome the limitations of pure physics or machine learning approaches. This approach is showcased as achieving higher accuracy than state-of-the-art models whilst being faster, more cost-effective, producing more detailed forecasts, and doing everything with a simplified codebase (vs 1m+ line FORTRAN codebase). This is actually published together with the full code available, as well as the pre-trained models, as well as a fully-fledged benchmarking suite - this is certainly an exciting time for this space."
            },
            {
                "title": "PlanetScale Embeddings SQL",
                "link": "https://planetscale.com/blog/announcing-planetscale-vectors-public-beta",
                "content": "Vector embeddings have been exploding in popularity, and similarly we have seen a similar growth on vector databases - this week we see an interesting new challenger with PlanetScale introducing native support for AI embedding vectors in its MySQL-compatible database; this is quite exciting as it comes as an integrated index that supports all relational database features, eliminating the need for a separate vector database. The vector search functionality is built upon Microsoft Research\u2019s SPANN and SPFresh algorithms, which in themselves deserve their own deep dive, as they have enabled integration into MySQL\u2019s default storage engine (InnoDB); this means that inserts, updates, and deletes of vector data are immediately reflected in the vector index as part of SQL transactions, ensuring ACID compliance. This is quite an interesting advancement, as we are able to see the foundational DB field and emerging technologies converge to ensure standardisation and best practice to simplify architecture and operations while leveraging familiar SQL features."
            },
            {
                "title": "Google Shopping 10m Embedding",
                "link": "https://github.com/marqo-ai/GCL",
                "content": "Vector Embedding Platform Marco has released a Google Shopping Dataset with 10m products for benchmarking of multi-modal ranking evaluation, together with a new approach to improve multi-modal retrieval and ranking. This is quite an interesting deep dive into their \u201cGeneralized Contrastive Learning\u201d framework for optimization of retrieval and ranking by encoding multiple data types (like text and images) and incorporating fine-grained relevance directly into embeddings. From the research they share, it seems this framework extends CLIP-style models to improve multi-modal retrieval and ranking whilst addressing limitations of existing approaches through unified representations of documents composed of multiple fields, enhancing intra-modal understanding, and optimizing embeddings for efficient storage in vector databases. It is great to see initiatives that bring together novel approaches together with benchmarking frameworks that encourage further breakthroughs."
            },
            {
                "title": "META Llama LLM Optimisation",
                "link": "https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/",
                "content": "Efficiency in LLMs is becoming growingly important; Meta has now released quantized versions of its Llama 3.2 1B and 3B models optimized for mobile devices which they suggest up to 4\u00d7 speedup + 56% reduction in model size + 41% less memory usage compared to the original models: This is quite an interesting approach using QLoRA + post-training quantization method which doesn\u2019t require the original training data. It is quite insightful to see that the race to larger accurate models is almost marching the race to smaller accurate models!"
            }
        ]
    },
    {
        "issue": "307",
        "items": [
            {
                "title": "Most Popular ML Training Tools",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "Almost 30% use a custom built in-house tool for ML model training, with Databricks being the 2nd most popular choice with 20%, closely followed by AWS SageMaker. Insightful results from our survey on the State of Prod ML in 2024; it seems that although the area of ML model training is one of the most consolidated areas in regards to tooling, there is still quite a significant percentage of organisations that do not use an off-the-shelf framework and build custom in-house tools for their ML Training. Not surprisingly it does seem like the main choices are the cloud providers, however with quite a large gap between Azure/Google vs AWS/Databricks. If you have a chance we would be grateful if you could spend a few minutes on the survey, as you\u2019ll contribute valuable information about the machine learning tools and platforms you use in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80"
            },
            {
                "title": "Billion Scale Time-Series Model",
                "link": "https://github.com/Time-MoE/Time-MoE?tab=readme-ov-file",
                "content": "This is an exciting time for time series machine learning, with a new Billion-parameter Mixture-of-Experts Forecasting model entering the arena released by Princeton, Squirrel AI and Griffith University, together with the largest OSS TS dataset: Following the steps of Google, Amazon, Nixtla and others, Time-MoE is the latest time series foundation model which brings new innovative approaches with a Mixture-of-Experts Transformer architecture aiming to handle universal zero-shot forecasting. They have been able to scale this model to 2.4 billion parameters by pre-training on \u201cTime-300B\u201d, the largest open-access time series dataset comprising over 300 billion data points from more than nine domains. It is an exciting time for research in this space, not only new models and architectures being released, but also huge datasets to support further benchmarking and research."
            },
            {
                "title": "Vector DBs as Wrong Abstraction",
                "link": "https://www.timescale.com/blog/vector-databases-are-the-wrong-abstraction/",
                "content": "TimescaleDB comes with a controversial take on Vector Databases - \u201cthey are the wrong abstraction\u201d: In production AI applications, managing vector embeddings tends to bring complexities due to vector databases treating embeddings as standalone data disconnected from their source - this is raised as an abstraction that should be addressed as it would otherwise lead to synchronization issues and stale data. TimescaleDB proposes treating embeddings as derived data similar to database indexes, which is interesting given recent extensions from DBs like planetscale to integrate embeddings natively into indexes, similarly through a \u201cnative vectorizer\u201d abstraction. In this case however they still leverage the OSS pgai Vectorizer for PostgreSQL which helps automating the synchronization of embeddings with their source data within the database, however this does provide an insight on some of the open challenges that are yet to be addressed, and perhaps also one of the reasons why we still see lack of standardisation on VectorDBs in the State of Prod ML 2024 Survey."
            },
            {
                "title": "Embeddings are Underrated",
                "link": "https://technicalwriting.dev/data/embeddings.html",
                "content": "Although many may claim that LLMs and GenAI are driving the current AI revolution, there is a strong reason to believe that one of the biggest breakthroughs and drivers are the innovations within embeddings, implemented beyond just text: Vector embeddings have grown to become a hugely powerful tool in ML, not only powering the GenAI / LLM products that have been blowing minds recently, but also powering things like product recommendations, similarity search and beyond. This is a great intuitive overview of embeddings with a few practical examples that can provide a high level conceptual understanding for individuals that may not have come across some of these internals - there are other interesting applications, such as how AirBNB used embeddings for similar listing recommendations all the way back in 2018."
            },
            {
                "title": "GPT-4o Data Poisoning",
                "link": "https://far.ai/post/2024-10-poisoning/",
                "content": "One of the most pressing challenges when deploying GenAI products is ensuring robust guardrails are in place - companies are investing heavily on increasing the safety of their products, but data poisoning and jailbreaking attacks keep advancing at a faster pace, and here is a great example: Even advanced and robust GenAI powered products like GPT-4o are suceptible to security vulnerabilities - this is a great example showcasing data poisoning and a potent new attack called \u201cjailbreak-tuning,\u201d where attackers inject harmful behaviors by fine-tuning models on poisoned datasets, even when advanced moderation systems are in place. This is a great deep dive into three threat models, including 1) malicious fine-tuning, 2) imperfect data curation, and 3) intentional data contamination, which really make it clear that that larger models become more susceptible to these attacks as they scale. This also makes it clear that it only continues to become more critical to ensure robust evaluation metrics, fine-tuning safeguards, and ongoing stress-testing to prevent exploitation of these vulnerabilities in production environments - this means that organisations also have to invest into their existing security / red-teaming capabilities to support this."
            }
        ]
    },
    {
        "issue": "308",
        "items": [
            {
                "title": "Tech University Munich AI Talk",
                "link": "https://www.ieai.sot.tum.de/event/speaker-series-on-the-state-of-responsible-ai/",
                "content": "What are the most pressing issues on ML Governance? What about the most important concepts of Responsible AI? Join us next week to find out, as we\u2019ll be joining the Technical University Munich\u2019s Institute for Ethics in AI to dive into the topic of \u201cResponsible AI in 2024\u201d: In this session we will explore the current landscape of responsible AI, focusing on the industrial, organizational, and technical aspects crucial for successful AI deployment, including governance challenges, accountability, security concerns, infrastructure complexities, risk mitigation, and building scalable, reliable AI systems that drive innovation while adhering to responsible practices."
            },
            {
                "title": "Most Popular ML Training Tools",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "Which do you think are the most popular frameworks in production ML? Tensorflow is a tool of the past with only 8%! Sklearn reaches the top with 35% closely followed by Pytorch with 32% - other contenders are XGBoost with 7% and Catboost with 6% \ud83d\udcbb We are uncovering great insights as part of our survey on The State of Production ML in 2024; please contribute to this valuable investigation on machine learning tools and platforms used in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80"
            },
            {
                "title": "McKinsey on AI Power Capacity",
                "link": "https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/ai-power-expanding-data-center-capacity-to-meet-growing-demand",
                "content": "McKinsey dives into the explosive growth of generative AI has been leading to a significant capacity shortfall due to the growing demand of AI data centers requiring global capacity to triple by 2030: An interesting analysis diving into how this surge has been driven primarily by hyperscalers hosting advanced AI workloads, and which limit computational resources for production machine learning practitioners, which requires the need to adapt strategies for efficient resource utilization."
            },
            {
                "title": "Superlinked on Vector Indexes",
                "link": "https://superlinked.com/vectorhub/articles/vector-indexes",
                "content": "Vector indexing techniques are making strides on bridging the gap between traditional RDBMS and Vector Databases: It is interesting to see how we\u2019re revisiting the foundations of databases with recent innovations on efficiency of similarity search in high-dimensional data for production machine learning applications which is becoming critical for Retrieval Augmented Generation. Superlinked dives into various approaches for indexing methods to address foundational challenges, such as Inverted File Indexing where clusters data points using K-means clustering. It is quite refreshing to see simple coding examples illustrating complex topics, particularly in this case showcasing how similar indexing techniques can help optimize search performance."
            },
            {
                "title": "OpenAI Doubling Down Search",
                "link": "https://openai.com/index/introducing-chatgpt-search/",
                "content": "Recently we have seen OpenAI exploring other avenues for innovation, most recently taking the search Giants by positioning ChatGPT powered products to tackle web search requirements: Quite interesting to see innovations in the space of web search, particularly in context of fine-tuning LLMs (aka GPT-4o) for conversational answers enriched with up-to-date information and direct links to relevant web sources. Only time will tell whether this avenue will be able to properly challenge the search giants in their own game, or whether this will fall under an interesting but limited set of features for information retrieval."
            }
        ]
    },
    {
        "issue": "309",
        "items": [
            {
                "title": "MLOps Organisational Setups",
                "link": "https://bit.ly/state-of-ml-2024",
                "content": "Central functions support machine learning ambitions across organisations; only ~30% of organisations have a central Data / ML platform, and less than 10% have central AI Risk Governance: Establishing central functions to support teams is a growing trend in machine learning maturity across organisations, an we see some interesting trends, with less than 10% or organisations with a central \u201cAI Inventory\u201d, or an \u201cAI Risk & Governance Function\u201d; less than 15% with a central dev productivity function, and; slightly over 30% having a central Data Platform or central ML Platform \ud83d\udcbb We are uncovering great insights as part of our survey on The State of Production ML in 2024; please contribute to this valuable investigation on machine learning tools and platforms used in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80"
            },
            {
                "title": "National Regulation on AI",
                "link": "https://github.com/EthicalML/awesome-artificial-intelligence-regulation?tab=readme-ov-file#overview",
                "content": "We have overhauled our repository of AI Regulation, Principles & Guidelines, which now contains a listing of major developments of national AI strategies, regulations and guidelines: The latest iteration of this github list provides an overview of global AI regulation, highlighting key resources from economic areas such as like the European Union\u2019s AI Act, the United Statesxecutive Order on AI, China\u2019s Interim Measures for Generative AI Services, and the UK\u2019s pro-innovation regulatory approach - between many others. As always it\u2019s an open source initiative so if there are any developments that are not included please do feel free to contribute with a PR!"
            },
            {
                "title": "Netflix\u2019s Time Series Infrastructure",
                "link": "https://netflixtechblog.com/introducing-netflix-timeseries-data-abstraction-layer-31552f6326f8",
                "content": "The scale that Netflix has to deal with is massive, and was reflected in last week\u2019s global streaming issues - they share one of their approaches to scaling, including their TimeSeries Data Abstraction Layer to efficiently store and query massive volumes of immutable temporal event data: This is quite an in-depth walkthrough into Netflix\u2019s architecture to handle up to 10 million writes per second and petabytes of data with low millisecond latency by using temporal partitioning and event bucketing strategies as part of their TimeSeries Abstraction Layer. They have been able to build flexible storage backends like Cassandra and Elasticsearch and tunable configurations for scalability and cost efficiency which is critical for internal use-cases such as production machine learning at massive scale."
            },
            {
                "title": "GenAI Increasing Tech Debt",
                "link": "https://www.gauge.sh/blog/ai-makes-tech-debt-more-expensive",
                "content": "Contrary to the belief that AI improves dev quality, we are starting to see growing resources showcasing how it actually amplifies tech debt costs: This is an insightful resource that shows how GenAI can widen the productivity gap between \u201clow tech-debt\u201d and \u201chigh tech-debt\u201d codebases. Generative AI tools tend to be useful with simple, modular, and ubiquituously developed systems; however, they struggle with complex or legacy codebases that contain tech debt, often making it hard to leverage AI effectively."
            },
            {
                "title": "What is an AI Engineer?",
                "link": "https://superlinked.com/vectorhub/articles/vector-indexes",
                "content": "The rise of generative AI and Large Language Models has transformed the role of the AI Engineer into a high-demand position that blends deep technical expertise with strategic business insight; but what does it actually consist of? This is a great resource from Gradient Flow that dives into providing some definition on the role that companies are seeking as AI engineers; this often consist technical practitioners who can develop and fine-tune LLMs for domain-specific applications, integrate them into scalable production systems using skills in Python, AI frameworks like PyTorch and TensorFlow. However this also extends to cloud platforms and MLOps practices - from a more personal perspective this seems to me like the role itself is still nascent and this would have to be broken down into sub-roles, such as data engineering, ML engineering, MLOps engineering and domain expertise, instead of fitting all into a single role."
            }
        ]
    },
    {
        "issue": "310",
        "items": [
            {
                "title": "MLOps Prod Best Practice",
                "link": "https://ethical.institute/state-of-ml-2024",
                "content": "In the MLOps ecosystem only about 30% leverage CI/CD or Dev/Staging/Prod environments; only 16% leverage A/B tests, and just about 10% leverage canary deployments. It is important to consider that the Machine Learning Development Lifecycle is still in the early stages of maturity in industry, particularly in production where best practices in software operations at scale are only slowly being adopted into the ML ecosystem. We are uncovering important insights as part of our survey on The State of Production ML in 2024; please contribute to this valuable investigation on machine learning tools and platforms used in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80"
            },
            {
                "title": "GenAI Simulating 1k Real People",
                "link": "https://arxiv.org/abs/2411.10109",
                "content": "Stanford leveraging GenAI to replicate 1,052 real individuals in a simulation of agents which aims to provide new mechanisms for testing large-scale policymaking and social science. This is quite an interesting area of GenAI exploring how agents can replicate the attitudes and behaviors of the\nindividuals that they represent, and simulate their interactions in specific test scenarios. These agents were evaluated against their real-world counterparts with professional surveys, performing with 85% accuracy compared to original human responses. This of course opens up important ethical considerations as world-simulations can be created with game-like NPCs replicating real-people behaviour and their interactions - certainly a space to keep a close eye on."
            },
            {
                "title": "Salesforce\u2019s Time Series ML",
                "link": "https://arxiv.org/pdf/2410.10469",
                "content": "Salesforce research enters the Foundation Model race with a time-series forecasting large model, which comes with interesting innovations in model size and optimization: Salesforce introduces Moirai-MoE, a state-of-the-art time series foundation model for universal forecasting which outperforms some of the previously released foundation models. It\u2019s great to see development in the forecasting space particularly after the releases of other foundation models from the likes of Google, Amazon, Nixtla, etc - looking forward to seeing the benchmarks as this field continues to evolve."
            },
            {
                "title": "The Data Engineer Handbook",
                "link": "https://github.com/DataExpert-io/data-engineer-handbook",
                "content": "A great resource for beginner and experienced data engineers - the Data Engineering Handbook: This is a great compilation of resources in the data engineering space with a clear roadmap for entering the field + a YouTube bootcamp - certainly worth checking out the wealth of blogs, whitepapers, podcasts, newsletters, glossaries, design patterns, courses, and certifications."
            },
            {
                "title": "Anthropic\u2019s Responsible AI",
                "link": "https://www.anthropic.com/voluntary-commitments",
                "content": "Anthropic has detailed its approach to responsible AI through risk assessment and mitigation practices across their end to end foundation model lifecycle. Anthropic presents their Responsible Scaling Policy, which outlines: 1) safeguards with model capabilities; 2) conducting rigorous risk assessments; 3) ensuring robust security and privacy measures; 4) contributing to global technical standards; 5) fostering societal impact by partnering with organizations; and 6) addressing trust and safety concerns. It is quite interesting to see organisations publishing their committments to responsible AI; it will now be more interesting to follow how these are implemented in practice."
            }
        ]
    },
    {
        "issue": "311",
        "items": [
            {
                "title": "Number of ML Models in Prod",
                "link": "https://ethical.institute/state-of-ml-2024",
                "content": "Almost 70% of teams reported to have less than 100 models in production; however most of them are looking to double the number of models in production within the next 12 months. This provides an interesting snapshot of the production ML ecosystem, as although many teams are operating at smaller relative sclaes, the rate of growth is only increasing; we can see this with 9-15% of teams operating already over 1000 models in production. We are uncovering important insights as part of our survey on The State of Production ML in 2024; please contribute to this valuable investigation on machine learning tools and platforms used in your production ML development. Your input will help create a comprehensive overview of common practices, tooling preferences, and challenges faced when deploying models to production, ultimately benefiting the entire ML community \ud83d\ude80"
            },
            {
                "title": "Building a GenAI Platform",
                "link": "https://huyenchip.com/2024/07/25/genai-platform.html",
                "content": "Chip Huyen has put together a fantastic resource on production architectural patterns and best practices for building GenAI platforms: This is a great guide for production machine learning practitioners on building a robust generative AI platform, starting from a basic model deployment and progressively adding essential components such as enhanced context with retrieval-augmented generation (RAG), safety guardrails to prevent data leakage and manage outputs, model routing and gateways for scalability and control, caching strategies for latency and cost optimization, and complex logic with write actions for advanced capabilities. This is a very much needed resource, as it emphasises the importance of observability and orchestration to monitor, debug, and manage complex AI pipelines effectively."
            },
            {
                "title": "Open Source Agentic Workflows",
                "link": "https://github.com/EthicalML/awesome-production-machine-learning/?tab=readme-ov-file#agentic-workflow",
                "content": "Our Production ML Github List has reached over 17,000+ stars \ud83d\ude80 this provides a snapshot of open source tools in the ecosystem and we just added \u201cAgentic Frameworks\u201d to the list! We have put together this list to help machine learning practitioners to deploy, monitor, version, scale, and secure their production ML systems. The new \u201cAgentic Workflow\u201d section captures the tools available for building AI agents and multi-agent systems, including libraries like AgentScope, AutoGen, Chidori, LangGraph, between many others. If you know of any open source framework that is not listed please do give us a heads up or feel free to open up a PR!"
            },
            {
                "title": "Over 1000 Python Videos",
                "link": "https://pyvideo.org/tag/machine-learning/",
                "content": "This is an absolutely fantastic to browse over 1000 python videos; more importantly for machine learning practitioners you can find a curated collection of machine learning talks from various conferences like PyCon, PyData, and EuroPython: This is quite a great resource for people that are looking to develop continuously, particularly in the ML space, there are a broad range of talks which cover topics such as scalable machine learning pipelines, MLOps best practices, model deployment strategies, deep learning advancements, and practical applications in industries like finance, healthcare, and technology."
            },
            {
                "title": "Advent of Code 2024",
                "link": "https://adventofcode.com/2024/about",
                "content": "The time has arrived to brush up our skills and jump into the advent of code. There will be one programming challenge released every day to take your skills to the test and have some fun, this is a great time to also pick up a new programming language if you\u2019ve been wanting to explore one for a while. It\u2019s also interesting that different to previous years, this time there is a big disclaimer discouraging the use of LLMs for submissions due to the increasing use of these; it is interesting to see how these become more pervasive, and perhaps also how some of these type of challenges will also have to adapt through time to make it such that they can still be providing a challenge despite AI-supported development."
            }
        ]
    },
    {
        "issue": "312",
        "items": [
            {
                "title": "The State of Responsible AI",
                "link": "https://www.ieai.sot.tum.de/the-state-of-responsible-ai/",
                "content": "What are the most pressing issues on ML Governance? What about the most important concepts of Responsible AI? Our keynote on Responsible AI is now live at the Technical University Munich\u2019s Institute for Ethics in AI page \ud83d\ude80 In this session we navigated the current landscape of responsible AI, focusing on the industrial, organizational, and technical aspects crucial for successful AI deployment, including governance challenges, accountability, security concerns, infrastructure complexities, risk mitigation, and building scalable, reliable AI systems that drive innovation while adhering to responsible practices. Check out the full video and slides!"
            },
            {
                "title": "Production LLM Usecase List",
                "link": "https://www.zenml.io/blog/demystifying-llmops-a-practical-database-of-real-world-generative-ai-implementations",
                "content": "ZenML dropped a massive new database of LLMOps usecases with 300+ curated generative AI and LLM implementations in the real world: It is important for practitioners to go beyond the hype when it comes to LLMs, and concrete / practical examples in industry can provide an actionable guidance \u00a0- this includes architectural choices, tooling stacks, evaluation methodologies, and operational best practices. This provides quite an interesting perspective on choices for handling RAG, monitoring, frameworks choice (e.g.\u00a0LangChain), etc."
            },
            {
                "title": "Google\u2019s 5-Day GenAI Course",
                "link": "https://www.kaggle.com/learn-guide/5-day-genai#GenAI",
                "content": "Google has released a self-paced 5-day intensive course on GenAI foundations with a structured approach to modern generative AI workflows: This is quite a comprehensive practical resource covering foundational models and prompt engineering, embeddings and vector databases, generative agents, domain-specific LLMs, and finally MLOps for generative AI. This is a good opportunity for practitioners to gain hands-on experience through whitepapers, code labs, and expert-led discussions on Kaggle and YouTube."
            },
            {
                "title": "DeepMind World Foundation AI",
                "link": "https://deepmind.google/discover/blog/genie-2-a-large-scale-foundation-world-model/",
                "content": "\u00ad \u00ad"
            },
            {
                "title": "MSFT Quantifying Bad Days",
                "link": "https://www.arxiv.org/abs/2410.18379",
                "content": "\u00ad \u00ad"
            }
        ]
    },
    {
        "issue": "313",
        "items": [
            {
                "title": "Ilya Sutskever NeurIPS Keynote",
                "link": "https://www.youtube.com/watch?v=1yvBqasHLZs",
                "content": "Ilya Sutskever\u2019s NeurIPS keynote is up - an interesting reflection on the decade since the seminal \u201cSequence to Sequence\u201d work that helped ignite the modern era of large-scale neural NLP: This is a comprehensive session where Ilya recounts how the original Seq2Seq approach established a template for present-day AI: big models plus big data equals breakthroughs. Over time, this scaling principle was validated far beyond translation, culminating in today\u2019s GPT-style models. However, it seems we are exhausting the \u201cfossil fuel\u201d of internet-scale data, and future progress will hinge on new techniques - eg. agents interacting with their environments, generating synthetic data, and improved reasoning capabilities."
            },
            {
                "title": "Google Releasing Gemini 2.0",
                "link": "https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/",
                "content": "Google drops the mic last week releasing Gemini 2.0 with a bunch of new features on their AI studio, doubling down towards \u201cagentic\u201d AI with multimodal input/output: As expected Google is building on the initial Gemini 1.x foundation, extending long-context and multimodality capabilities, improves latency and performance, and introducing features like native image and audio generation. Something that comes across as novel is the integration into Google\u2019s products and ecosystem, however the race continues to move at breakneck speed so we can only expect similar pace from the tech ecosystem."
            },
            {
                "title": "Tiktok\u2019s Recommendation System",
                "link": "https://arxiv.org/abs/2209.07663",
                "content": "Tiktok has published the architecture behind their recommendation system called \u201cMonolith\u201d, a real-time massive-scale recommendation system designed specifically to address production challenges such as large-scale, sparse, and dynamic feature spaces: The paper provides interesting insights such as collisionless embedding table based on Cuckoo hashing, which enables dynamic inclusion and eviction of new model features. Monolith tightly integrates training and serving which they highlight as one of the reasons they can allow for fast online updates so that the model can adapt to changing user behavior within minutes."
            },
            {
                "title": "META FAIR Major Releases",
                "link": "https://ai.meta.com/blog/meta-fair-updates-agents-robustness-safety-architecture/",
                "content": "Meta Fundamental AI Research (FAIR) has quietly shared a huge release last week with new open-source AI systems across CLIP, Motivo and Seal: Meta released Motivo, a foundation model that enables embodied humanoid agents to efficiently solve complex tasks without additional training. Meta also released Video Seal, a robust watermarking solution for videos that remains intact through common transformations. They\u2019ve also introduced Flow Matching, a hierarchical byte-level tokenizer-free approach (Dynamic Byte Latent Transformer) for generative modeling. Additionally, they released a new version of Meta CLIP, which improves on previous versions for vision-language alignment. Quite surprising and exciting to see so much movement from META\u2019s research arm furthering the research ecosystem across quite a few of these interesting areas."
            },
            {
                "title": "OpenAI Releases Text-to-Video",
                "link": "https://openai.com/index/sora-is-here/",
                "content": "OpenAI has finally released their Text-to-Video SORA model as a public offering! As per the usual naming convention, this comes with Sora Turbo, focusing on fast generation of higher fidelity videos across multiple aspect ratios, and up to 20-second. These services continue to surprise us with the quality of the video generation, certainly still with quite some limitations (such as many posts showing the limits when rendering scenes from gymnastics, etc). The model is still imperfect, struggling with complex sequences and realistic physics - however it is great to see finally OpenAI is releasing to encourage community input and iteration norm-setting, and responsible use."
            }
        ]
    },
    {
        "issue": "314",
        "items": [
            {
                "title": "Raschka\u2019s Top LLM Papers in 2024",
                "link": "https://magazine.sebastianraschka.com/p/llm-research-papers-the-2024-list",
                "content": "Sebastian Raschka\u2019s \u201cbest of 2024\u201d on LLM research papers has some great resources: There\u2019s quite a broad selection of research themes, many quite interesting emerging areas such as parameter-efficient fine-tuning (e.g., LoRA, MoE), extending context windows, retrieval-augmented generation (RAG), multi-modal expansions that integrate visual or structured data, refined alignment strategies (like DPO and RLHF) to steer model outputs, knowledge editing for domain-specific modifications, and advanced compression (quantization, pruning). There\u2019s quite a lot of variety in this list, with also quite a lot of papers that delve into techniques for improved inference efficiency, dynamic architectures (state space models, mixture-of-experts), and novel prompting or training paradigms. If anyone is looking for a Christmas read, this is a great resource to catch up on 2024 LLM research over the winter holidays!"
            },
            {
                "title": "DeepMind on Agent Cooperation",
                "link": "https://arxiv.org/abs/2412.10270",
                "content": "DeepMind published an interesting paper exploring how LLM agents might learn to cooperate over multiple \u201cgenerations\u201d through an indirect reciprocity scenario: They tested three different models (Claude 3.5 Sonnet, Gemini 1.5 Flash, and GPT\u20114o), some interesting insights such as showing that only Claude consistently evolved higher levels of cooperation across generations. Surprisingly, GPT\u20114o tended to revert to \u201cmutual defection\u201d, and Gemini 1.5 showed only \u201cweak gains\u201d. It seems like there is a growing number of similar studies around LLMs for simulations of specific environments, which provide interesting sandboxes to test human-like interactions between actors at scale."
            },
            {
                "title": "Google\u2019s Globally Distributed DB",
                "link": "https://research.google/pubs/spanner-googles-globally-distributed-database-2/",
                "content": "An excellent paper for MLOps and Machine Learning Engineering practitioners is the classic Google\u2019s Spanner paper: Google proposed an interesting globally distributed database architecture which offers strong external consistency at the cost of slight latency increase. The paper dives into how it integrates a two-phase commit with Paxos replication to automatically shard data and ensure high availability with lock-free snapshot reads. This commit wait is what introduces the design trade-off of slightly increased write latency (e.g., \u201ccommit wait\u201d), but it is also what delivers synchronous replication and globally consistent reads, which is particularly useful for example in large-scale machine learning and MLOps systems requiring reproducible data snapshots, as well as the ability to evolve data schemas and indexes without downtime."
            },
            {
                "title": "Gentle Intro to Graph Neural Networks",
                "link": "https://distill.pub/2021/gnn-intro/",
                "content": "This is one of the best visual/intuitive introductions to Graph Neural Networks out there! As a reminder on GNNs, these graph neural networks are able to generalize deep learning by handling entities as nodes and their relationships as edges. This enables \u201cpassing messages\u201d between connected nodes to learn context-aware representations that can power node-, edge-, or graph-level predictions. There are some nuances when working with GNNs vs traditional NNs, such as key design choices on how to represent nodes/edges, how to aggregate local or global information (e.g., via sum, mean, or max pooling), and how many layers to stack for broader context. GNNs are certainly worth learning, as a lot of real-world applications we see these relationships, and we have shown success in varied domains such as social networks, molecule property prediction, recommendation systems, etc."
            },
            {
                "title": "An Evolved Transformer Memory",
                "link": "https://sakana.ai/namm/",
                "content": "OpenAI O1\u2019s impressive performance at high compute ($3k est. per task) highlights that performance is the next tech race - Japanese startup Sakana AI brings a new approach to reduce memory by 75% with improved inference: Sakana AI releases this new \u201cuniversal transformer memory\u201d technique which uses small neural \u201cattention memory\u201d modules (NAMMs) to dynamically decide which tokens to keep or discard within an LLM\u2019s context window. This sounds like quite a simple technique, but it promises to potentially cut memory usage by up to 75%. This is ceratinly going to be an interesting space to watch throughout 2025 and beyond!"
            }
        ]
    }
]
